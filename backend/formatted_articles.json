[
  {
    "id": "0d97500e47bc89b194411a6f82719984",
    "title": "A Framework for the Assurance of AI-Enabled Systems",
    "slug": "a-framework-for-the-assurance-of-ai-enabled-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Ariel S. Kapusta",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The United States Department of Defense (DOD) looks to accelerate the development and deployment of AI capabilities across a wide spectrum of defense applications to maintain strategic advantages. However, many common features of AI algorithms that make them powerful, such as capacity for learning, large-scale data ingestion, and problem-solving, raise new technical, security, and ethical challenges. These challenges may hinder adoption due to uncertainty in development, testing, assurance, processes, and requirements. Trustworthiness through assurance is essential to achieve the expected value from AI.\nThis paper proposes a claims-based framework for risk management and assurance of AI systems that addresses the competing needs for faster deployment, successful adoption, and rigorous evaluation. This framework supports programs across all acquisition pathways provide grounds for sufficient confidence that an AI-enabled system (AIES) meets its intended mission goals without introducing unacceptable risks throughout its lifecycle. The paper's contributions are a framework process for AI assurance, a set of relevant definitions to enable constructive conversations on the topic of AI assurance, and a discussion of important considerations in AI assurance. The framework aims to provide the DOD a robust yet efficient mechanism for swiftly fielding effective AI capabilities without overlooking critical risks or undermining stakeholder trust.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16937",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.890651Z"
  },
  {
    "id": "b8fde1bd702210a1da00906199519b71",
    "title": "Rational Inference in Formal Concept Analysis",
    "slug": "rational-inference-in-formal-concept-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Lucas Carr",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Defeasible conditionals are a form of non-monotonic inference which enable the expression of statements like \"if $\\phi$ then normally $\\psi$\". The KLM framework defines a semantics for the propositional case of defeasible conditionals by construction of a preference ordering over possible worlds. The pattern of reasoning induced by these semantics is characterised by consequence relations satisfying certain desirable properties of non-monotonic reasoning. In FCA, implications are used to describe dependencies between attributes. However, these implications are unsuitable to reason with erroneous data or data prone to exceptions. Until recently, the topic of non-monotonic inference in FCA has remained largely uninvestigated. In this paper, we provide a construction of the KLM framework for defeasible reasoning in FCA and show that this construction remains faithful to the principle of non-monotonic inference described in the original framework. We present an additional argument that, while remaining consistent with the original ideas around non-monotonic reasoning, the defeasible reasoning we propose in FCA offers a more contextual view on inference, providing the ability for more relevant conclusions to be drawn when compared to the propositional case.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16938",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.890966Z"
  },
  {
    "id": "e1af0bd207880a72f9491218827e8d1a",
    "title": "A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions",
    "slug": "a-desideratum-for-conversational-agents:-capabilities,-challenges,-and-future-directions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Emre Can Acikgoz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advances in Large Language Models (LLMs) have propelled conversational AI from traditional dialogue systems into sophisticated agents capable of autonomous actions, contextual awareness, and multi-turn interactions with users. Yet, fundamental questions about their capabilities, limitations, and paths forward remain open. This survey paper presents a desideratum for next-generation Conversational Agents - what has been achieved, what challenges persist, and what must be done for more scalable systems that approach human-level intelligence. To that end, we systematically analyze LLM-driven Conversational Agents by organizing their capabilities into three primary dimensions: (i) Reasoning - logical, systematic thinking inspired by human intelligence for decision making, (ii) Monitor - encompassing self-awareness and user interaction monitoring, and (iii) Control - focusing on tool utilization and policy following. Building upon this, we introduce a novel taxonomy by classifying recent work on Conversational Agents around our proposed desideratum. We identify critical research gaps and outline key directions, including realistic evaluations, long-term multi-turn reasoning skills, self-evolution capabilities, collaborative and multi-agent task completion, personalization, and proactivity. This work aims to provide a structured foundation, highlight existing limitations, and offer insights into potential future research directions for Conversational Agents, ultimately advancing progress toward Artificial General Intelligence (AGI). We maintain a curated repository of papers at: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16939",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.891289Z"
  },
  {
    "id": "e52c6575d55fa526ffab0b0235110f69",
    "title": "A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs",
    "slug": "a-systematic-approach-to-design-real-world-human-in-the-loop-deep-reinforcement-learning:-salient-features,-challenges-and-trade-offs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Jalal Arabneydi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "With the growing popularity of deep reinforcement learning (DRL), human-in-the-loop (HITL) approach has the potential to revolutionize the way we approach decision-making problems and create new opportunities for human-AI collaboration. In this article, we introduce a novel multi-layered hierarchical HITL DRL algorithm that comprises three types of learning: self learning, imitation learning and transfer learning. In addition, we consider three forms of human inputs: reward, action and demonstration. Furthermore, we discuss main challenges, trade-offs and advantages of HITL in solving complex problems and how human information can be integrated in the AI solution systematically. To verify our technical results, we present a real-world unmanned aerial vehicles (UAV) problem wherein a number of enemy drones attack a restricted area. The objective is to design a scalable HITL DRL algorithm for ally drones to neutralize the enemy drones before they reach the area. To this end, we first implement our solution using an award-winning open-source HITL software called Cogment. We then demonstrate several interesting results such as (a) HITL leads to faster training and higher performance, (b) advice acts as a guiding direction for gradient methods and lowers variance, and (c) the amount of advice should neither be too large nor too small to avoid over-training and under-training. Finally, we illustrate the role of human-AI cooperation in solving two real-world complex scenarios, i.e., overloaded and decoy attacks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17006",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.891577Z"
  },
  {
    "id": "18faca217e2011e26bc95c2c4c24662c",
    "title": "Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification",
    "slug": "neural-theorem-proving:-generating-and-structuring-proofs-for-formal-verification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Balaji Rao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Formally verifying properties of software code has been a highly desirable task, especially with the emergence of LLM-generated code. In the same vein, they provide an interesting avenue for the exploration of formal verification and mechanistic interpretability. Since the introduction of code-specific models, despite their successes in generating code in Lean4 and Isabelle, the task of generalized theorem proving still remains far from being fully solved and will be a benchmark for reasoning capability in LLMs. In this work, we introduce a framework that generates whole proofs in a formal language to be used within systems that utilize the power of built-in tactics and off-the-shelf automated theorem provers. Our framework includes 3 components: generating natural language statements of the code to be verified, an LLM that generates formal proofs for the given statement, and a module employing heuristics for building the final proof. To train the LLM, we employ a 2-stage fine-tuning process, where we first use SFT-based training to enable the model to generate syntactically correct Isabelle code and then RL-based training that encourages the model to generate proofs verified by a theorem prover. We validate our framework using the miniF2F-test benchmark and the Isabelle proof assistant and design a use case to verify the correctness of the AWS S3 bucket access policy code. We also curate a dataset based on the FVEL\\textsubscript{\\textnormal{ER}} dataset for future training tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17017",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.891808Z"
  },
  {
    "id": "7904accc7eba1e9af7596d6e27c833c8",
    "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments",
    "slug": "leveraging-llms-as-meta-judges:-a-multi-agent-framework-for-evaluating-llm-judgments",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Yuran Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) are being widely applied across various fields, but as tasks become more complex, evaluating their responses is increasingly challenging. Compared to human evaluators, the use of LLMs to support performance evaluation offers a more efficient alternative. However, most studies focus mainly on aligning LLMs' judgments with human preferences, overlooking the existence of biases and mistakes in human judgment. Furthermore, how to select suitable LLM judgments given multiple potential LLM responses remains underexplored. To address these two aforementioned issues, we propose a three-stage meta-judge selection pipeline: 1) developing a comprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM agents to score judgments, and 3) applying a threshold to filter out low-scoring judgments. Compared to methods using a single LLM as both judge and meta-judge, our pipeline introduces multi-agent collaboration and a more comprehensive rubric. Experimental results on the JudgeBench dataset show about 15.55\\% improvement compared to raw judgments and about 8.37\\% improvement over the single-agent baseline. Our work demonstrates the potential of LLMs as meta-judges and lays the foundation for future research on constructing preference datasets for LLM-as-a-judge reinforcement learning.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17087",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.892136Z"
  },
  {
    "id": "10536ca35011acc43f303910cb696ecc",
    "title": "AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models",
    "slug": "authentication:-identifying-rare-failure-modes-in-autonomous-vehicle-perception-systems-using-adversarially-guided-diffusion-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Mohammad Zarei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autonomous Vehicles (AVs) rely on artificial intelligence (AI) to accurately detect objects and interpret their surroundings. However, even when trained using millions of miles of real-world data, AVs are often unable to detect rare failure modes (RFMs). The problem of RFMs is commonly referred to as the \"long-tail challenge\", due to the distribution of data including many instances that are very rarely seen. In this paper, we present a novel approach that utilizes advanced generative and explainable AI techniques to aid in understanding RFMs. Our methods can be used to enhance the robustness and reliability of AVs when combined with both downstream model training and testing. We extract segmentation masks for objects of interest (e.g., cars) and invert them to create environmental masks. These masks, combined with carefully crafted text prompts, are fed into a custom diffusion model. We leverage the Stable Diffusion inpainting model guided by adversarial noise optimization to generate images containing diverse environments designed to evade object detection models and expose vulnerabilities in AI systems. Finally, we produce natural language descriptions of the generated RFMs that can guide developers and policymakers to improve the safety and reliability of AV systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17179",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.892376Z"
  },
  {
    "id": "d99fcbef1af3944c25a4ae62bf0880a7",
    "title": "Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning",
    "slug": "cracking-the-code-of-action:-a-generative-approach-to-affordances-for-reinforcement-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Lynn Cherif",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Agents that can autonomously navigate the web through a graphical user interface (GUI) using a unified action space (e.g., mouse and keyboard actions) can require very large amounts of domain-specific expert demonstrations to achieve good performance. Low sample efficiency is often exacerbated in sparse-reward and large-action-space environments, such as a web GUI, where only a few actions are relevant in any given situation. In this work, we consider the low-data regime, with limited or no access to expert behavior. To enable sample-efficient learning, we explore the effect of constraining the action space through $\\textit{intent-based affordances}$ -- i.e., considering in any situation only the subset of actions that achieve a desired outcome. We propose $\\textbf{Code as Generative Affordances}$ $(\\textbf{$\\texttt{CoGA}$})$, a method that leverages pre-trained vision-language models (VLMs) to generate code that determines affordable actions through implicit intent-completion functions and using a fully-automated program generation and verification pipeline. These programs are then used in-the-loop of a reinforcement learning agent to return a set of affordances given a pixel observation. By greatly reducing the number of actions that an agent must consider, we demonstrate on a wide range of tasks in the MiniWob++ benchmark that: $\\textbf{1)}$ $\\texttt{CoGA}$ is orders of magnitude more sample efficient than its RL agent, $\\textbf{2)}$ $\\texttt{CoGA}$'s programs can generalize within a family of tasks, and $\\textbf{3)}$ $\\texttt{CoGA}$ performs better or on par compared with behavior cloning when a small number of expert demonstrations is available.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17282",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.892610Z"
  },
  {
    "id": "a8c6e740bdb41a82dd7bc2bc1933c228",
    "title": "AI-Enhanced Business Process Automation: A Case Study in the Insurance Domain Using Object-Centric Process Mining",
    "slug": "ai-enhanced-business-process-automation:-a-case-study-in-the-insurance-domain-using-object-centric-process-mining",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Shahrzad Khayatbashi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advancements in Artificial Intelligence (AI), particularly Large Language Models (LLMs), have enhanced organizations' ability to reengineer business processes by automating knowledge-intensive tasks. This automation drives digital transformation, often through gradual transitions that improve process efficiency and effectiveness. To fully assess the impact of such automation, a data-driven analysis approach is needed - one that examines how traditional and AI-enhanced process variants coexist during this transition. Object-Centric Process Mining (OCPM) has emerged as a valuable method that enables such analysis, yet real-world case studies are still needed to demonstrate its applicability. This paper presents a case study from the insurance sector, where an LLM was deployed in production to automate the identification of claim parts, a task previously performed manually and identified as a bottleneck for scalability. To evaluate this transformation, we apply OCPM to assess the impact of AI-driven automation on process scalability. Our findings indicate that while LLMs significantly enhance operational capacity, they also introduce new process dynamics that require further refinement. This study also demonstrates the practical application of OCPM in a real-world setting, highlighting its advantages and limitations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17295",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.893019Z"
  },
  {
    "id": "2018193a37b5125a1227214a27c26d18",
    "title": "Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning",
    "slug": "comprehend,-divide,-and-conquer:-feature-subspace-exploration-via-multi-agent-hierarchical-reinforcement-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Weiliang Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Feature selection aims to preprocess the target dataset, find an optimal and most streamlined feature subset, and enhance the downstream machine learning task. Among filter, wrapper, and embedded-based approaches, the reinforcement learning (RL)-based subspace exploration strategy provides a novel objective optimization-directed perspective and promising performance. Nevertheless, even with improved performance, current reinforcement learning approaches face challenges similar to conventional methods when dealing with complex datasets. These challenges stem from the inefficient paradigm of using one agent per feature and the inherent complexities present in the datasets. This observation motivates us to investigate and address the above issue and propose a novel approach, namely HRLFS. Our methodology initially employs a Large Language Model (LLM)-based hybrid state extractor to capture each feature's mathematical and semantic characteristics. Based on this information, features are clustered, facilitating the construction of hierarchical agents for each cluster and sub-cluster. Extensive experiments demonstrate the efficiency, scalability, and robustness of our approach. Compared to contemporary or the one-feature-one-agent RL-based approaches, HRLFS improves the downstream ML performance with iterative feature subspace exploration while accelerating total run time by reducing the number of agents involved.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17356",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.893541Z"
  },
  {
    "id": "fd574dc5b58a4e8c603eaad7b000659f",
    "title": "Assessing the Capability of Large Language Models for Domain-Specific Ontology Generation",
    "slug": "assessing-the-capability-of-large-language-models-for-domain-specific-ontology-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Anna Sofia Lippolis",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) have shown significant potential for ontology engineering. However, it is still unclear to what extent they are applicable to the task of domain-specific ontology generation. In this study, we explore the application of LLMs for automated ontology generation and evaluate their performance across different domains. Specifically, we investigate the generalizability of two state-of-the-art LLMs, DeepSeek and o1-preview, both equipped with reasoning capabilities, by generating ontologies from a set of competency questions (CQs) and related user stories. Our experimental setup comprises six distinct domains carried out in existing ontology engineering projects and a total of 95 curated CQs designed to test the models' reasoning for ontology engineering. Our findings show that with both LLMs, the performance of the experiments is remarkably consistent across all domains, indicating that these methods are capable of generalizing ontology generation tasks irrespective of the domain. These results highlight the potential of LLM-based approaches in achieving scalable and domain-agnostic ontology construction and lay the groundwork for further research into enhancing automated reasoning and knowledge representation techniques.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17402",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.893765Z"
  },
  {
    "id": "df8778b4c9413d3c3c0d9efa867c15f3",
    "title": "Redefining Superalignment: From Weak-to-Strong Alignment to Human-AI Co-Alignment to Sustainable Symbiotic Society",
    "slug": "redefining-superalignment:-from-weak-to-strong-alignment-to-human-ai-co-alignment-to-sustainable-symbiotic-society",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Feifei Zhao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Artificial Intelligence (AI) systems are becoming increasingly powerful and autonomous, and may progress to surpass human intelligence levels, namely Artificial Superintelligence (ASI). During the progression from AI to ASI, it may exceed human control, violate human values, and even lead to irreversible catastrophic consequences in extreme cases. This gives rise to a pressing issue that needs to be addressed: superalignment, ensuring that AI systems much smarter than humans, remain aligned with human (compatible) intentions and values. Existing scalable oversight and weak-to-strong generalization methods may prove substantially infeasible and inadequate when facing ASI. We must explore safer and more pluralistic frameworks and approaches for superalignment. In this paper, we redefine superalignment as the human-AI co-alignment towards a sustainable symbiotic society, and highlight a framework that integrates external oversight and intrinsic proactive alignment. External oversight superalignment should be grounded in human-centered ultimate decision, supplemented by interpretable automated evaluation and correction, to achieve continuous alignment with humanity's evolving values. Intrinsic proactive superalignment is rooted in a profound understanding of the self, others, and society, integrating self-awareness, self-reflection, and empathy to spontaneously infer human intentions, distinguishing good from evil and proactively considering human well-being, ultimately attaining human-AI co-alignment through iterative interaction. The integration of externally-driven oversight with intrinsically-driven proactive alignment empowers sustainable symbiotic societies through human-AI co-alignment, paving the way for achieving safe and beneficial AGI and ASI for good, for human, and for a symbiotic ecology.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17404",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.894040Z"
  },
  {
    "id": "92fa94d0e568142c063ecf3ad6678ccb",
    "title": "Towards Machine-Generated Code for the Resolution of User Intentions",
    "slug": "towards-machine-generated-code-for-the-resolution-of-user-intentions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Justus Flerlage",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The growing capabilities of Artificial Intelligence (AI), particularly Large Language Models (LLMs), prompt a reassessment of the interaction mechanisms between users and their devices. Currently, users are required to use a set of high-level applications to achieve their desired results. However, the advent of AI may signal a shift in this regard, as its capabilities have generated novel prospects for user-provided intent resolution through the deployment of model-generated code, which is tantamount to the generation of workflows comprising a multitude of interdependent steps. This development represents a significant progression in the realm of hybrid workflows, where human and artificial intelligence collaborate to address user intentions, with the former responsible for defining these intentions and the latter for implementing the solutions to address them. In this paper, we investigate the feasibility of generating and executing workflows through code generation that results from prompting an LLM with a concrete user intention, such as \\emph{Please send my car title to my insurance company}, and a simplified application programming interface for a GUI-less operating system. We provide in-depth analysis and comparison of various user intentions, the resulting code, and its execution. The findings demonstrate a general feasibility of our approach and that the employed LLM, GPT-4o-mini, exhibits remarkable proficiency in the generation of code-oriented workflows in accordance with provided user intentions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17531",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.894249Z"
  },
  {
    "id": "661a4cce6cbbc886686dfcf896dd6c2d",
    "title": "Auditing the Ethical Logic of Generative AI Models",
    "slug": "auditing-the-ethical-logic-of-generative-ai-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "W. Russell Neuman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As generative AI models become increasingly integrated into high-stakes domains, the need for robust methods to evaluate their ethical reasoning becomes increasingly important. This paper introduces a five-dimensional audit model -- assessing Analytic Quality, Breadth of Ethical Considerations, Depth of Explanation, Consistency, and Decisiveness -- to evaluate the ethical logic of leading large language models (LLMs). Drawing on traditions from applied ethics and higher-order thinking, we present a multi-battery prompt approach, including novel ethical dilemmas, to probe the models' reasoning across diverse contexts. We benchmark seven major LLMs finding that while models generally converge on ethical decisions, they vary in explanatory rigor and moral prioritization. Chain-of-Thought prompting and reasoning-optimized models significantly enhance performance on our audit metrics. This study introduces a scalable methodology for ethical benchmarking of AI systems and highlights the potential for AI to complement human moral reasoning in complex decision-making contexts.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17544",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.894471Z"
  },
  {
    "id": "84e782f1ac88b1e346b415d015891709",
    "title": "Can deep neural networks learn biological vision?",
    "slug": "can-deep-neural-networks-learn-biological-vision?",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neurons and Cognition (q-bio.NC)",
    "author": {
      "name": "Drew Linsley",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deep neural networks (DNNs) once showed increasing alignment with primate neural responses as they improved on computer vision benchmarks. This trend raised the exciting possibility that better models of biological vision would come as a byproduct of the deep learning revolution in artificial intelligence. However, the trend has reversed over recent years as DNNs have scaled to human or superhuman recognition accuracy, a divergence that may stem from modern DNNs learning to rely on different visual features than primates to solve tasks. Where will better computational models of biological vision come from? We propose that vision science must break from artificial intelligence to develop algorithms that are designed with biological visual systems in mind instead of internet data benchmarks. We predict that the next generation of deep learning models of biological vision will be trained with data diets, training routines, and objectives that are closer to those that shape human vision than those that are in use today.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16940",
    "tags": [
      "Neurons and Cognition (q-bio.NC)"
    ],
    "createdAt": "2025-04-25T15:49:13.894680Z"
  },
  {
    "id": "aff718660d6028699b3a93012e4c9d3c",
    "title": "S2Vec: Self-Supervised Geospatial Embeddings",
    "slug": "s2vec:-self-supervised-geospatial-embeddings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Shushman Choudhury",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Scalable general-purpose representations of the built environment are crucial for geospatial artificial intelligence applications. This paper introduces S2Vec, a novel self-supervised framework for learning such geospatial embeddings. S2Vec uses the S2 Geometry library to partition large areas into discrete S2 cells, rasterizes built environment feature vectors within cells as images, and applies masked autoencoding on these rasterized images to encode the feature vectors. This approach yields task-agnostic embeddings that capture local feature characteristics and broader spatial relationships. We evaluate S2Vec on three large-scale socioeconomic prediction tasks, showing its competitive performance against state-of-the-art image-based embeddings. We also explore the benefits of combining S2Vec embeddings with image-based embeddings downstream, showing that such multimodal fusion can often improve performance. Our results highlight how S2Vec can learn effective general-purpose geospatial representations and how it can complement other data modalities in geospatial artificial intelligence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16942",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:13.894911Z"
  },
  {
    "id": "90d69307046aade605be6617c2c77e30",
    "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation",
    "slug": "mobilecity:-an-efficient-framework-for-large-scale-urban-behavior-simulation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Xiaotong Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Generative agents offer promising capabilities for simulating realistic urban behaviors. However, existing methods oversimplify transportation choices in modern cities, and require prohibitive computational resources for large-scale population simulation. To address these limitations, we first present a virtual city that features multiple functional buildings and transportation modes. Then, we conduct extensive surveys to model behavioral choices and mobility preferences among population groups. Building on these insights, we introduce a simulation framework that captures the complexity of urban mobility while remaining scalable, enabling the simulation of over 4,000 agents. To assess the realism of the generated behaviors, we perform a series of micro and macro-level analyses. Beyond mere performance comparison, we explore insightful experiments, such as predicting crowd density from movement patterns and identifying trends in vehicle preferences across agent demographics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16946",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:13.895587Z"
  },
  {
    "id": "18c07979866354ecc3abba02ddc47d49",
    "title": "SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments",
    "slug": "scrag:-social-computing-based-retrieval-augmented-generation-for-community-response-forecasting-in-social-media-environments",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Dachun Sun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces SCRAG, a prediction framework inspired by social computing, designed to forecast community responses to real or hypothetical social media posts. SCRAG can be used by public relations specialists (e.g., to craft messaging in ways that avoid unintended misinterpretations) or public figures and influencers (e.g., to anticipate social responses), among other applications related to public sentiment prediction, crisis management, and social what-if analysis. While large language models (LLMs) have achieved remarkable success in generating coherent and contextually rich text, their reliance on static training data and susceptibility to hallucinations limit their effectiveness at response forecasting in dynamic social media environments. SCRAG overcomes these challenges by integrating LLMs with a Retrieval-Augmented Generation (RAG) technique rooted in social computing. Specifically, our framework retrieves (i) historical responses from the target community to capture their ideological, semantic, and emotional makeup, and (ii) external knowledge from sources such as news articles to inject time-sensitive context. This information is then jointly used to forecast the responses of the target community to new posts or narratives. Extensive experiments across six scenarios on the X platform (formerly Twitter), tested with various embedding models and LLMs, demonstrate over 10% improvements on average in key evaluation metrics. A concrete example further shows its effectiveness in capturing diverse ideologies and nuances. Our work provides a social computing tool for applications where accurate and concrete insights into community responses are crucial.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16947",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:13.896180Z"
  },
  {
    "id": "65beaf9f86c348786ee7ea82f6d28973",
    "title": "Intrinsic Barriers to Explaining Deep Foundation Models",
    "slug": "intrinsic-barriers-to-explaining-deep-foundation-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Zhen Tan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deep Foundation Models (DFMs) offer unprecedented capabilities but their increasing complexity presents profound challenges to understanding their internal workings-a critical need for ensuring trust, safety, and accountability. As we grapple with explaining these systems, a fundamental question emerges: Are the difficulties we face merely temporary hurdles, awaiting more sophisticated analytical techniques, or do they stem from \\emph{intrinsic barriers} deeply rooted in the nature of these large-scale models themselves? This paper delves into this critical question by examining the fundamental characteristics of DFMs and scrutinizing the limitations encountered by current explainability methods when confronted with this inherent challenge. We probe the feasibility of achieving satisfactory explanations and consider the implications for how we must approach the verification and governance of these powerful technologies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16948",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:13.896407Z"
  },
  {
    "id": "fb58946142bea1dd00572fe698eba1c0",
    "title": "Backslash: Rate Constrained Optimized Training of Large Language Models",
    "slug": "backslash:-rate-constrained-optimized-training-of-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jun Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid advancement of large-language models (LLMs) has driven extensive research into parameter compression after training has been completed, yet compression during the training phase remains largely unexplored. In this work, we introduce Rate-Constrained Training (Backslash), a novel training-time compression approach based on rate-distortion optimization (RDO). Backslash enables a flexible trade-off between model accuracy and complexity, significantly reducing parameter redundancy while preserving performance. Experiments in various architectures and tasks demonstrate that Backslash can reduce memory usage by 60\\% - 90\\% without accuracy loss and provides significant compression gain compared to compression after training. Moreover, Backslash proves to be highly versatile: it enhances generalization with small Lagrange multipliers, improves model robustness to pruning (maintaining accuracy even at 80\\% pruning rates), and enables network simplification for accelerated inference on edge devices.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16968",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.896662Z"
  },
  {
    "id": "415c6f34ca176b6fa352fc8e703e9311",
    "title": "Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications",
    "slug": "unsupervised-time-series-signal-analysis-with-autoencoders-and-vision-transformers:-a-review-of-architectures-and-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hossein Ahmadi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid growth of unlabeled time-series data in domains such as wireless communications, radar, biomedical engineering, and the Internet of Things (IoT) has driven advancements in unsupervised learning. This review synthesizes recent progress in applying autoencoders and vision transformers for unsupervised signal analysis, focusing on their architectures, applications, and emerging trends. We explore how these models enable feature extraction, anomaly detection, and classification across diverse signal types, including electrocardiograms, radar waveforms, and IoT sensor data. The review highlights the strengths of hybrid architectures and self-supervised learning, while identifying challenges in interpretability, scalability, and domain generalization. By bridging methodological innovations and practical applications, this work offers a roadmap for developing robust, adaptive models for signal intelligence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16972",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.896891Z"
  },
  {
    "id": "ad9b1c3d9fc5a5918554a45940d871cf",
    "title": "Tokenization Matters: Improving Zero-Shot NER for Indic Languages",
    "slug": "tokenization-matters:-improving-zero-shot-ner-for-indic-languages",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Priyaranjan Pattnayak",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Tokenization is a critical component of Natural Language Processing (NLP), especially for low resource languages, where subword segmentation influences vocabulary structure and downstream task accuracy. Although Byte Pair Encoding (BPE) is a standard tokenization method in multilingual language models, its suitability for Named Entity Recognition (NER) in low resource Indic languages remains underexplored due to its limitations in handling morphological complexity. In this work, we systematically compare BPE, SentencePiece, and Character Level tokenization strategies using IndicBERT for NER tasks in low resource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as extremely low resource Indic languages like Santali, Manipuri, and Sindhi. We assess both intrinsic linguistic properties tokenization efficiency, out of vocabulary (OOV) rates, and morphological preservation as well as extrinsic downstream performance, including fine tuning and zero shot cross lingual transfer.\nOur experiments show that SentencePiece is a consistently better performing approach than BPE for NER in low resource Indic Languages, particularly in zero shot cross lingual settings, as it better preserves entity consistency. While BPE provides the most compact tokenization form, it is not capable of generalization because it misclassifies or even fails to recognize entity labels when tested on unseen languages. In contrast, SentencePiece constitutes a better linguistic structural preservation model, benefiting extremely low resource and morphologically rich Indic languages, such as Santali and Manipuri, for superior entity recognition, as well as high generalization across scripts, such as Sindhi, written in Arabic. The results point to SentencePiece as the more effective tokenization strategy for NER within multilingual and low resource Indic NLP applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16977",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.897138Z"
  },
  {
    "id": "bf2a280b9366954b5997e2130743fb35",
    "title": "Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline",
    "slug": "automating-tumor-infiltrating-lymphocyte-assessment-in-breast-cancer-histopathology-images-using-qupath:-a-transparent-and-accessible-machine-learning-pipeline",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantitative Methods (q-bio.QM)",
    "author": {
      "name": "Masoud Tafavvoghi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs) assessment pipeline within QuPath, demonstrating the potential of easily accessible tools to perform complex tasks in a fully automatic fashion. First, we trained a pixel classifier to segment tumor, tumor-associated stroma, and other tissue compartments in breast cancer H&E-stained whole-slide images (WSI) to isolate tumor-associated stroma for subsequent analysis. Next, we applied a pre-trained StarDist deep learning model in QuPath for cell detection and used the extracted cell features to train a binary classifier distinguishing TILs from other cells. To evaluate our TILs assessment pipeline, we calculated the TIL density in each WSI and categorized them as low, medium, or high TIL levels. Our pipeline was evaluated against pathologist-assigned TIL scores, achieving a Cohen's kappa of 0.71 on the external test set, corroborating previous research findings. These results confirm that existing software can offer a practical solution for the assessment of TILs in H&E-stained WSIs of breast cancer.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16979",
    "tags": [
      "Quantitative Methods (q-bio.QM)"
    ],
    "createdAt": "2025-04-25T15:49:13.897379Z"
  },
  {
    "id": "f34b4af627a687b8fda97668585ea4e1",
    "title": "(Im)possibility of Automated Hallucination Detection in Large Language Models",
    "slug": "(im)possibility-of-automated-hallucination-detection-in-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Amin Karbasi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Is automated hallucination detection possible? In this work, we introduce a theoretical framework to analyze the feasibility of automatically detecting hallucinations produced by large language models (LLMs). Inspired by the classical Gold-Angluin framework for language identification and its recent adaptation to language generation by Kleinberg and Mullainathan, we investigate whether an algorithm, trained on examples drawn from an unknown target language $K$ (selected from a countable collection) and given access to an LLM, can reliably determine whether the LLM's outputs are correct or constitute hallucinations.\nFirst, we establish an equivalence between hallucination detection and the classical task of language identification. We prove that any hallucination detection method can be converted into a language identification method, and conversely, algorithms solving language identification can be adapted for hallucination detection. Given the inherent difficulty of language identification, this implies that hallucination detection is fundamentally impossible for most language collections if the detector is trained using only correct examples from the target language.\nSecond, we show that the use of expert-labeled feedback, i.e., training the detector with both positive examples (correct statements) and negative examples (explicitly labeled incorrect statements), dramatically changes this conclusion. Under this enriched training regime, automated hallucination detection becomes possible for all countable language collections.\nThese results highlight the essential role of expert-labeled examples in training hallucination detectors and provide theoretical support for feedback-based methods, such as reinforcement learning with human feedback (RLHF), which have proven critical for reliable LLM deployment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17004",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.897590Z"
  },
  {
    "id": "22f55b83e2edfe7be40ef62851e1e032",
    "title": "Analyzing Value Functions of States in Parametric Markov Chains",
    "slug": "analyzing-value-functions-of-states-in-parametric-markov-chains",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic in Computer Science (cs.LO)",
    "author": {
      "name": "Kasper Engelen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Parametric Markov chains (pMC) are used to model probabilistic systems with unknown or partially known probabilities. Although (universal) pMC verification for reachability properties is known to be coETR-complete, there have been efforts to approach it using potentially easier-to-check properties such as asking whether the pMC is monotonic in certain parameters. In this paper, we first reduce monotonicity to asking whether the reachability probability from a given state is never less than that of another given state. Recent results for the latter property imply an efficient algorithm to collapse same-value equivalence classes, which in turn preserves verification results and monotonicity. We implement our algorithm to collapse \"trivial\" equivalence classes in the pMC and show empirical evidence for the following: First, the collapse gives reductions in size for some existing benchmarks and significant reductions on some custom benchmarks; Second, the collapse speeds up existing algorithms to check monotonicity and parameter lifting, and hence can be used as a fast pre-processing step in practice.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17020",
    "tags": [
      "Logic in Computer Science (cs.LO)"
    ],
    "createdAt": "2025-04-25T15:49:13.897821Z"
  },
  {
    "id": "d7d5634bcdf519fe365f557dafad6142",
    "title": "What Makes for a Good Saliency Map? Comparing Strategies for Evaluating Saliency Maps in Explainable AI (XAI)",
    "slug": "what-makes-for-a-good-saliency-map?-comparing-strategies-for-evaluating-saliency-maps-in-explainable-ai-(xai)",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Felix Kares",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Saliency maps are a popular approach for explaining classifications of (convolutional) neural networks. However, it remains an open question as to how best to evaluate salience maps, with three families of evaluation methods commonly being used: subjective user measures, objective user measures, and mathematical metrics. We examine three of the most popular saliency map approaches (viz., LIME, Grad-CAM, and Guided Backpropagation) in a between subject study (N=166) across these families of evaluation methods. We test 1) for subjective measures, if the maps differ with respect to user trust and satisfaction; 2) for objective measures, if the maps increase users' abilities and thus understanding of a model; 3) for mathematical metrics, which map achieves the best ratings across metrics; and 4) whether the mathematical metrics can be associated with objective user measures. To our knowledge, our study is the first to compare several salience maps across all these evaluation methods$-$with the finding that they do not agree in their assessment (i.e., there was no difference concerning trust and satisfaction, Grad-CAM improved users' abilities best, and Guided Backpropagation had the most favorable mathematical metrics). Additionally, we show that some mathematical metrics were associated with user understanding, although this relationship was often counterintuitive. We discuss these findings in light of general debates concerning the complementary use of user studies and mathematical metrics in the evaluation of explainable AI (XAI) approaches.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17023",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:13.898042Z"
  },
  {
    "id": "d2089c436cf6e5606772789c00d6c969",
    "title": "Democracy of AI Numerical Weather Models: An Example of Global Forecasting with FourCastNetv2 Made by a University Research Lab Using GPU",
    "slug": "democracy-of-ai-numerical-weather-models:-an-example-of-global-forecasting-with-fourcastnetv2-made-by-a-university-research-lab-using-gpu",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Iman Khadir",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper demonstrates the feasibility of democratizing AI-driven global weather forecasting models among university research groups by leveraging Graphics Processing Units (GPUs) and freely available AI models, such as NVIDIA's FourCastNetv2. FourCastNetv2 is an NVIDIA's advanced neural network for weather prediction and is trained on a 73-channel subset of the European Centre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset at single levels and different pressure levels. Although the training specifications for FourCastNetv2 are not released to the public, the training documentation of the model's first generation, FourCastNet, is available to all users. The training had 64 A100 GPUs and took 16 hours to complete. Although NVIDIA's models offer significant reductions in both time and cost compared to traditional Numerical Weather Prediction (NWP), reproducing published forecasting results presents ongoing challenges for resource-constrained university research groups with limited GPU availability. We demonstrate both (i) leveraging FourCastNetv2 to create predictions through the designated application programming interface (API) and (ii) utilizing NVIDIA hardware to train the original FourCastNet model. Further, this paper demonstrates the capabilities and limitations of NVIDIA A100's for resource-limited research groups in universities. We also explore data management, training efficiency, and model validation, highlighting the advantages and challenges of using limited high-performance computing resources. Consequently, this paper and its corresponding GitHub materials may serve as an initial guide for other university research groups and courses related to machine learning, climate science, and data science to develop research and education programs on AI weather forecasting, and hence help democratize the AI NWP in the digital economy.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17028",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.898289Z"
  },
  {
    "id": "de9eadf8688f619075966ca21923ecc2",
    "title": "Fried Parameter Estimation from Single Wavefront Sensor Image with Artificial Neural Networks",
    "slug": "fried-parameter-estimation-from-single-wavefront-sensor-image-with-artificial-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
    "author": {
      "name": "Jeffrey Smith",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Atmospheric turbulence degrades the quality of astronomical observations in ground-based telescopes, leading to distorted and blurry images. Adaptive Optics (AO) systems are designed to counteract these effects, using atmospheric measurements captured by a wavefront sensor to make real-time corrections to the incoming wavefront. The Fried parameter, r0, characterises the strength of atmospheric turbulence and is an essential control parameter for optimising the performance of AO systems and more recently sky profiling for Free Space Optical (FSO) communication channels. In this paper, we develop a novel data-driven approach, adapting machine learning methods from computer vision for Fried parameter estimation from a single Shack-Hartmann or pyramid wavefront sensor image. Using these data-driven methods, we present a detailed simulation-based evaluation of our approach using the open-source COMPASS AO simulation tool to evaluate both the Shack-Hartmann and pyramid wavefront sensors. Our evaluation is over a range of guide star magnitudes, and realistic noise, atmospheric and instrument conditions. Remarkably, we are able to develop a single network-based estimator that is accurate in both open and closed-loop AO configurations. Our method accurately estimates the Fried parameter from a single WFS image directly from AO telemetry to a few millimetres. Our approach is suitable for real time control, exhibiting 0.83ms r0 inference times on retail NVIDIA RTX 3090 GPU hardware, and thereby demonstrating a compelling economic solution for use in real-time instrument control.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17029",
    "tags": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "createdAt": "2025-04-25T15:49:13.898507Z"
  },
  {
    "id": "450a5db653676d16c351d735ea367f39",
    "title": "DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs",
    "slug": "dymu:-dynamic-merging-and-virtual-unmerging-for-efficient-vlms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhenhailong Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present DyMU, an efficient, training-free framework that dynamically reduces the computational burden of vision-language models (VLMs) while maintaining high task performance. Our approach comprises two key components. First, Dynamic Token Merging (DToMe) reduces the number of visual token embeddings by merging similar tokens based on image complexity, addressing the inherent inefficiency of fixed-length outputs in vision transformers. Second, Virtual Token Unmerging (VTU) simulates the expected token sequence for large language models (LLMs) by efficiently reconstructing the attention dynamics of a full sequence, thus preserving the downstream performance without additional fine-tuning. Unlike previous approaches, our method dynamically adapts token compression to the content of the image and operates completely training-free, making it readily applicable to most state-of-the-art VLM architectures. Extensive experiments on image and video understanding tasks demonstrate that DyMU can reduce the average visual token count by 32%-85% while achieving comparable performance to full-length models across diverse VLM architectures, including the recently popularized AnyRes-based visual encoders. Furthermore, through qualitative analyses, we demonstrate that DToMe effectively adapts token reduction based on image complexity and, unlike existing systems, provides users more control over computational costs. Project page: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17040",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.898721Z"
  },
  {
    "id": "29a8d316ab8f2f403b7ce237fdf4d62f",
    "title": "Approaches to Responsible Governance of GenAI in Organizations",
    "slug": "approaches-to-responsible-governance-of-genai-in-organizations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Dhari Gandhi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid evolution of Generative AI (GenAI) has introduced unprecedented opportunities while presenting complex challenges around ethics, accountability, and societal impact. This paper draws on a literature review, established governance frameworks, and industry roundtable discussions to identify core principles for integrating responsible GenAI governance into diverse organizational structures. Our objective is to provide actionable recommendations for a balanced, risk-based governance approach that enables both innovation and oversight. Findings emphasize the need for adaptable risk assessment tools, continuous monitoring practices, and cross-sector collaboration to establish trustworthy GenAI. These insights provide a structured foundation and Responsible GenAI Guide (ResAI) for organizations to align GenAI initiatives with ethical, legal, and operational best practices.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17044",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:13.898938Z"
  },
  {
    "id": "a9f3df8a662a571053104d12a3ecdf62",
    "title": "Psychological Effect of AI driven marketing tools for beauty/facial feature enhancement",
    "slug": "psychological-effect-of-ai-driven-marketing-tools-for-beauty/facial-feature-enhancement",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Ayushi Agrawal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "AI-powered facial assessment tools are reshaping how individuals evaluate appearance and internalize social judgments. This study examines the psychological impact of such tools on self-objectification, self-esteem, and emotional responses, with attention to gender differences. Two samples used distinct versions of a facial analysis tool: one overtly critical (N=75; M=22.9 years), and another more neutral (N=51; M=19.9 years). Participants completed validated self-objectification and self-esteem scales and custom items measuring emotion, digital/physical appearance enhancement (DAE, PAEE), and perceived social emotion (PSE). Results revealed consistent links between high self-objectification, low self-esteem, and increased appearance enhancement behaviors across both versions. Despite softer framing, the newer tool still evoked negative emotional responses (U=1466.5, p=0.013), indicating implicit feedback may reinforce appearance-related insecurities. Gender differences emerged in DAE (p=0.025) and PSE (p<0.001), with females more prone to digital enhancement and less likely to perceive emotional impact in others. These findings reveal how AI tools may unintentionally reinforce and amplify existing social biases and underscore the critical need for responsible AI design and development. Future research will investigate how human ideologies embedded in the training data of such tools shape their evaluative outputs, and how these, in turn, influence user attitudes and decisions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17055",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:13.899141Z"
  },
  {
    "id": "ba582911e2deae514a316b6de3e0f7eb",
    "title": "Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation",
    "slug": "statistical-guarantees-in-synthetic-data-through-conformal-adversarial-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Rahul Vishwakarma",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The generation of high-quality synthetic data presents significant challenges in machine learning research, particularly regarding statistical fidelity and uncertainty quantification. Existing generative models produce compelling synthetic samples but lack rigorous statistical guarantees about their relation to the underlying data distribution, limiting their applicability in critical domains requiring robust error bounds. We address this fundamental limitation by presenting a novel framework that incorporates conformal prediction methodologies into Generative Adversarial Networks (GANs). By integrating multiple conformal prediction paradigms including Inductive Conformal Prediction (ICP), Mondrian Conformal Prediction, Cross-Conformal Prediction, and Venn-Abers Predictors, we establish distribution-free uncertainty quantification in generated samples. This approach, termed Conformalized GAN (cGAN), demonstrates enhanced calibration properties while maintaining the generative power of traditional GANs, producing synthetic data with provable statistical guarantees. We provide rigorous mathematical proofs establishing finite-sample validity guarantees and asymptotic efficiency properties, enabling the reliable application of synthetic data in high-stakes domains including healthcare, finance, and autonomous systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17058",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.899340Z"
  },
  {
    "id": "29645924818788e6183fe5863c2fd53e",
    "title": "Distilling semantically aware orders for autoregressive image generation",
    "slug": "distilling-semantically-aware-orders-for-autoregressive-image-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Rishav Pramanik",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autoregressive patch-based image generation has recently shown competitive results in terms of image quality and scalability. It can also be easily integrated and scaled within Vision-Language models. Nevertheless, autoregressive models require a defined order for patch generation. While a natural order based on the dictation of the words makes sense for text generation, there is no inherent generation order that exists for image generation. Traditionally, a raster-scan order (from top-left to bottom-right) guides autoregressive image generation models. In this paper, we argue that this order is suboptimal, as it fails to respect the causality of the image content: for instance, when conditioned on a visual description of a sunset, an autoregressive model may generate clouds before the sun, even though the color of clouds should depend on the color of the sun and not the inverse. In this work, we show that first by training a model to generate patches in any-given-order, we can infer both the content and the location (order) of each patch during generation. Secondly, we use these extracted orders to finetune the any-given-order model to produce better-quality images. Through our experiments, we show on two datasets that this new generation method produces better images than the traditional raster-scan approach, with similar training costs and no extra annotations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17069",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.899559Z"
  },
  {
    "id": "d5c4dbae201c390314da4d74dfc7f0c1",
    "title": "Robo-Troj: Attacking LLM-based Task Planners",
    "slug": "robo-troj:-attacking-llm-based-task-planners",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Mohaiminul Al Nahian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Robots need task planning methods to achieve goals that require more than individual actions. Recently, large language models (LLMs) have demonstrated impressive performance in task planning. LLMs can generate a step-by-step solution using a description of actions and the goal. Despite the successes in LLM-based task planning, there is limited research studying the security aspects of those systems. In this paper, we develop Robo-Troj, the first multi-trigger backdoor attack for LLM-based task planners, which is the main contribution of this work. As a multi-trigger attack, Robo-Troj is trained to accommodate the diversity of robot application domains. For instance, one can use unique trigger words, e.g., \"herical\", to activate a specific malicious behavior, e.g., cutting hand on a kitchen robot. In addition, we develop an optimization method for selecting the trigger words that are most effective. Through demonstrating the vulnerability of LLM-based planners, we aim to promote the development of secured robot systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17070",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:13.899771Z"
  },
  {
    "id": "59ddaa34676ae75e8698053addd83707",
    "title": "Physics-guided and fabrication-aware inverse design of photonic devices using diffusion models",
    "slug": "physics-guided-and-fabrication-aware-inverse-design-of-photonic-devices-using-diffusion-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optics (physics.optics)",
    "author": {
      "name": "Dongjin Seo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Designing free-form photonic devices is fundamentally challenging due to the vast number of possible geometries and the complex requirements of fabrication constraints. Traditional inverse-design approaches--whether driven by human intuition, global optimization, or adjoint-based gradient methods--often involve intricate binarization and filtering steps, while recent deep learning strategies demand prohibitively large numbers of simulations (10^5 to 10^6). To overcome these limitations, we present AdjointDiffusion, a physics-guided framework that integrates adjoint sensitivity gradients into the sampling process of diffusion models. AdjointDiffusion begins by training a diffusion network on a synthetic, fabrication-aware dataset of binary masks. During inference, we compute the adjoint gradient of a candidate structure and inject this physics-based guidance at each denoising step, steering the generative process toward high figure-of-merit (FoM) solutions without additional post-processing. We demonstrate our method on two canonical photonic design problems--a bent waveguide and a CMOS image sensor color router--and show that our method consistently outperforms state-of-the-art nonlinear optimizers (such as MMA and SLSQP) in both efficiency and manufacturability, while using orders of magnitude fewer simulations (approximately 2 x 10^2) than pure deep learning approaches (approximately 10^5 to 10^6). By eliminating complex binarization schedules and minimizing simulation overhead, AdjointDiffusion offers a streamlined, simulation-efficient, and fabrication-aware pipeline for next-generation photonic device design. Our open-source implementation is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17077",
    "tags": [
      "Optics (physics.optics)"
    ],
    "createdAt": "2025-04-25T15:49:13.900003Z"
  },
  {
    "id": "54b63462d0908033f1d281ca16505a45",
    "title": "Anatomy-constrained modelling of image-derived input functions in dynamic PET using multi-organ segmentation",
    "slug": "anatomy-constrained-modelling-of-image-derived-input-functions-in-dynamic-pet-using-multi-organ-segmentation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Valentin Langer",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate kinetic analysis of [$^{18}$F]FDG distribution in dynamic positron emission tomography (PET) requires anatomically constrained modelling of image-derived input functions (IDIFs). Traditionally, IDIFs are obtained from the aorta, neglecting anatomical variations and complex vascular contributions. This study proposes a multi-organ segmentation-based approach that integrates IDIFs from the aorta, portal vein, pulmonary artery, and ureters. Using high-resolution CT segmentations of the liver, lungs, kidneys, and bladder, we incorporate organ-specific blood supply sources to improve kinetic modelling. Our method was evaluated on dynamic [$^{18}$F]FDG PET data from nine patients, resulting in a mean squared error (MSE) reduction of $13.39\\%$ for the liver and $10.42\\%$ for the lungs. These initial results highlight the potential of multiple IDIFs in improving anatomical modelling and fully leveraging dynamic PET imaging. This approach could facilitate the integration of tracer kinetic modelling into clinical routine.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17114",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:13.900221Z"
  },
  {
    "id": "bd18d0c1b44b32578d47af1a25cb2d02",
    "title": "The Rise of Small Language Models in Healthcare: A Comprehensive Survey",
    "slug": "the-rise-of-small-language-models-in-healthcare:-a-comprehensive-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Muskan Garg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Despite substantial progress in healthcare applications driven by large language models (LLMs), growing concerns around data privacy, and limited resources; the small language models (SLMs) offer a scalable and clinically viable solution for efficient performance in resource-constrained environments for next-generation healthcare informatics. Our comprehensive survey presents a taxonomic framework to identify and categorize them for healthcare professionals and informaticians. The timeline of healthcare SLM contributions establishes a foundational framework for analyzing models across three dimensions: NLP tasks, stakeholder roles, and the continuum of care. We present a taxonomic framework to identify the architectural foundations for building models from scratch; adapting SLMs to clinical precision through prompting, instruction fine-tuning, and reasoning; and accessibility and sustainability through compression techniques. Our primary objective is to offer a comprehensive survey for healthcare professionals, introducing recent innovations in model optimization and equipping them with curated resources to support future research and development in the field. Aiming to showcase the groundbreaking advancements in SLMs for healthcare, we present a comprehensive compilation of experimental results across widely studied NLP tasks in healthcare to highlight the transformative potential of SLMs in healthcare. The updated repository is available at Github",
    "pdfUrl": "https://arxiv.org/pdf/2504.17119",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.900435Z"
  },
  {
    "id": "6d1a944f6f75fab30cfc8bfbc07bf42f",
    "title": "Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET",
    "slug": "physiological-neural-representation-for-personalised-tracer-kinetic-parameter-estimation-from-dynamic-pet",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Kartikay Tehlan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables non-invasive quantification of glucose metabolism through kinetic analysis, often modelled by the two-tissue compartment model (TCKM). However, voxel-wise kinetic parameter estimation using conventional methods is computationally intensive and limited by spatial resolution. Deep neural networks (DNNs) offer an alternative but require large training datasets and significant computational resources. To address these limitations, we propose a physiological neural representation based on implicit neural representations (INRs) for personalized kinetic parameter estimation. INRs, which learn continuous functions, allow for efficient, high-resolution parametric imaging with reduced data requirements. Our method also integrates anatomical priors from a 3D CT foundation model to enhance robustness and precision in kinetic modelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset and compare it to state-of-the-art DNNs. Results demonstrate superior spatial resolution, lower mean-squared error, and improved anatomical consistency, particularly in tumour and highly vascularized regions. Our findings highlight the potential of INRs for personalized, data-efficient tracer kinetic modelling, enabling applications in tumour characterization, segmentation, and prognostic assessment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17122",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:13.900642Z"
  },
  {
    "id": "496c42522840eb42925c1e613000967f",
    "title": "Demonstration of an AI-driven workflow for dynamic x-ray spectroscopy",
    "slug": "demonstration-of-an-ai-driven-workflow-for-dynamic-x-ray-spectroscopy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Applied Physics (physics.app-ph)",
    "author": {
      "name": "Ming Du",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "X-ray absorption near edge structure (XANES) spectroscopy is a powerful technique for characterizing the chemical state and symmetry of individual elements within materials, but requires collecting data at many energy points which can be time-consuming. While adaptive sampling methods exist for efficiently collecting spectroscopic data, they often lack domain-specific knowledge about XANES spectra structure. Here we demonstrate a knowledge-injected Bayesian optimization approach for adaptive XANES data collection that incorporates understanding of spectral features like absorption edges and pre-edge peaks. We show this method accurately reconstructs the absorption edge of XANES spectra using only 15-20% of the measurement points typically needed for conventional sampling, while maintaining the ability to determine the x-ray energy of the sharp peak after absorption edge with errors less than 0.03 eV, the absorption edge with errors less than 0.1 eV; and overall root-mean-square errors less than 0.005 compared to compared to traditionally sampled spectra. Our experiments on battery materials and catalysts demonstrate the method's effectiveness for both static and dynamic XANES measurements, improving data collection efficiency and enabling better time resolution for tracking chemical changes. This approach advances the degree of automation in XANES experiments reducing the common errors of under- or over-sampling points in near the absorption edge and enabling dynamic experiments that require high temporal resolution or limited measurement time.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17124",
    "tags": [
      "Applied Physics (physics.app-ph)"
    ],
    "createdAt": "2025-04-25T15:49:13.900852Z"
  },
  {
    "id": "673e7953462a127698e8c5399a5c3855",
    "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference",
    "slug": "peer-aware-cost-estimation-in-nonlinear-general-sum-dynamic-games-for-mutual-learning-and-intent-inference",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Seyed Yousef Soltanian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Human-robot interactions can be modeled as incomplete-information general-sum dynamic games since the objective functions of both agents are not explicitly known to each other. However, solving for equilibrium policies for such games presents a major challenge, especially if the games involve nonlinear underlying dynamics. To simplify the problem, existing work often assumes that one agent is an expert with complete information about its peer, which can lead to biased estimates and failures in coordination. To address this challenge, we propose a nonlinear peer-aware cost estimation (N-PACE) algorithm for general-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ) approximation of the nonlinear general-sum game, each agent explicitly models the learning dynamics of its peer agent while inferring their objective functions, leading to unbiased fast learning in inferring the unknown objective function of the peer agent, which is critical for task completion and safety assurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent communication} in such multi-agent systems by explicitly modeling the peer's learning dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17129",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:13.901071Z"
  },
  {
    "id": "9fbbb25ebf05d83d05696e35dcb17281",
    "title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation",
    "slug": "mirage:-a-metric-intensive-benchmark-for-retrieval-augmented-generation-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Chanhee Park",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Retrieval-Augmented Generation (RAG) has gained prominence as an effective method for enhancing the generative capabilities of Large Language Models (LLMs) through the incorporation of external knowledge. However, the evaluation of RAG systems remains a challenge, due to the intricate interplay between retrieval and generation components. This limitation has resulted in a scarcity of benchmarks that facilitate a detailed, component-specific assessment. In this work, we present MIRAGE, a Question Answering dataset specifically designed for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped to a retrieval pool of 37,800 entries, enabling an efficient and precise evaluation of both retrieval and generation tasks. We also introduce novel evaluation metrics aimed at measuring RAG adaptability, encompassing dimensions such as noise vulnerability, context acceptability, context insensitivity, and context misinterpretation. Through comprehensive experiments across various retriever-LLM configurations, we provide new insights into the optimal alignment of model pairs and the nuanced dynamics within RAG systems. The dataset and evaluation code are publicly available, allowing for seamless integration and customization in diverse research settings\\footnote{The MIRAGE code and data are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17137",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.901532Z"
  },
  {
    "id": "157cc36badab4eb5d1b7636edfb1811f",
    "title": "Scalable Permutation-Aware Modeling for Temporal Set Prediction",
    "slug": "scalable-permutation-aware-modeling-for-temporal-set-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ashish Ranjan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Temporal set prediction involves forecasting the elements that will appear in the next set, given a sequence of prior sets, each containing a variable number of elements. Existing methods often rely on intricate architectures with substantial computational overhead, which hampers their scalability. In this work, we introduce a novel and scalable framework that leverages permutation-equivariant and permutation-invariant transformations to efficiently model set dynamics. Our approach significantly reduces both training and inference time while maintaining competitive performance. Extensive experiments on multiple public benchmarks show that our method achieves results on par with or superior to state-of-the-art models across several evaluation metrics. These results underscore the effectiveness of our model in enabling efficient and scalable temporal set prediction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17140",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.901945Z"
  },
  {
    "id": "f7e6ee346e69e11dec819132edc3d22d",
    "title": "OUI Need to Talk About Weight Decay: A New Perspective on Overfitting Detection",
    "slug": "oui-need-to-talk-about-weight-decay:-a-new-perspective-on-overfitting-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Alberto Fernndez-Hernndez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce the Overfitting-Underfitting Indicator (OUI), a novel tool for monitoring the training dynamics of Deep Neural Networks (DNNs) and identifying optimal regularization hyperparameters. Specifically, we validate that OUI can effectively guide the selection of the Weight Decay (WD) hyperparameter by indicating whether a model is overfitting or underfitting during training without requiring validation data. Through experiments on DenseNet-BC-100 with CIFAR- 100, EfficientNet-B0 with TinyImageNet and ResNet-34 with ImageNet-1K, we show that maintaining OUI within a prescribed interval correlates strongly with improved generalization and validation scores. Notably, OUI converges significantly faster than traditional metrics such as loss or accuracy, enabling practitioners to identify optimal WD (hyperparameter) values within the early stages of training. By leveraging OUI as a reliable indicator, we can determine early in training whether the chosen WD value leads the model to underfit the training data, overfit, or strike a well-balanced trade-off that maximizes validation scores. This enables more precise WD tuning for optimal performance on the tested datasets and DNNs. All code for reproducing these experiments is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17160",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.902205Z"
  },
  {
    "id": "cef86af2d7ff09bd69452f367efe9427",
    "title": "A Comprehensive Review on RNA Subcellular Localization Prediction",
    "slug": "a-comprehensive-review-on-rna-subcellular-localization-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Cece Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The subcellular localization of RNAs, including long non-coding RNAs (lncRNAs), messenger RNAs (mRNAs), microRNAs (miRNAs) and other smaller RNAs, plays a critical role in determining their biological functions. For instance, lncRNAs are predominantly associated with chromatin and act as regulators of gene transcription and chromatin structure, while mRNAs are distributed across the nucleus and cytoplasm, facilitating the transport of genetic information for protein synthesis. Understanding RNA localization sheds light on processes like gene expression regulation with spatial and temporal precision. However, traditional wet lab methods for determining RNA localization, such as in situ hybridization, are often time-consuming, resource-demanding, and costly. To overcome these challenges, computational methods leveraging artificial intelligence (AI) and machine learning (ML) have emerged as powerful alternatives, enabling large-scale prediction of RNA subcellular localization. This paper provides a comprehensive review of the latest advancements in AI-based approaches for RNA subcellular localization prediction, covering various RNA types and focusing on sequence-based, image-based, and hybrid methodologies that combine both data types. We highlight the potential of these methods to accelerate RNA research, uncover molecular pathways, and guide targeted disease treatments. Furthermore, we critically discuss the challenges in AI/ML approaches for RNA subcellular localization, such as data scarcity and lack of benchmarks, and opportunities to address them. This review aims to serve as a valuable resource for researchers seeking to develop innovative solutions in the field of RNA subcellular localization and beyond.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17162",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.902454Z"
  },
  {
    "id": "fb0232e1c3d77bf1301817e1975e5b82",
    "title": "Improving Human-Autonomous Vehicle Interaction in Complex Systems",
    "slug": "improving-human-autonomous-vehicle-interaction-in-complex-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Robert Kaufman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Unresolved questions about how autonomous vehicles (AVs) should meet the informational needs of riders hinder real-world adoption. Complicating our ability to satisfy rider needs is that different people, goals, and driving contexts have different criteria for what constitutes interaction success. Unfortunately, most human-AV research and design today treats all people and situations uniformly. It is crucial to understand how an AV should communicate to meet rider needs, and how communications should change when the human-AV complex system changes. I argue that understanding the relationships between different aspects of the human-AV system can help us build improved and adaptable AV communications. I support this argument using three empirical studies. First, I identify optimal communication strategies that enhance driving performance, confidence, and trust for learning in extreme driving environments. Findings highlight the need for task-sensitive, modality-appropriate communications tuned to learner cognitive limits and goals. Next, I highlight the consequences of deploying faulty communication systems and demonstrate the need for context-sensitive communications. Third, I use machine learning (ML) to illuminate personal factors predicting trust in AVs, emphasizing the importance of tailoring designs to individual traits and concerns. Together, this dissertation supports the necessity of transparent, adaptable, and personalized AV systems that cater to individual needs, goals, and contextual demands. By considering the complex system within which human-AV interactions occur, we can deliver valuable insights for designers, researchers, and policymakers. This dissertation also provides a concrete domain to study theories of human-machine joint action and situational awareness, and can be used to guide future human-AI interaction research. [shortened for arxiv]",
    "pdfUrl": "https://arxiv.org/pdf/2504.17170",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:13.902653Z"
  },
  {
    "id": "5827951398332e70355bf13065a366e8",
    "title": "We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback",
    "slug": "we'll-fix-it-in-post:-improving-text-to-video-generation-with-neuro-symbolic-feedback",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Minkyu Choi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Current text-to-video (T2V) generation models are increasingly popular due to their ability to produce coherent videos from textual prompts. However, these models often struggle to generate semantically and temporally consistent videos when dealing with longer, more complex prompts involving multiple objects or sequential events. Additionally, the high computational costs associated with training or fine-tuning make direct improvements impractical. To overcome these limitations, we introduce \\(\\projectname\\), a novel zero-training video refinement pipeline that leverages neuro-symbolic feedback to automatically enhance video generation, achieving superior alignment with the prompts. Our approach first derives the neuro-symbolic feedback by analyzing a formal video representation and pinpoints semantically inconsistent events, objects, and their corresponding frames. This feedback then guides targeted edits to the original video. Extensive empirical evaluations on both open-source and proprietary T2V models demonstrate that \\(\\projectname\\) significantly enhances temporal and logical alignment across diverse prompts by almost $40\\%$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17180",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.902885Z"
  },
  {
    "id": "17d72407b45202249b781448188624a5",
    "title": "Automatically Generating Rules of Malicious Software Packages via Large Language Model",
    "slug": "automatically-generating-rules-of-malicious-software-packages-via-large-language-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "XiangRui Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Today's security tools predominantly rely on predefined rules crafted by experts, making them poorly adapted to the emergence of software supply chain attacks. To tackle this limitation, we propose a novel tool, RuleLLM, which leverages large language models (LLMs) to automate rule generation for OSS ecosystems. RuleLLM extracts metadata and code snippets from malware as its input, producing YARA and Semgrep rules that can be directly deployed in software development. Specifically, the rule generation task involves three subtasks: crafting rules, refining rules, and aligning rules. To validate RuleLLM's effectiveness, we implemented a prototype system and conducted experiments on the dataset of 1,633 malicious packages. The results are promising that RuleLLM generated 763 rules (452 YARA and 311 Semgrep) with a precision of 85.2\\% and a recall of 91.8\\%, outperforming state-of-the-art (SOTA) tools and scored-based approaches. We further analyzed generated rules and proposed a rule taxonomy: 11 categories and 38 subcategories.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17198",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:13.903107Z"
  },
  {
    "id": "42a2b858f6c3949365352c6e601241a5",
    "title": "Synthetic Power Flow Data Generation Using Physics-Informed Denoising Diffusion Probabilistic Models",
    "slug": "synthetic-power-flow-data-generation-using-physics-informed-denoising-diffusion-probabilistic-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Junfei Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many data-driven modules in smart grid rely on access to high-quality power flow data; however, real-world data are often limited due to privacy and operational constraints. This paper presents a physics-informed generative framework based on Denoising Diffusion Probabilistic Models (DDPMs) for synthesizing feasible power flow data. By incorporating auxiliary training and physics-informed loss functions, the proposed method ensures that the generated data exhibit both statistical fidelity and adherence to power system feasibility. We evaluate the approach on the IEEE 14-bus and 30-bus benchmark systems, demonstrating its ability to capture key distributional properties and generalize to out-of-distribution scenarios. Comparative results show that the proposed model outperforms three baseline models in terms of feasibility, diversity, and accuracy of statistical features. This work highlights the potential of integrating generative modelling into data-driven power system applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17210",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.903343Z"
  },
  {
    "id": "b7df9c50c78c46845136ae66ea05a656",
    "title": "MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing",
    "slug": "mcaf:-efficient-agent-based-video-understanding-framework-through-multimodal-coarse-to-fine-attention-focusing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Shiwen Cao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Even in the era of rapid advances in large models, video understanding, particularly long videos, remains highly challenging. Compared with textual or image-based information, videos commonly contain more information with redundancy, requiring large models to strategically allocate attention at a global level for accurate comprehension. To address this, we propose MCAF, an agent-based, training-free framework perform video understanding through Multimodal Coarse-to-fine Attention Focusing. The key innovation lies in its ability to sense and prioritize segments of the video that are highly relevant to the understanding task. First, MCAF hierarchically concentrates on highly relevant frames through multimodal information, enhancing the correlation between the acquired contextual information and the query. Second, it employs a dilated temporal expansion mechanism to mitigate the risk of missing crucial details when extracting information from these concentrated frames. In addition, our framework incorporates a self-reflection mechanism utilizing the confidence level of the model's responses as feedback. By iteratively applying these two creative focusing strategies, it adaptively adjusts attention to capture highly query-connected context and thus improves response accuracy. MCAF outperforms comparable state-of-the-art methods on average. On the EgoSchema dataset, it achieves a remarkable 5% performance gain over the leading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms the current state-of-the-art standard by 0.2% and 0.3% respectively. On the Video-MME dataset, which features videos averaging nearly an hour in length, MCAF also outperforms other agent-based methods.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17213",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.903649Z"
  },
  {
    "id": "3832b9b58a81c253d518510694906ffa",
    "title": "Enhancing Variational Autoencoders with Smooth Robust Latent Encoding",
    "slug": "enhancing-variational-autoencoders-with-smooth-robust-latent-encoding",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hyomin Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Variational Autoencoders (VAEs) have played a key role in scaling up diffusion-based generative models, as in Stable Diffusion, yet questions regarding their robustness remain largely underexplored. Although adversarial training has been an established technique for enhancing robustness in predictive models, it has been overlooked for generative models due to concerns about potential fidelity degradation by the nature of trade-offs between performance and robustness. In this work, we challenge this presumption, introducing Smooth Robust Latent VAE (SRL-VAE), a novel adversarial training framework that boosts both generation quality and robustness. In contrast to conventional adversarial training, which focuses on robustness only, our approach smooths the latent space via adversarial perturbations, promoting more generalizable representations while regularizing with originality representation to sustain original fidelity. Applied as a post-training step on pre-trained VAEs, SRL-VAE improves image robustness and fidelity with minimal computational overhead. Experiments show that SRL-VAE improves both generation quality, in image reconstruction and text-guided image editing, and robustness, against Nightshade attacks and image editing attacks. These results establish a new paradigm, showing that adversarial training, once thought to be detrimental to generative models, can instead enhance both fidelity and robustness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17219",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.903871Z"
  },
  {
    "id": "14a39ac272764c12fb3d997a441b6782",
    "title": "NeuralGrok: Accelerate Grokking by Neural Gradient Transformation",
    "slug": "neuralgrok:-accelerate-grokking-by-neural-gradient-transformation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Xinyu Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Grokking is proposed and widely studied as an intricate phenomenon in which generalization is achieved after a long-lasting period of overfitting. In this work, we propose NeuralGrok, a novel gradient-based approach that learns an optimal gradient transformation to accelerate the generalization of transformers in arithmetic tasks. Specifically, NeuralGrok trains an auxiliary module (e.g., an MLP block) in conjunction with the base model. This module dynamically modulates the influence of individual gradient components based on their contribution to generalization, guided by a bilevel optimization algorithm. Our extensive experiments demonstrate that NeuralGrok significantly accelerates generalization, particularly in challenging arithmetic tasks. We also show that NeuralGrok promotes a more stable training paradigm, constantly reducing the model's complexity, while traditional regularization methods, such as weight decay, can introduce substantial instability and impede generalization. We further investigate the intrinsic model complexity leveraging a novel Absolute Gradient Entropy (AGE) metric, which explains that NeuralGrok effectively facilitates generalization by reducing the model complexity. We offer valuable insights on the grokking phenomenon of Transformer models, which encourages a deeper understanding of the fundamental principles governing generalization ability.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17243",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.904086Z"
  },
  {
    "id": "0b85ed7d5ee66eb6fc8590e240673606",
    "title": "Targeted AMP generation through controlled diffusion with efficient embeddings",
    "slug": "targeted-amp-generation-through-controlled-diffusion-with-efficient-embeddings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Diogo Soares",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deep learning-based antimicrobial peptide (AMP) discovery faces critical challenges such as low experimental hit rates as well as the need for nuanced controllability and efficient modeling of peptide properties. To address these challenges, we introduce OmegAMP, a framework that leverages a diffusion-based generative model with efficient low-dimensional embeddings, precise controllability mechanisms, and novel classifiers with drastically reduced false positive rates for candidate filtering. OmegAMP enables the targeted generation of AMPs with specific physicochemical properties, activity profiles, and species-specific effectiveness. Moreover, it maximizes sample diversity while ensuring faithfulness to the underlying data distribution during generation. We demonstrate that OmegAMP achieves state-of-the-art performance across all stages of the AMP discovery pipeline, significantly advancing the potential of computational frameworks in combating antimicrobial resistance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17247",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.904315Z"
  },
  {
    "id": "76114e8e0938bb647f21160b5b47218e",
    "title": "3D Deep-learning-based Segmentation of Human Skin Sweat Glands and Their 3D Morphological Response to Temperature Variations",
    "slug": "3d-deep-learning-based-segmentation-of-human-skin-sweat-glands-and-their-3d-morphological-response-to-temperature-variations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Shaoyu Pei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Skin, the primary regulator of heat exchange, relies on sweat glands for thermoregulation. Alterations in sweat gland morphology play a crucial role in various pathological conditions and clinical diagnoses. Current methods for observing sweat gland morphology are limited by their two-dimensional, in vitro, and destructive nature, underscoring the urgent need for real-time, non-invasive, quantifiable technologies. We proposed a novel three-dimensional (3D) transformer-based multi-object segmentation framework, integrating a sliding window approach, joint spatial-channel attention mechanism, and architectural heterogeneity between shallow and deep layers. Our proposed network enables precise 3D sweat gland segmentation from skin volume data captured by optical coherence tomography (OCT). For the first time, subtle variations of sweat gland 3D morphology in response to temperature changes, have been visualized and quantified. Our approach establishes a benchmark for normal sweat gland morphology and provides a real-time, non-invasive tool for quantifying 3D structural parameters. This enables the study of individual variability and pathological changes in sweat gland structure, advancing dermatological research and clinical applications, including thermoregulation and bromhidrosis treatment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17255",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:13.904544Z"
  },
  {
    "id": "294fccd88d27dc116f07d9f4301c75fd",
    "title": "Symbolic Representation for Any-to-Any Generative Tasks",
    "slug": "symbolic-representation-for-any-to-any-generative-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jiaqi Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a symbolic generative task description language and a corresponding inference engine capable of representing arbitrary multimodal tasks as structured symbolic flows. Unlike conventional generative models that rely on large-scale training and implicit neural representations to learn cross-modal mappings, often at high computational cost and with limited flexibility, our framework introduces an explicit symbolic representation comprising three core primitives: functions, parameters, and topological logic. Leveraging a pre-trained language model, our inference engine maps natural language instructions directly to symbolic workflows in a training-free manner. Our framework successfully performs over 12 diverse multimodal generative tasks, demonstrating strong performance and flexibility without the need for task-specific tuning. Experiments show that our method not only matches or outperforms existing state-of-the-art unified models in content quality, but also offers greater efficiency, editability, and interruptibility. We believe that symbolic task representations provide a cost-effective and extensible foundation for advancing the capabilities of generative AI.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17261",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.904802Z"
  },
  {
    "id": "e2fd68b0e3141195db7d8a8bb4277af3",
    "title": "JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning",
    "slug": "jurisctc:-enhancing-legal-judgment-prediction-via-cross-domain-transfer-and-contrastive-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Zhaolu Kang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In recent years, Unsupervised Domain Adaptation (UDA) has gained significant attention in the field of Natural Language Processing (NLP) owing to its ability to enhance model generalization across diverse domains. However, its application for knowledge transfer between distinct legal domains remains largely unexplored. To address the challenges posed by lengthy and complex legal texts and the limited availability of large-scale annotated datasets, we propose JurisCTC, a novel model designed to improve the accuracy of Legal Judgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC facilitates effective knowledge transfer across various legal domains and employs contrastive learning to distinguish samples from different domains. Specifically, for the LJP task, we enable knowledge transfer between civil and criminal law domains. Compared to other models and specific large language models (LLMs), JurisCTC demonstrates notable advancements, achieving peak accuracies of 76.59% and 78.83%, respectively.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17264",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.905036Z"
  },
  {
    "id": "dae2c56ed68376f5b70d5c1ab2fa2680",
    "title": "ExOSITO: Explainable Off-Policy Learning with Side Information for Intensive Care Unit Blood Test Orders",
    "slug": "exosito:-explainable-off-policy-learning-with-side-information-for-intensive-care-unit-blood-test-orders",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zongliang Ji",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Ordering a minimal subset of lab tests for patients in the intensive care unit (ICU) can be challenging. Care teams must balance between ensuring the availability of the right information and reducing the clinical burden and costs associated with each lab test order. Most in-patient settings experience frequent over-ordering of lab tests, but are now aiming to reduce this burden on both hospital resources and the environment. This paper develops a novel method that combines off-policy learning with privileged information to identify the optimal set of ICU lab tests to order. Our approach, EXplainable Off-policy learning with Side Information for ICU blood Test Orders (ExOSITO) creates an interpretable assistive tool for clinicians to order lab tests by considering both the observed and predicted future status of each patient. We pose this problem as a causal bandit trained using offline data and a reward function derived from clinically-approved rules; we introduce a novel learning framework that integrates clinical knowledge with observational data to bridge the gap between the optimal and logging policies. The learned policy function provides interpretable clinical information and reduces costs without omitting any vital lab orders, outperforming both a physician's policy and prior approaches to this practical problem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17277",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.905258Z"
  },
  {
    "id": "4f301b6db085a7789acef2d05b7cd863",
    "title": "You Are What You Bought: Generating Customer Personas for E-commerce Applications",
    "slug": "you-are-what-you-bought:-generating-customer-personas-for-e-commerce-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Yimin Shi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In e-commerce, user representations are essential for various applications. Existing methods often use deep learning techniques to convert customer behaviors into implicit embeddings. However, these embeddings are difficult to understand and integrate with external knowledge, limiting the effectiveness of applications such as customer segmentation, search navigation, and product recommendations. To address this, our paper introduces the concept of the customer persona. Condensed from a customer's numerous purchasing histories, a customer persona provides a multi-faceted and human-readable characterization of specific purchase behaviors and preferences, such as Busy Parents or Bargain Hunters.\nThis work then focuses on representing each customer by multiple personas from a predefined set, achieving readable and informative explicit user representations. To this end, we propose an effective and efficient solution GPLR. To ensure effectiveness, GPLR leverages pre-trained LLMs to infer personas for customers. To reduce overhead, GPLR applies LLM-based labeling to only a fraction of users and utilizes a random walk technique to predict personas for the remaining customers. We further propose RevAff, which provides an absolute error $\\epsilon$ guarantee while improving the time complexity of the exact solution by a factor of at least $O(\\frac{\\epsilon\\cdot|E|N}{|E|+N\\log N})$, where $N$ represents the number of customers and products, and $E$ represents the interactions between them. We evaluate the performance of our persona-based representation in terms of accuracy and robustness for recommendation and customer segmentation tasks using three real-world e-commerce datasets. Most notably, we find that integrating customer persona representations improves the state-of-the-art graph convolution-based recommendation model by up to 12% in terms of NDCG@K and F1-Score@K.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17304",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:13.905488Z"
  },
  {
    "id": "2d7ddba2c10de89aded82990605525ee",
    "title": "Advanced Segmentation of Diabetic Retinopathy Lesions Using DeepLabv3+",
    "slug": "advanced-segmentation-of-diabetic-retinopathy-lesions-using-deeplabv3+",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Meher Boulaabi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "To improve the segmentation of diabetic retinopathy lesions (microaneurysms, hemorrhages, exudates, and soft exudates), we implemented a binary segmentation method specific to each type of lesion. As post-segmentation, we combined the individual model outputs into a single image to better analyze the lesion types. This approach facilitated parameter optimization and improved accuracy, effectively overcoming challenges related to dataset limitations and annotation complexity. Specific preprocessing steps included cropping and applying contrast-limited adaptive histogram equalization to the L channel of the LAB image. Additionally, we employed targeted data augmentation techniques to further refine the model's efficacy. Our methodology utilized the DeepLabv3+ model, achieving a segmentation accuracy of 99%. These findings highlight the efficacy of innovative strategies in advancing medical image analysis, particularly in the precise segmentation of diabetic retinopathy lesions. The IDRID dataset was utilized to validate and demonstrate the robustness of our approach.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17306",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.905701Z"
  },
  {
    "id": "0d6e9b6517b6be01bfb2c31fce1142b1",
    "title": "FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation",
    "slug": "fluke:-a-linguistically-driven-and-task-agnostic-framework-for-robustness-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yulia Otmakhova",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present FLUKE (Framework for LingUistically-driven and tasK-agnostic robustness Evaluation), a task-agnostic framework for assessing model robustness through systematic minimal variations of test data. FLUKE introduces controlled variations across linguistic levels - from orthography to dialect and style varieties - and leverages large language models (LLMs) with human validation to generate modifications. We demonstrate FLUKE's utility by evaluating both fine-tuned models and LLMs across four diverse NLP tasks, and reveal that (1) the impact of linguistic variations is highly task-dependent, with some tests being critical for certain tasks but irrelevant for others; (2) while LLMs have better overall robustness compared to fine-tuned models, they still exhibit significant brittleness to certain linguistic variations; (3) all models show substantial vulnerability to negation modifications across most tasks. These findings highlight the importance of systematic robustness testing for understanding model behaviors.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17311",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.905922Z"
  },
  {
    "id": "39bf6fe8cbb78588eda29b51748f6cc5",
    "title": "DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model",
    "slug": "dimt25@icdar2025:-hw-tsc's-end-to-end-document-image-machine-translation-system-leveraging-large-vision-language-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhanglin Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper presents the technical solution proposed by Huawei Translation Service Center (HW-TSC) for the \"End-to-End Document Image Machine Translation for Complex Layouts\" competition at the 19th International Conference on Document Analysis and Recognition (DIMT25@ICDAR2025). Leveraging state-of-the-art open-source large vision-language model (LVLM), we introduce a training framework that combines multi-task learning with perceptual chain-of-thought to develop a comprehensive end-to-end document translation system. During the inference phase, we apply minimum Bayesian decoding and post-processing strategies to further enhance the system's translation capabilities. Our solution uniquely addresses both OCR-based and OCR-free document image translation tasks within a unified framework. This paper systematically details the training methods, inference strategies, LVLM base models, training data, experimental setups, and results, demonstrating an effective approach to document image machine translation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17315",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.906159Z"
  },
  {
    "id": "82da5feb8c99f5638f413d4e728b4b7a",
    "title": "Exploring Context-aware and LLM-driven Locomotion for Immersive Virtual Reality",
    "slug": "exploring-context-aware-and-llm-driven-locomotion-for-immersive-virtual-reality",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Sleyman zdel",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Locomotion plays a crucial role in shaping the user experience within virtual reality environments. In particular, hands-free locomotion offers a valuable alternative by supporting accessibility and freeing users from reliance on handheld controllers. To this end, traditional speech-based methods often depend on rigid command sets, limiting the naturalness and flexibility of interaction. In this study, we propose a novel locomotion technique powered by large language models (LLMs), which allows users to navigate virtual environments using natural language with contextual awareness. We evaluate three locomotion methods: controller-based teleportation, voice-based steering, and our language model-driven approach. Our evaluation measures include eye-tracking data analysis, including explainable machine learning through SHAP analysis as well as standardized questionnaires for usability, presence, cybersickness, and cognitive load to examine user attention and engagement. Our findings indicate that the LLM-driven locomotion possesses comparable usability, presence, and cybersickness scores to established methods like teleportation, demonstrating its novel potential as a comfortable, natural language-based, hands-free alternative. In addition, it enhances user attention within the virtual environment, suggesting greater engagement. Complementary to these findings, SHAP analysis revealed that fixation, saccade, and pupil-related features vary across techniques, indicating distinct patterns of visual attention and cognitive processing. Overall, we state that our method can facilitate hands-free locomotion in virtual spaces, especially in supporting accessibility.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17331",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:13.906369Z"
  },
  {
    "id": "3dc4e86b957f2aeb9fb994338ff8460d",
    "title": "Dual-Individual Genetic Algorithm: A Dual-Individual Approach for Efficient Training of Multi-Layer Neural Networks",
    "slug": "dual-individual-genetic-algorithm:-a-dual-individual-approach-for-efficient-training-of-multi-layer-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "Tran Thuy Nga Truong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces an enhanced Genetic Algorithm technique called Dual-Individual Genetic Algorithm (Dual-Individual GA), which optimizes neural networks for binary image classification tasks, such as cat vs. non-cat classification. The proposed method employs only two individuals for crossover, represented by two parameter sets: Leader and Follower. The Leader focuses on exploitation, representing the primary optimal solution at even-indexed positions (0, 2, 4, ...), while the Follower promotes exploration by preserving diversity and avoiding premature convergence, operating at odd-indexed positions (1, 3, 5, ...). Leader and Follower are modeled as two phases or roles. The key contributions of this work are threefold: (1) a self-adaptive layer dimension mechanism that eliminates the need for manual tuning of layer architectures; (2) generates two parameter sets, leader and follower parameter sets, with 10 layer architecture configurations (5 for each set), ranked by Pareto dominance and cost. post-optimization; and (3) demonstrated superior performance compared to traditional gradient-based methods. Experimental results show that the Dual-Individual GA achieves 99.04% training accuracy and 80% testing accuracy (cost = 0.034) on a three-layer network with architecture [12288, 17, 4, 1], outperforming a gradient-based approach that achieves 98% training accuracy and 80% testing accuracy (cost = 0.092) on a four-layer network with architecture [12288, 20, 7, 5, 1]. These findings highlight the efficiency and effectiveness of the proposed method in optimizing neural networks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17346",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:13.906573Z"
  },
  {
    "id": "c67dccfdc68afd8dfd2937f8f8df7f7f",
    "title": "Data-Driven Surrogate Modeling Techniques to Predict the Effective Contact Area of Rough Surface Contact Problems",
    "slug": "data-driven-surrogate-modeling-techniques-to-predict-the-effective-contact-area-of-rough-surface-contact-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Engineering, Finance, and Science (cs.CE)",
    "author": {
      "name": "Tarik Sahin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The effective contact area in rough surface contact plays a critical role in multi-physics phenomena such as wear, sealing, and thermal or electrical conduction. Although accurate numerical methods, like the Boundary Element Method (BEM), are available to compute this quantity, their high computational cost limits their applicability in multi-query contexts, such as uncertainty quantification, parameter identification, and multi-scale algorithms, where many repeated evaluations are required. This study proposes a surrogate modeling framework for predicting the effective contact area using fast-to-evaluate data-driven techniques. Various machine learning algorithms are trained on a precomputed dataset, where the inputs are the imposed load and statistical roughness parameters, and the output is the corresponding effective contact area. All models undergo hyperparameter optimization to enable fair comparisons in terms of predictive accuracy and computational efficiency, evaluated using established quantitative metrics. Among the models, the Kernel Ridge Regressor demonstrates the best trade-off between accuracy and efficiency, achieving high predictive accuracy, low prediction time, and minimal training overhead-making it a strong candidate for general-purpose surrogate modeling. The Gaussian Process Regressor provides an attractive alternative when uncertainty quantification is required, although it incurs additional computational cost due to variance estimation. The generalization capability of the Kernel Ridge model is validated on an unseen simulation scenario, confirming its ability to transfer to new configurations. Database generation constitutes the dominant cost in the surrogate modeling process. Nevertheless, the approach proves practical and efficient for multi-query tasks, even when accounting for this initial expense.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17354",
    "tags": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "createdAt": "2025-04-25T15:49:13.906780Z"
  },
  {
    "id": "ad3ff3e7b756d22318bde23e81f37fb7",
    "title": "Collaborative Multi-Agent Reinforcement Learning for Automated Feature Transformation with Graph-Driven Path Optimization",
    "slug": "collaborative-multi-agent-reinforcement-learning-for-automated-feature-transformation-with-graph-driven-path-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Xiaohan Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Feature transformation methods aim to find an optimal mathematical feature-feature crossing process that generates high-value features and improves the performance of downstream machine learning tasks. Existing frameworks, though designed to mitigate manual costs, often treat feature transformations as isolated operations, ignoring dynamic dependencies between transformation steps. To address the limitations, we propose TCTO, a collaborative multi-agent reinforcement learning framework that automates feature engineering through graph-driven path optimization. The framework's core innovation lies in an evolving interaction graph that models features as nodes and transformations as edges. Through graph pruning and backtracking, it dynamically eliminates low-impact edges, reduces redundant operations, and enhances exploration stability. This graph also provides full traceability to empower TCTO to reuse high-utility subgraphs from historical transformations. To demonstrate the efficacy and adaptability of our approach, we conduct comprehensive experiments and case studies, which show superior performance across a range of datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17355",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.907020Z"
  },
  {
    "id": "3eebeedb55661869c4dace0f3327a8ae",
    "title": "LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams",
    "slug": "livelongbench:-tackling-long-context-understanding-for-spoken-texts-from-live-streams",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yongxuan Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Long-context understanding poses significant challenges in natural language processing, particularly for real-world dialogues characterized by speech-based elements, high redundancy, and uneven information density. Although large language models (LLMs) achieve impressive results on existing benchmarks, these datasets fail to reflect the complexities of such texts, limiting their applicability to practical scenarios. To bridge this gap, we construct the first spoken long-text dataset, derived from live streams, designed to reflect the redundancy-rich and conversational nature of real-world scenarios. We construct tasks in three categories: retrieval-dependent, reasoning-dependent, and hybrid. We then evaluate both popular LLMs and specialized methods to assess their ability to understand long-contexts in these tasks. Our results show that current methods exhibit strong task-specific preferences and perform poorly on highly redundant inputs, with no single method consistently outperforming others. We propose a new baseline that better handles redundancy in spoken text and achieves strong performance across tasks. Our findings highlight key limitations of current methods and suggest future directions for improving long-context understanding. Finally, our benchmark fills a gap in evaluating long-context spoken language understanding and provides a practical foundation for developing real-world e-commerce systems. The code and benchmark are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17366",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.907224Z"
  },
  {
    "id": "33a229870ad392e1acb7188e0cec1b5c",
    "title": "On the workflow, opportunities and challenges of developing foundation model in geophysics",
    "slug": "on-the-workflow,-opportunities-and-challenges-of-developing-foundation-model-in-geophysics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geophysics (physics.geo-ph)",
    "author": {
      "name": "Hanlin Sheng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Foundation models, as a mainstream technology in artificial intelligence, have demonstrated immense potential across various domains in recent years, particularly in handling complex tasks and multimodal data. In the field of geophysics, although the application of foundation models is gradually expanding, there is currently a lack of comprehensive reviews discussing the full workflow of integrating foundation models with geophysical data. To address this gap, this paper presents a complete framework that systematically explores the entire process of developing foundation models in conjunction with geophysical data. From data collection and preprocessing to model architecture selection, pre-training strategies, and model deployment, we provide a detailed analysis of the key techniques and methodologies at each stage. In particular, considering the diversity, complexity, and physical consistency constraints of geophysical data, we discuss targeted solutions to address these challenges. Furthermore, we discuss how to leverage the transfer learning capabilities of foundation models to reduce reliance on labeled data, enhance computational efficiency, and incorporate physical constraints into model training, thereby improving physical consistency and interpretability. Through a comprehensive summary and analysis of the current technological landscape, this paper not only fills the gap in the geophysics domain regarding a full-process review of foundation models but also offers valuable practical guidance for their application in geophysical data analysis, driving innovation and advancement in the field.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17384",
    "tags": [
      "Geophysics (physics.geo-ph)"
    ],
    "createdAt": "2025-04-25T15:49:13.907457Z"
  },
  {
    "id": "149def33290ceda331ad6be297a8ddcd",
    "title": "Towards User-Centred Design of AI-Assisted Decision-Making in Law Enforcement",
    "slug": "towards-user-centred-design-of-ai-assisted-decision-making-in-law-enforcement",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Vesna Nowack",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Artificial Intelligence (AI) has become an important part of our everyday lives, yet user requirements for designing AI-assisted systems in law enforcement remain unclear. To address this gap, we conducted qualitative research on decision-making within a law enforcement agency. Our study aimed to identify limitations of existing practices, explore user requirements and understand the responsibilities that humans expect to undertake in these systems.\nParticipants in our study highlighted the need for a system capable of processing and analysing large volumes of data efficiently to help in crime detection and prevention. Additionally, the system should satisfy requirements for scalability, accuracy, justification, trustworthiness and adaptability to be adopted in this domain. Participants also emphasised the importance of having end users review the input data that might be challenging for AI to interpret, and validate the generated output to ensure the system's accuracy. To keep up with the evolving nature of the law enforcement domain, end users need to help the system adapt to the changes in criminal behaviour and government guidance, and technical experts need to regularly oversee and monitor the system. Furthermore, user-friendly human interaction with the system is essential for its adoption and some of the participants confirmed they would be happy to be in the loop and provide necessary feedback that the system can learn from. Finally, we argue that it is very unlikely that the system will ever achieve full automation due to the dynamic and complex nature of the law enforcement domain.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17393",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:13.907787Z"
  },
  {
    "id": "d040e770551526dde4a98bf1daf5a94f",
    "title": "StereoMamba: Real-time and Robust Intraoperative Stereo Disparity Estimation via Long-range Spatial Dependencies",
    "slug": "stereomamba:-real-time-and-robust-intraoperative-stereo-disparity-estimation-via-long-range-spatial-dependencies",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Xu Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Stereo disparity estimation is crucial for obtaining depth information in robot-assisted minimally invasive surgery (RAMIS). While current deep learning methods have made significant advancements, challenges remain in achieving an optimal balance between accuracy, robustness, and inference speed. To address these challenges, we propose the StereoMamba architecture, which is specifically designed for stereo disparity estimation in RAMIS. Our approach is based on a novel Feature Extraction Mamba (FE-Mamba) module, which enhances long-range spatial dependencies both within and across stereo images. To effectively integrate multi-scale features from FE-Mamba, we then introduce a novel Multidimensional Feature Fusion (MFF) module. Experiments against the state-of-the-art on the ex-vivo SCARED benchmark demonstrate that StereoMamba achieves superior performance on EPE of 2.64 px and depth MAE of 2.55 mm, the second-best performance on Bad2 of 41.49% and Bad3 of 26.99%, while maintaining an inference speed of 21.28 FPS for a pair of high-resolution images (1280*1024), striking the optimum balance between accuracy, robustness, and efficiency. Furthermore, by comparing synthesized right images, generated from warping left images using the generated disparity maps, with the actual right image, StereoMamba achieves the best average SSIM (0.8970) and PSNR (16.0761), exhibiting strong zero-shot generalization on the in-vivo RIS2017 and StereoMIS datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17401",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.908022Z"
  },
  {
    "id": "cd5de82eb543cdfa5384db4c0fb72684",
    "title": "Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks",
    "slug": "towards-harnessing-the-collaborative-power-of-large-and-small-models-for-domain-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yang Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) have demonstrated remarkable capabilities, but they require vast amounts of data and computational resources. In contrast, smaller models (SMs), while less powerful, can be more efficient and tailored to specific domains. In this position paper, we argue that taking a collaborative approach, where large and small models work synergistically, can accelerate the adaptation of LLMs to private domains and unlock new potential in AI. We explore various strategies for model collaboration and identify potential challenges and opportunities. Building upon this, we advocate for industry-driven research that prioritizes multi-objective benchmarks on real-world private datasets and applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17421",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.908268Z"
  },
  {
    "id": "e93f1766d6ff077bca42b95d361175be",
    "title": "Object Pose Estimation by Camera Arm Control Based on the Next Viewpoint Estimation",
    "slug": "object-pose-estimation-by-camera-arm-control-based-on-the-next-viewpoint-estimation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Tomoki Mizuno",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We have developed a new method to estimate a Next Viewpoint (NV) which is effective for pose estimation of simple-shaped products for product display robots in retail stores. Pose estimation methods using Neural Networks (NN) based on an RGBD camera are highly accurate, but their accuracy significantly decreases when the camera acquires few texture and shape features at a current view point. However, it is difficult for previous mathematical model-based methods to estimate effective NV which is because the simple shaped objects have few shape features. Therefore, we focus on the relationship between the pose estimation and NV estimation. When the pose estimation is more accurate, the NV estimation is more accurate. Therefore, we develop a new pose estimation NN that estimates NV simultaneously. Experimental results showed that our NV estimation realized a pose estimation success rate 77.3\\%, which was 7.4pt higher than the mathematical model-based NV calculation did. Moreover, we verified that the robot using our method displayed 84.2\\% of products.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17424",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:13.908472Z"
  },
  {
    "id": "4208446f6ee8f21f5fbf5893657f3362",
    "title": "Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code",
    "slug": "towards-leveraging-large-language-model-summaries-for-topic-modeling-in-source-code",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Michele Carissimi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Understanding source code is a topic of great interest in the software engineering community, since it can help programmers in various tasks such as software maintenance and reuse. Recent advances in large language models (LLMs) have demonstrated remarkable program comprehension capabilities, while transformer-based topic modeling techniques offer effective ways to extract semantic information from text. This paper proposes and explores a novel approach that combines these strengths to automatically identify meaningful topics in a corpus of Python programs. Our method consists in applying topic modeling on the descriptions obtained by asking an LLM to summarize the code. To assess the internal consistency of the extracted topics, we compare them against topics inferred from function names alone, and those derived from existing docstrings. Experimental results suggest that leveraging LLM-generated summaries provides interpretable and semantically rich representation of code structure. The promising results suggest that our approach can be fruitfully applied in various software engineering tasks such as automatic documentation and tagging, code search, software reorganization and knowledge discovery in large repositories.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17426",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:13.908700Z"
  },
  {
    "id": "ea67458f049d3b3ab7ed934bc649ffed",
    "title": "Detection, Classification and Prevalence of Self-Admitted Aging Debt",
    "slug": "detection,-classification-and-prevalence-of-self-admitted-aging-debt",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Murali Sridharan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Context: Previous research on software aging is limited with focus on dynamic runtime indicators like memory and performance, often neglecting evolutionary indicators like source code comments and narrowly examining legacy issues within the TD context. Objective: We introduce the concept of Aging Debt (AD), representing the increased maintenance efforts and costs needed to keep software updated. We study AD through Self-Admitted Aging Debt (SAAD) observed in source code comments left by software developers. Method: We employ a mixed-methods approach, combining qualitative and quantitative analyses to detect and measure AD in software. This includes framing SAAD patterns from the source code comments after analysing the source code context, then utilizing the SAAD patterns to detect SAAD comments. In the process, we develop a taxonomy for SAAD that reflects the temporal aging of software and its associated debt. Then we utilize the taxonomy to quantify the different types of AD prevalent in OSS repositories. Results: Our proposed taxonomy categorizes temporal software aging into Active and Dormant types. Our extensive analysis of over 9,000+ Open Source Software (OSS) repositories reveals that more than 21% repositories exhibit signs of SAAD as observed from our gold standard SAAD dataset. Notably, Dormant AD emerges as the predominant category, highlighting a critical but often overlooked aspect of software maintenance. Conclusion: As software volume grows annually, so do evolutionary aging and maintenance challenges; our proposed taxonomy can aid researchers in detailed software aging studies and help practitioners develop improved and proactive maintenance strategies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17428",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:13.908923Z"
  },
  {
    "id": "349c01e3e8e2f22a2c2e72f8f96d8b24",
    "title": "FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding",
    "slug": "frag:-frame-selection-augmented-generation-for-long-video-and-long-document-understanding",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "De-An Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "There has been impressive progress in Large Multimodal Models (LMMs). Recent works extend these models to long inputs, including multi-page documents and long videos. However, the model size and performance of these long context models are still limited due to the computational cost in both training and inference. In this work, we explore an orthogonal direction and process long inputs without long context LMMs. We propose Frame Selection Augmented Generation (FRAG), where the model first selects relevant frames within the input, and then only generates the final outputs based on the selected frames. The core of the selection process is done by scoring each frame independently, which does not require long context processing. The frames with the highest scores are then selected by a simple Top-K selection. We show that this frustratingly simple framework is applicable to both long videos and multi-page documents using existing LMMs without any fine-tuning. We consider two models, LLaVA-OneVision and InternVL2, in our experiments and show that FRAG consistently improves the performance and achieves state-of-the-art performances for both long video and long document understanding. For videos, FRAG substantially improves InternVL2-76B by 5.8% on MLVU and 3.7% on Video-MME. For documents, FRAG achieves over 20% improvements on MP-DocVQA compared with recent LMMs specialized in long document understanding. Code is available at: this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17447",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.909137Z"
  },
  {
    "id": "e343f1498347f73eb0cd13537fff7472",
    "title": "HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models",
    "slug": "hmi:-hierarchical-knowledge-management-for-efficient-multi-tenant-inference-in-pretrained-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jun Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The significant computational demands of pretrained language models (PLMs), which often require dedicated hardware, present a substantial challenge in serving them efficiently, especially in multi-tenant environments. To address this, we introduce HMI, a Hierarchical knowledge management-based Multi-tenant Inference system, designed to manage tenants with distinct PLMs resource-efficiently. Our approach is three-fold: Firstly, we categorize PLM knowledge into general, domain-specific, and task-specific. Leveraging insights on knowledge acquisition across different model layers, we construct hierarchical PLMs (hPLMs) by extracting and storing knowledge at different levels, significantly reducing GPU memory usage per tenant. Secondly, we establish hierarchical knowledge management for hPLMs generated by various tenants in HMI. We manage domain-specific knowledge with acceptable storage increases by constructing and updating domain-specific knowledge trees based on frequency. We manage task-specific knowledge within limited GPU memory through parameter swapping. Finally, we propose system optimizations to enhance resource utilization and inference throughput. These include fine-grained pipelining via hierarchical knowledge prefetching to overlap CPU and I/O operations with GPU computations, and optimizing parallel implementations with batched matrix multiplications. Our experimental results demonstrate that the proposed HMI can efficiently serve up to 10,000 hPLMs (hBERTs and hGPTs) on a single GPU, with only a negligible compromise in accuracy.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17449",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.909379Z"
  },
  {
    "id": "287fe1045a9783e4fbd0cf14ad5e6800",
    "title": "Evaluating Time Series Models for Urban Wastewater Management: Predictive Performance, Model Complexity and Resilience",
    "slug": "evaluating-time-series-models-for-urban-wastewater-management:-predictive-performance,-model-complexity-and-resilience",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Vipin Singh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Climate change increases the frequency of extreme rainfall, placing a significant strain on urban infrastructures, especially Combined Sewer Systems (CSS). Overflows from overburdened CSS release untreated wastewater into surface waters, posing environmental and public health risks. Although traditional physics-based models are effective, they are costly to maintain and difficult to adapt to evolving system dynamics. Machine Learning (ML) approaches offer cost-efficient alternatives with greater adaptability. To systematically assess the potential of ML for modeling urban infrastructure systems, we propose a protocol for evaluating Neural Network architectures for CSS time series forecasting with respect to predictive performance, model complexity, and robustness to perturbations. In addition, we assess model performance on peak events and critical fluctuations, as these are the key regimes for urban wastewater management. To investigate the feasibility of lightweight models suitable for IoT deployment, we compare global models, which have access to all information, with local models, which rely solely on nearby sensor readings. Additionally, to explore the security risks posed by network outages or adversarial attacks on urban infrastructure, we introduce error models that assess the resilience of models. Our results demonstrate that while global models achieve higher predictive performance, local models provide sufficient resilience in decentralized scenarios, ensuring robust modeling of urban infrastructure. Furthermore, models with longer native forecast horizons exhibit greater robustness to data perturbations. These findings contribute to the development of interpretable and reliable ML solutions for sustainable urban wastewater management. The implementation is available in our GitHub repository.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17461",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.909605Z"
  },
  {
    "id": "c1ca163d2f9b49caec431b78426c9bff",
    "title": "GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework",
    "slug": "granite-:-a-byzantine-resilient-dynamic-gossip-learning-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yacine Belal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Gossip Learning (GL) is a decentralized learning paradigm where users iteratively exchange and aggregate models with a small set of neighboring peers. Recent GL approaches rely on dynamic communication graphs built and maintained using Random Peer Sampling (RPS) protocols. Thanks to graph dynamics, GL can achieve fast convergence even over extremely sparse topologies. However, the robustness of GL over dy- namic graphs to Byzantine (model poisoning) attacks remains unaddressed especially when Byzantine nodes attack the RPS protocol to scale up model poisoning. We address this issue by introducing GRANITE, a framework for robust learning over sparse, dynamic graphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two key components (i) a History-aware Byzantine-resilient Peer Sampling protocol (HaPS), which tracks previously encountered identifiers to reduce adversarial influence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which leverages an estimate of Byzantine presence to set aggregation thresholds with formal guarantees. Empirical results confirm that GRANITE maintains convergence with up to 30% Byzantine nodes, improves learning speed via adaptive filtering of poisoned models and obtains these results in up to 9 times sparser graphs than dictated by current theory.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17471",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.909815Z"
  },
  {
    "id": "a8cd9dd9e5b36afd1d9c8004d934b4fa",
    "title": "Enhanced Sample Selection with Confidence Tracking: Identifying Correctly Labeled yet Hard-to-Learn Samples in Noisy Data",
    "slug": "enhanced-sample-selection-with-confidence-tracking:-identifying-correctly-labeled-yet-hard-to-learn-samples-in-noisy-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Weiran Pan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a novel sample selection method for image classification in the presence of noisy labels. Existing methods typically consider small-loss samples as correctly labeled. However, some correctly labeled samples are inherently difficult for the model to learn and can exhibit high loss similar to mislabeled samples in the early stages of training. Consequently, setting a threshold on per-sample loss to select correct labels results in a trade-off between precision and recall in sample selection: a lower threshold may miss many correctly labeled hard-to-learn samples (low recall), while a higher threshold may include many mislabeled samples (low precision). To address this issue, our goal is to accurately distinguish correctly labeled yet hard-to-learn samples from mislabeled ones, thus alleviating the trade-off dilemma. We achieve this by considering the trends in model prediction confidence rather than relying solely on loss values. Empirical observations show that only for correctly labeled samples, the model's prediction confidence for the annotated labels typically increases faster than for any other classes. Based on this insight, we propose tracking the confidence gaps between the annotated labels and other classes during training and evaluating their trends using the Mann-Kendall Test. A sample is considered potentially correctly labeled if all its confidence gaps tend to increase. Our method functions as a plug-and-play component that can be seamlessly integrated into existing sample selection techniques. Experiments on several standard benchmarks and real-world datasets demonstrate that our method enhances the performance of existing methods for learning with noisy labels.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17474",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.910017Z"
  },
  {
    "id": "9d150ffdcd7b1919497080745bad98c6",
    "title": "Plasticine: Accelerating Research in Plasticity-Motivated Deep Reinforcement Learning",
    "slug": "plasticine:-accelerating-research-in-plasticity-motivated-deep-reinforcement-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Mingqi Yuan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Developing lifelong learning agents is crucial for artificial general intelligence. However, deep reinforcement learning (RL) systems often suffer from plasticity loss, where neural networks gradually lose their ability to adapt during training. Despite its significance, this field lacks unified benchmarks and evaluation protocols. We introduce Plasticine, the first open-source framework for benchmarking plasticity optimization in deep RL. Plasticine provides single-file implementations of over 13 mitigation methods, 10 evaluation metrics, and learning scenarios with increasing non-stationarity levels from standard to open-ended environments. This framework enables researchers to systematically quantify plasticity loss, evaluate mitigation strategies, and analyze plasticity dynamics across different contexts. Our documentation, examples, and source code are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17490",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.910268Z"
  },
  {
    "id": "7c282a4b228de505b66331d407f17535",
    "title": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design",
    "slug": "goal-oriented-time-series-forecasting:-foundation-framework-design",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Luca-Andrei Fechete",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Traditional time-series forecasting often focuses only on minimizing prediction errors, ignoring the specific requirements of real-world applications that employ them. This paper presents a new training methodology, which allows a forecasting model to dynamically adjust its focus based on the importance of forecast ranges specified by the end application. Unlike previous methods that fix these ranges beforehand, our training approach breaks down predictions over the entire signal range into smaller segments, which are then dynamically weighted and combined to produce accurate forecasts. We tested our method on standard datasets, including a new dataset from wireless communication, and found that not only it improves prediction accuracy but also improves the performance of end application employing the forecasting model. This research provides a basis for creating forecasting systems that better connect prediction and decision-making in various practical applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17493",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.910484Z"
  },
  {
    "id": "af1f43cada66e22dabff0ab8aea9acd8",
    "title": "Combining GCN Structural Learning with LLM Chemical Knowledge for or Enhanced Virtual Screening",
    "slug": "combining-gcn-structural-learning-with-llm-chemical-knowledge-for-or-enhanced-virtual-screening",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Radia Berreziga",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Virtual screening plays a critical role in modern drug discovery by enabling the identification of promising candidate molecules for experimental validation. Traditional machine learning methods such as support vector machines (SVM) and XGBoost rely on predefined molecular representations, often leading to information loss and potential bias. In contrast, deep learning approaches-particularly Graph Convolutional Networks (GCNs)-offer a more expressive and unbiased alternative by operating directly on molecular graphs. Meanwhile, Large Language Models (LLMs) have recently demonstrated state-of-the-art performance in drug design, thanks to their capacity to capture complex chemical patterns from large-scale data via attention mechanisms.\nIn this paper, we propose a hybrid architecture that integrates GCNs with LLM-derived embeddings to combine localized structural learning with global chemical knowledge. The LLM embeddings can be precomputed and stored in a molecular feature library, removing the need to rerun the LLM during training or inference and thus maintaining computational efficiency. We found that concatenating the LLM embeddings after each GCN layer-rather than only at the final layer-significantly improves performance, enabling deeper integration of global context throughout the network. The resulting model achieves superior results, with an F1-score of (88.8%), outperforming standalone GCN (87.9%), XGBoost (85.5%), and SVM (85.4%) baselines.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17497",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.910704Z"
  },
  {
    "id": "c878159597f2fa1e6ef92b149ff66411",
    "title": "TACO: Tackling Over-correction in Federated Learning with Tailored Adaptive Correction",
    "slug": "taco:-tackling-over-correction-in-federated-learning-with-tailored-adaptive-correction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Weijie Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Non-independent and identically distributed (Non-IID) data across edge clients have long posed significant challenges to federated learning (FL) training in edge computing environments. Prior works have proposed various methods to mitigate this statistical heterogeneity. While these works can achieve good theoretical performance, in this work we provide the first investigation into a hidden over-correction phenomenon brought by the uniform model correction coefficients across clients adopted by existing methods. Such over-correction could degrade model performance and even cause failures in model convergence. To address this, we propose TACO, a novel algorithm that addresses the non-IID nature of clients' data by implementing fine-grained, client-specific gradient correction and model aggregation, steering local models towards a more accurate global optimum. Moreover, we verify that leading FL algorithms generally have better model accuracy in terms of communication rounds rather than wall-clock time, resulting from their extra computation overhead imposed on clients. To enhance the training efficiency, TACO deploys a lightweight model correction and tailored aggregation approach that requires minimum computation overhead and no extra information beyond the synchronized model parameters. To validate TACO's effectiveness, we present the first FL convergence analysis that reveals the root cause of over-correction. Extensive experiments across various datasets confirm TACO's superior and stable performance in practice.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17528",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.911138Z"
  },
  {
    "id": "5c41330d0bba75b3f42ea6d973fe2344",
    "title": "Learning Isometric Embeddings of Road Networks using Multidimensional Scaling",
    "slug": "learning-isometric-embeddings-of-road-networks-using-multidimensional-scaling",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Juan Carlos Climent Pardo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The lack of generalization in learning-based autonomous driving applications is shown by the narrow range of road scenarios that vehicles can currently cover. A generalizable approach should capture many distinct road structures and topologies, as well as consider traffic participants, and dynamic changes in the environment, so that vehicles can navigate and perform motion planning tasks even in the most difficult situations. Designing suitable feature spaces for neural network-based motion planers that encapsulate all kinds of road scenarios is still an open research challenge. This paper tackles this learning-based generalization challenge and shows how graph representations of road networks can be leveraged by using multidimensional scaling (MDS) techniques in order to obtain such feature spaces. State-of-the-art graph representations and MDS approaches are analyzed for the autonomous driving use case. Finally, the option of embedding graph nodes is discussed in order to perform easier learning procedures and obtain dimensionality reduction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17534",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.911349Z"
  },
  {
    "id": "324daa7f0f478d3d80334fd5ce9e501a",
    "title": "Proof of Useful Intelligence (PoUI): Blockchain Consensus Beyond Energy Waste",
    "slug": "proof-of-useful-intelligence-(poui):-blockchain-consensus-beyond-energy-waste",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Zan-Kai Chong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Blockchain technology enables secure, transparent data management in decentralized systems, supporting applications from cryptocurrencies like Bitcoin to tokenizing real-world assets like property. Its scalability and sustainability hinge on consensus mechanisms balancing security and efficiency. Proof of Work (PoW), used by Bitcoin, ensures security through energy-intensive computations but demands significant resources. Proof of Stake (PoS), as in Ethereum post-Merge, selects validators based on staked cryptocurrency, offering energy efficiency but risking centralization from wealth concentration. With AI models straining computational resources, we propose Proof of Useful Intelligence (PoUI), a hybrid consensus mechanism. In PoUI, workers perform AI tasks like language processing or image analysis to earn coins, which are staked to secure the network, blending security with practical utility. Decentralized nodes--job posters, market coordinators, workers, and validators --collaborate via smart contracts to manage tasks and rewards.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17539",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:13.911577Z"
  },
  {
    "id": "d3b342d0e4b04e4528452d4b81a1bade",
    "title": "An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm",
    "slug": "an-explainable-nature-inspired-framework-for-monkeypox-diagnosis:-xception-features-combined-with-ngboost-and-african-vultures-optimization-algorithm",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ahmadreza Shateri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The recent global spread of monkeypox, particularly in regions where it has not historically been prevalent, has raised significant public health concerns. Early and accurate diagnosis is critical for effective disease management and control. In response, this study proposes a novel deep learning-based framework for the automated detection of monkeypox from skin lesion images, leveraging the power of transfer learning, dimensionality reduction, and advanced machine learning techniques. We utilize the newly developed Monkeypox Skin Lesion Dataset (MSLD), which includes images of monkeypox, chickenpox, and measles, to train and evaluate our models. The proposed framework employs the Xception architecture for deep feature extraction, followed by Principal Component Analysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting (NGBoost) algorithm for classification. To optimize the model's performance and generalization, we introduce the African Vultures Optimization Algorithm (AVOA) for hyperparameter tuning, ensuring efficient exploration of the parameter space. Our results demonstrate that the proposed AVOA-NGBoost model achieves state-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72% and an AUC of 97.47%. Additionally, we enhance model interpretability using Grad-CAM and LIME techniques, providing insights into the decision-making process and highlighting key features influencing classification. This framework offers a highly precise and efficient diagnostic tool, potentially aiding healthcare providers in early detection and diagnosis, particularly in resource-constrained environments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17540",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.911797Z"
  },
  {
    "id": "e80919fb73e6ee66f6e9b4b83b686dde",
    "title": "HalluLens: LLM Hallucination Benchmark",
    "slug": "hallulens:-llm-hallucination-benchmark",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yejin Bang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) often generate responses that deviate from user input or training data, a phenomenon known as \"hallucination.\" These hallucinations undermine user trust and hinder the adoption of generative AI systems. Addressing hallucinations is essential for the advancement of LLMs. This paper introduces a comprehensive hallucination benchmark, incorporating both new extrinsic and existing intrinsic evaluation tasks, built upon clear taxonomy of hallucination. A major challenge in benchmarking hallucinations is the lack of a unified framework due to inconsistent definitions and categorizations. We disentangle LLM hallucination from \"factuality,\" proposing a clear taxonomy that distinguishes between extrinsic and intrinsic hallucinations, to promote consistency and facilitate research. Extrinsic hallucinations, where the generated content is not consistent with the training data, are increasingly important as LLMs evolve. Our benchmark includes dynamic test set generation to mitigate data leakage and ensure robustness against such leakage. We also analyze existing benchmarks, highlighting their limitations and saturation. The work aims to: (1) establish a clear taxonomy of hallucinations, (2) introduce new extrinsic hallucination tasks, with data that can be dynamically regenerated to prevent saturation by leakage, (3) provide a comprehensive analysis of existing benchmarks, distinguishing them from factuality evaluations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17550",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.912038Z"
  },
  {
    "id": "9651dbc157c840ef90337997a3db7a68",
    "title": "Unsupervised Urban Land Use Mapping with Street View Contrastive Clustering and a Geographical Prior",
    "slug": "unsupervised-urban-land-use-mapping-with-street-view-contrastive-clustering-and-a-geographical-prior",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Lin Che",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Urban land use classification and mapping are critical for urban planning, resource management, and environmental monitoring. Existing remote sensing techniques often lack precision in complex urban environments due to the absence of ground-level details. Unlike aerial perspectives, street view images provide a ground-level view that captures more human and social activities relevant to land use in complex urban scenes. Existing street view-based methods primarily rely on supervised classification, which is challenged by the scarcity of high-quality labeled data and the difficulty of generalizing across diverse urban landscapes. This study introduces an unsupervised contrastive clustering model for street view images with a built-in geographical prior, to enhance clustering performance. When combined with a simple visual assignment of the clusters, our approach offers a flexible and customizable solution to land use mapping, tailored to the specific needs of urban planners. We experimentally show that our method can generate land use maps from geotagged street view image datasets of two cities. As our methodology relies on the universal spatial coherence of geospatial data (\"Tobler's law\"), it can be adapted to various settings where street view images are available, to enable scalable, unsupervised land use mapping and updating. The code will be available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17551",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.912306Z"
  },
  {
    "id": "6de23002ebad47cc72d7032bd74fefd4",
    "title": "STCL:Curriculum learning Strategies for deep learning image steganography models",
    "slug": "stcl:curriculum-learning-strategies-for-deep-learning-image-steganography-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Fengchun Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Aiming at the problems of poor quality of steganographic images and slow network convergence of image steganography models based on deep learning, this paper proposes a Steganography Curriculum Learning training strategy (STCL) for deep learning image steganography models. So that only easy images are selected for training when the model has poor fitting ability at the initial stage, and gradually expand to more difficult images, the strategy includes a difficulty evaluation strategy based on the teacher model and an knee point-based training scheduling strategy. Firstly, multiple teacher models are trained, and the consistency of the quality of steganographic images under multiple teacher models is used as the difficulty score to construct the training subsets from easy to difficult. Secondly, a training control strategy based on knee points is proposed to reduce the possibility of overfitting on small training sets and accelerate the training process. Experimental results on three large public datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed image steganography scheme is able to improve the model performance under multiple algorithmic frameworks, which not only has a high PSNR, SSIM score, and decoding accuracy, but also the steganographic images generated by the model under the training of the STCL strategy have a low steganography analysis scores. You can find our code at \\href{this https URL}{this https URL}.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17609",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.912610Z"
  },
  {
    "id": "be015d14f19ed9f82fe0932801fc2362",
    "title": "Decentralized Time Series Classification with ROCKET Features",
    "slug": "decentralized-time-series-classification-with-rocket-features",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Bruno Casella",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Time series classification (TSC) is a critical task with applications in various domains, including healthcare, finance, and industrial monitoring. Due to privacy concerns and data regulations, Federated Learning has emerged as a promising approach for learning from distributed time series data without centralizing raw information. However, most FL solutions rely on a client-server architecture, which introduces robustness and confidentiality risks related to the distinguished role of the server, which is a single point of failure and can observe knowledge extracted from clients. To address these challenges, we propose DROCKS, a fully decentralized FL framework for TSC that leverages ROCKET (RandOm Convolutional KErnel Transform) features. In DROCKS, the global model is trained by sequentially traversing a structured path across federation nodes, where each node refines the model and selects the most effective local kernels before passing them to the successor. Extensive experiments on the UCR archive demonstrate that DROCKS outperforms state-of-the-art client-server FL approaches while being more resilient to node failures and malicious attacks. Our code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17617",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.912832Z"
  },
  {
    "id": "920c700b3be1fc3137f6946bb6b3a889",
    "title": "Enhancing CNNs robustness to occlusions with bioinspired filters for border completion",
    "slug": "enhancing-cnns-robustness-to-occlusions-with-bioinspired-filters-for-border-completion",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Catarina P. Coutinho",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We exploit the mathematical modeling of the visual cortex mechanism for border completion to define custom filters for CNNs. We see a consistent improvement in performance, particularly in accuracy, when our modified LeNet 5 is tested with occluded MNIST images.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17619",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.913065Z"
  },
  {
    "id": "c45f85cc3b1ffacc7b5d1fab63856c88",
    "title": "Deciphering the unique dynamic activation pathway in a G protein-coupled receptor enables unveiling biased signaling and identifying cryptic allosteric sites in conformational intermediates",
    "slug": "deciphering-the-unique-dynamic-activation-pathway-in-a-g-protein-coupled-receptor-enables-unveiling-biased-signaling-and-identifying-cryptic-allosteric-sites-in-conformational-intermediates",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Biomolecules (q-bio.BM)",
    "author": {
      "name": "Jigang Fan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Neurotensin receptor 1 (NTSR1), a member of the Class A G protein-coupled receptor superfamily, plays an important role in modulating dopaminergic neuronal activity and eliciting opioid-independent analgesia. Recent studies suggest that promoting \\{beta}-arrestin-biased signaling in NTSR1 may diminish drugs of abuse, such as psychostimulants, thereby offering a potential avenue for treating human addiction-related disorders. In this study, we utilized a novel computational and experimental approach that combined nudged elastic band-based molecular dynamics simulations, Markov state models, temporal communication network analysis, site-directed mutagenesis, and conformational biosensors, to explore the intricate mechanisms underlying NTSR1 activation and biased signaling. Our study reveals a dynamic stepwise transition mechanism and activated transmission network associated with NTSR1 activation. It also yields valuable insights into the complex interplay between the unique polar network, non-conserved ion locks, and aromatic clusters in NTSR1 signaling. Moreover, we identified a cryptic allosteric site located in the intracellular region of the receptor that exists in an intermediate state within the activation pathway. Collectively, these findings contribute to a more profound understanding of NTSR1 activation and biased signaling at the atomic level, thereby providing a potential strategy for the development of NTSR1 allosteric modulators in the realm of G protein-coupled receptor biology, biophysics, and medicine.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17624",
    "tags": [
      "Biomolecules (q-bio.BM)"
    ],
    "createdAt": "2025-04-25T15:49:13.913300Z"
  },
  {
    "id": "50ea81f47d17c12bcd660a242374743c",
    "title": "PTCL: Pseudo-Label Temporal Curriculum Learning for Label-Limited Dynamic Graph",
    "slug": "ptcl:-pseudo-label-temporal-curriculum-learning-for-label-limited-dynamic-graph",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Shengtao Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dynamic node classification is critical for modeling evolving systems like financial transactions and academic collaborations. In such systems, dynamically capturing node information changes is critical for dynamic node classification, which usually requires all labels at every timestamp. However, it is difficult to collect all dynamic labels in real-world scenarios due to high annotation costs and label uncertainty (e.g., ambiguous or delayed labels in fraud detection). In contrast, final timestamp labels are easier to obtain as they rely on complete temporal patterns and are usually maintained as a unique label for each user in many open platforms, without tracking the history data. To bridge this gap, we propose PTCL(Pseudo-label Temporal Curriculum Learning), a pioneering method addressing label-limited dynamic node classification where only final labels are available. PTCL introduces: (1) a temporal decoupling architecture separating the backbone (learning time-aware representations) and decoder (strictly aligned with final labels), which generate pseudo-labels, and (2) a Temporal Curriculum Learning strategy that prioritizes pseudo-labels closer to the final timestamp by assigning them higher weights using an exponentially decaying function. We contribute a new academic dataset (CoOAG), capturing long-range research interest in dynamic graph. Experiments across real-world scenarios demonstrate PTCL's consistent superiority over other methods adapted to this task. Beyond methodology, we propose a unified framework FLiD (Framework for Label-Limited Dynamic Node Classification), consisting of a complete preparation workflow, training pipeline, and evaluation standards, and supporting various models and datasets. The code can be found at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17641",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.913557Z"
  },
  {
    "id": "2635971a1de91b76163a038a7737c2ac",
    "title": "Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction",
    "slug": "aerial-image-classification-in-scarce-and-unconstrained-environments-via-conformal-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Farhad Pourkamali-Anaraki",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper presents a comprehensive empirical analysis of conformal prediction methods on a challenging aerial image dataset featuring diverse events in unconstrained environments. Conformal prediction is a powerful post-hoc technique that takes the output of any classifier and transforms it into a set of likely labels, providing a statistical guarantee on the coverage of the true label. Unlike evaluations on standard benchmarks, our study addresses the complexities of data-scarce and highly variable real-world settings. We investigate the effectiveness of leveraging pretrained models (MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to generate informative prediction sets. To further evaluate the impact of calibration, we consider two parallel pipelines (with and without temperature scaling) and assess performance using two key metrics: empirical coverage and average prediction set size. This setup allows us to systematically examine how calibration choices influence the trade-off between reliability and efficiency. Our findings demonstrate that even with relatively small labeled samples and simple nonconformity scores, conformal prediction can yield valuable uncertainty estimates for complex tasks. Moreover, our analysis reveals that while temperature scaling is often employed for calibration, it does not consistently lead to smaller prediction sets, underscoring the importance of careful consideration in its application. Furthermore, our results highlight the significant potential of model compression techniques within the conformal prediction pipeline for deployment in resource-constrained environments. Based on our observations, we advocate for future research to delve into the impact of noisy or ambiguous labels on conformal prediction performance and to explore effective model reduction strategies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17655",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.913763Z"
  },
  {
    "id": "f59a73ac5f7a1c1cf8533819a23c1814",
    "title": "The Malicious Technical Ecosystem: Exposing Limitations in Technical Governance of AI-Generated Non-Consensual Intimate Images of Adults",
    "slug": "the-malicious-technical-ecosystem:-exposing-limitations-in-technical-governance-of-ai-generated-non-consensual-intimate-images-of-adults",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Michelle L. Ding",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we adopt a survivor-centered approach to locate and dissect the role of sociotechnical AI governance in preventing AI-Generated Non-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as \"deep fake pornography.\" We identify a \"malicious technical ecosystem\" or \"MTE,\" comprising of open-source face-swapping models and nearly 200 \"nudifying\" software programs that allow non-technical users to create AIG-NCII within minutes. Then, using the National Institute of Standards and Technology (NIST) AI 100-4 report as a reflection of current synthetic content governance methods, we show how the current landscape of practices fails to effectively regulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining these gaps.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17663",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:13.913960Z"
  },
  {
    "id": "e4860845f7589c31593effe503de8db7",
    "title": "Towards a HIPAA Compliant Agentic AI System in Healthcare",
    "slug": "towards-a-hipaa-compliant-agentic-ai-system-in-healthcare",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multiagent Systems (cs.MA)",
    "author": {
      "name": "Subash Neupane",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Agentic AI systems powered by Large Language Models (LLMs) as their foundational reasoning engine, are transforming clinical workflows such as medical report generation and clinical summarization by autonomously analyzing sensitive healthcare data and executing decisions with minimal human oversight. However, their adoption demands strict compliance with regulatory frameworks such as Health Insurance Portability and Accountability Act (HIPAA), particularly when handling Protected Health Information (PHI). This work-in-progress paper introduces a HIPAA-compliant Agentic AI framework that enforces regulatory compliance through dynamic, context-aware policy enforcement. Our framework integrates three core mechanisms: (1) Attribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid PHI sanitization pipeline combining regex patterns and BERT-based model to minimize leakage, and (3) immutable audit trails for compliance verification.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17669",
    "tags": [
      "Multiagent Systems (cs.MA)"
    ],
    "createdAt": "2025-04-25T15:49:13.914166Z"
  },
  {
    "id": "e4946c543be26d06ee1041396e7cb55b",
    "title": "Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction",
    "slug": "data-driven-calibration-of-prediction-sets-in-large-vision-language-models-based-on-inductive-conformal-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yuanchang Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study addresses the critical challenge of hallucination mitigation in Large Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks through a Split Conformal Prediction (SCP) framework. While LVLMs excel in multi-modal reasoning, their outputs often exhibit hallucinated content with high confidence, posing risks in safety-critical applications. We propose a model-agnostic uncertainty quantification method that integrates dynamic threshold calibration and cross-modal consistency verification. By partitioning data into calibration and test sets, the framework computes nonconformity scores to construct prediction sets with statistical guarantees under user-defined risk levels ($\\alpha$). Key innovations include: (1) rigorous control of \\textbf{marginal coverage} to ensure empirical error rates remain strictly below $\\alpha$; (2) dynamic adjustment of prediction set sizes inversely with $\\alpha$, filtering low-confidence outputs; (3) elimination of prior distribution assumptions and retraining requirements. Evaluations on benchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces theoretical guarantees across all $\\alpha$ values. The framework achieves stable performance across varying calibration-to-test split ratios, underscoring its robustness for real-world deployment in healthcare, autonomous systems, and other safety-sensitive domains. This work bridges the gap between theoretical reliability and practical applicability in multi-modal AI systems, offering a scalable solution for hallucination detection and uncertainty-aware decision-making.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17671",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.914357Z"
  },
  {
    "id": "43023b7952993df88720cc062665876e",
    "title": "Optimized Cloud Resource Allocation Using Genetic Algorithms for Energy Efficiency and QoS Assurance",
    "slug": "optimized-cloud-resource-allocation-using-genetic-algorithms-for-energy-efficiency-and-qos-assurance",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Caroline Panggabean",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Cloud computing environments demand dynamic and efficient resource management to ensure optimal performance, reduced energy consumption, and adherence to Service Level Agreements (SLAs). This paper presents a Genetic Algorithm (GA)-based approach for Virtual Machine (VM) placement and consolidation, aiming to minimize power usage while maintaining QoS constraints. The proposed method dynamically adjusts VM allocation based on real-time workload variations, outperforming traditional heuristics such as First Fit Decreasing (FFD) and Best Fit Decreasing (BFD). Experimental results show notable reductions in energy consumption, VM migrations, SLA violation rates, and execution time. A correlation heatmap further illustrates strong relationships among these key performance indicators, confirming the effectiveness of our approach in optimizing cloud resource utilization.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17675",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:13.914571Z"
  },
  {
    "id": "70f37e125d011dfc1631df211b2d8b3c",
    "title": "INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models",
    "slug": "insight:-bridging-the-student-teacher-gap-in-times-of-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Jarne Thys",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rise of AI, especially Large Language Models, presents challenges and opportunities to integrate such technology into the classroom. AI has the potential to revolutionize education by helping teaching staff with various tasks, such as personalizing their teaching methods, but it also raises concerns, for example, about the degradation of student-teacher interactions and user privacy. This paper introduces INSIGHT, a proof of concept to combine various AI tools to assist teaching staff and students in the process of solving exercises. INSIGHT has a modular design that allows it to be integrated into various higher education courses. We analyze students' questions to an LLM by extracting keywords, which we use to dynamically build an FAQ from students' questions and provide new insights for the teaching staff to use for more personalized face-to-face support. Future work could build upon INSIGHT by using the collected data to provide adaptive learning and adjust content based on student progress and learning styles to offer a more interactive and inclusive learning experience.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17677",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:13.914779Z"
  },
  {
    "id": "1d580e9eb2e2dbc7c5c0c50794b143ec",
    "title": "Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks",
    "slug": "ensemble-bayesian-inference:-leveraging-small-language-models-to-achieve-llm-level-accuracy-in-profile-matching-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Haru-Tada Sato",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study explores the potential of small language model(SLM) ensembles to achieve accuracy comparable to proprietary large language models (LLMs). We propose Ensemble Bayesian Inference (EBI), a novel approach that applies Bayesian estimation to combine judgments from multiple SLMs, allowing them to exceed the performance limitations of individual models. Our experiments on diverse tasks(aptitude assessments and consumer profile analysis in both Japanese and English) demonstrate EBI's effectiveness. Notably, we analyze cases where incorporating models with negative Lift values into ensembles improves overall performance, and we examine the method's efficacy across different languages. These findings suggest new possibilities for constructing high-performance AI systems with limited computational resources and for effectively utilizing models with individually lower performance. Building on existing research on LLM performance evaluation, ensemble methods, and open-source LLM utilization, we discuss the novelty and significance of our approach.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17685",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.914991Z"
  },
  {
    "id": "f2f6206e1bec64239909b8ba0adcbc74",
    "title": "Hierarchical and Multimodal Data for Daily Activity Understanding",
    "slug": "hierarchical-and-multimodal-data-for-daily-activity-understanding",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ghazal Kaviani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Daily Activity Recordings for Artificial Intelligence (DARai, pronounced \"Dahr-ree\") is a multimodal, hierarchically annotated dataset constructed to understand human activities in real-world settings. DARai consists of continuous scripted and unscripted recordings of 50 participants in 10 different environments, totaling over 200 hours of data from 20 sensors including multiple camera views, depth and radar sensors, wearable inertial measurement units (IMUs), electromyography (EMG), insole pressure sensors, biomonitor sensors, and gaze tracker.\nTo capture the complexity in human activities, DARai is annotated at three levels of hierarchy: (i) high-level activities (L1) that are independent tasks, (ii) lower-level actions (L2) that are patterns shared between activities, and (iii) fine-grained procedures (L3) that detail the exact execution steps for actions. The dataset annotations and recordings are designed so that 22.7% of L2 actions are shared between L1 activities and 14.2% of L3 procedures are shared between L2 actions. The overlap and unscripted nature of DARai allows counterfactual activities in the dataset.\nExperiments with various machine learning models showcase the value of DARai in uncovering important challenges in human-centered applications. Specifically, we conduct unimodal and multimodal sensor fusion experiments for recognition, temporal localization, and future action anticipation across all hierarchical annotation levels. To highlight the limitations of individual sensors, we also conduct domain-variant experiments that are enabled by DARai's multi-sensor and counterfactual activity design setup.\nThe code, documentation, and dataset are available at the dedicated DARai website: this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17696",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.915213Z"
  },
  {
    "id": "b82347b232de122fc17469cca1512e4a",
    "title": "Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence",
    "slug": "federated-learning:-a-survey-on-privacy-preserving-collaborative-intelligence",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Edward Collins",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Federated Learning (FL) has emerged as a transformative paradigm in the field of distributed machine learning, enabling multiple clients such as mobile devices, edge nodes, or organizations to collaboratively train a shared global model without the need to centralize sensitive data. This decentralized approach addresses growing concerns around data privacy, security, and regulatory compliance, making it particularly attractive in domains such as healthcare, finance, and smart IoT systems. This survey provides a concise yet comprehensive overview of Federated Learning, beginning with its core architecture and communication protocol. We discuss the standard FL lifecycle, including local training, model aggregation, and global updates. A particular emphasis is placed on key technical challenges such as handling non-IID (non-independent and identically distributed) data, mitigating system and hardware heterogeneity, reducing communication overhead, and ensuring privacy through mechanisms like differential privacy and secure aggregation. Furthermore, we examine emerging trends in FL research, including personalized FL, cross-device versus cross-silo settings, and integration with other paradigms such as reinforcement learning and quantum computing. We also highlight real-world applications and summarize benchmark datasets and evaluation metrics commonly used in FL research. Finally, we outline open research problems and future directions to guide the development of scalable, efficient, and trustworthy FL systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17703",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.915424Z"
  },
  {
    "id": "182c3cbcc707fe2798ce9e787fc69389",
    "title": "Early Detection of Multidrug Resistance Using Multivariate Time Series Analysis and Interpretable Patient-Similarity Representations",
    "slug": "early-detection-of-multidrug-resistance-using-multivariate-time-series-analysis-and-interpretable-patient-similarity-representations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "scar Escudero-Arnanz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Background and Objectives: Multidrug Resistance (MDR) is a critical global health issue, causing increased hospital stays, healthcare costs, and mortality. This study proposes an interpretable Machine Learning (ML) framework for MDR prediction, aiming for both accurate inference and enhanced explainability.\nMethods: Patients are modeled as Multivariate Time Series (MTS), capturing clinical progression and patient-to-patient interactions. Similarity among patients is quantified using MTS-based methods: descriptive statistics, Dynamic Time Warping, and Time Cluster Kernel. These similarity measures serve as inputs for MDR classification via Logistic Regression, Random Forest, and Support Vector Machines, with dimensionality reduction and kernel transformations improving model performance. For explainability, patient similarity networks are constructed from these metrics. Spectral clustering and t-SNE are applied to identify MDR-related subgroups and visualize high-risk clusters, enabling insight into clinically relevant patterns.\nResults: The framework was validated on ICU Electronic Health Records from the University Hospital of Fuenlabrada, achieving an AUC of 81%. It outperforms baseline ML and deep learning models by leveraging graph-based patient similarity. The approach identifies key risk factors -- prolonged antibiotic use, invasive procedures, co-infections, and extended ICU stays -- and reveals clinically meaningful clusters. Code and results are available at \\this https URL.\nConclusions: Patient similarity representations combined with graph-based analysis provide accurate MDR prediction and interpretable insights. This method supports early detection, risk factor identification, and patient stratification, highlighting the potential of explainable ML in critical care.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17717",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.915642Z"
  },
  {
    "id": "1dde0a0b526659cd13fbc6dcefbc86a0",
    "title": "Multilingual Performance Biases of Large Language Models in Education",
    "slug": "multilingual-performance-biases-of-large-language-models-in-education",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Vansh Gupta",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) are increasingly being adopted in educational settings. These applications expand beyond English, though current LLMs remain primarily English-centric. In this work, we ascertain if their use in education settings in non-English languages is warranted. We evaluated the performance of popular LLMs on four educational tasks: identifying student misconceptions, providing targeted feedback, interactive tutoring, and grading translations in six languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to English. We find that the performance on these tasks somewhat corresponds to the amount of language represented in training data, with lower-resource languages having poorer task performance. Although the models perform reasonably well in most languages, the frequent performance drop from English is significant. Thus, we recommend that practitioners first verify that the LLM works well in the target language for their educational task before deployment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17720",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.915857Z"
  },
  {
    "id": "dc9a31365368682e8f2c2609ae63dd10",
    "title": "Conformal Segmentation in Industrial Surface Defect Detection with Statistical Guarantees",
    "slug": "conformal-segmentation-in-industrial-surface-defect-detection-with-statistical-guarantees",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Cheng Shen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In industrial settings, surface defects on steel can significantly compromise its service life and elevate potential safety risks. Traditional defect detection methods predominantly rely on manual inspection, which suffers from low efficiency and high costs. Although automated defect detection approaches based on Convolutional Neural Networks(e.g., Mask R-CNN) have advanced rapidly, their reliability remains challenged due to data annotation uncertainties during deep model training and overfitting issues. These limitations may lead to detection deviations when processing the given new test samples, rendering automated detection processes unreliable. To address this challenge, we first evaluate the detection model's practical performance through calibration data that satisfies the independent and identically distributed (i.i.d) condition with test data. Specifically, we define a loss function for each calibration sample to quantify detection error rates, such as the complement of recall rate and false discovery rate. Subsequently, we derive a statistically rigorous threshold based on a user-defined risk level to identify high-probability defective pixels in test images, thereby constructing prediction sets (e.g., defect regions). This methodology ensures that the expected error rate (mean error rate) on the test set remains strictly bounced by the predefined risk level. Additionally, we observe a negative correlation between the average prediction set size and the risk level on the test set, establishing a statistically rigorous metric for assessing detection model uncertainty. Furthermore, our study demonstrates robust and efficient control over the expected test set error rate across varying calibration-to-test partitioning ratios, validating the method's adaptability and operational effectiveness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17721",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.916074Z"
  },
  {
    "id": "5e9d323dc8d0bb34133562bb1cf2adba",
    "title": "Revisiting Reset Mechanisms in Spiking Neural Networks for Sequential Modeling: Specialized Discretization for Binary Activated RNN",
    "slug": "revisiting-reset-mechanisms-in-spiking-neural-networks-for-sequential-modeling:-specialized-discretization-for-binary-activated-rnn",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "Enqi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the field of image recognition, spiking neural networks (SNNs) have achieved performance comparable to conventional artificial neural networks (ANNs). In such applications, SNNs essentially function as traditional neural networks with quantized activation values. This article focuses on an another alternative perspective,viewing SNNs as binary-activated recurrent neural networks (RNNs) for sequential modeling this http URL this viewpoint, current SNN architectures face several fundamental challenges in sequence modeling: (1) Traditional models lack effective memory mechanisms for long-range sequence modeling; (2) The biological-inspired components in SNNs (such as reset mechanisms and refractory period applications) remain theoretically under-explored for sequence tasks; (3) The RNN-like computational paradigm in SNNs prevents parallel training across different this http URL address these challenges, this study conducts a systematic analysis of the fundamental mechanisms underlying reset operations and refractory periods in binary-activated RNN-based SNN sequence models. We re-examine whether such biological mechanisms are strictly necessary for generating sparse spiking patterns, provide new theoretical explanations and insights, and ultimately propose the fixed-refractory-period SNN architecture for sequence modeling.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17751",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:13.916268Z"
  },
  {
    "id": "92105dc5bd3557801fdb82e6e2d2ae41",
    "title": "Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control",
    "slug": "integrating-learning-based-manipulation-and-physics-based-locomotion-for-whole-body-badminton-robot-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Haochen Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Learning-based methods, such as imitation learning (IL) and reinforcement learning (RL), can produce excel control policies over challenging agile robot tasks, such as sports robot. However, no existing work has harmonized learning-based policy with model-based methods to reduce training complexity and ensure the safety and stability for agile badminton robot control. In this paper, we introduce \\ourmethod, a novel hybrid control system for agile badminton robots. Specifically, we propose a model-based strategy for chassis locomotion which provides a base for arm policy. We introduce a physics-informed ``IL+RL'' training framework for learning-based arm policy. In this train framework, a model-based strategy with privileged information is used to guide arm policy training during both IL and RL phases. In addition, we train the critic model during IL phase to alleviate the performance drop issue when transitioning from IL to RL. We present results on our self-engineered badminton robot, achieving 94.5% success rate against the serving machine and 90.7% success rate against human players. Our system can be easily generalized to other agile mobile manipulation tasks such as agile catching and table tennis. Our project website: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17771",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:13.916501Z"
  },
  {
    "id": "fb55b6fbe118dd8379de091a00fdce31",
    "title": "Learning Type-Generalized Actions for Symbolic Planning",
    "slug": "learning-type-generalized-actions-for-symbolic-planning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Daniel Tanneberg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Symbolic planning is a powerful technique to solve complex tasks that require long sequences of actions and can equip an intelligent agent with complex behavior. The downside of this approach is the necessity for suitable symbolic representations describing the state of the environment as well as the actions that can change it. Traditionally such representations are carefully hand-designed by experts for distinct problem domains, which limits their transferability to different problems and environment complexities. In this paper, we propose a novel concept to generalize symbolic actions using a given entity hierarchy and observed similar behavior. In a simulated grid-based kitchen environment, we show that type-generalized actions can be learned from few observations and generalize to novel situations. Incorporating an additional on-the-fly generalization mechanism during planning, unseen task combinations, involving longer sequences, novel entities and unexpected environment behavior, can be solved.",
    "pdfUrl": "https://arxiv.org/pdf/2308.04867",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.916711Z"
  },
  {
    "id": "5405afc71bcccbffc23d58e7d8cc19c6",
    "title": "Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning",
    "slug": "unlocking-large-language-model's-planning-capabilities-with-maximum-diversity-fine-tuning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Wenjun Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) have demonstrated impressive task-solving capabilities through prompting techniques and system designs, including solving planning tasks (e.g., math proofs, basic travel planning) when sufficient data is available online and used during pre-training. However, for planning tasks with limited prior data (e.g., blocks world, advanced travel planning), the performance of LLMs, including proprietary models like GPT and Gemini, is poor. This paper investigates the impact of fine-tuning on the planning capabilities of LLMs, revealing that LLMs can achieve strong performance in planning through substantial (tens of thousands of specific examples) fine-tuning. Yet, this process incurs high economic, time, and computational costs for each planning problem variation. To address this, we propose Clustering-Based Maximum Diversity Sampling (CMDS), which selects diverse and representative data to enhance sample efficiency and the model's generalization capability. Extensive evaluations demonstrate that CMDS-l, a baseline method combining CMDS with language embeddings, outperforms random sampling. Furthermore, we introduce a novel algorithm, CMDS-g, which encodes planning task instances with their graph representations into the embedding space. Empirical results show that CMDS-g consistently outperforms baseline methods across various scales and multiple benchmark domains.",
    "pdfUrl": "https://arxiv.org/pdf/2406.10479",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.916921Z"
  },
  {
    "id": "f592fc44b77c2f7fb05712b37f0b281f",
    "title": "Feature-to-Image Data Augmentation: Improving Model Feature Extraction with Cluster-Guided Synthetic Samples",
    "slug": "feature-to-image-data-augmentation:-improving-model-feature-extraction-with-cluster-guided-synthetic-samples",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Yasaman Haghbin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "One of the growing trends in machine learning is the use of data generation techniques, since the performance of machine learning models is dependent on the quantity of the training dataset. However, in many real-world applications, particularly in medical and low-resource domains, collecting large datasets is challenging due to resource constraints, which leads to overfitting and poor generalization. This study introduces FICAug, a novel feature-to-image data augmentation framework designed to improve model generalization under limited data conditions by generating structured synthetic samples.\nFICAug first operates in the feature space, where original data are clustered using the k-means algorithm. Within pure-label clusters, synthetic data are generated through Gaussian sampling to increase diversity while maintaining label consistency. These synthetic features are then projected back into the image domain using a generative neural network, and a convolutional neural network is trained on the reconstructed images to learn enhanced representations.\nExperimental results demonstrate that FICAug significantly improves classification accuracy. In feature space, it achieved a cross-validation accuracy of 84.09%, while training a ResNet-18 model on the reconstructed images further boosted performance to 88.63%, illustrating the effectiveness of the proposed framework in extracting new and task-relevant features.",
    "pdfUrl": "https://arxiv.org/pdf/2409.17685",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.917147Z"
  },
  {
    "id": "c668c3606cbccc4c874d104e79fb54dd",
    "title": "Enhancing LLMs with Smart Preprocessing for EHR Analysis",
    "slug": "enhancing-llms-with-smart-preprocessing-for-ehr-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Yixiang Qu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency in natural language processing; however, their application in sensitive domains such as healthcare, especially in processing Electronic Health Records (EHRs), is constrained by limited computational resources and privacy concerns. This paper introduces a compact LLM framework optimized for local deployment in environments with stringent privacy requirements and restricted access to high-performance GPUs. Our approach leverages simple yet powerful preprocessing techniques, including regular expressions (regex) and Retrieval-Augmented Generation (RAG), to extract and highlight critical information from clinical notes. By pre-filtering long, unstructured text, we enhance the performance of smaller LLMs on EHR-related tasks. Our framework is evaluated using zero-shot and few-shot learning paradigms on both private and publicly available datasets (MIMIC-IV), with additional comparisons against fine-tuned LLMs on MIMIC-IV. Experimental results demonstrate that our preprocessing strategy significantly supercharges the performance of smaller LLMs, making them well-suited for privacy-sensitive and resource-constrained applications. This study offers valuable insights into optimizing LLM performance for local, secure, and efficient healthcare applications. It provides practical guidance for real-world deployment for LLMs while tackling challenges related to privacy, computational feasibility, and clinical applicability.",
    "pdfUrl": "https://arxiv.org/pdf/2412.02868",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.917376Z"
  },
  {
    "id": "529fa6f2f5cac0c4b11c07225d490693",
    "title": "Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and Editable Policies",
    "slug": "neural-dnf-mt:-a-neuro-symbolic-approach-for-learning-interpretable-and-editable-policies",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Kexin Gu Baugh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Although deep reinforcement learning has been shown to be effective, the model's black-box nature presents barriers to direct policy interpretation. To address this problem, we propose a neuro-symbolic approach called neural DNF-MT for end-to-end policy learning. The differentiable nature of the neural DNF-MT model enables the use of deep actor-critic algorithms for training. At the same time, its architecture is designed so that trained models can be directly translated into interpretable policies expressed as standard (bivalent or probabilistic) logic programs. Moreover, additional layers can be included to extract abstract features from complex observations, acting as a form of predicate invention. The logic representations are highly interpretable, and we show how the bivalent representations of deterministic policies can be edited and incorporated back into a neural model, facilitating manual intervention and adaptation of learned policies. We evaluate our approach on a range of tasks requiring learning deterministic or stochastic behaviours from various forms of observations. Our empirical results show that our neural DNF-MT model performs at the level of competing black-box methods whilst providing interpretable policies.",
    "pdfUrl": "https://arxiv.org/pdf/2501.03888",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.917589Z"
  },
  {
    "id": "4bc1576379d550192ed099a6eb1733d9",
    "title": "Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?",
    "slug": "are-transformers-able-to-reason-by-connecting-separated-knowledge-in-training-data?",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Yutong Yin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Humans exhibit remarkable compositional reasoning by integrating knowledge from various sources. For example, if someone learns ( B = f(A) ) from one source and ( C = g(B) ) from another, they can deduce ( C=g(B)=g(f(A)) ) even without encountering ( ABC ) together, showcasing the generalization ability of human intelligence. In this paper, we introduce a synthetic learning task, \"FTCT\" (Fragmented at Training, Chained at Testing), to validate the potential of Transformers in replicating this skill and interpret its inner mechanism. In the training phase, data consist of separated knowledge fragments from an overall causal graph. During testing, Transformers must infer complete causal graph traces by integrating these fragments. Our findings demonstrate that few-shot Chain-of-Thought prompting enables Transformers to perform compositional reasoning on FTCT by revealing correct combinations of fragments, even if such combinations were absent in the training data. Furthermore, the emergence of compositional reasoning ability is strongly correlated with the model complexity and training-testing data similarity. We propose, both theoretically and empirically, that Transformers learn an underlying generalizable program from training, enabling effective compositional reasoning during testing.",
    "pdfUrl": "https://arxiv.org/pdf/2501.15857",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.917800Z"
  },
  {
    "id": "fc42f900d06fb051584c45d57b80c28d",
    "title": "Engineering Artificial Intelligence: Framework, Challenges, and Future Direction",
    "slug": "engineering-artificial-intelligence:-framework,-challenges,-and-future-direction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Jay Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Over the past ten years, the application of artificial intelligence (AI) and machine learning (ML) in engineering domains has gained significant popularity, showcasing their potential in data-driven contexts. However, the complexity and diversity of engineering problems often require the development of domain-specific AI approaches, which are frequently hindered by a lack of systematic methodologies, scalability, and robustness during the development process. To address this gap, this paper introduces the \"ABCDE\" as the key elements of Engineering AI and proposes a unified, systematic engineering AI ecosystem framework, including eight essential layers, along with attributes, goals, and applications, to guide the development and deployment of AI solutions for specific engineering needs. Additionally, key challenges are examined, and eight future research directions are highlighted. By providing a comprehensive perspective, this paper aims to advance the strategic implementation of AI, fostering the development of next-generation engineering AI solutions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.02269",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.918011Z"
  },
  {
    "id": "e2d0942fe2d442f4813d5b418ac6b736",
    "title": "TALES: Text Adventure Learning Environment Suite",
    "slug": "tales:-text-adventure-learning-environment-suite",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Christopher Zhang Cui",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reasoning is an essential skill to enable Large Language Models (LLMs) to interact with the world. As tasks become more complex, they demand increasingly sophisticated and diverse reasoning capabilities for sequential decision-making, requiring structured reasoning over the context history to determine the next best action. We introduce TALES, a diverse collection of synthetic and human-written text-adventure games designed to challenge and evaluate diverse reasoning capabilities. We present results over a range of LLMs, open- and closed-weights, performing a qualitative analysis on the top performing models. Despite an impressive showing on synthetic games, even the top LLM-driven agents fail to achieve 15% on games designed for human enjoyment. Code and visualization of the experiments can be found at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14128",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.918237Z"
  },
  {
    "id": "2e5284c0b9b9471edbe687a8db12d383",
    "title": "KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments",
    "slug": "keydiff:-key-similarity-based-kv-cache-eviction-for-long-context-llm-inference-in-resource-constrained-environments",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Junyoung Park",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, we demonstrate that distinctive keys during LLM inference tend to have high attention scores. We explore this phenomenon and propose KeyDiff, a training-free KV cache eviction method based on key similarity. This method facilitates the deployment of LLM-based application requiring long input prompts in resource-constrained environments with limited memory and compute budgets. Unlike other KV cache eviction methods, KeyDiff can process arbitrarily long prompts within strict resource constraints and efficiently generate responses. We demonstrate that KeyDiff computes the optimal solution to a KV cache selection problem that maximizes key diversity, providing a theoretical understanding of KeyDiff. Notably,KeyDiff does not rely on attention scores, allowing the use of optimized attention mechanisms like FlashAttention. We demonstrate the effectiveness of KeyDiff across diverse tasks and models, illustrating a performance gap of less than 0.04\\% with 8K cache budget ($\\sim$ 23\\% KV cache reduction) from the non-evicting baseline on the LongBench benchmark for Llama 3.1-8B and Llama 3.2-3B.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15364",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.918465Z"
  },
  {
    "id": "c61bc19a57ef23af6da61ad0c54706b2",
    "title": "Impact of Noise on LLM-Models Performance in Abstraction and Reasoning Corpus (ARC) Tasks with Model Temperature Considerations",
    "slug": "impact-of-noise-on-llm-models-performance-in-abstraction-and-reasoning-corpus-(arc)-tasks-with-model-temperature-considerations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Nikhil Khandalkar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advancements in Large Language Models (LLMs) have generated growing interest in their structured reasoning capabilities, particularly in tasks involving abstraction and pattern recognition. The Abstraction and Reasoning Corpus (ARC) benchmark plays a crucial role in evaluating these capabilities by testing how well AI models generalize to novel problems. While GPT-4o demonstrates strong performance by solving all ARC tasks under zero-noise conditions, other models like DeepSeek R1 and LLaMA 3.2 fail to solve any, suggesting limitations in their ability to reason beyond simple pattern matching. To explore this gap, we systematically evaluate these models across different noise levels and temperature settings. Our results reveal that the introduction of noise consistently impairs model performance, regardless of architecture. This decline highlights a shared vulnerability: current LLMs, despite showing signs of abstract reasoning, remain highly sensitive to input perturbations. Such fragility raises concerns about their real-world applicability, where noise and uncertainty are common. By comparing how different model architectures respond to these challenges, we offer insights into the structural weaknesses of modern LLMs in reasoning tasks. This work underscores the need for developing more robust and adaptable AI systems capable of handling the ambiguity and variability inherent in real-world scenarios. Our findings aim to guide future research toward enhancing model generalization, robustness, and alignment with human-like cognitive flexibility.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15903",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:13.918678Z"
  },
  {
    "id": "3a431d9aa63140eeb2449e4da7538057",
    "title": "CoPAL: Corrective Planning of Robot Actions with Large Language Models",
    "slug": "copal:-corrective-planning-of-robot-actions-with-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Frank Joublin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the pursuit of fully autonomous robotic systems capable of taking over tasks traditionally performed by humans, the complexity of open-world environments poses a considerable challenge. Addressing this imperative, this study contributes to the field of Large Language Models (LLMs) applied to task and motion planning for robots. We propose a system architecture that orchestrates a seamless interplay between multiple cognitive levels, encompassing reasoning, planning, and motion generation. At its core lies a novel replanning strategy that handles physically grounded, logical, and semantic errors in the generated plans. We demonstrate the efficacy of the proposed feedback architecture, particularly its impact on executability, correctness, and time complexity via empirical evaluation in the context of a simulation and two intricate real-world scenarios: blocks world, barman and pizza preparation.",
    "pdfUrl": "https://arxiv.org/pdf/2310.07263",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:13.918921Z"
  },
  {
    "id": "c561b9c0a76b9bb1d9d9a1650c38df48",
    "title": "Learning by Doing: An Online Causal Reinforcement Learning Framework with Causal-Aware Policy",
    "slug": "learning-by-doing:-an-online-causal-reinforcement-learning-framework-with-causal-aware-policy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ruichu Cai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As a key component to intuitive cognition and reasoning solutions in human intelligence, causal knowledge provides great potential for reinforcement learning (RL) agents' interpretability towards decision-making by helping reduce the searching space. However, there is still a considerable gap in discovering and incorporating causality into RL, which hinders the rapid development of causal RL. In this paper, we consider explicitly modeling the generation process of states with the causal graphical model, based on which we augment the policy. We formulate the causal structure updating into the RL interaction process with active intervention learning of the environment. To optimize the derived objective, we propose a framework with theoretical performance guarantees that alternates between two steps: using interventions for causal structure learning during exploration and using the learned causal structure for policy guidance during exploitation. Due to the lack of public benchmarks that allow direct intervention in the state space, we design the root cause localization task in our simulated fault alarm environment and then empirically show the effectiveness and robustness of the proposed method against state-of-the-art baselines. Theoretical analysis shows that our performance improvement attributes to the virtuous cycle of causal-guided policy learning and causal structure learning, which aligns with our experimental results. Codes are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2402.04869",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.919153Z"
  },
  {
    "id": "ecf9f47480b4de39e95a39749e236475",
    "title": "Effective Bayesian Causal Inference via Structural Marginalisation and Autoregressive Orders",
    "slug": "effective-bayesian-causal-inference-via-structural-marginalisation-and-autoregressive-orders",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Christian Toth",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The traditional two-stage approach to causal inference first identifies a single causal model (or equivalence class of models), which is then used to answer causal queries. However, this neglects any epistemic model uncertainty. In contrast, Bayesian causal inference does incorporate epistemic uncertainty into query estimates via Bayesian marginalisation (posterior averaging) over all causal models. While principled, this marginalisation over entire causal models, i.e., both causal structures (graphs) and mechanisms, poses a tremendous computational challenge. In this work, we address this challenge by decomposing structure marginalisation into the marginalisation over (i) causal orders and (ii) directed acyclic graphs (DAGs) given an order. We can marginalise the latter in closed form by limiting the number of parents per variable and utilising Gaussian processes to model mechanisms. To marginalise over orders, we use a sampling-based approximation, for which we devise a novel auto-regressive distribution over causal orders (ARCO). Our method outperforms state-of-the-art in structure learning on simulated non-linear additive noise benchmarks, and yields competitive results on real-world data. Furthermore, we can accurately infer interventional distributions and average causal effects.",
    "pdfUrl": "https://arxiv.org/pdf/2402.14781",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.919365Z"
  },
  {
    "id": "0298596107039ec7b8d990dee004f936",
    "title": "Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An Application for MxIF Oncology Data",
    "slug": "towards-spatially-lucid-ai-classification-in-non-euclidean-space:-an-application-for-mxif-oncology-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Majid Farhadloo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Given multi-category point sets from different place-types, our goal is to develop a spatially-lucid classifier that can distinguish between two classes based on the arrangements of their points. This problem is important for many applications, such as oncology, for analyzing immune-tumor relationships and designing new immunotherapies. It is challenging due to spatial variability and interpretability needs. Previously proposed techniques require dense training data or have limited ability to handle significant spatial variability within a single place-type. Most importantly, these deep neural network (DNN) approaches are not designed to work in non-Euclidean space, particularly point sets. Existing non-Euclidean DNN methods are limited to one-size-fits-all approaches. We explore a spatial ensemble framework that explicitly uses different training strategies, including weighted-distance learning rate and spatial domain adaptation, on various place-types for spatially-lucid classification. Experimental results on real-world datasets (e.g., MxIF oncology data) show that the proposed framework provides higher prediction accuracy than baseline methods.",
    "pdfUrl": "https://arxiv.org/pdf/2402.14974",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:13.919583Z"
  },
  {
    "id": "236c42ab71895b68c52db612fa522b4c",
    "title": "To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions",
    "slug": "to-help-or-not-to-help:-llm-based-attentive-support-for-human-robot-group-interactions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Daniel Tanneberg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "How can a robot provide unobtrusive physical support within a group of humans? We present Attentive Support, a novel interaction concept for robots to support a group of humans. It combines scene perception, dialogue acquisition, situation understanding, and behavior generation with the common-sense reasoning capabilities of Large Language Models (LLMs). In addition to following user instructions, Attentive Support is capable of deciding when and how to support the humans, and when to remain silent to not disturb the group. With a diverse set of scenarios, we show and evaluate the robot's attentive behavior, which supports and helps the humans when required, while not disturbing if no help is needed.",
    "pdfUrl": "https://arxiv.org/pdf/2403.12533",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:13.919808Z"
  },
  {
    "id": "44d56ae073cd2a51570a62bf6c7a3a25",
    "title": "AI in Lung Health: Benchmarking Detection and Diagnostic Models Across Multiple CT Scan Datasets",
    "slug": "ai-in-lung-health:-benchmarking-detection-and-diagnostic-models-across-multiple-ct-scan-datasets",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Fakrul Islam Tushar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Lung cancer remains the leading cause of cancer-related mortality worldwide, and early detection through low-dose computed tomography (LDCT) has shown significant promise in reducing death rates. With the growing integration of artificial intelligence (AI) into medical imaging, the development and evaluation of robust AI models require access to large, well-annotated datasets. In this study, we introduce the utility of Duke Lung Cancer Screening (DLCS) Dataset, the largest open-access LDCT dataset with over 2,000 scans and 3,000 expert-verified nodules. We benchmark deep learning models for both 3D nodule detection and lung cancer classification across internal and external datasets including LUNA16, LUNA25, and NLST-3D+. For detection, we develop two MONAI-based RetinaNet models (DLCSDmD and LUNA16-mD), evaluated using the Competition Performance Metric (CPM). For classification, we compare five models, including state-of-the-art pretrained models (Models Genesis, Med3D), a selfsupervised foundation model (FMCB), a randomly initialized ResNet50, and proposed a novel Strategic Warm-Start++ (SWS++) model. SWS++ uses curated candidate patches to pretrain a classification backbone within the same detection pipeline, enabling task-relevant feature learning. Our models demonstrated strong generalizability, with SWS++ achieving comparable or superior performance to existing foundational models across multiple datasets (AUC: 0.71 to 0.90). All code, models, and data are publicly released to promote reproducibility and collaboration. This work establishes a standardized benchmarking resource for lung cancer AI research, supporting future efforts in model development, validation, and clinical translation.",
    "pdfUrl": "https://arxiv.org/pdf/2405.04605",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.920031Z"
  },
  {
    "id": "b4594a2812d083830bc20a9394099e07",
    "title": "MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation",
    "slug": "mage:-model-level-graph-neural-networks-explanations-via-motif-based-graph-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhaoning Yu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Graph Neural Networks (GNNs) have shown remarkable success in molecular tasks, yet their interpretability remains challenging. Traditional model-level explanation methods like XGNN and GNNInterpreter often fail to identify valid substructures like rings, leading to questionable interpretability. This limitation stems from XGNN's atom-by-atom approach and GNNInterpreter's reliance on average graph embeddings, which overlook the essential structural elements crucial for molecules. To address these gaps, we introduce an innovative \\textbf{M}otif-b\\textbf{A}sed \\textbf{G}NN \\textbf{E}xplainer (MAGE) that uses motifs as fundamental units for generating explanations. Our approach begins with extracting potential motifs through a motif decomposition technique. Then, we utilize an attention-based learning method to identify class-specific motifs. Finally, we employ a motif-based graph generator for each class to create molecular graph explanations based on these class-specific motifs. This novel method not only incorporates critical substructures into the explanations but also guarantees their validity, yielding results that are human-understandable. Our proposed method's effectiveness is demonstrated through quantitative and qualitative assessments conducted on six real-world molecular datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2405.12519",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.920228Z"
  },
  {
    "id": "6971b37c693e7a0cf7739b2e6e666184",
    "title": "On Minimizing Adversarial Counterfactual Error in Adversarial RL",
    "slug": "on-minimizing-adversarial-counterfactual-error-in-adversarial-rl",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Roman Belaire",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deep Reinforcement Learning (DRL) policies are highly susceptible to adversarial noise in observations, which poses significant risks in safety-critical scenarios. The challenge inherent to adversarial perturbations is that by altering the information observed by the agent, the state becomes only partially observable. Existing approaches address this by either enforcing consistent actions across nearby states or maximizing the worst-case value within adversarially perturbed observations. However, the former suffers from performance degradation when attacks succeed, while the latter tends to be overly conservative, leading to suboptimal performance in benign settings. We hypothesize that these limitations stem from their failing to account for partial observability directly. To this end, we introduce a novel objective called Adversarial Counterfactual Error (ACoE), defined on the beliefs about the true state and balancing value optimization with robustness. To make ACoE scalable in model-free settings, we propose the theoretically-grounded surrogate objective Cumulative-ACoE (C-ACoE). Our empirical evaluations on standard benchmarks (MuJoCo, Atari, and Highway) demonstrate that our method significantly outperforms current state-of-the-art approaches for addressing adversarial RL challenges, offering a promising direction for improving robustness in DRL under adversarial conditions. Our code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2406.04724",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.920449Z"
  },
  {
    "id": "a117604ba715486cdfca95fc4752fa08",
    "title": "CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization",
    "slug": "cads:-a-systematic-literature-review-on-the-challenges-of-abstractive-dialogue-summarization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Frederic Kirstein",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Abstractive dialogue summarization is the task of distilling conversations into informative and concise summaries. Although reviews have been conducted on this topic, there is a lack of comprehensive work detailing the challenges of dialogue summarization, unifying the differing understanding of the task, and aligning proposed techniques, datasets, and evaluation metrics with the challenges. This article summarizes the research on Transformer-based abstractive summarization for English dialogues by systematically reviewing 1262 unique research papers published between 2019 and 2024, relying on the Semantic Scholar and DBLP databases. We cover the main challenges present in dialog summarization (i.e., language, structure, comprehension, speaker, salience, and factuality) and link them to corresponding techniques such as graph-based approaches, additional training tasks, and planning strategies, which typically overly rely on BART-based encoder-decoder models. We find that while some challenges, like language, have seen considerable progress, mainly due to training methods, others, such as comprehension, factuality, and salience, remain difficult and hold significant research opportunities. We investigate how these approaches are typically assessed, covering the datasets for the subdomains of dialogue (e.g., meeting, medical), the established automatic metrics and human evaluation approaches for assessing scores and annotator agreement. We observe that only a few datasets span across all subdomains. The ROUGE metric is the most used, while human evaluation is frequently reported without sufficient detail on inner-annotator agreement and annotation guidelines. Additionally, we discuss the possible implications of the recently explored large language models and conclude that despite a potential shift in relevance and difficulty, our described challenge taxonomy remains relevant.",
    "pdfUrl": "https://arxiv.org/pdf/2406.07494",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.920669Z"
  },
  {
    "id": "3ae2c8fff5247109dbf768ec57c56aad",
    "title": "RSEND: Retinex-based Squeeze and Excitation Network with Dark Region Detection for Efficient Low Light Image Enhancement",
    "slug": "rsend:-retinex-based-squeeze-and-excitation-network-with-dark-region-detection-for-efficient-low-light-image-enhancement",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Jingcheng Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Images captured under low-light scenarios often suffer from low quality. Previous CNN-based deep learning methods often involve using Retinex theory. Nevertheless, most of them cannot perform well in more complicated datasets like LOL-v2 while consuming too much computational resources. Besides, some of these methods require sophisticated training at different stages, making the procedure even more time-consuming and tedious. In this paper, we propose a more accurate, concise, and one-stage Retinex theory based framework, RSEND. RSEND first divides the low-light image into the illumination map and reflectance map, then captures the important details in the illumination map and performs light enhancement. After this step, it refines the enhanced gray-scale image and does element-wise matrix multiplication with the reflectance map. By denoising the output it has from the previous step, it obtains the final result. In all the steps, RSEND utilizes Squeeze and Excitation network to better capture the details. Comprehensive quantitative and qualitative experiments show that our Efficient Retinex model significantly outperforms other CNN-based models, achieving a PSNR improvement ranging from 0.44 dB to 4.2 dB in different datasets and even outperforms transformer-based models in the LOL-v2-real dataset.",
    "pdfUrl": "https://arxiv.org/pdf/2406.09656",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.920866Z"
  },
  {
    "id": "add84aa839b3e1eb69df9cc6e03c31be",
    "title": "ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation",
    "slug": "real:-efficient-rlhf-training-of-large-language-models-with-parameter-reallocation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Zhiyu Mei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for empowering large language model (LLM) applications. Compared with the supervised training process of LLMs, the RLHF training process is much more sophisticated, requiring a diverse range of computation workloads with intricate dependencies between multiple LLM instances. Therefore, simply adopting the fixed parallelization strategies from supervised training for LLMs can be insufficient for RLHF and result in low training efficiency. To overcome this limitation, we propose a novel technique named parameter ReaLlocation, which dynamically adapts the parallelization strategies for different workloads during training by redistributing LLM parameters across the training cluster. Building upon this idea, we introduce ReaL, a pioneering system for efficient RLHF training. ReaL introduces the concept of an execution plan, which defines a fine-grained resource allocation and parallelization strategy particularly designed for RLHF training. Based on this concept, ReaL employs a tailored search algorithm with a lightweight run-time estimator to automatically discover an efficient execution plan for an instance of RLHF experiment. Subsequently, the runtime engine deploys the selected plan by effectively parallelizing computations and redistributing parameters. We evaluate ReaL on the LLaMA models with up to 70 billion parameters and 128 GPUs. The experimental results demonstrate that ReaL achieves speedups of up to $3.58\\times$ compared to baseline methods. Furthermore, the execution plans generated by ReaL exhibit an average of $81\\%$ performance improvement over heuristic approaches based on Megatron-LM in the long-context scenario. The source code of ReaL is publicly available at this https URL .",
    "pdfUrl": "https://arxiv.org/pdf/2406.14088",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:13.921089Z"
  },
  {
    "id": "877a212471b3e2419cdbf4f905b8ec16",
    "title": "Synthetic Lyrics Detection Across Languages and Genres",
    "slug": "synthetic-lyrics-detection-across-languages-and-genres",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yanis Labrak",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In recent years, the use of large language models (LLMs) to generate music content, particularly lyrics, has gained in popularity. These advances provide valuable tools for artists and enhance their creative processes, but they also raise concerns about copyright violations, consumer satisfaction, and content spamming. Previous research has explored content detection in various domains. However, no work has focused on the text modality, lyrics, in music. To address this gap, we curated a diverse dataset of real and synthetic lyrics from multiple languages, music genres, and artists. The generation pipeline was validated using both humans and automated methods. We performed a thorough evaluation of existing synthetic text detection approaches on lyrics, a previously unexplored data type. We also investigated methods to adapt the best-performing features to lyrics through unsupervised domain adaptation. Following both music and industrial constraints, we examined how well these approaches generalize across languages, scale with data availability, handle multilingual language content, and perform on novel genres in few-shot settings. Our findings show promising results that could inform policy decisions around AI-generated music and enhance transparency for users.",
    "pdfUrl": "https://arxiv.org/pdf/2406.15231",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.921296Z"
  },
  {
    "id": "d781c08b5e7716742b51e88e939d58ee",
    "title": "Label-Free Model Failure Detection for Lidar-based Point Cloud Segmentation",
    "slug": "label-free-model-failure-detection-for-lidar-based-point-cloud-segmentation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Daniel Bogdoll",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autonomous vehicles drive millions of miles on the road each year. Under such circumstances, deployed machine learning models are prone to failure both in seemingly normal situations and in the presence of outliers. However, in the training phase, they are only evaluated on small validation and test sets, which are unable to reveal model failures due to their limited scenario coverage. While it is difficult and expensive to acquire large and representative labeled datasets for evaluation, large-scale unlabeled datasets are typically available. In this work, we introduce label-free model failure detection for lidar-based point cloud segmentation, taking advantage of the abundance of unlabeled data available. We leverage different data characteristics by training a supervised and self-supervised stream for the same task to detect failure modes. We perform a large-scale qualitative analysis and present LidarCODA, the first publicly available dataset with labeled anomalies in real-world lidar data, for an extensive quantitative analysis.",
    "pdfUrl": "https://arxiv.org/pdf/2407.14306",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:13.921511Z"
  },
  {
    "id": "a025d8badf7212fe6105ba6aa0b2d9bd",
    "title": "Diffusion Models Are Real-Time Game Engines",
    "slug": "diffusion-models-are-real-time-game-engines",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Dani Valevski",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present GameNGen, the first game engine powered entirely by a neural model that also enables real-time interaction with a complex environment over long trajectories at high quality. When trained on the classic game DOOM, GameNGen extracts gameplay and uses it to generate a playable environment that can interactively simulate new trajectories. GameNGen runs at 20 frames per second on a single TPU and remains stable over extended multi-minute play sessions. Next frame prediction achieves a PSNR of 29.4, comparable to lossy JPEG compression. Human raters are only slightly better than random chance at distinguishing short clips of the game from clips of the simulation, even after 5 minutes of auto-regressive generation. GameNGen is trained in two phases: (1) an RL-agent learns to play the game and the training sessions are recorded, and (2) a diffusion model is trained to produce the next frame, conditioned on the sequence of past frames and actions. Conditioning augmentations help ensure stable auto-regressive generation over long trajectories, and decoder fine-tuning improves the fidelity of visual details and text.",
    "pdfUrl": "https://arxiv.org/pdf/2408.14837",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.921728Z"
  },
  {
    "id": "f417315e9599a57daae8d0992244bc30",
    "title": "On the Benefits of Memory for Modeling Time-Dependent PDEs",
    "slug": "on-the-benefits-of-memory-for-modeling-time-dependent-pdes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ricardo Buitrago Ruiz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Data-driven techniques have emerged as a promising alternative to traditional numerical methods for solving PDEs. For time-dependent PDEs, many approaches are Markovian -- the evolution of the trained system only depends on the current state, and not the past states. In this work, we investigate the benefits of using memory for modeling time-dependent PDEs: that is, when past states are explicitly used to predict the future. Motivated by the Mori-Zwanzig theory of model reduction, we theoretically exhibit examples of simple (even linear) PDEs, in which a solution that uses memory is arbitrarily better than a Markovian solution. Additionally, we introduce Memory Neural Operator (MemNO), a neural operator architecture that combines recent state space models (specifically, S4) and Fourier Neural Operators (FNOs) to effectively model memory. We empirically demonstrate that when the PDEs are supplied in low resolution or contain observation noise at train and test time, MemNO significantly outperforms the baselines without memory -- with up to 6x reduction in test error. Furthermore, we show that this benefit is particularly pronounced when the PDE solutions have significant high-frequency Fourier modes (e.g., low-viscosity fluid dynamics) and we construct a challenging benchmark dataset consisting of such PDEs.",
    "pdfUrl": "https://arxiv.org/pdf/2409.02313",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.921929Z"
  },
  {
    "id": "e71d71f02fcfb5980be89c74cfde3af6",
    "title": "Lab-AI: Using Retrieval Augmentation to Enhance Language Models for Personalized Lab Test Interpretation in Clinical Medicine",
    "slug": "lab-ai:-using-retrieval-augmentation-to-enhance-language-models-for-personalized-lab-test-interpretation-in-clinical-medicine",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Xiaoyu Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate interpretation of lab results is crucial in clinical medicine, yet most patient portals use universal normal ranges, ignoring conditional factors like age and gender. This study introduces Lab-AI, an interactive system that offers personalized normal ranges using retrieval-augmented generation (RAG) from credible health sources. Lab-AI has two modules: factor retrieval and normal range retrieval. We tested these on 122 lab tests: 40 with conditional factors and 82 without. For tests with factors, normal ranges depend on patient-specific information. Our results show GPT-4-turbo with RAG achieved a 0.948 F1 score for factor retrieval and 0.995 accuracy for normal range retrieval. GPT-4-turbo with RAG outperformed the best non-RAG system by 33.5% in factor retrieval and showed 132% and 100% improvements in question-level and lab-level performance, respectively, for normal range retrieval. These findings highlight Lab-AI's potential to enhance patient understanding of lab results.",
    "pdfUrl": "https://arxiv.org/pdf/2409.18986",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.922152Z"
  },
  {
    "id": "5d1c7f6359549070c6f5b7226891b16e",
    "title": "nGPT: Normalized Transformer with Representation Learning on the Hypersphere",
    "slug": "ngpt:-normalized-transformer-with-representation-learning-on-the-hypersphere",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ilya Loshchilov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a novel neural network architecture, the normalized Transformer (nGPT) with representation learning on the hypersphere. In nGPT, all vectors forming the embeddings, MLP, attention matrices and hidden states are unit norm normalized. The input stream of tokens travels on the surface of a hypersphere, with each layer contributing a displacement towards the target output predictions. These displacements are defined by the MLP and attention blocks, whose vector components also reside on the same hypersphere. Experiments show that nGPT learns much faster, reducing the number of training steps required to achieve the same accuracy by a factor of 4 to 20, depending on the sequence length.",
    "pdfUrl": "https://arxiv.org/pdf/2410.01131",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.922355Z"
  },
  {
    "id": "b222b309bb003b987f0dafcb3bb21174",
    "title": "Selective Attention Improves Transformer",
    "slug": "selective-attention-improves-transformer",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yaniv Leviathan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Unneeded elements in the attention's context degrade performance. We introduce Selective Attention, a simple parameter-free change to the standard attention mechanism which reduces attention to unneeded elements. Selective attention consistently improves language modeling and downstream task performance in a variety of model sizes and context lengths. For example, transformers trained with the language modeling objective on C4 with selective attention perform language modeling equivalently to standard transformers with ~2X more heads and parameters in their attention modules. Selective attention also allows decreasing the size of the attention's context buffer, leading to meaningful reductions in the memory and compute requirements during inference. For example, transformers trained on C4 with context sizes of 512, 1,024, and 2,048 need 16X, 25X, and 47X less memory for their attention module, respectively, when equipped with selective attention, as those without selective attention, with the same validation perplexity.",
    "pdfUrl": "https://arxiv.org/pdf/2410.02703",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.922564Z"
  },
  {
    "id": "96ae566923927b2406029800a8f9cad3",
    "title": "Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF",
    "slug": "regressing-the-relative-future:-efficient-policy-optimization-for-multi-turn-rlhf",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhaolin Gao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) have achieved remarkable success at tasks like summarization that involve a single turn of interaction. However, they can still struggle with multi-turn tasks like dialogue that require long-term planning. Previous works on multi-turn dialogue extend single-turn reinforcement learning from human feedback (RLHF) methods to the multi-turn setting by treating all prior dialogue turns as a long context. Such approaches suffer from covariate shift: the conversations in the training set have previous turns generated by some reference policy, which means that low training error may not necessarily correspond to good performance when the learner is actually in the conversation loop. In response, we introduce REgressing the RELative FUture (REFUEL), an efficient policy optimization approach designed to address multi-turn RLHF in LLMs. REFUEL employs a single model to estimate $Q$-values and trains on self-generated data, addressing the covariate shift issue. REFUEL frames the multi-turn RLHF problem as a sequence of regression tasks on iteratively collected datasets, enabling ease of implementation. Theoretically, we prove that REFUEL can match the performance of any policy covered by the training set. Empirically, we evaluate our algorithm by using Llama-3.1-70B-it to simulate a user in conversation with our model. REFUEL consistently outperforms state-of-the-art methods such as DPO and REBEL across various settings. Furthermore, despite having only 8 billion parameters, Llama-3-8B-it fine-tuned with REFUEL outperforms Llama-3.1-70B-it on long multi-turn dialogues. Implementation of REFUEL can be found at this https URL, and models trained by REFUEL can be found at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2410.04612",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.922784Z"
  },
  {
    "id": "c74582cc6c72813c46774517ac1fd281",
    "title": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation",
    "slug": "post-hoc-study-of-climate-microtargeting-on-social-media-ads-with-llms:-thematic-insights-and-fairness-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Tunazzina Islam",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Climate change communication on social media increasingly employs microtargeting strategies to effectively reach and influence specific demographic groups. This study presents a post-hoc analysis of microtargeting practices within climate campaigns by leveraging large language models (LLMs) to examine Facebook advertisements. Our analysis focuses on two key aspects: demographic targeting and fairness. We evaluate the ability of LLMs to accurately predict the intended demographic targets, such as gender and age group, achieving an overall accuracy of 88.55%. Furthermore, we instruct the LLMs to generate explanations for their classifications, providing transparent reasoning behind each decision. These explanations reveal the specific thematic elements used to engage different demographic segments, highlighting distinct strategies tailored to various audiences. Our findings show that young adults are primarily targeted through messages emphasizing activism and environmental consciousness, while women are engaged through themes related to caregiving roles and social advocacy. In addition to evaluating the effectiveness of LLMs in detecting microtargeted messaging, we conduct a comprehensive fairness analysis to identify potential biases in model predictions. Our findings indicate that while LLMs perform well overall, certain biases exist, particularly in the classification of senior citizens and male audiences. By showcasing the efficacy of LLMs in dissecting and explaining targeted communication strategies and by highlighting fairness concerns, this study provides a valuable framework for future research aimed at enhancing transparency, accountability, and inclusivity in social media-driven climate campaigns.",
    "pdfUrl": "https://arxiv.org/pdf/2410.05401",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.922980Z"
  },
  {
    "id": "aa93147ada402e6a7ea36ffc8ecf5678",
    "title": "Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies",
    "slug": "parameter-efficient-fine-tuning-in-large-models:-a-survey-of-methodologies",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Luping Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The large models, as predicted by scaling raw forecasts, have made groundbreaking progress in many fields, particularly in natural language generation tasks, where they have approached or even surpassed human levels. However, the unprecedented scale of their parameters brings significant computational and storage costs. These large models require substantial computational resources and GPU memory to operate. When adapting large models to specific downstream tasks, their massive parameter scale poses a significant challenge in fine-tuning on hardware platforms with limited computational power and GPU memory. To address this issue, Parameter-Efficient Fine-Tuning (PEFT) offers a practical solution by efficiently adjusting the parameters of large pre-trained models to suit various downstream tasks. Specifically, PEFT adjusts the parameters of pre-trained large models to adapt to specific tasks or domains, minimizing the introduction of additional parameters and the computational resources required. This review mainly introduces the preliminary knowledge of PEFT, the core ideas and principles of various PEFT algorithms, the applications of PEFT, and potential future research directions. By reading this review, we believe that interested parties can quickly grasp the PEFT methodology, thereby accelerating its development and innovation.",
    "pdfUrl": "https://arxiv.org/pdf/2410.19878",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.923194Z"
  },
  {
    "id": "e21b3ba91ca69fa3bed8001569de3637",
    "title": "A Simple and Efficient Approach to Batch Bayesian Optimization",
    "slug": "a-simple-and-efficient-approach-to-batch-bayesian-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Dawei Zhan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Extending Bayesian optimization to batch evaluation can enable the designer to make the most use of parallel computing technology. However, most of current batch approaches do not scale well with the batch size. That is, their performances deteriorate dramatically as the batch size increases. To address this issue, we propose a simple and efficient approach to extend Bayesian optimization to large-scale batch evaluation in this work. Different from existing batch approaches, the idea of the new approach is to draw a batch of axis-aligned subspaces of the original problem and select one acquisition point from each subspace. To achieve this, we propose the expected subspace improvement criterion to measure the amount of the improvement that a candidate point can achieve within a certain axis-aligned subspace. By optimizing these expected subspace improvement functions simultaneously, we can get a batch of query points for parallel evaluation. Numerical experiments show that our proposed approach can speedup the convergence significantly when compared with the sequential Bayesian optimization algorithm, and performs very competitively when compared with seven batch Bayesian optimization algorithms. A Matlab implementation of the proposed approach is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2411.16206",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.923400Z"
  },
  {
    "id": "143127003becc76d28022b904d971d31",
    "title": "Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification",
    "slug": "neuro-symbolic-evaluation-of-text-to-video-models-using-formal-verification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "S. P. Sharan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advancements in text-to-video models such as Sora, Gen-3, MovieGen, and CogVideoX are pushing the boundaries of synthetic video generation, with adoption seen in fields like robotics, autonomous driving, and entertainment. As these models become prevalent, various metrics and benchmarks have emerged to evaluate the quality of the generated videos. However, these metrics emphasize visual quality and smoothness, neglecting temporal fidelity and text-to-video alignment, which are crucial for safety-critical applications. To address this gap, we introduce NeuS-V, a novel synthetic video evaluation metric that rigorously assesses text-to-video alignment using neuro-symbolic formal verification techniques. Our approach first converts the prompt into a formally defined Temporal Logic (TL) specification and translates the generated video into an automaton representation. Then, it evaluates the text-to-video alignment by formally checking the video automaton against the TL specification. Furthermore, we present a dataset of temporally extended prompts to evaluate state-of-the-art video generation models against our benchmark. We find that NeuS-V demonstrates a higher correlation by over 5x with human evaluations when compared to existing metrics. Our evaluation further reveals that current video generation models perform poorly on these temporally complex prompts, highlighting the need for future work in improving text-to-video generation capabilities.",
    "pdfUrl": "https://arxiv.org/pdf/2411.16718",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.923667Z"
  },
  {
    "id": "a08ef15a12c2c50bcc19963486166e34",
    "title": "Improved implicit diffusion model with knowledge distillation to estimate the spatial distribution density of carbon stock in remote sensing imagery",
    "slug": "improved-implicit-diffusion-model-with-knowledge-distillation-to-estimate-the-spatial-distribution-density-of-carbon-stock-in-remote-sensing-imagery",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhenyu Yu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The forest serves as the most significant terrestrial carbon stock mechanism, effectively reducing atmospheric CO2 concentrations and mitigating climate change. Remote sensing provides high data accuracy and enables large-scale observations. Optical images facilitate long-term monitoring, which is crucial for future carbon stock estimation studies. This study focuses on Huize County, Qujing City, Yunnan Province, China, utilizing GF-1 WFV satellite imagery. The KD-VGG and KD-UNet modules were introduced for initial feature extraction, and the improved implicit diffusion model (IIDM) was proposed. The results showed: (1) The VGG module improved initial feature extraction, improving accuracy, and reducing inference time with optimized model parameters. (2) The Cross-attention + MLPs module enabled effective feature fusion, establishing critical relationships between global and local features, achieving high-accuracy estimation. (3) The IIDM model, a novel contribution, demonstrated the highest estimation accuracy with an RMSE of 12.17%, significantly improving by 41.69% to 42.33% compared to the regression model. In carbon stock estimation, the generative model excelled in extracting deeper features, significantly outperforming other models, demonstrating the feasibility of AI-generated content in quantitative remote sensing. The 16-meter resolution estimates provide a robust basis for tailoring forest carbon sink regulations, enhancing regional carbon stock management.",
    "pdfUrl": "https://arxiv.org/pdf/2411.17973",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.923877Z"
  },
  {
    "id": "a5b50b139f2dd7ae5c81963d4875721b",
    "title": "Know Unreported Roadway Incidents in Real-time: Early Traffic Anomaly Detection",
    "slug": "know-unreported-roadway-incidents-in-real-time:-early-traffic-anomaly-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Haocheng Duan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This research aims to know traffic anomalies as early as possible. A traffic anomaly refers to a generic incident on the road that influences traffic flow and calls for urgent traffic management measures. `Knowing'' the occurrence of a traffic anomaly is twofold: the ability to detect this anomaly before it is reported anywhere, or it may be such that an anomaly can be predicted before it actually occurs on the road (e.g., non-recurrent traffic breakdown). In either way, the objective is to inform traffic operators of unreported incidents in real time and as early as possible. The key is to stay ahead of the curve. Time is of the essence.\nConventional automatic incident detection (AID) methods often struggle with early detection due to their limited consideration of spatial effects and early-stage characteristics. Therefore, we propose a deep learning framework utilizing prior domain knowledge and model-designing strategies. This allows the model to detect a broader range of anomalies, not only incidents that significantly influence traffic flow but also early characteristics of incidents along with historically unreported anomalies. We specially design the model to target the early-stage detection/prediction of an incident. Additionally, unlike most conventional AID studies, our method is highly scalable and generalizable, as it is fully automated with no manual selection of historical reports required, relies solely on widely available low-cost data, and requires no additional detectors. The experimental results across numerous road segments on different maps demonstrate that our model leads to more effective and early anomaly detection.",
    "pdfUrl": "https://arxiv.org/pdf/2412.10892",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.924088Z"
  },
  {
    "id": "d250cfe033373fa7a73556164082e6a9",
    "title": "Less is More: Towards Green Code Large Language Models via Unified Structural Pruning",
    "slug": "less-is-more:-towards-green-code-large-language-models-via-unified-structural-pruning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Guang Yang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The extensive application of Large Language Models (LLMs) in generative coding tasks has raised concerns due to their high computational demands and energy consumption. Unlike previous structural pruning methods designed for classification models that deal with lowdimensional classification logits, generative Code LLMs produce high-dimensional token logit sequences, making traditional pruning objectives inherently limited. Moreover, existing single component pruning approaches further constrain the effectiveness when applied to generative Code LLMs. In response, we propose Flab-Pruner, an innovative unified structural pruning method that combines vocabulary, layer, and Feed-Forward Network (FFN) pruning. This approach effectively reduces model parameters while maintaining performance. Additionally, we introduce a customized code instruction data strategy for coding tasks to enhance the performance recovery efficiency of the pruned model. Through extensive evaluations on three state-of-the-art Code LLMs across multiple generative coding tasks, the results demonstrate that Flab-Pruner retains 97% of the original performance after pruning 22% of the parameters and achieves the same or even better performance after post-training. The pruned models exhibit significant improvements in storage, GPU usage, computational efficiency, and environmental impact, while maintaining well robustness. Our research provides a sustainable solution for green software engineering and promotes the efficient deployment of LLMs in real-world generative coding intelligence applications.",
    "pdfUrl": "https://arxiv.org/pdf/2412.15921",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:13.924337Z"
  },
  {
    "id": "5c0b173898b5c56a7cc25c11e848b81e",
    "title": "Machine Learning-Based Automated Assessment of Intracorporeal Suturing in Laparoscopic Fundoplication",
    "slug": "machine-learning-based-automated-assessment-of-intracorporeal-suturing-in-laparoscopic-fundoplication",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Shekhar Madhav Khairnar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Automated assessment of surgical skills using artificial intelligence (AI) provides trainees with instantaneous feedback. After bimanual tool motions are captured, derived kinematic metrics are reliable predictors of performance in laparoscopic tasks. Implementing automated tool tracking requires time-intensive human annotation. We developed AI-based tool tracking using the Segment Anything Model (SAM) to eliminate the need for human annotators. Here, we describe a study evaluating the usefulness of our tool tracking model in automated assessment during a laparoscopic suturing task in the fundoplication procedure. An automated tool tracking model was applied to recorded videos of Nissen fundoplication on porcine bowel. Surgeons were grouped as novices (PGY1-2) and experts (PGY3-5, attendings). The beginning and end of each suturing step were segmented, and motions of the left and right tools were extracted. A low-pass filter with a 24 Hz cut-off frequency removed noise. Performance was assessed using supervised and unsupervised models, and an ablation study compared results. Kinematic features--RMS velocity, RMS acceleration, RMS jerk, total path length, and Bimanual Dexterity--were extracted and analyzed using Logistic Regression, Random Forest, Support Vector Classifier, and XGBoost. PCA was performed for feature reduction. For unsupervised learning, a Denoising Autoencoder (DAE) model with classifiers, such as a 1-D CNN and traditional models, was trained. Data were extracted for 28 participants (9 novices, 19 experts). Supervised learning with PCA and Random Forest achieved an accuracy of 0.795 and an F1 score of 0.778. The unsupervised 1-D CNN achieved superior results with an accuracy of 0.817 and an F1 score of 0.806, eliminating the need for kinematic feature computation. We demonstrated an AI model capable of automated performance classification, independent of human annotation.",
    "pdfUrl": "https://arxiv.org/pdf/2412.16195",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.924810Z"
  },
  {
    "id": "d0204ed0bf3a02154a3af1d056225975",
    "title": "Emergent Symbol-like Number Variables in Artificial Neural Networks",
    "slug": "emergent-symbol-like-number-variables-in-artificial-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Satchel Grant",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "What types of numeric representations emerge in neural systems? What would a satisfying answer to this question look like? In this work, we interpret Neural Network (NN) solutions to sequence based counting tasks through a variety of lenses. We seek to understand how well we can understand NNs through the lens of interpretable Symbolic Algorithms (SAs), where SAs are defined by precise, abstract, mutable variables used to perform computations. We use GRUs, LSTMs, and Transformers trained using Next Token Prediction (NTP) on numeric tasks where the solutions to the tasks depend on numeric information only latent in the task structure. We show through multiple causal and theoretical methods that we can interpret NN's raw activity through the lens of simplified SAs when we frame the neural activity in terms of interpretable subspaces rather than individual neurons. Depending on the analysis, however, these interpretations can be graded, existing on a continuum, highlighting the philosophical question of what it means to \"interpret\" neural activity, and motivating us to introduce Alignment Functions to add flexibility to the existing Distributed Alignment Search (DAS) method. Through our specific analyses we show the importance of causal interventions for NN interpretability; we show that recurrent models develop graded, symbol-like number variables within their neural activity; we introduce a generalization of DAS to frame NN activity in terms of linear functions of interpretable variables; and we show that Transformers must use anti-Markovian solutions -- solutions that avoid using cumulative, Markovian hidden states -- in the absence of sufficient attention layers. We use our results to encourage interpreting NNs at the level of neural subspaces through the lens of SAs.",
    "pdfUrl": "https://arxiv.org/pdf/2501.06141",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.925065Z"
  },
  {
    "id": "12952f92c4220ff86eca2aa19c3d8bf0",
    "title": "Model Alignment Search",
    "slug": "model-alignment-search",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Satchel Grant",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "When can we say that two neural systems are the same? The answer to this question is goal-dependent, and it is often addressed through correlative methods such as Representational Similarity Analysis (RSA) and Centered Kernel Alignment (CKA). We find ourselves chiefly interested in the relationship between representations and behavior, asking ourselves how we can isolate specific functional aspects of representational similarity to relate our measures to behavior -- avoiding cause vs. correlation pitfalls in the process. In this work, we introduce Model Alignment Search (MAS), a method for causally exploring distributed representational similarity as it relates to behavior. The method learns invertible linear transformations that find an aligned subspace between two distributed networks' representations where functional information can be isolated and manipulated. We first show that the method can be used to transfer values of specific causal variables -- such as the number of items in a counting task -- between networks with different training seeds and different architectures. We then explore open questions in number cognition by comparing different types of numeric representations in models trained on structurally different tasks, we explore differences between MAS and preexisting functional similarity methods, and lastly, we introduce a counterfactual latent auxiliary loss that helps shape functionally relevant alignments even in cases where we do not have causal access to one of the two models for training.",
    "pdfUrl": "https://arxiv.org/pdf/2501.06164",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.925274Z"
  },
  {
    "id": "29a67a3170631971c0db3edf585210d7",
    "title": "Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics",
    "slug": "robotic-world-model:-a-neural-network-simulator-for-robust-policy-optimization-in-robotics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Chenhao Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Learning robust and generalizable world models is crucial for enabling efficient and scalable robotic control in real-world environments. In this work, we introduce a novel framework for learning world models that accurately capture complex, partially observable, and stochastic dynamics. The proposed method employs a dual-autoregressive mechanism and self-supervised training to achieve reliable long-horizon predictions without relying on domain-specific inductive biases, ensuring adaptability across diverse robotic tasks. We further propose a policy optimization framework that leverages world models for efficient training in imagined environments and seamless deployment in real-world systems. This work advances model-based reinforcement learning by addressing the challenges of long-horizon prediction, error accumulation, and sim-to-real transfer. By providing a scalable and robust framework, the introduced methods pave the way for adaptive and efficient robotic systems in real-world applications.",
    "pdfUrl": "https://arxiv.org/pdf/2501.10100",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:13.925485Z"
  },
  {
    "id": "8a9ea7b3f5e46b5d435c76ad2ad9562c",
    "title": "Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data",
    "slug": "spatially-delineated-domain-adapted-ai-classification:-an-application-for-oncology-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Majid Farhadloo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Given multi-type point maps from different place-types (e.g., tumor regions), our objective is to develop a classifier trained on the source place-type to accurately distinguish between two classes of the target place-type based on their point arrangements. This problem is societally important for many applications, such as generating clinical hypotheses for designing new immunotherapies for cancer treatment. The challenge lies in the spatial variability, the inherent heterogeneity and variation observed in spatial properties or arrangements across different locations (i.e., place-types). Previous techniques focus on self-supervised tasks to learn domain-invariant features and mitigate domain differences; however, they often neglect the underlying spatial arrangements among data points, leading to significant discrepancies across different place-types. We explore a novel multi-task self-learning framework that targets spatial arrangements, such as spatial mix-up masking and spatial contrastive predictive coding, for spatially-delineated domain-adapted AI classification. Experimental results on real-world datasets (e.g., oncology data) show that the proposed framework provides higher prediction accuracy than baseline methods.",
    "pdfUrl": "https://arxiv.org/pdf/2501.11695",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.925701Z"
  },
  {
    "id": "7d0bc5b8a54249f4a496b74a95de906f",
    "title": "Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting",
    "slug": "large-image-object-detection-for-fine-grained-recognition-of-punches-patterns-in-medieval-panel-painting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Josh Bruegger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The attribution of the author of an art piece is typically a laborious manual process, usually relying on subjective evaluations of expert figures. However, there are some situations in which quantitative features of the artwork can support these evaluations. The extraction of these features can sometimes be automated, for instance, with the use of Machine Learning (ML) techniques. An example of these features is represented by repeated, mechanically impressed patterns, called punches, present chiefly in 13th and 14th-century panel paintings from Tuscany. Previous research in art history showcased a strong connection between the shapes of punches and specific artists or workshops, suggesting the possibility of using these quantitative cues to support the attribution. In the present work, we first collect a dataset of large-scale images of these panel paintings. Then, using YOLOv10, a recent and popular object detection model, we train a ML pipeline to perform object detection on the punches contained in the images. Due to the large size of the images, the detection procedure is split across multiple frames by adopting a sliding-window approach with overlaps, after which the predictions are combined for the whole image using a custom non-maximal suppression routine. Our results indicate how art historians working in the field can reliably use our method for the identification and extraction of punches.",
    "pdfUrl": "https://arxiv.org/pdf/2501.12489",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.925918Z"
  },
  {
    "id": "a4d651fe7d0b21a6c0c84a1ac9ef75b7",
    "title": "GraphRAG under Fire",
    "slug": "graphrag-under-fire",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jiacheng Liang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "GraphRAG advances retrieval-augmented generation (RAG) by structuring external knowledge as multi-scale knowledge graphs, enabling language models to integrate both broad context and granular details in their generation. While GraphRAG has demonstrated success across domains, its security implications remain largely unexplored. To bridge this gap, this work examines GraphRAG's vulnerability to poisoning attacks, uncovering an intriguing security paradox: compared to conventional RAG, GraphRAG's graph-based indexing and retrieval enhance resilience against simple poisoning attacks; yet, the same features also create new attack surfaces. We present GRAGPoison, a novel attack that exploits shared relations in the underlying knowledge graph to craft poisoning text capable of compromising multiple queries simultaneously. GRAGPoison employs three key strategies: i) relation injection to introduce false knowledge, ii) relation enhancement to amplify poisoning influence, and iii) narrative generation to embed malicious content within coherent text. Empirical evaluation across diverse datasets and models shows that GRAGPoison substantially outperforms existing attacks in terms of effectiveness (up to 98\\% success rate) and scalability (using less than 68\\% poisoning text) on various GraphRAG-based systems. We also explore potential defensive measures and their limitations, identifying promising directions for future research.",
    "pdfUrl": "https://arxiv.org/pdf/2501.14050",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.926141Z"
  },
  {
    "id": "431208a9bfeb0add3c76932d0e5b3aea",
    "title": "Context-Aware Neural Gradient Mapping for Fine-Grained Instruction Processing",
    "slug": "context-aware-neural-gradient-mapping-for-fine-grained-instruction-processing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "David Boldo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The integration of contextual embeddings into the optimization processes of large language models is an advancement in natural language processing. The Context-Aware Neural Gradient Mapping framework introduces a dynamic gradient adjustment mechanism, incorporating contextual embeddings directly into the optimization process. This approach facilitates real-time parameter adjustments, enhancing task-specific generalization even in the presence of sparse or noisy data inputs. The mathematical foundation of this framework relies on gradient descent modifications, where contextual embeddings are derived from a supplementary neural network trained to map input features to optimal adaptation gradients. By employing differential geometry principles, high-dimensional input dependencies are encoded into low-dimensional gradient manifolds, enabling efficient adaptation without necessitating the retraining of the entire model. Empirical evaluations demonstrate that the proposed framework consistently outperforms baseline models across various metrics, including accuracy, robustness to noise, and computational efficiency. The integration of context-specific embeddings allows for a more complex understanding of language, thereby improving the model's ability to handle diverse linguistic phenomena. Furthermore, the computational efficiency achieved through this method demonstrates its scalability for large-scale language models operating under diverse constraints.",
    "pdfUrl": "https://arxiv.org/pdf/2501.14936",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.926358Z"
  },
  {
    "id": "229259ad85197c71b9e2629d37dc072d",
    "title": "Prediction-Powered Inference with Imputed Covariates and Nonuniform Sampling",
    "slug": "prediction-powered-inference-with-imputed-covariates-and-nonuniform-sampling",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Methodology (stat.ME)",
    "author": {
      "name": "Dan M. Kluger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Machine learning models are increasingly used to produce predictions that serve as input data in subsequent statistical analyses. For example, computer vision predictions of economic and environmental indicators based on satellite imagery are used in downstream regressions; similarly, language models are widely used to approximate human ratings and opinions in social science research. However, failure to properly account for errors in the machine learning predictions renders standard statistical procedures invalid. Prior work uses what we call the Predict-Then-Debias estimator to give valid confidence intervals when machine learning algorithms impute missing variables, assuming a small complete sample from the population of interest. We expand the scope by introducing bootstrap confidence intervals that apply when the complete data is a nonuniform (i.e., weighted, stratified, or clustered) sample and to settings where an arbitrary subset of features is imputed. Importantly, the method can be applied to many settings without requiring additional calculations. We prove that these confidence intervals are valid under no assumptions on the quality of the machine learning model and are no wider than the intervals obtained by methods that do not use machine learning predictions.",
    "pdfUrl": "https://arxiv.org/pdf/2501.18577",
    "tags": [
      "Methodology (stat.ME)"
    ],
    "createdAt": "2025-04-25T15:49:13.926575Z"
  },
  {
    "id": "ef02efbec8847e61e8b3fcf5c7907653",
    "title": "Multilingual State Space Models for Structured Question Answering in Indic Languages",
    "slug": "multilingual-state-space-models-for-structured-question-answering-in-indic-languages",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Arpita Vats",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The diversity and complexity of Indic languages present unique challenges for natural language processing (NLP) tasks, particularly in the domain of question answering (QA).To address these challenges, this paper explores the application of State Space Models (SSMs),to build efficient and contextually aware QA systems tailored for Indic languages. SSMs are particularly suited for this task due to their ability to model long-term and short-term dependencies in sequential data, making them well-equipped to handle the rich morphology, complex syntax, and contextual intricacies characteristic of Indian languages. We evaluated multiple SSM architectures across diverse datasets representing various Indic languages and conducted a comparative analysis of their performance. Our results demonstrate that these models effectively capture linguistic subtleties, leading to significant improvements in question interpretation, context alignment, and answer generation. This work represents the first application of SSMs to question answering tasks in Indic languages, establishing a foundational benchmark for future research in this domain. We propose enhancements to existing SSM frameworks, optimizing their applicability to low-resource settings and multilingual scenarios prevalent in Indic languages.",
    "pdfUrl": "https://arxiv.org/pdf/2502.01673",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.926785Z"
  },
  {
    "id": "d5f9d9de22cff93102e0b5be6875bdcf",
    "title": "Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs",
    "slug": "generating-privacy-preserving-personalized-advice-with-zero-knowledge-proofs-and-llms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Hiroki Watanabe",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) are increasingly utilized in domains such as finance, healthcare, and interpersonal relationships to provide advice tailored to user traits and contexts. However, this personalization often relies on sensitive data, raising critical privacy concerns and necessitating data minimization. To address these challenges, we propose a framework that integrates zero-knowledge proof (ZKP) technology, specifically zkVM, with LLM-based chatbots. This integration enables privacy-preserving data sharing by verifying user traits without disclosing sensitive information. Our research introduces both an architecture and a prompting strategy for this approach. Through empirical evaluation, we clarify the current constraints and performance limitations of both zkVM and the proposed prompting strategy, thereby demonstrating their practical feasibility in real-world scenarios.",
    "pdfUrl": "https://arxiv.org/pdf/2502.06425",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:13.927003Z"
  },
  {
    "id": "5e6faf58e830c1ac9012616c8121e35d",
    "title": "Nonasymptotic CLT and Error Bounds for Two-Time-Scale Stochastic Approximation",
    "slug": "nonasymptotic-clt-and-error-bounds-for-two-time-scale-stochastic-approximation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Seo Taek Kong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider linear two-time-scale stochastic approximation algorithms driven by martingale noise. Recent applications in machine learning motivate the need to understand finite-time error rates, but conventional stochastic approximation analysis focus on either asymptotic convergence in distribution or finite-time bounds that are far from optimal. Prior work on asymptotic central limit theorems (CLTs) suggest that two-time-scale algorithms may be able to achieve $1/\\sqrt{n}$ error in expectation, with a constant given by the expected norm of the limiting Gaussian vector. However, the best known finite-time rates are much slower. We derive the first non-asymptotic central limit theorem with respect to the Wasserstein-1 distance for two-time-scale stochastic approximation with Polyak-Ruppert averaging. As a corollary, we show that expected error achieved by Polyak-Ruppert averaging decays at rate $1/\\sqrt{n}$, which significantly improves on the rates of convergence in prior works.",
    "pdfUrl": "https://arxiv.org/pdf/2502.09884",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.927210Z"
  },
  {
    "id": "d2edf207b5e8611c4c05fd6edb58d14d",
    "title": "Towards Reasoning Ability of Small Language Models",
    "slug": "towards-reasoning-ability-of-small-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Gaurav Srivastava",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reasoning has long been viewed as an emergent property of large language models (LLMs), appearing at or above a certain scale ($\\sim$100B parameters). However, recent studies challenge this assumption, showing that small language models (SLMs) can also achieve competitive reasoning performance. SLMs are increasingly favored for their efficiency and deployability. However, there is a lack of systematic study on the reasoning abilities of diverse SLMs, including those trained from scratch or derived from LLMs through quantization, pruning, and distillation. This raises a critical question: Can SLMs achieve reasoning abilities comparable to LLMs? In this work, we systematically survey, benchmark, and analyze 72 SLMs from six model families across 14 reasoning benchmarks. For reliable evaluation, we examine four evaluation methods and compare four LLM judges against human evaluations on 800 data points. We repeat all experiments three times to ensure a robust performance assessment. Additionally, we analyze the impact of different prompting strategies in small models. Beyond accuracy, we also evaluate model robustness under adversarial conditions and intermediate reasoning steps. Our findings challenge the assumption that scaling is the only way to achieve strong reasoning. Instead, we foresee a future where SLMs with strong reasoning capabilities can be developed through structured training or post-training compression. They can serve as efficient alternatives to LLMs for reasoning-intensive tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2502.11569",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.927411Z"
  },
  {
    "id": "b30e7cf48784864708a3694f7c77567c",
    "title": "\"I'm not for sale\" -- Perceptions and limited awareness of privacy risks by digital natives about location data",
    "slug": "\"i'm-not-for-sale\"----perceptions-and-limited-awareness-of-privacy-risks-by-digital-natives-about-location-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Antoine Boutet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Although mobile devices benefit users in their daily lives in numerous ways, they also raise several privacy concerns. For instance, they can reveal sensitive information that can be inferred from location data. This location data is shared through service providers as well as mobile applications. Understanding how and with whom users share their location data -- as well as users' perception of the underlying privacy risks --, are important notions to grasp in order to design usable privacy-enhancing technologies. In this work, we perform a quantitative and qualitative analysis of smartphone users' awareness, perception and self-reported behavior towards location data-sharing through a survey of n=99 young adult participants (i.e., digital natives). We compare stated practices with actual behaviors to better understand their mental models, and survey participants' understanding of privacy risks before and after the inspection of location traces and the information that can be inferred therefrom.\nOur empirical results show that participants have risky privacy practices: about 54% of participants underestimate the number of mobile applications to which they have granted access to their data, and 33% forget or do not think of revoking access to their data. Also, by using a demonstrator to perform inferences from location data, we observe that slightly more than half of participants (57%) are surprised by the extent of potentially inferred information, and that 47% intend to reduce access to their data via permissions as a result of using the demonstrator. Last, a majority of participants have little knowledge of the tools to better protect themselves, but are nonetheless willing to follow suggestions to improve privacy (51%). Educating people, including digital natives, about privacy risks through transparency tools seems a promising approach.",
    "pdfUrl": "https://arxiv.org/pdf/2502.11658",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:13.927619Z"
  },
  {
    "id": "ad06b2a15be8b70a3836715610a919db",
    "title": "PSCon: Product Search Through Conversations",
    "slug": "pscon:-product-search-through-conversations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jie Zou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Conversational Product Search ( CPS ) systems interact with users via natural language to offer personalized and context-aware product lists. However, most existing research on CPS is limited to simulated conversations, due to the lack of a real CPS dataset driven by human-like language. Moreover, existing conversational datasets for e-commerce are constructed for a particular market or a particular language and thus can not support cross-market and multi-lingual usage. In this paper, we propose a CPS data collection protocol and create a new CPS dataset, called PSCon, which assists product search through conversations with human-like language. The dataset is collected by a coached human-human data collection protocol and is available for dual markets and two languages. By formulating the task of CPS, the dataset allows for comprehensive and in-depth research on six subtasks: user intent detection, keyword extraction, system action prediction, question selection, item ranking, and response generation. Moreover, we present a concise analysis of the dataset and propose a benchmark model on the proposed CPS dataset. Our proposed dataset and model will be helpful for facilitating future research on CPS.",
    "pdfUrl": "https://arxiv.org/pdf/2502.13881",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.928021Z"
  },
  {
    "id": "44008ed06f3db940e0822d0843d457e6",
    "title": "Disentangling Visual Transformers: Patch-level Interpretability for Image Classification",
    "slug": "disentangling-visual-transformers:-patch-level-interpretability-for-image-classification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Guillaume Jeanneret",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Visual transformers have achieved remarkable performance in image classification tasks, but this performance gain has come at the cost of interpretability. One of the main obstacles to the interpretation of transformers is the self-attention mechanism, which mixes visual information across the whole image in a complex way. In this paper, we propose Hindered Transformer (HiT), a novel interpretable by design architecture inspired by visual transformers. Our proposed architecture rethinks the design of transformers to better disentangle patch influences at the classification stage. Ultimately, HiT can be interpreted as a linear combination of patch-level information. We show that the advantages of our approach in terms of explicability come with a reasonable trade-off in performance, making it an attractive alternative for applications where interpretability is paramount.",
    "pdfUrl": "https://arxiv.org/pdf/2502.17196",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.928236Z"
  },
  {
    "id": "a158ca1367967d454e53c7613307f254",
    "title": "Investigating the Relationship Between Debiasing and Artifact Removal using Saliency Maps",
    "slug": "investigating-the-relationship-between-debiasing-and-artifact-removal-using-saliency-maps",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Lukasz Sztukiewicz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The widespread adoption of machine learning systems has raised critical concerns about fairness and bias, making mitigating harmful biases essential for AI development. In this paper, we investigate the relationship between debiasing and removing artifacts in neural networks for computer vision tasks. First, we introduce a set of novel XAI-based metrics that analyze saliency maps to assess shifts in a model's decision-making process. Then, we demonstrate that successful debiasing methods systematically redirect model focus away from protected attributes. Finally, we show that techniques originally developed for artifact removal can be effectively repurposed for improving fairness. These findings provide evidence for the existence of a bidirectional connection between ensuring fairness and removing artifacts corresponding to protected attributes.",
    "pdfUrl": "https://arxiv.org/pdf/2503.00234",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.928450Z"
  },
  {
    "id": "7a15aa8aaab260dc466c9b56af3ea393",
    "title": "HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks",
    "slug": "hyperdas:-towards-automating-mechanistic-interpretability-with-hypernetworks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jiuding Sun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Mechanistic interpretability has made great strides in identifying neural network features (e.g., directions in hidden activation space) that mediate concepts(e.g., the birth year of a person) and enable predictable manipulation. Distributed alignment search (DAS) leverages supervision from counterfactual data to learn concept features within hidden states, but DAS assumes we can afford to conduct a brute force search over potential feature locations. To address this, we present HyperDAS, a transformer-based hypernetwork architecture that (1) automatically locates the token-positions of the residual stream that a concept is realized in and (2) constructs features of those residual stream vectors for the concept. In experiments with Llama3-8B, HyperDAS achieves state-of-the-art performance on the RAVEL benchmark for disentangling concepts in hidden states. In addition, we review the design decisions we made to mitigate the concern that HyperDAS (like all powerful interpretabilty methods) might inject new information into the target model rather than faithfully interpreting it.",
    "pdfUrl": "https://arxiv.org/pdf/2503.10894",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.928715Z"
  },
  {
    "id": "076fcff748a3517bf67def545e1606c3",
    "title": "Adaptive Resampling with Bootstrap for Noisy Multi-Objective Optimization Problems",
    "slug": "adaptive-resampling-with-bootstrap-for-noisy-multi-objective-optimization-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Timo Budszuhn",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The challenge of noisy multi-objective optimization lies in the constant trade-off between exploring new decision points and improving the precision of known points through resampling. This decision should take into account both the variability of the objective functions and the current estimate of a point in relation to the Pareto front. Since the amount and distribution of noise are generally unknown, it is desirable for a decision function to be highly adaptive to the properties of the optimization problem. This paper presents a resampling decision function that incorporates the stochastic nature of the optimization problem by using bootstrapping and the probability of dominance. The distribution-free estimation of the probability of dominance is achieved using bootstrap estimates of the means. To make the procedure applicable even with very few observations, we transfer the distribution observed at other decision points. The efficiency of this resampling approach is demonstrated by applying it in the NSGA-II algorithm with a sequential resampling procedure under multiple noise variations.",
    "pdfUrl": "https://arxiv.org/pdf/2503.21495",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.928983Z"
  },
  {
    "id": "59a55308a3cc81a86ef257e765e68805",
    "title": "How Well Can Vison-Language Models Understand Humans' Intention? An Open-ended Theory of Mind Question Evaluation Benchmark",
    "slug": "how-well-can-vison-language-models-understand-humans'-intention?-an-open-ended-theory-of-mind-question-evaluation-benchmark",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ximing Wen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Vision Language Models (VLMs) have demonstrated strong reasoning capabilities in Visual Question Answering (VQA) tasks; however, their ability to perform Theory of Mind (ToM) tasks, such as inferring human intentions, beliefs, and mental states, remains underexplored. We propose an open-ended question framework to evaluate VLMs' performance across diverse categories of ToM tasks. We curated and annotated a benchmark dataset of 30 images and evaluated the performance of four VLMs of varying sizes. Our results show that the GPT-4 model outperformed all the others, with only one smaller model, GPT-4o-mini, achieving comparable performance. We observed that VLMs often struggle to infer intentions in complex scenarios such as bullying or cheating. Our findings reveal that smaller models can sometimes infer correct intentions despite relying on incorrect visual cues. The dataset is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2503.22093",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.929345Z"
  },
  {
    "id": "99b59399d8fd0c88c26856ce72527870",
    "title": "Cognitive Memory in Large Language Models",
    "slug": "cognitive-memory-in-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Lianlei Shan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper examines memory mechanisms in Large Language Models (LLMs), emphasizing their importance for context-rich responses, reduced hallucinations, and improved efficiency. It categorizes memory into sensory, short-term, and long-term, with sensory memory corresponding to input prompts, short-term memory processing immediate context, and long-term memory implemented via external databases or structures. The text-based memory section covers acquisition (selection and summarization), management (updating, accessing, storing, and resolving conflicts), and utilization (full-text search, SQL queries, semantic search). The KV cache-based memory section discusses selection methods (regularity-based summarization, score-based approaches, special token embeddings) and compression techniques (low-rank compression, KV merging, multimodal compression), along with management strategies like offloading and shared attention mechanisms. Parameter-based memory methods (LoRA, TTT, MoE) transform memories into model parameters to enhance efficiency, while hidden-state-based memory approaches (chunk mechanisms, recurrent transformers, Mamba model) improve long-text processing by combining RNN hidden states with current methods. Overall, the paper offers a comprehensive analysis of LLM memory mechanisms, highlighting their significance and future research directions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.02441",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.929583Z"
  },
  {
    "id": "23d675c0e57c192d7940da0966c27733",
    "title": "Looking beyond the next token",
    "slug": "looking-beyond-the-next-token",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Abitha Thankaraj",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The structure of causal language model training assumes that each token can be accurately predicted from the previous context. This contrasts with humans' natural writing and reasoning process, where goals are typically known before the exact argument or phrasings. While this mismatch has been well studied in the literature, the working assumption has been that architectural changes are needed to address this mismatch. We argue that rearranging and processing the training data sequences can allow models to more accurately imitate the true data-generating process, and does not require any other changes to the architecture or training infrastructure. We demonstrate that this technique, Trelawney, and the inference algorithms derived from it allow us to improve performance on several key benchmarks that span planning, algorithmic reasoning, and story generation tasks. Finally, our method naturally enables the generation of long-term goals at no additional cost. We investigate how using the model's goal-generation capability can further improve planning and reasoning. Additionally, we believe Trelawney could potentially open doors to new capabilities beyond the current language modeling paradigm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.11336",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.929816Z"
  },
  {
    "id": "41d621a353d4a5c65a552d445437d61c",
    "title": "Teaching Large Language Models to Reason through Learning and Forgetting",
    "slug": "teaching-large-language-models-to-reason-through-learning-and-forgetting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Tianwei Ni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Leveraging inference-time search in large language models has proven effective in further enhancing a trained model's capability to solve complex mathematical and reasoning problems. However, this approach significantly increases computational costs and inference time, as the model must generate and evaluate multiple candidate solutions to identify a viable reasoning path. To address this, we propose an effective approach that integrates search capabilities directly into the model by fine-tuning it using both successful (learning) and failed reasoning paths (forgetting) derived from diverse search methods. While fine-tuning the model with these data might seem straightforward, we identify a critical issue: the model's search capability tends to degrade rapidly if fine-tuning is performed naively. We show that this degradation can be substantially mitigated by employing a smaller learning rate. Extensive experiments on the challenging Game-of-24 and Countdown mathematical reasoning benchmarks show that our approach not only outperforms both standard fine-tuning and inference-time search baselines but also significantly reduces inference time by 180$\\times$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.11364",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.930046Z"
  },
  {
    "id": "4dd74362147defb5092123f380853f43",
    "title": "Deep Generative Model-Based Generation of Synthetic Individual-Specific Brain MRI Segmentations",
    "slug": "deep-generative-model-based-generation-of-synthetic-individual-specific-brain-mri-segmentations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neurons and Cognition (q-bio.NC)",
    "author": {
      "name": "Ruijie Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "To the best of our knowledge, all existing methods that can generate synthetic brain magnetic resonance imaging (MRI) scans for a specific individual require detailed structural or volumetric information about the individual's brain. However, such brain information is often scarce, expensive, and difficult to obtain. In this paper, we propose the first approach capable of generating synthetic brain MRI segmentations -- specifically, 3D white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) segmentations -- for individuals using their easily obtainable and often readily available demographic, interview, and cognitive test information. Our approach features a novel deep generative model, CSegSynth, which outperforms existing prominent generative models, including conditional variational autoencoder (C-VAE), conditional generative adversarial network (C-GAN), and conditional latent diffusion model (C-LDM). We demonstrate the high quality of our synthetic segmentations through extensive evaluations. Also, in assessing the effectiveness of the individual-specific generation, we achieve superior volume prediction, with mean absolute errors of only 36.44mL, 29.20mL, and 35.51mL between the ground-truth WM, GM, and CSF volumes of test individuals and those volumes predicted based on generated individual-specific segmentations, respectively.",
    "pdfUrl": "https://arxiv.org/pdf/2504.12352",
    "tags": [
      "Neurons and Cognition (q-bio.NC)"
    ],
    "createdAt": "2025-04-25T15:49:13.930305Z"
  },
  {
    "id": "b47e0b84a950d05c3ebcac21656883c9",
    "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent",
    "slug": "cheatagent:-attacking-llm-empowered-recommender-systems-via-llm-agent",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Liang-bo Ning",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13192",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:13.930549Z"
  },
  {
    "id": "6c53a0b28ed1d2410044ea14cef8a21a",
    "title": "Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks",
    "slug": "building-trustworthy-multimodal-ai:-a-review-of-fairness,-transparency,-and-ethics-in-vision-language-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Mohammad Saleh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Objective: This review explores the trustworthiness of multimodal artificial intelligence (AI) systems, specifically focusing on vision-language tasks. It addresses critical challenges related to fairness, transparency, and ethical implications in these systems, providing a comparative analysis of key tasks such as Visual Question Answering (VQA), image captioning, and visual dialogue. Background: Multimodal models, particularly vision-language models, enhance artificial intelligence (AI) capabilities by integrating visual and textual data, mimicking human learning processes. Despite significant advancements, the trustworthiness of these models remains a crucial concern, particularly as AI systems increasingly confront issues regarding fairness, transparency, and ethics. Methods: This review examines research conducted from 2017 to 2024 focusing on forenamed core vision-language tasks. It employs a comparative approach to analyze these tasks through the lens of trustworthiness, underlining fairness, explainability, and ethics. This study synthesizes findings from recent literature to identify trends, challenges, and state-of-the-art solutions. Results: Several key findings were highlighted. Transparency: Explainability of vision language tasks is important for user trust. Techniques, such as attention maps and gradient-based methods, have successfully addressed this issue. Fairness: Bias mitigation in VQA and visual dialogue systems is essential for ensuring unbiased outcomes across diverse demographic groups. Ethical Implications: Addressing biases in multilingual models and ensuring ethical data handling is critical for the responsible deployment of vision-language systems. Conclusion: This study underscores the importance of integrating fairness, transparency, and ethical considerations in developing vision-language models within a unified framework.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13199",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:13.930746Z"
  },
  {
    "id": "ba5cb64200038dee26175bfd7fd0c056",
    "title": "Putting the Segment Anything Model to the Test with 3D Knee MRI - A Comparison with State-of-the-Art Performance",
    "slug": "putting-the-segment-anything-model-to-the-test-with-3d-knee-mri---a-comparison-with-state-of-the-art-performance",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Oliver Mills",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Menisci are cartilaginous tissue found within the knee that contribute to joint lubrication and weight dispersal. Damage to menisci can lead to onset and progression of knee osteoarthritis (OA), a condition that is a leading cause of disability, and for which there are few effective therapies. Accurate automated segmentation of menisci would allow for earlier detection and treatment of meniscal abnormalities, as well as shedding more light on the role the menisci play in OA pathogenesis. Focus in this area has mainly used variants of convolutional networks, but there has been no attempt to utilise recent large vision transformer segmentation models. The Segment Anything Model (SAM) is a so-called foundation segmentation model, which has been found useful across a range of different tasks due to the large volume of data used for training the model. In this study, SAM was adapted to perform fully-automated segmentation of menisci from 3D knee magnetic resonance images. A 3D U-Net was also trained as a baseline. It was found that, when fine-tuning only the decoder, SAM was unable to compete with 3D U-Net, achieving a Dice score of $0.81\\pm0.03$, compared to $0.87\\pm0.03$, on a held-out test set. When fine-tuning SAM end-to-end, a Dice score of $0.87\\pm0.03$ was achieved. The performance of both the end-to-end trained SAM configuration and the 3D U-Net were comparable to the winning Dice score ($0.88\\pm0.03$) in the IWOAI Knee MRI Segmentation Challenge 2019. Performance in terms of the Hausdorff Distance showed that both configurations of SAM were inferior to 3D U-Net in matching the meniscus morphology. Results demonstrated that, despite its generalisability, SAM was unable to outperform a basic 3D U-Net in meniscus segmentation, and may not be suitable for similar 3D medical image segmentation tasks also involving fine anatomical structures with low contrast and poorly-defined boundaries.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13340",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:13.930973Z"
  },
  {
    "id": "72d69fe3d88eea47b0dc16122c698026",
    "title": "Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning",
    "slug": "nemotron-crossthink:-scaling-self-learning-beyond-math-reasoning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Syeda Nahida Akter",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) have shown strong reasoning capabilities, particularly when enhanced through Reinforcement Learning (RL). While prior work has successfully applied RL to mathematical reasoning -- where rules and correctness are well-defined -- generalizing these methods to broader reasoning domains remains challenging due to limited data, the lack of verifiable reward structures, and diverse task requirements. In this work, we propose NEMOTRON-CROSSTHINK, a framework that systematically incorporates multi-domain corpora, including both synthetic and real-world question-answer pairs, into RL training to improve generalization across diverse reasoning tasks. NEMOTRON-CROSSTHINK addresses key challenges by (1) incorporating data from varied sources spanning STEM, humanities, social sciences, etc.; (2) applying structured templates (e.g., multiple-choice and open-ended) to control answer-space complexity; (3) filtering for verifiable answers; and (4) optimizing data blending strategies that utilizes data from multiple sources effectively. Our approach enables scalable and verifiable reward modeling beyond mathematics and demonstrates improved accuracies on both math (MATH-500: +30.1%, AMC23:+27.5%) and non-math reasoning benchmarks (MMLU-PRO: +12.8%, GPQA-DIAMOND: +11.3%, AGIEVAL: +15.1%, SUPERGPQA: +3.8%). Moreover, NEMOTRON-CROSSTHINK exhibits significantly improved response efficiency -- using 28% fewer tokens for correct answers -- highlighting more focused and effective reasoning. Through NEMOTRON-CROSSTHINK, we demonstrate that integrating multi-domain, multi-format data in RL leads to more accurate, efficient, and generalizable LLMs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13941",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.931215Z"
  },
  {
    "id": "16e488f1eebe23195806e83aed50ebd3",
    "title": "Clifford Group Equivariant Diffusion Models for 3D Molecular Generation",
    "slug": "clifford-group-equivariant-diffusion-models-for-3d-molecular-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Cong Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper explores leveraging the Clifford algebra's expressive power for $\\E(n)$-equivariant diffusion models. We utilize the geometric products between Clifford multivectors and the rich geometric information encoded in Clifford subspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion process beyond just Clifford one-vectors to incorporate all higher-grade multivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us to apply latent diffusion across complete multivectors. This enables CDMs to capture the joint distribution across different subspaces of the algebra, incorporating richer geometric information through higher-order features. We provide empirical results for unconditional molecular generation on the QM9 dataset, showing that CDMs provide a promising avenue for generative modeling.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15773",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:13.931427Z"
  },
  {
    "id": "7187c2820e26c0bb1a10a88ccd6cb4aa",
    "title": "Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models",
    "slug": "meta-entity-driven-triplet-mining-for-aligning-medical-vision-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Saban Ozturk",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Diagnostic imaging relies on interpreting both images and radiology reports, but the growing data volumes place significant pressure on medical experts, yielding increased errors and workflow backlogs. Medical vision-language models (med-VLMs) have emerged as a powerful framework to efficiently process multimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit their performance hinges on how well image and text representations are aligned. Existing alignment methods, predominantly based on contrastive learning, prioritize separation between disease classes over segregation of fine-grained pathology attributes like location, size or severity, leading to suboptimal representations. Here, we propose MedTrim (Meta-entity-driven Triplet mining), a novel method that enhances image-text alignment through multimodal triplet learning synergistically guided by disease class as well as adjectival and directional pathology descriptors. Unlike common alignment methods that separate broad disease classes, MedTrim leverages structured meta-entity information to preserve subtle but clinically significant intra-class variations. For this purpose, we first introduce an ontology-based entity recognition module that extracts pathology-specific meta-entities from CXR reports, as annotations on pathology attributes are rare in public datasets. For refined sample selection in triplet mining, we then introduce a novel score function that captures an aggregate measure of inter-sample similarity based on disease classes and adjectival/directional descriptors. Lastly, we introduce a multimodal triplet alignment objective for explicit within- and cross-modal alignment between samples sharing detailed pathology characteristics. Our demonstrations indicate that MedTrim improves performance in downstream retrieval and classification tasks compared to state-of-the-art alignment methods.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15929",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.931648Z"
  },
  {
    "id": "656bb71b17f80eeb0f33d21b42f27e6f",
    "title": "Trends in AI Supercomputers",
    "slug": "trends-in-ai-supercomputers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Konstantin F. Pilz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Frontier AI development relies on powerful AI supercomputers, yet analysis of these systems is limited. We create a dataset of 500 AI supercomputers from 2019 to 2025 and analyze key trends in performance, power needs, hardware cost, ownership, and global distribution. We find that the computational performance of AI supercomputers has doubled every nine months, while hardware acquisition cost and power needs both doubled every year. The leading system in March 2025, xAI's Colossus, used 200,000 AI chips, had a hardware cost of \\$7B, and required 300 MW of power, as much as 250,000 households. As AI supercomputers evolved from tools for science to industrial machines, companies rapidly expanded their share of total AI supercomputer performance, while the share of governments and academia diminished. Globally, the United States accounts for about 75% of total performance in our dataset, with China in second place at 15%. If the observed trends continue, the leading AI supercomputer in 2030 will achieve $2\\times10^{22}$ 16-bit FLOP/s, use two million AI chips, have a hardware cost of \\$200 billion, and require 9 GW of power. Our analysis provides visibility into the AI supercomputer landscape, allowing policymakers to assess key AI trends like resource needs, ownership, and national competitiveness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16026",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:13.931848Z"
  },
  {
    "id": "86976e2a9f60b43daa8156ecea445ba0",
    "title": "AI-Based Vulnerability Analysis of NFT Smart Contracts",
    "slug": "ai-based-vulnerability-analysis-of-nft-smart-contracts",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Xin Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "With the rapid growth of the NFT market, the security of smart contracts has become crucial. However, existing AI-based detection models for NFT contract vulnerabilities remain limited due to their complexity, while traditional manual methods are time-consuming and costly. This study proposes an AI-driven approach to detect vulnerabilities in NFT smart contracts.\nWe collected 16,527 public smart contract codes, classifying them into five vulnerability categories: Risky Mutable Proxy, ERC-721 Reentrancy, Unlimited Minting, Missing Requirements, and Public Burn. Python-processed data was structured into training/test sets. Using the CART algorithm with Gini coefficient evaluation, we built initial decision trees for feature extraction. A random forest model was implemented to improve robustness through random data/feature sampling and multitree integration. GridSearch hyperparameter tuning further optimized the model, with 3D visualizations demonstrating parameter impacts on vulnerability detection.\nResults show the random forest model excels in detecting all five vulnerabilities. For example, it identifies Risky Mutable Proxy by analyzing authorization mechanisms and state modifications, while ERC-721 Reentrancy detection relies on external call locations and lock mechanisms. The ensemble approach effectively reduces single-tree overfitting, with stable performance improvements after parameter tuning. This method provides an efficient technical solution for automated NFT contract detection and lays groundwork for scaling AI applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16113",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:13.932047Z"
  },
  {
    "id": "a8bc4079927d3de26cf6d94083398b9e",
    "title": "MARFT: Multi-Agent Reinforcement Fine-Tuning",
    "slug": "marft:-multi-agent-reinforcement-fine-tuning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multiagent Systems (cs.MA)",
    "author": {
      "name": "Junwei Liao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LLM-based Multi-Agent Systems have demonstrated remarkable capabilities in addressing complex, agentic tasks requiring multifaceted reasoning and collaboration, from generating high-quality presentation slides to conducting sophisticated scientific research. Meanwhile, RL has been widely recognized for its effectiveness in enhancing agent intelligence, but limited research has investigated the fine-tuning of LaMAS using foundational RL techniques. Moreover, the direct application of MARL methodologies to LaMAS introduces significant challenges, stemming from the unique characteristics and mechanisms inherent to LaMAS. To address these challenges, this article presents a comprehensive study of LLM-based MARL and proposes a novel paradigm termed Multi-Agent Reinforcement Fine-Tuning (MARFT). We introduce a universal algorithmic framework tailored for LaMAS, outlining the conceptual foundations, key distinctions, and practical implementation strategies. We begin by reviewing the evolution from RL to Reinforcement Fine-Tuning, setting the stage for a parallel analysis in the multi-agent domain. In the context of LaMAS, we elucidate critical differences between MARL and MARFT. These differences motivate a transition toward a novel, LaMAS-oriented formulation of RFT. Central to this work is the presentation of a robust and scalable MARFT framework. We detail the core algorithm and provide a complete, open-source implementation to facilitate adoption and further research. The latter sections of the paper explore real-world application perspectives and opening challenges in MARFT. By bridging theoretical underpinnings with practical methodologies, this work aims to serve as a roadmap for researchers seeking to advance MARFT toward resilient and adaptive solutions in agentic systems. Our implementation of the proposed framework is publicly available at: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16129",
    "tags": [
      "Multiagent Systems (cs.MA)"
    ],
    "createdAt": "2025-04-25T15:49:13.932262Z"
  },
  {
    "id": "dc09ffdbe020ba0a20434b75d822da27",
    "title": "FPGA-Based Neural Network Accelerators for Space Applications: A Survey",
    "slug": "fpga-based-neural-network-accelerators-for-space-applications:-a-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Pedro Antunes",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Space missions are becoming increasingly ambitious, necessitating high-performance onboard spacecraft computing systems. In response, field-programmable gate arrays (FPGAs) have garnered significant interest due to their flexibility, cost-effectiveness, and radiation tolerance potential. Concurrently, neural networks (NNs) are being recognized for their capability to execute space mission tasks such as autonomous operations, sensor data analysis, and data compression. This survey serves as a valuable resource for researchers aiming to implement FPGA-based NN accelerators in space applications. By analyzing existing literature, identifying trends and gaps, and proposing future research directions, this work highlights the potential of these accelerators to enhance onboard computing systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16173",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:13.932464Z"
  },
  {
    "id": "85b90d4fa9b28cd51ecda68c42b6bdc2",
    "title": "Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark",
    "slug": "can-large-language-models-help-multimodal-language-analysis?-mmla:-a-comprehensive-benchmark",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Hanlei Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Multimodal language analysis is a rapidly evolving field that leverages multiple modalities to enhance the understanding of high-level semantics underlying human conversational utterances. Despite its significance, little research has investigated the capability of multimodal large language models (MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce MMLA, a comprehensive benchmark specifically designed to address this gap. MMLA comprises over 61K multimodal utterances drawn from both staged and real-world scenarios, covering six core dimensions of multimodal semantics: intent, emotion, dialogue act, sentiment, speaking style, and communication behavior. We evaluate eight mainstream branches of LLMs and MLLMs using three methods: zero-shot inference, supervised fine-tuning, and instruction tuning. Extensive experiments reveal that even fine-tuned models achieve only about 60%~70% accuracy, underscoring the limitations of current MLLMs in understanding complex human language. We believe that MMLA will serve as a solid foundation for exploring the potential of large language models in multimodal language analysis and provide valuable resources to advance this field. The datasets and code are open-sourced at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16427",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:13.932708Z"
  },
  {
    "id": "7b8676cc4bd57eab8de3f554bf63ba3b",
    "title": "V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations",
    "slug": "v$^2$r-bench:-holistically-evaluating-lvlm-robustness-to-fundamental-visual-variations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhiyuan Fan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Vision Language Models (LVLMs) excel in various vision-language tasks. Yet, their robustness to visual variations in position, scale, orientation, and context that objects in natural scenes inevitably exhibit due to changes in viewpoint and environment remains largely underexplored. To bridge this gap, we introduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating Visual Variation Robustness of LVLMs, which encompasses automated evaluation dataset generation and principled metrics for thorough robustness assessment. Through extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability to visual variations, in which even advanced models that excel at complex vision-language tasks significantly underperform on simple tasks such as object recognition. Interestingly, these models exhibit a distinct visual position bias that contradicts theories of effective receptive fields, and demonstrate a human-like visual acuity threshold. To identify the source of these vulnerabilities, we present a systematic framework for component-level analysis, featuring a novel visualization approach for aligned visual features. Results show that these vulnerabilities stem from error accumulation in the pipeline architecture and inadequate multimodal alignment. Complementary experiments with synthetic data further demonstrate that these limitations are fundamentally architectural deficiencies, scoring the need for architectural innovations in future LVLM designs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16727",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:13.932908Z"
  },
  {
    "id": "03cdc4a936ff64ef72d42dfd787feb85",
    "title": "FLAG: Formal and LLM-assisted SVA Generation for Formal Specifications of On-Chip Communication Protocols",
    "slug": "flag:-formal-and-llm-assisted-sva-generation-for-formal-specifications-of-on-chip-communication-protocols",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Yu-An Shih",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Formal specifications of on-chip communication protocols are crucial for system-on-chip (SoC) design and verification. However, manually constructing these formal specifications from informal documents remains a tedious and error-prone task. Although recent efforts have used Large Language Models (LLMs) to generate SystemVerilog Assertion (SVA) properties from design documents for Register-Transfer Level (RTL) design verification, in our experience these approaches have not shown promise in generating SVA properties for communication protocols. Since protocol specification documents are unstructured and ambiguous in nature, LLMs often fail to extract the necessary information and end up generating irrelevant or even incorrect properties. We propose FLAG, a two-stage framework to help construct formal protocol specifications from informal documents. In the first stage, a predefined template set is used to generate candidate SVA properties. To avoid missing necessary properties, we develop a grammar-based approach to generate comprehensive template sets that capture critical signal behaviors for various communication protocols. In the second stage, we utilize unambiguous timing diagrams in conjunction with textual descriptions from the specification documents to filter out incorrect properties. A formal approach is first implemented to check the candidate properties and filter out those inconsistent with the timing diagrams. An LLM is then consulted to further remove incorrect properties with respect to the textual description, obtaining the final property set. Experiments on various open-source communication protocols demonstrate the effectiveness of FLAG in generating SVA properties from informal documents.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17226",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:14.188028Z"
  },
  {
    "id": "4d8a935b2263eb3b3be6f36de24b5877",
    "title": "Fine-Grained Fusion: The Missing Piece in Area-Efficient State Space Model Acceleration",
    "slug": "fine-grained-fusion:-the-missing-piece-in-area-efficient-state-space-model-acceleration",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Robin Geens",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "State Space Models (SSMs) offer a promising alternative to transformers for long-sequence processing. However, their efficiency remains hindered by memory-bound operations, particularly in the prefill stage. While MARCA, a recent first effort to accelerate SSMs through a dedicated hardware accelerator, achieves great speedup over high-end GPUs, an analysis into the broader accelerator design space is lacking. This work systematically analyzes SSM acceleration opportunities both from the scheduling perspective through fine-grained operator fusion and the hardware perspective through design space exploration, using an extended version of the Stream modeling framework.\nOur results demonstrate that the improved data locality stemming from our optimized fusion and scheduling strategy enables a speedup of up to 4.8x over unfused execution, while our adaptive memory-aware fusion approach reduces on-chip memory requirements by an order of magnitude without sacrificing performance. We further explore accelerator design trade-offs, showing that a fusion-aware hardware architecture can achieve 1.78x higher performance than the state-of-the-art MARCA accelerator, within the same area budget. These results establish operator fusion as a key enabler for next-generation SSM accelerators.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17333",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:14.188259Z"
  },
  {
    "id": "e5da52204c72263ba922f161142cf103",
    "title": "On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration",
    "slug": "on-device-qwen2.5:-efficient-llm-inference-with-model-compression-and-hardware-acceleration",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Maoyang Xiang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Transformer-based Large Language Models (LLMs) have significantly advanced AI capabilities but pose considerable challenges for deployment on edge devices due to high computational demands, memory bandwidth constraints, and energy consumption. This paper addresses these challenges by presenting an efficient framework for deploying the Qwen2.5-0.5B model on the Xilinx Kria KV260 edge platform, a heterogeneous system integrating an ARM Cortex-A53 CPU with reconfigurable FPGA logic. Leveraging Activation-aware Weight Quantization (AWQ) with FPGA-accelerated execution pipelines, the proposed approach enhances both model compression rate and system throughput. Additionally, we propose a hybrid execution strategy that intelligently offloads compute-intensive operations to the FPGA while utilizing the CPU for lighter tasks, effectively balancing the computational workload and maximizing overall performance. Our framework achieves a model compression rate of 55.08% compared to the original model and produces output at a rate of 5.1 tokens per second, outperforming the baseline performance of 2.8 tokens per second.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17376",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:14.188469Z"
  },
  {
    "id": "e0817b455b3a038f89105ecfe0e98618",
    "title": "L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference",
    "slug": "l3:-dimm-pim-integrated-architecture-and-coordination-for-scalable-long-context-llm-inference",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Qingyuan Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) increasingly require processing long text sequences, but GPU memory limitations force difficult trade-offs between memory capacity and bandwidth. While HBM-based acceleration offers high bandwidth, its capacity remains constrained. Offloading data to host-side DIMMs improves capacity but introduces costly data swapping overhead. We identify that the critical memory bottleneck lies in the decoding phase of multi-head attention (MHA) exclusively, which demands substantial capacity for storing KV caches and high bandwidth for attention computation. Our key insight reveals this operation uniquely aligns with modern DIMM-based processing-in-memory (PIM) architectures, which offers scalability of both capacity and bandwidth.\nBased on this observation and insight, we propose L3, a hardware-software co-designed system integrating DIMM-PIM and GPU devices. L3 introduces three innovations: First, hardware redesigns resolve data layout mismatches and computational element mismatches in DIMM-PIM, enhancing LLM inference utilization. Second, communication optimization enables hiding the data transfer overhead with the computation. Third, an adaptive scheduler coordinates GPU-DIMM-PIM operations to maximize parallelism between devices. Evaluations using real-world traces show L3 achieves up to 6.1$\\times$ speedup over state-of-the-art HBM-PIM solutions while significantly improving batch sizes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17584",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:14.188700Z"
  },
  {
    "id": "ada4e68a27f6eea1a8db250899ed9934",
    "title": "OneAdapt: Adaptive Compilation for Resource-Constrained Photonic One-Way Quantum Computing",
    "slug": "oneadapt:-adaptive-compilation-for-resource-constrained-photonic-one-way-quantum-computing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Hezi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Measurement-based quantum computing (MBQC), a.k.a. one-way quantum computing (1WQC), is a universal quantum computing model, which is particularly well-suited for photonic platforms. In this model, computation is driven by measurements on an entangled state, which serves as an intermediate representation (IR) between program and hardware. However, compilers on previous IRs lacks the adaptability to the resource constraint in photonic quantum computers. In this work, we propose a novel IR with new optimization passes. Based on this, it realizes a resource-adaptive compiler that minimizes the required hardware size and execution time while restricting the requirement for fusion devices within an adaptive limit. Moreover, our optimization can be integrated with Quantum Error Correction (QEC) to improve the efficiency of photonic fault-tolerant quantum computing (FTQC).",
    "pdfUrl": "https://arxiv.org/pdf/2504.17116",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:14.188911Z"
  },
  {
    "id": "925564689ecd5beda55f4ce24ac664fe",
    "title": "Rethinking Programmed I/O for Fast Devices, Cheap Cores, and Coherent Interconnects",
    "slug": "rethinking-programmed-i/o-for-fast-devices,-cheap-cores,-and-coherent-interconnects",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Anastasiia Ruzhanskaia",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Conventional wisdom holds that an efficient interface between an OS running on a CPU and a high-bandwidth I/O device should use Direct Memory Access (DMA) to offload data transfer, descriptor rings for buffering and queuing, and interrupts for asynchrony between cores and device.\nIn this paper we question this wisdom in the light of two trends: modern and emerging cache-coherent interconnects like CXL3.0, and workloads, particularly microservices and serverless computing. Like some others before us, we argue that the assumptions of the DMA-based model are obsolete, and in many use-cases programmed I/O, where the CPU explicitly transfers data and control information to and from a device via loads and stores, delivers a more efficient system.\nHowever, we push this idea much further. We show, in a real hardware implementation, the gains in latency for fine-grained communication achievable using an open cache-coherence protocol which exposes cache transitions to a smart device, and that throughput is competitive with DMA over modern interconnects. We also demonstrate three use-cases: fine-grained RPC-style invocation of functions on an accelerator, offloading of operators in a streaming dataflow engine, and a network interface targeting serverless functions, comparing our use of coherence with both traditional DMA-style interaction and a highly-optimized implementation using memory-mapped programmed I/O over PCIe.",
    "pdfUrl": "https://arxiv.org/pdf/2409.08141",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:14.189116Z"
  },
  {
    "id": "f77f5c6a952e58b8e9294634af9b8c57",
    "title": "Count2Multiply: Reliable In-Memory High-Radix Counting",
    "slug": "count2multiply:-reliable-in-memory-high-radix-counting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Joo Paulo Cardoso de Lima",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Computing-in-memory (CIM) has been demonstrated across various memory technologies, ranging from memristive crossbars performing analog dot-product computations to large-scale digital bitwise operations in commodity DRAM and other proposed non-volative memory technologies. However, current CIM solutions face latency and reliability challenges. CIM fidelity lags considerably behind access fidelity. Furthermore, bulk-bitwise CIM, although highly parallelized, requires long latency for operations like multiplication and addition, due to their bit-serial computation. This paper presents Count2Multiply, a technology-agnostic digital CIM approach to perform multiplication, addition and other operations using high-radix, massively parallel counting enabled by CIM bulk-bitwise logic operations. Designed to meet fault tolerance requirements, Count2Multiply integrates traditional row-wise error correction codes, such as Hamming and BCH, to address the high error rates in existing CIM designs. We demonstrate Count2Multiply with a detailed application to CIM in conventional DRAM due to its ubiquity and high endurance. However, we note that the Count2Multiply architecture is compatible with other functionally complete CIM proposals. Compared to the state-of-the-art in-DRAM CIM method, Count2Multiply achieves up to 10x speedup, 8x higher GOPS/Watt, and 9.5x higher GOPS/area, while outperforming GPU for vector-matrix multiplications.",
    "pdfUrl": "https://arxiv.org/pdf/2409.10136",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:14.189453Z"
  },
  {
    "id": "dc09ffdbe020ba0a20434b75d822da27",
    "title": "FPGA-Based Neural Network Accelerators for Space Applications: A Survey",
    "slug": "fpga-based-neural-network-accelerators-for-space-applications:-a-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Pedro Antunes",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Space missions are becoming increasingly ambitious, necessitating high-performance onboard spacecraft computing systems. In response, field-programmable gate arrays (FPGAs) have garnered significant interest due to their flexibility, cost-effectiveness, and radiation tolerance potential. Concurrently, neural networks (NNs) are being recognized for their capability to execute space mission tasks such as autonomous operations, sensor data analysis, and data compression. This survey serves as a valuable resource for researchers aiming to implement FPGA-based NN accelerators in space applications. By analyzing existing literature, identifying trends and gaps, and proposing future research directions, this work highlights the potential of these accelerators to enhance onboard computing systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16173",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:14.189663Z"
  },
  {
    "id": "a07cab6ea0bb9ec7a9e0d0e3edaf80c3",
    "title": "EPOCH: Enabling Preemption Operation for Context Saving in Heterogeneous FPGA Systems",
    "slug": "epoch:-enabling-preemption-operation-for-context-saving-in-heterogeneous-fpga-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Arsalan Ali Malik",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "FPGAs are increasingly used in multi-tenant cloud environments to offload compute-intensive tasks from the main CPU. The operating system (OS) plays a vital role in identifying tasks suitable for offloading and coordinating between the CPU and FPGA for seamless task execution. The OS leverages preemption to manage CPU efficiently and balance CPU time; however, preempting tasks running on FPGAs without context loss remains challenging. Despite growing reliance on FPGAs, vendors have yet to deliver a solution that fully preserves and restores task context.\nThis paper presents EPOCH, the first out-of-the-box framework to seamlessly preserve the state of tasks running on multi-tenant cloud FPGAs. EPOCH enables interrupting a tenant's execution at any arbitrary clock cycle, capturing its state, and saving this 'state snapshot' in off-chip memory with fine-grain granularity. Subsequently, when task resumption is required, EPOCH can resume execution from the saved 'state snapshot', eliminating the need to restart the task from scratch. EPOCH automates intricate processes, shields users from complexities, and synchronizes all underlying logic in a common clock domain, mitigating timing violations and ensuring seamless handling of interruptions.\nEPOCH proficiently captures the state of fundamental FPGA elements, such as look-up tables, flip-flops, block--RAMs, and digital signal processing units. On real hardware, ZynQ-XC7Z020 SoC, the proposed solution achieves context save and restore operations per frame in 62.2us and 67.4us, respectively.",
    "pdfUrl": "https://arxiv.org/pdf/2501.16205",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:14.189886Z"
  },
  {
    "id": "13d8b19b972900ee55849f3d3ef29a50",
    "title": "CRAFT: Characterizing and Root-Causing Fault Injection Threats at Pre-Silicon",
    "slug": "craft:-characterizing-and-root-causing-fault-injection-threats-at-pre-silicon",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Arsalan Ali Malik",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Fault injection attacks represent a class of threats that can compromise embedded systems across multiple layers of abstraction, such as system software, instruction set architecture (ISA), microarchitecture, and physical implementation. Early detection of these vulnerabilities and understanding their root causes, along with their propagation from the physical layer to the system software, is critical to secure the cyberinfrastructure. This work presents a comprehensive methodology for conducting controlled fault injection attacks at the pre-silicon level and an analysis of the underlying system for root-causing behavior. As the driving application, we use the clock glitch attacks in AI/ML applications for critical misclassification. Our study aims to characterize and diagnose the impact of faults within the RISC-V instruction set and pipeline stages, while tracing fault propagation from the circuit level to the AI/ML application software. This analysis resulted in discovering two new vulnerabilities through controlled clock glitch parameters. First, we reveal a novel method for causing instruction skips, thereby preventing the loading of critical values from memory. This can cause disruption and affect program continuity and correctness. Second, we demonstrate an attack that converts legal instructions into illegal ones, thereby diverting control flow in a manner exploitable by attackers. Our work underscores the complexity of fault injection attack exploits and emphasizes the importance of preemptive security analysis.",
    "pdfUrl": "https://arxiv.org/pdf/2503.03877",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:14.190090Z"
  },
  {
    "id": "f27329f09637b67346809c52b5563480",
    "title": "Catalytic Computing and Register Programs Beyond Log-Depth",
    "slug": "catalytic-computing-and-register-programs-beyond-log-depth",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Complexity (cs.CC)",
    "author": {
      "name": "Yaroslav Alekseev",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In a seminal work, Buhrman et al. (STOC 2014) defined the class $CSPACE(s,c)$ of problems solvable in space $s$ with an additional catalytic tape of size $c$, which is a tape whose initial content must be restored at the end of the computation. They showed that uniform $TC^1$ circuits are computable in catalytic logspace, i.e., $CL=CSPACE(O(\\log{n}), 2^{O(\\log{n})})$, thus giving strong evidence that catalytic space gives $L$ strict additional power. Their study focuses on an arithmetic model called register programs, which has been a focal point in development since then.\nUnderstanding $CL$ remains a major open problem, as $TC^1$ remains the most powerful containment to date. In this work, we study the power of catalytic space and register programs to compute circuits of larger depth. Using register programs, we show that for every $\\epsilon > 0$,\n$SAC^2 \\subseteq CSPACE\\left(O\\left(\\frac{\\log^2{n}}{\\log\\log{n}}\\right), 2^{O(\\log^{1+\\epsilon} n)}\\right)$\nThis is an $O(\\log \\log n)$ factor improvement on the free space needed to compute $SAC^2$, which can be accomplished with near-polynomial catalytic space.\nWe also exhibit non-trivial register programs for matrix powering, which is a further step towards showing $NC^2 \\subseteq CL$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17412",
    "tags": [
      "Computational Complexity (cs.CC)"
    ],
    "createdAt": "2025-04-25T15:49:14.448854Z"
  },
  {
    "id": "c637564e4b24b5610273264bc61c7bca",
    "title": "On the Degree Automatability of Sum-of-Squares Proofs",
    "slug": "on-the-degree-automatability-of-sum-of-squares-proofs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Complexity (cs.CC)",
    "author": {
      "name": "Alex Bortolotti",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Sum-of-Squares (SoS) hierarchy, also known as Lasserre hierarchy, has emerged as a promising tool in optimization. However, it remains unclear whether fixed-degree SoS proofs can be automated [O'Donnell (2017)]. Indeed, there are examples of polynomial systems with bounded coefficients that admit low-degree SoS proofs, but these proofs necessarily involve numbers with an exponential number of bits, implying that low-degree SoS proofs cannot always be found efficiently.\nA sufficient condition derived from the Nullstellensatz proof system [Raghavendra and Weitz (2017)] identifies cases where bit complexity issues can be circumvented. One of the main problems left open by Raghavendra and Weitz is proving any result for refutations, as their condition applies only to polynomial systems with a large set of solutions.\nIn this work, we broaden the class of polynomial systems for which degree-$d$ SoS proofs can be automated. To achieve this, we develop a new criterion and we demonstrate how our criterion applies to polynomial systems beyond the scope of Raghavendra and Weitz's result. In particular, we establish a separation for instances arising from Constraint Satisfaction Problems (CSPs). Moreover, our result extends to refutations, establishing that polynomial-time refutation is possible for broad classes of polynomial time solvable constraint problems, highlighting a first advancement in this area.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17756",
    "tags": [
      "Computational Complexity (cs.CC)"
    ],
    "createdAt": "2025-04-25T15:49:14.449071Z"
  },
  {
    "id": "144ab76aed3c7a488bf80f811d46923e",
    "title": "Feasibility of Primality in Bounded Arithmetic",
    "slug": "feasibility-of-primality-in-bounded-arithmetic",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic (math.LO)",
    "author": {
      "name": "Raheleh Jalali",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove the correctness of the AKS algorithm \\cite{AKS} within the bounded arithmetic theory $T^{count}_2$ or, equivalently, the first-order consequence of the theory $VTC^0$ expanded by the smash function, which we denote by $VTC^0_2$. Our approach initially demonstrates the correctness within the theory $S^1_2 + iWPHP$ augmented by two algebraic axioms and then show that they are provable in $VTC^0_2$. The two axioms are: a generalized version of Fermat's Little Theorem and an axiom adding a new function symbol which injectively maps roots of polynomials over a definable finite field to numbers bounded by the degree of the given polynomial. To obtain our main result, we also give new formalizations of parts of number theory and algebra:\n$\\bullet$ In $PV_1$: We formalize Legendre's Formula on the prime factorization of $n!$, key properties of the Combinatorial Number System and the existence of cyclotomic polynomials over the finite fields $Z/p$.\n$\\bullet$ In $S^1_2$: We prove the inequality $lcm(1,\\dots, 2n) \\geq 2^n$.\n$\\bullet$ In $VTC^0$: We verify the correctness of the Kung--Sieveking algorithm for polynomial division.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17041",
    "tags": [
      "Logic (math.LO)"
    ],
    "createdAt": "2025-04-25T15:49:14.449276Z"
  },
  {
    "id": "db1ccdb2ffa997464d2cf3fccc1bbdc3",
    "title": "Precision Neural Network Quantization via Learnable Adaptive Modules",
    "slug": "precision-neural-network-quantization-via-learnable-adaptive-modules",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Wenqiang Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Quantization Aware Training (QAT) is a neural network quantization technique that compresses model size and improves operational efficiency while effectively maintaining model performance. The paradigm of QAT is to introduce fake quantization operators during the training process, allowing the model to autonomously compensate for information loss caused by quantization. Making quantization parameters trainable can significantly improve the performance of QAT, but at the cost of compromising the flexibility during inference, especially when dealing with activation values with substantially different distributions. In this paper, we propose an effective learnable adaptive neural network quantization method, called Adaptive Step Size Quantization (ASQ), to resolve this conflict. Specifically, the proposed ASQ method first dynamically adjusts quantization scaling factors through a trained module capable of accommodating different activations. Then, to address the rigid resolution issue inherent in Power of Two (POT) quantization, we propose an efficient non-uniform quantization scheme. We utilize the Power Of Square root of Two (POST) as the basis for exponential quantization, effectively handling the bell-shaped distribution of neural network weights across various bit-widths while maintaining computational efficiency through a Look-Up Table method (LUT). Extensive experimental results demonstrate that the proposed ASQ method is superior to the state-of-the-art QAT approaches. Notably that the ASQ is even competitive compared to full precision baselines, with its 4-bit quantized ResNet34 model improving accuracy by 1.2\\% on ImageNet.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17263",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:14.449493Z"
  },
  {
    "id": "b9255f1c8242398629c831d1b1ecffdd",
    "title": "Knapsack on Graphs with Relaxed Neighborhood Constraints",
    "slug": "knapsack-on-graphs-with-relaxed-neighborhood-constraints",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Palash Dey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the knapsack problems with neighborhood constraints that were studied before, the input is a graph $\\mathcal{G}$ on a set $\\mathcal{V}$ of items, each item $v \\in \\mathcal{V}$ has a weight $w_v$ and profit $p_v$, the size $s$ of the knapsack, and the demand $d$. The goal is to compute if there exists a feasible solution whose total weight is at most $s$ and total profit is at most $d$. Here, feasible solutions are all subsets $\\mathcal{S}$ of the items such that, for every item in $\\mathcal{S}$, at least one of its neighbors in $\\mathcal{G}$ is also in $\\mathcal{S}$ for \\hor, and all its neighbors in $\\mathcal{G}$ are also in $\\mathcal{S}$ for \\hand~\\cite{borradaile2012knapsack}. We study a relaxation of the above problems. Specifically, we allow all possible subsets of items to be feasible solutions. However, only those items for which we pick at least one or all of its neighbor (out-neighbor for directed graph) contribute to profit whereas every item picked contribute to the weight; we call the corresponding problems \\sor and \\sand. We show that both \\sor and \\sand are strongly \\NPC even on undirected graphs. Regarding parameterized complexity, we show both \\sor and \\hor are \\WTH parameterized by the size $s$ of the knapsack size. Interestingly, both \\sand and \\hand are \\WOH parameterized by knapsack size, $s$ plus profit demand, $d$ and also parameterized by solution size, $b$. For \\sor and \\hor, we present a randomized color-coding-based pseudo-\\FPT algorithm, parameterized by the solution size $b$, and consequently by the demand $d$. We then consider the treewidth of the input graph as our parameter and design pseudo fixed-parameter tractable (\\FPT) algorithm parameterized by treewidth, $\\text{tw}$ for all variants. Finally, we present an additive $1$ approximation for \\sor when both the weight and profit of every vertex is $1$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17297",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:14.449684Z"
  },
  {
    "id": "556f644cbd34b87e646dd2faf1feefb3",
    "title": "A general framework for finding diverse solutions via network flow and its applications",
    "slug": "a-general-framework-for-finding-diverse-solutions-via-network-flow-and-its-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Yuni Iwamasa",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we present a general framework for efficiently computing diverse solutions to combinatorial optimization problems. Given a problem instance, the goal is to find $k$ solutions that maximize a specified diversity measure; the sum of pairwise Hamming distances or the size of the union of the $k$ solutions. Our framework applies to problems satisfying two structural properties: (i) All solutions are of equal size and (ii) the family of all solutions can be represented by a surjection from the family of ideals of some finite poset. Under these conditions, we show that the problem of computing $k$ diverse solutions can be reduced to the minimum cost flow problem and the maximum $s$-$t$ flow problem. As applications, we demonstrate that both the unweighted minimum $s$-$t$ cut problem and the stable matching problem satisfy the requirements of our framework. By utilizing the recent advances in network flows algorithms, we improve the previously known time complexities of the diverse problems, which were based on submodular function minimization.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17633",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:14.449883Z"
  },
  {
    "id": "afa3e7c4e2db4e77e05c78be70f89f9b",
    "title": "Pseudorandomness of the Sticky Random Walk",
    "slug": "pseudorandomness-of-the-sticky-random-walk",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Emile Anand",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We extend the pseudorandomness of random walks on expander graphs using the sticky random walk. Building on prior works, it was recently shown that expander random walks can fool all symmetric functions in total variation distance (TVD) upto an $O(\\lambda(\\frac{p}{\\min f})^{O(p)})$ error, where $\\lambda$ is the second largest eigenvalue of the expander, $p$ is the size of the arbitrary alphabet used to label the vertices, and $\\min f = \\min_{b\\in[p]} f_b$, where $f_b$ is the fraction of vertices labeled $b$ in the graph. Golowich and Vadhan conjecture that the dependency on the $(\\frac{p}{\\min f})^{O(p)}$ term is not tight. In this paper, we resolve the conjecture in the affirmative for a family of expanders. We present a generalization of the sticky random walk for which Golowich and Vadhan predict a TVD upper bound of $O(\\lambda p^{O(p)})$ using a Fourier-analytic approach. For this family of graphs, we use a combinatorial approach involving the Krawtchouk functions to derive a strengthened TVD of $O(\\lambda)$. Furthermore, we present equivalencies between the generalized sticky random walk, and, using linear-algebraic techniques, show that the generalized sticky random walk parameterizes an infinite family of expander graphs.",
    "pdfUrl": "https://arxiv.org/pdf/2307.11104",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:14.450088Z"
  },
  {
    "id": "f318d16faf4a0d7a17ee941867aeb675",
    "title": "Algorithms and Hardness for Estimating Statistical Similarity",
    "slug": "algorithms-and-hardness-for-estimating-statistical-similarity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Arnab Bhattacharyya",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the problem of computing statistical similarity between probability distributions. For distributions $P$ and $Q$ over a finite sample space, their statistical similarity is defined as $S_{\\mathrm{stat}}(P, Q) := \\sum_{x} \\min(P(x), Q(x))$. Statistical similarity is a basic measure of similarity between distributions, with several natural interpretations, and captures the Bayes error in prediction and hypothesis testing problems. Recent work has established that, somewhat surprisingly, even for the simple class of product distributions, exactly computing statistical similarity is $\\#\\mathsf{P}$-hard. This motivates the question of designing approximation algorithms for statistical similarity. Our primary contribution is a Fully Polynomial-Time deterministic Approximation Scheme (FPTAS) for estimating statistical similarity between two product distributions. To obtain this result, we introduce a new variant of the Knapsack problem, which we call the Masked Knapsack problem, and design an FPTAS to estimate the number of solutions of a multidimensional version of this problem. This new technical contribution could be of independent interest. Furthermore, we also establish a complementary hardness result. We show that it is $\\mathsf{NP}$-hard to estimate statistical similarity when $P$ and $Q$ are Bayes net distributions of in-degree $2$.",
    "pdfUrl": "https://arxiv.org/pdf/2502.10527",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:14.450300Z"
  },
  {
    "id": "bfbfa361074c3774a05ca01f4262bf2a",
    "title": "An Entropy Stable Formulation of Two-equation Turbulence Models with Particular Reference to the k-epsilon Model",
    "slug": "an-entropy-stable-formulation-of-two-equation-turbulence-models-with-particular-reference-to-the-k-epsilon-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Engineering, Finance, and Science (cs.CE)",
    "author": {
      "name": "Guillermo Hauke",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Consistency and stability are two essential ingredients in the design of numerical algorithms for partial differential equations. Robust algorithms can be developed by incorporating nonlinear physical stability principles in their design, such as the entropy production inequality (i.e., the Clausius-Duhem inequality or second law of thermodynamics), rather than by simply adding artificial viscosity (a common approach). This idea is applied to the k-epsilon and two-equation turbulence models by introducing space-time averaging. Then, a set of entropy variables can be defined which leads to a symmetric system of advective-diffusive equations. Positivity and symmetry of the equations require certain constraints on the turbulence diffusivity coefficients and the turbulence source terms. With these, we are able to design entropy producing two-equation turbulence models and, in particular, the k-epsilon model.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17110",
    "tags": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "createdAt": "2025-04-25T15:49:14.709757Z"
  },
  {
    "id": "13cc2657ad79efbdca1e5013e946e26e",
    "title": "Tokenizing Stock Prices for Enhanced Multi-Step Forecast and Prediction",
    "slug": "tokenizing-stock-prices-for-enhanced-multi-step-forecast-and-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Engineering, Finance, and Science (cs.CE)",
    "author": {
      "name": "Zhuohang Zhu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Effective stock price forecasting (estimating future prices) and prediction (estimating future price changes) are pivotal for investors, regulatory agencies, and policymakers. These tasks enable informed decision-making, risk management, strategic planning, and superior portfolio returns. Despite their importance, forecasting and prediction are challenging due to the dynamic nature of stock price data, which exhibit significant temporal variations in distribution and statistical properties. Additionally, while both forecasting and prediction targets are derived from the same dataset, their statistical characteristics differ significantly. Forecasting targets typically follow a log-normal distribution, characterized by significant shifts in mean and variance over time, whereas prediction targets adhere to a normal distribution. Furthermore, although multi-step forecasting and prediction offer a broader perspective and richer information compared to single-step approaches, it is much more challenging due to factors such as cumulative errors and long-term temporal variance. As a result, many previous works have tackled either single-step stock price forecasting or prediction instead. To address these issues, we introduce a novel model, termed Patched Channel Integration Encoder (PCIE), to tackle both stock price forecasting and prediction. In this model, we utilize multiple stock channels that cover both historical prices and price changes, and design a novel tokenization method to effectively embed these channels in a cross-channel and temporally efficient manner. Specifically, the tokenization process involves univariate patching and temporal learning with a channel-mixing encoder to reduce cumulative errors. Comprehensive experiments validate that PCIE outperforms current state-of-the-art models in forecast and prediction tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17313",
    "tags": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "createdAt": "2025-04-25T15:49:14.709981Z"
  },
  {
    "id": "c67dccfdc68afd8dfd2937f8f8df7f7f",
    "title": "Data-Driven Surrogate Modeling Techniques to Predict the Effective Contact Area of Rough Surface Contact Problems",
    "slug": "data-driven-surrogate-modeling-techniques-to-predict-the-effective-contact-area-of-rough-surface-contact-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Engineering, Finance, and Science (cs.CE)",
    "author": {
      "name": "Tarik Sahin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The effective contact area in rough surface contact plays a critical role in multi-physics phenomena such as wear, sealing, and thermal or electrical conduction. Although accurate numerical methods, like the Boundary Element Method (BEM), are available to compute this quantity, their high computational cost limits their applicability in multi-query contexts, such as uncertainty quantification, parameter identification, and multi-scale algorithms, where many repeated evaluations are required. This study proposes a surrogate modeling framework for predicting the effective contact area using fast-to-evaluate data-driven techniques. Various machine learning algorithms are trained on a precomputed dataset, where the inputs are the imposed load and statistical roughness parameters, and the output is the corresponding effective contact area. All models undergo hyperparameter optimization to enable fair comparisons in terms of predictive accuracy and computational efficiency, evaluated using established quantitative metrics. Among the models, the Kernel Ridge Regressor demonstrates the best trade-off between accuracy and efficiency, achieving high predictive accuracy, low prediction time, and minimal training overhead-making it a strong candidate for general-purpose surrogate modeling. The Gaussian Process Regressor provides an attractive alternative when uncertainty quantification is required, although it incurs additional computational cost due to variance estimation. The generalization capability of the Kernel Ridge model is validated on an unseen simulation scenario, confirming its ability to transfer to new configurations. Database generation constitutes the dominant cost in the surrogate modeling process. Nevertheless, the approach proves practical and efficient for multi-query tasks, even when accounting for this initial expense.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17354",
    "tags": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "createdAt": "2025-04-25T15:49:14.710203Z"
  },
  {
    "id": "7432993161f809e0b80c6d48673dcaea",
    "title": "polyGen: A Learning Framework for Atomic-level Polymer Structure Generation",
    "slug": "polygen:-a-learning-framework-for-atomic-level-polymer-structure-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Engineering, Finance, and Science (cs.CE)",
    "author": {
      "name": "Ayush Jain",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Synthetic polymeric materials underpin fundamental technologies in the energy, electronics, consumer goods, and medical sectors, yet their development still suffers from prolonged design timelines. Although polymer informatics tools have supported speedup, polymer simulation protocols continue to face significant challenges: on-demand generation of realistic 3D atomic structures that respect the conformational diversity of polymer structures. Generative algorithms for 3D structures of inorganic crystals, bio-polymers, and small molecules exist, but have not addressed synthetic polymers. In this work, we introduce polyGen, the first latent diffusion model designed specifically to generate realistic polymer structures from minimal inputs such as the repeat unit chemistry alone, leveraging a molecular encoding that captures polymer connectivity throughout the architecture. Due to a scarce dataset of only 3855 DFT-optimized polymer structures, we augment our training with DFT-optimized molecular structures, showing improvement in joint learning between similar chemical structures. We also establish structure matching criteria to benchmark our approach on this novel problem. polyGen effectively generates diverse conformations of both linear chains and complex branched structures, though its performance decreases when handling repeat units with a high atom count. Given these initial results, polyGen represents a paradigm shift in atomic-level structure generation for polymer science-the first proof-of-concept for predicting realistic atomic-level polymer conformations while accounting for their intrinsic structural flexibility.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17656",
    "tags": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "createdAt": "2025-04-25T15:49:14.710400Z"
  },
  {
    "id": "496c42522840eb42925c1e613000967f",
    "title": "Demonstration of an AI-driven workflow for dynamic x-ray spectroscopy",
    "slug": "demonstration-of-an-ai-driven-workflow-for-dynamic-x-ray-spectroscopy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Applied Physics (physics.app-ph)",
    "author": {
      "name": "Ming Du",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "X-ray absorption near edge structure (XANES) spectroscopy is a powerful technique for characterizing the chemical state and symmetry of individual elements within materials, but requires collecting data at many energy points which can be time-consuming. While adaptive sampling methods exist for efficiently collecting spectroscopic data, they often lack domain-specific knowledge about XANES spectra structure. Here we demonstrate a knowledge-injected Bayesian optimization approach for adaptive XANES data collection that incorporates understanding of spectral features like absorption edges and pre-edge peaks. We show this method accurately reconstructs the absorption edge of XANES spectra using only 15-20% of the measurement points typically needed for conventional sampling, while maintaining the ability to determine the x-ray energy of the sharp peak after absorption edge with errors less than 0.03 eV, the absorption edge with errors less than 0.1 eV; and overall root-mean-square errors less than 0.005 compared to compared to traditionally sampled spectra. Our experiments on battery materials and catalysts demonstrate the method's effectiveness for both static and dynamic XANES measurements, improving data collection efficiency and enabling better time resolution for tracking chemical changes. This approach advances the degree of automation in XANES experiments reducing the common errors of under- or over-sampling points in near the absorption edge and enabling dynamic experiments that require high temporal resolution or limited measurement time.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17124",
    "tags": [
      "Applied Physics (physics.app-ph)"
    ],
    "createdAt": "2025-04-25T15:49:14.710611Z"
  },
  {
    "id": "d7b5ca4be6e8abdd9e61dcf7e06fae48",
    "title": "Reinforcement learning framework for the mechanical design of microelectronic components under multiphysics constraints",
    "slug": "reinforcement-learning-framework-for-the-mechanical-design-of-microelectronic-components-under-multiphysics-constraints",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Physics (physics.comp-ph)",
    "author": {
      "name": "Siddharth Nair",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study focuses on the development of reinforcement learning based techniques for the design of microelectronic components under multiphysics constraints. While traditional design approaches based on global optimization approaches are effective when dealing with a small number of design parameters, as the complexity of the solution space and of the constraints increases different techniques are needed. This is an important reason that makes the design and optimization of microelectronic components (characterized by large solution space and multiphysics constraints) very challenging for traditional methods. By taking as prototypical elements an application-specific integrated circuit (ASIC) and a heterogeneously integrated (HI) interposer, we develop and numerically test an optimization framework based on reinforcement learning (RL). More specifically, we consider the optimization of the bonded interconnect geometry for an ASIC chip as well as the placement of components on a HI interposer while satisfying thermoelastic and design constraints. This placement problem is particularly interesting because it features a high-dimensional solution space.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17142",
    "tags": [
      "Computational Physics (physics.comp-ph)"
    ],
    "createdAt": "2025-04-25T15:49:14.710825Z"
  },
  {
    "id": "ea67458f049d3b3ab7ed934bc649ffed",
    "title": "Detection, Classification and Prevalence of Self-Admitted Aging Debt",
    "slug": "detection,-classification-and-prevalence-of-self-admitted-aging-debt",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Murali Sridharan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Context: Previous research on software aging is limited with focus on dynamic runtime indicators like memory and performance, often neglecting evolutionary indicators like source code comments and narrowly examining legacy issues within the TD context. Objective: We introduce the concept of Aging Debt (AD), representing the increased maintenance efforts and costs needed to keep software updated. We study AD through Self-Admitted Aging Debt (SAAD) observed in source code comments left by software developers. Method: We employ a mixed-methods approach, combining qualitative and quantitative analyses to detect and measure AD in software. This includes framing SAAD patterns from the source code comments after analysing the source code context, then utilizing the SAAD patterns to detect SAAD comments. In the process, we develop a taxonomy for SAAD that reflects the temporal aging of software and its associated debt. Then we utilize the taxonomy to quantify the different types of AD prevalent in OSS repositories. Results: Our proposed taxonomy categorizes temporal software aging into Active and Dormant types. Our extensive analysis of over 9,000+ Open Source Software (OSS) repositories reveals that more than 21% repositories exhibit signs of SAAD as observed from our gold standard SAAD dataset. Notably, Dormant AD emerges as the predominant category, highlighting a critical but often overlooked aspect of software maintenance. Conclusion: As software volume grows annually, so do evolutionary aging and maintenance challenges; our proposed taxonomy can aid researchers in detailed software aging studies and help practitioners develop improved and proactive maintenance strategies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17428",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:14.711033Z"
  },
  {
    "id": "5a9120261a772515008e3e60e1f5c715",
    "title": "An approach based on metaheuristic algorithms to the timetabling problem in deregulated railway markets",
    "slug": "an-approach-based-on-metaheuristic-algorithms-to-the-timetabling-problem-in-deregulated-railway-markets",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "David Muoz-Valero",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The train timetabling problem in liberalized railway markets represents a challenge to the coordination between infrastructure managers and railway undertakings. Efficient scheduling is critical in maximizing infrastructure capacity and utilization while adhering as closely as possible to the requests of railway undertakings. These objectives ultimately contribute to maximizing the infrastructure manager's revenues. This paper sets out a modular simulation framework to reproduce the dynamics of deregulated railway systems. Ten metaheuristic algorithms using the MEALPY Python library are then evaluated in order to optimize train schedules in the liberalized Spanish railway market. The results show that the Genetic Algorithm outperforms others in revenue optimization, convergence speed, and schedule adherence. Alternatives, such as Particle Swarm Optimization and Ant Colony Optimization Continuous, show slower convergence and higher variability. The results emphasize the trade-off between scheduling more trains and adhering to requested times, providing insights into solving complex scheduling problems in deregulated railway systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17455",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:14.711246Z"
  },
  {
    "id": "a2fac57acaf98c4f045245385fb5e324",
    "title": "Towards Equitable Rail Service Allocation Through Fairness-Oriented Timetabling in Liberalized Markets",
    "slug": "towards-equitable-rail-service-allocation-through-fairness-oriented-timetabling-in-liberalized-markets",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "David Muoz-Valero",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Over the last few decades, European rail transport has undergone major changes as part of the process of liberalization set out in European regulations. In this context of liberalization, railway undertakings compete with each other for the limited infrastructure capacity available to offer their rail services. The infrastructure manager is responsible for the equitable allocation of infrastructure between all companies in the market, which is essential to ensure the efficiency and sustainability of this competitive ecosystem. In this paper, a methodology based on Jain, Gini and Atkinson equity metrics is used to solve the rail service allocation problem in a liberalized railway market, analyzing the solutions obtained. The results show that the proposed methodology and the equity metrics used allow for equitable planning in different competitiveness scenarios. These results contrast with solutions where the objective of the infrastructure manager is to maximize its own profit, without regard for the equitable allocation of infrastructure. Therefore, the computational tests support the methodology and metrics used as a planning and decision support tool in a liberalized railway market.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17489",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:14.711460Z"
  },
  {
    "id": "1cc9dd1caffdd536b1b54412c4c2d501",
    "title": "Separating Two Points with Obstacles in the Plane: Improved Upper and Lower Bounds",
    "slug": "separating-two-points-with-obstacles-in-the-plane:-improved-upper-and-lower-bounds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Geometry (cs.CG)",
    "author": {
      "name": "Jack Spalding-Jamieson",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Given two points in the plane, and a set of \"obstacles\" given as curves through the plane with assigned weights, we consider the point-separation problem, which asks for the minimum-weight subset of the obstacles separating the two points. A few computational models for this problem have been previously studied. We give a unified approach to this problem in all models via a reduction to a particular shortest-path problem, and obtain improved running times in essentially all cases. In addition, we also give fine-grained lower bounds for many cases.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17289",
    "tags": [
      "Computational Geometry (cs.CG)"
    ],
    "createdAt": "2025-04-25T15:49:14.935035Z"
  },
  {
    "id": "a6245b5998fc0038b5ed405056de6761",
    "title": "Frchet Distance in Unweighted Planar Graphs",
    "slug": "frchet-distance-in-unweighted-planar-graphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Geometry (cs.CG)",
    "author": {
      "name": "Ivor van der Hoog",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Frchet distance is a distance measure between trajectories in the plane or walks in a graph G. Given constant-time shortest path queries in a graph G, the Discrete Frchet distance $F_G(P, Q)$ between two walks P and Q can be computed in $O(|P| \\cdot |Q|)$ time using a dynamic program. Driemel, van der Hoog, and Rotenberg [SoCG'22] show that for weighted planar graphs this approach is likely tight, as there can be no strongly subquadratic algorithm to compute a $1.01$-approximation of $F_G(P, Q)$ unless the Orthogonal Vector Hypothesis (OVH) fails.\nSuch quadratic-time conditional lower bounds are common to many Frchet distance variants. However, they can be circumvented by assuming that the input comes from some well-behaved class: There exist $(1+\\varepsilon)$-approximations, both in weighted graphs and in Rd, that take near-linear time for $c$-packed or $\\kappa$-straight walks in the graph. In Rd, there also exists a near-linear time algorithm to compute the Frchet distance whenever all input edges are long compared to the distance.\nWe consider computing the Frchet distance in unweighted planar graphs. We show that there exist no 1.25-approximations of the discrete Frchet distance between two disjoint simple paths in an unweighted planar graph in strongly subquadratic time, unless OVH fails. This improves the previous lower bound, both in terms of generality and approximation factor. We subsequently show that adding graph structure circumvents this lower bound: If the graph is a regular tiling with unit-weighted edges, then there exists an $\\tilde{O}( (|P| + |Q|)^{1.5})$-time algorithm to compute $D_F(P, Q)$. Our result has natural implications in the plane, as it allows us to define a new class of well-behaved curves that facilitate $(1+\\varepsilon)$-approximations of their discrete Frchet distance in subquadratic time.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17342",
    "tags": [
      "Computational Geometry (cs.CG)"
    ],
    "createdAt": "2025-04-25T15:49:14.935257Z"
  },
  {
    "id": "0d53cfcf017bfbecb268f7dbafd6e172",
    "title": "Subtrajectory Clustering and Coverage Maximization in Cubic Time, or Better",
    "slug": "subtrajectory-clustering-and-coverage-maximization-in-cubic-time,-or-better",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Geometry (cs.CG)",
    "author": {
      "name": "Jacobus Conradi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many application areas collect unstructured trajectory data. In subtrajectory clustering, one is interested to find patterns in this data using a hybrid combination of segmentation and clustering. We analyze two variants of this problem based on the well-known \\textsc{SetCover} and \\textsc{CoverageMaximization} problems. In both variants the set system is induced by metric balls under the Frchet distance centered at polygonal curves. Our algorithms focus on improving the running time of the update step of the generic greedy algorithm by means of a careful combination of sweeps through a candidate space. In the first variant, we are given a polygonal curve $P$ of complexity $n$, distance threshold $\\Delta$ and complexity bound $\\ell$ and the goal is to identify a minimum-size set of center curves $\\mathcal{C}$, where each center curve is of complexity at most $\\ell$ and every point $p$ on $P$ is covered. A point $p$ on $P$ is covered if it is part of a subtrajectory $\\pi_p$ of $P$ such that there is a center $c\\in\\mathcal{C}$ whose Frchet distance to $\\pi_p$ is at most $\\Delta$. We present an approximation algorithm for this problem with a running time of $O((n^2\\ell + \\sqrt{k_\\Delta}n^{5/2})\\log^2n)$, where $k_\\Delta$ is the size of an optimal solution. The algorithm gives a bicriterial approximation guarantee that relaxes the Frchet distance threshold by a constant factor and the size of the solution by a factor of $O(\\log n)$. The second problem variant asks for the maximum fraction of the input curve $P$ that can be covered using $k$ center curves, where $k\\leq n$ is a parameter to the algorithm. Here, we show that our techniques lead to an algorithm with a running time of $O((k+\\ell)n^2\\log^2 n)$ and similar approximation guarantees. Note that in both algorithms $k,k_\\Delta\\in O(n)$ and hence the running time is cubic, or better if $k\\ll n$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17381",
    "tags": [
      "Computational Geometry (cs.CG)"
    ],
    "createdAt": "2025-04-25T15:49:14.935449Z"
  },
  {
    "id": "50a4a5c2080bfa6af9a4b301490c03a4",
    "title": "Online Hitting Sets for Disks of Bounded Radii",
    "slug": "online-hitting-sets-for-disks-of-bounded-radii",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Geometry (cs.CG)",
    "author": {
      "name": "Minati De",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present algorithms for the online minimum hitting set problem in geometric range spaces: Given a set $P$ of $n$ points in the plane and a sequence of geometric objects that arrive one-by-one, we need to maintain a hitting set at all times. For disks of radii in the interval $[1,M]$, we present an $O(\\log M \\log n)$-competitive algorithm. This result generalizes from disks to positive homothets of any convex body in the plane with scaling factors in the interval $[1,M]$. As a main technical tool, we reduce the problem to the online hitting set problem for a finite subset of integer points and bottomless rectangles. Specifically, for a given $N>1$, we present an $O(\\log N)$-competitive algorithm for the variant where $P$ is a subset of an $N\\times N$ section of the integer lattice, and the geometric objects are bottomless rectangles.",
    "pdfUrl": "https://arxiv.org/pdf/2412.04646",
    "tags": [
      "Computational Geometry (cs.CG)"
    ],
    "createdAt": "2025-04-25T15:49:14.935654Z"
  },
  {
    "id": "22f61945dfe22c39ab7aec9d7a61bb28",
    "title": "Bidirectional Mamba for Single-Cell Data: Efficient Context Learning with Biological Fidelity",
    "slug": "bidirectional-mamba-for-single-cell-data:-efficient-context-learning-with-biological-fidelity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Cong Qi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of cellular heterogeneity, but its complexity, which is marked by high dimensionality, sparsity, and batch effects, which poses major computational challenges. Transformer-based models have made significant advances in this domain but are often limited by their quadratic complexity and suboptimal handling of long-range dependencies. In this work, we introduce GeneMamba, a scalable and efficient foundation model for single-cell transcriptomics built on state space modeling. Leveraging the Bi-Mamba architecture, GeneMamba captures bidirectional gene context with linear-time complexity, offering substantial computational gains over transformer baselines. The model is pretrained on nearly 30 million cells and incorporates biologically informed objectives, including pathway-aware contrastive loss and rank-based gene encoding. We evaluate GeneMamba across diverse tasks, including multi-batch integration, cell type annotation, and gene-gene correlation, demonstrating strong performance, interpretability, and robustness. These results position GeneMamba as a practical and powerful alternative to transformer-based methods, advancing the development of biologically grounded, scalable tools for large-scale single-cell data analysis.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16956",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.772396Z"
  },
  {
    "id": "ad9b1c3d9fc5a5918554a45940d871cf",
    "title": "Tokenization Matters: Improving Zero-Shot NER for Indic Languages",
    "slug": "tokenization-matters:-improving-zero-shot-ner-for-indic-languages",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Priyaranjan Pattnayak",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Tokenization is a critical component of Natural Language Processing (NLP), especially for low resource languages, where subword segmentation influences vocabulary structure and downstream task accuracy. Although Byte Pair Encoding (BPE) is a standard tokenization method in multilingual language models, its suitability for Named Entity Recognition (NER) in low resource Indic languages remains underexplored due to its limitations in handling morphological complexity. In this work, we systematically compare BPE, SentencePiece, and Character Level tokenization strategies using IndicBERT for NER tasks in low resource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as extremely low resource Indic languages like Santali, Manipuri, and Sindhi. We assess both intrinsic linguistic properties tokenization efficiency, out of vocabulary (OOV) rates, and morphological preservation as well as extrinsic downstream performance, including fine tuning and zero shot cross lingual transfer.\nOur experiments show that SentencePiece is a consistently better performing approach than BPE for NER in low resource Indic Languages, particularly in zero shot cross lingual settings, as it better preserves entity consistency. While BPE provides the most compact tokenization form, it is not capable of generalization because it misclassifies or even fails to recognize entity labels when tested on unseen languages. In contrast, SentencePiece constitutes a better linguistic structural preservation model, benefiting extremely low resource and morphologically rich Indic languages, such as Santali and Manipuri, for superior entity recognition, as well as high generalization across scripts, such as Sindhi, written in Arabic. The results point to SentencePiece as the more effective tokenization strategy for NER within multilingual and low resource Indic NLP applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16977",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.772616Z"
  },
  {
    "id": "16cd1b6baac85e7e40adb485e0c32a60",
    "title": "Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation",
    "slug": "optimizing-llms-for-italian:-reducing-token-fertility-and-enhancing-efficiency-through-vocabulary-adaptation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Luca Moroni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The number of pretrained Large Language Models (LLMs) is increasing steadily, though the majority are designed predominantly for the English language. While state-of-the-art LLMs can handle other languages, due to language contamination or some degree of multilingual pretraining data, they are not optimized for non-English languages, leading to inefficient encoding (high token \"fertility\") and slower inference speed. In this work, we thoroughly compare a variety of vocabulary adaptation techniques for optimizing English LLMs for the Italian language, and put forward Semantic Alignment Vocabulary Adaptation (SAVA), a novel method that leverages neural mapping for vocabulary substitution. SAVA achieves competitive performance across multiple downstream tasks, enhancing grounded alignment strategies. We adapt two LLMs: Mistral-7b-v0.1, reducing token fertility by 25\\%, and Llama-3.1-8B, optimizing the vocabulary and reducing the number of parameters by 1 billion. We show that, following the adaptation of the vocabulary, these models can recover their performance with a relatively limited stage of continual training on the target language. Finally, we test the capabilities of the adapted models on various multi-choice and generative tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17025",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.772842Z"
  },
  {
    "id": "dd8388f122a4ed24aad08337de66d8f2",
    "title": "Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models",
    "slug": "do-words-reflect-beliefs?-evaluating-belief-depth-in-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Shariar Kabir",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) are increasingly shaping political discourse, yet their responses often display inconsistency when subjected to scrutiny. While prior research has primarily categorized LLM outputs as left- or right-leaning to assess their political stances, a critical question remains: Do these responses reflect genuine internal beliefs or merely surface-level alignment with training data? To address this, we propose a novel framework for evaluating belief depth by analyzing (1) argumentative consistency and (2) uncertainty quantification. We evaluate 12 LLMs on 19 economic policies from the Political Compass Test, challenging their belief stability with both supportive and opposing arguments. Our analysis reveals that LLMs exhibit topic-specific belief stability rather than a uniform ideological stance. Notably, up to 95% of left-leaning models' responses and 89% of right-leaning models' responses remain consistent under the challenge, enabling semantic entropy to achieve high accuracy (AUROC=0.78), effectively distinguishing between surface-level alignment from genuine belief. These findings call into question the assumption that LLMs maintain stable, human-like political ideologies, emphasizing the importance of conducting topic-specific reliability assessments for real-world applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17052",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.773058Z"
  },
  {
    "id": "1c9a7f5ffea3bb21796b14ad6e23b374",
    "title": "Agree to Disagree? A Meta-Evaluation of LLM Misgendering",
    "slug": "agree-to-disagree?-a-meta-evaluation-of-llm-misgendering",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Arjun Subramonian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Numerous methods have been proposed to measure LLM misgendering, including probability-based evaluations (e.g., automatically with templatic sentences) and generation-based evaluations (e.g., with automatic heuristics or human validation). However, it has gone unexamined whether these evaluation methods have convergent validity, that is, whether their results align. Therefore, we conduct a systematic meta-evaluation of these methods across three existing datasets for LLM misgendering. We propose a method to transform each dataset to enable parallel probability- and generation-based evaluation. Then, by automatically evaluating a suite of 6 models from 3 families, we find that these methods can disagree with each other at the instance, dataset, and model levels, conflicting on 20.2% of evaluation instances. Finally, with a human evaluation of 2400 LLM generations, we show that misgendering behaviour is complex and goes far beyond pronouns, which automatic evaluations are not currently designed to capture, suggesting essential disagreement with human evaluations. Based on our findings, we provide recommendations for future evaluations of LLM misgendering. Our results are also more widely relevant, as they call into question broader methodological conventions in LLM evaluation, which often assume that different evaluation methods agree.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17075",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.773280Z"
  },
  {
    "id": "44d3be11391e5ac442ed3263be30cf71",
    "title": "How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study",
    "slug": "how-individual-traits-and-language-styles-shape-preferences-in-open-ended-user-llm-interaction:-a-preliminary-study",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Rendi Chevi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "What makes an interaction with the LLM more preferable for the user? While it is intuitive to assume that information accuracy in the LLM's responses would be one of the influential variables, recent studies have found that inaccurate LLM's responses could still be preferable when they are perceived to be more authoritative, certain, well-articulated, or simply verbose. These variables interestingly fall under the broader category of language style, implying that the style in the LLM's responses might meaningfully influence users' preferences. This hypothesized dynamic could have double-edged consequences: enhancing the overall user experience while simultaneously increasing their susceptibility to risks such as LLM's misinformation or hallucinations. In this short paper, we present our preliminary studies in exploring this subject. Through a series of exploratory and experimental user studies, we found that LLM's language style does indeed influence user's preferences, but how and which language styles influence the preference varied across different user populations, and more interestingly, moderated by the user's very own individual traits. As a preliminary work, the findings in our studies should be interpreted with caution, particularly given the limitations in our samples, which still need wider demographic diversity and larger sample sizes. Our future directions will first aim to address these limitations, which would enable a more comprehensive joint effect analysis between the language style, individual traits, and preferences, and further investigate the potential causal relationship between and beyond these variables.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17083",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.773492Z"
  },
  {
    "id": "1cde5c7ca0606102d06f15e73064bfe7",
    "title": "Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning",
    "slug": "co-cot:-a-prompt-based-framework-for-collaborative-chain-of-thought-reasoning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Seunghyun Yoo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Due to the proliferation of short-form content and the rapid adoption of AI, opportunities for deep, reflective thinking have significantly diminished, undermining users' critical thinking and reducing engagement with the reasoning behind AI-generated outputs. To address this issue, we propose an Interactive Chain-of-Thought (CoT) Framework that enhances human-centered explainability and responsible AI usage by making the model's inference process transparent, modular, and user-editable. The framework decomposes reasoning into clearly defined blocks that users can inspect, modify, and re-execute, encouraging active cognitive engagement rather than passive consumption. It further integrates a lightweight edit-adaptation mechanism inspired by preference learning, allowing the system to align with diverse cognitive styles and user intentions. Ethical transparency is ensured through explicit metadata disclosure, built-in bias checkpoint functionality, and privacy-preserving safeguards. This work outlines the design principles and architecture necessary to promote critical engagement, responsible interaction, and inclusive adaptation in AI systems aimed at addressing complex societal challenges.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17091",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.773684Z"
  },
  {
    "id": "bd18d0c1b44b32578d47af1a25cb2d02",
    "title": "The Rise of Small Language Models in Healthcare: A Comprehensive Survey",
    "slug": "the-rise-of-small-language-models-in-healthcare:-a-comprehensive-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Muskan Garg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Despite substantial progress in healthcare applications driven by large language models (LLMs), growing concerns around data privacy, and limited resources; the small language models (SLMs) offer a scalable and clinically viable solution for efficient performance in resource-constrained environments for next-generation healthcare informatics. Our comprehensive survey presents a taxonomic framework to identify and categorize them for healthcare professionals and informaticians. The timeline of healthcare SLM contributions establishes a foundational framework for analyzing models across three dimensions: NLP tasks, stakeholder roles, and the continuum of care. We present a taxonomic framework to identify the architectural foundations for building models from scratch; adapting SLMs to clinical precision through prompting, instruction fine-tuning, and reasoning; and accessibility and sustainability through compression techniques. Our primary objective is to offer a comprehensive survey for healthcare professionals, introducing recent innovations in model optimization and equipping them with curated resources to support future research and development in the field. Aiming to showcase the groundbreaking advancements in SLMs for healthcare, we present a comprehensive compilation of experimental results across widely studied NLP tasks in healthcare to highlight the transformative potential of SLMs in healthcare. The updated repository is available at Github",
    "pdfUrl": "https://arxiv.org/pdf/2504.17119",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.773908Z"
  },
  {
    "id": "6ee377a5ca9b24d8efaec61fcb886674",
    "title": "Steering the CensorShip: Uncovering Representation Vectors for LLM \"Thought\" Control",
    "slug": "steering-the-censorship:-uncovering-representation-vectors-for-llm-\"thought\"-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Hannah Cyberey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) have transformed the way we access information. These models are often tuned to refuse to comply with requests that are considered harmful and to produce responses that better align with the preferences of those who control the models. To understand how this \"censorship\" works. We use representation engineering techniques to study open-weights safety-tuned models. We present a method for finding a refusal--compliance vector that detects and controls the level of censorship in model outputs. We also analyze recent reasoning LLMs, distilled from DeepSeek-R1, and uncover an additional dimension of censorship through \"thought suppression\". We show a similar approach can be used to find a vector that suppresses the model's reasoning process, allowing us to remove censorship by applying the negative multiples of this vector",
    "pdfUrl": "https://arxiv.org/pdf/2504.17130",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.774111Z"
  },
  {
    "id": "9fbbb25ebf05d83d05696e35dcb17281",
    "title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation",
    "slug": "mirage:-a-metric-intensive-benchmark-for-retrieval-augmented-generation-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Chanhee Park",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Retrieval-Augmented Generation (RAG) has gained prominence as an effective method for enhancing the generative capabilities of Large Language Models (LLMs) through the incorporation of external knowledge. However, the evaluation of RAG systems remains a challenge, due to the intricate interplay between retrieval and generation components. This limitation has resulted in a scarcity of benchmarks that facilitate a detailed, component-specific assessment. In this work, we present MIRAGE, a Question Answering dataset specifically designed for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped to a retrieval pool of 37,800 entries, enabling an efficient and precise evaluation of both retrieval and generation tasks. We also introduce novel evaluation metrics aimed at measuring RAG adaptability, encompassing dimensions such as noise vulnerability, context acceptability, context insensitivity, and context misinterpretation. Through comprehensive experiments across various retriever-LLM configurations, we provide new insights into the optimal alignment of model pairs and the nuanced dynamics within RAG systems. The dataset and evaluation code are publicly available, allowing for seamless integration and customization in diverse research settings\\footnote{The MIRAGE code and data are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17137",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.774331Z"
  },
  {
    "id": "52ab77e6078cf81a64006fe8c87a761d",
    "title": "Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning",
    "slug": "paper2code:-automating-code-generation-from-scientific-papers-in-machine-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Minju Seo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Despite the rapid growth of machine learning research, corresponding code implementations are often unavailable, making it slow and labor-intensive for researchers to reproduce results and build upon prior work. In the meantime, recent Large Language Models (LLMs) excel at understanding scientific documents and generating high-quality code. Inspired by this, we introduce PaperCoder, a multi-agent LLM framework that transforms machine learning papers into functional code repositories. PaperCoder operates in three stages: planning, where it constructs a high-level roadmap, designs the system architecture with diagrams, identifies file dependencies, and generates configuration files; analysis, which focuses on interpreting implementation-specific details; and generation, where modular, dependency-aware code is produced. Moreover, each phase is instantiated through a set of specialized agents designed to collaborate effectively across the pipeline. We then evaluate PaperCoder on generating code implementations from machine learning papers based on both model-based and human evaluations, specifically from the original paper authors, with author-released repositories as ground truth if available. Our results demonstrate the effectiveness of PaperCoder in creating high-quality, faithful implementations. Furthermore, it consistently shows strengths in the recently released PaperBench benchmark, surpassing strong baselines by substantial margins.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17192",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.774543Z"
  },
  {
    "id": "0b0258cce5ba4c8fbe149eadb40f972a",
    "title": "A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation",
    "slug": "a-rag-based-multi-agent-llm-system-for-natural-hazard-resilience-and-adaptation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yangxinyu Xie",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) are a transformational capability at the frontier of artificial intelligence and machine learning that can support decision-makers in addressing pressing societal challenges such as extreme natural hazard events. As generalized models, LLMs often struggle to provide context-specific information, particularly in areas requiring specialized knowledge. In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM system to support analysis and decision-making in the context of natural hazards and extreme weather events. As a proof of concept, we present WildfireGPT, a specialized system focused on wildfire hazards. The architecture employs a user-centered, multi-agent design to deliver tailored risk insights across diverse stakeholder groups. By integrating natural hazard and extreme weather projection data, observational datasets, and scientific literature through an RAG framework, the system ensures both the accuracy and contextual relevance of the information it provides. Evaluation across ten expert-led case studies demonstrates that WildfireGPT significantly outperforms existing LLM-based solutions for decision support.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17200",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.774791Z"
  },
  {
    "id": "2ab6de565c395cb683f697990ebb391b",
    "title": "Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?",
    "slug": "does-knowledge-distillation-matter-for-large-language-model-based-bundle-generation?",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Kaidong Feng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LLMs are increasingly explored for bundle generation, thanks to their reasoning capabilities and knowledge. However, deploying large-scale LLMs introduces significant efficiency challenges, primarily high computational costs during fine-tuning and inference due to their massive parameterization. Knowledge distillation (KD) offers a promising solution, transferring expertise from large teacher models to compact student models. This study systematically investigates knowledge distillation approaches for bundle generation, aiming to minimize computational demands while preserving performance. We explore three critical research questions: (1) how does the format of KD impact bundle generation performance? (2) to what extent does the quantity of distilled knowledge influence performance? and (3) how do different ways of utilizing the distilled knowledge affect performance? We propose a comprehensive KD framework that (i) progressively extracts knowledge (patterns, rules, deep thoughts); (ii) captures varying quantities of distilled knowledge through different strategies; and (iii) exploits complementary LLM adaptation techniques (in-context learning, supervised fine-tuning, combination) to leverage distilled knowledge in small student models for domain-specific adaptation and enhanced efficiency. Extensive experiments provide valuable insights into how knowledge format, quantity, and utilization methodologies collectively shape LLM-based bundle generation performance, exhibiting KD's significant potential for more efficient yet effective LLM-based bundle generation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17220",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.775015Z"
  },
  {
    "id": "2efd20b5ae31c39f557e6a1b042e9d55",
    "title": "Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues",
    "slug": "crisp:-cognitive-restructuring-of-negative-thoughts-through-multi-turn-supportive-dialogues",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jinfeng Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Cognitive Restructuring (CR) is a psychotherapeutic process aimed at identifying and restructuring an individual's negative thoughts, arising from mental health challenges, into more helpful and positive ones via multi-turn dialogues. Clinician shortage and stigma urge the development of human-LLM interactive psychotherapy for CR. Yet, existing efforts implement CR via simple text rewriting, fixed-pattern dialogues, or a one-shot CR workflow, failing to align with the psychotherapeutic process for effective CR. To address this gap, we propose CRDial, a novel framework for CR, which creates multi-turn dialogues with specifically designed identification and restructuring stages of negative thoughts, integrates sentence-level supportive conversation strategies, and adopts a multi-channel loop mechanism to enable iterative CR. With CRDial, we distill Crisp, a large-scale and high-quality bilingual dialogue dataset, from LLM. We then train Crispers, Crisp-based conversational LLMs for CR, at 7B and 14B scales. Extensive human studies show the superiority of Crispers in pointwise, pairwise, and intervention evaluations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17238",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.775276Z"
  },
  {
    "id": "5cf3bc24d3d92b24ce7cc8fc07f9d7a4",
    "title": "Low-Resource Neural Machine Translation Using Recurrent Neural Networks and Transfer Learning: A Case Study on English-to-Igbo",
    "slug": "low-resource-neural-machine-translation-using-recurrent-neural-networks-and-transfer-learning:-a-case-study-on-english-to-igbo",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Ocheme Anthony Ekle",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this study, we develop Neural Machine Translation (NMT) and Transformer-based transfer learning models for English-to-Igbo translation - a low-resource African language spoken by over 40 million people across Nigeria and West Africa. Our models are trained on a curated and benchmarked dataset compiled from Bible corpora, local news, Wikipedia articles, and Common Crawl, all verified by native language experts. We leverage Recurrent Neural Network (RNN) architectures, including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), enhanced with attention mechanisms to improve translation accuracy. To further enhance performance, we apply transfer learning using MarianNMT pre-trained models within the SimpleTransformers framework. Our RNN-based system achieves competitive results, closely matching existing English-Igbo benchmarks. With transfer learning, we observe a performance gain of +4.83 BLEU points, reaching an estimated translation accuracy of 70%. These findings highlight the effectiveness of combining RNNs with transfer learning to address the performance gap in low-resource language translation tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17252",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.775485Z"
  },
  {
    "id": "e2fd68b0e3141195db7d8a8bb4277af3",
    "title": "JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning",
    "slug": "jurisctc:-enhancing-legal-judgment-prediction-via-cross-domain-transfer-and-contrastive-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Zhaolu Kang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In recent years, Unsupervised Domain Adaptation (UDA) has gained significant attention in the field of Natural Language Processing (NLP) owing to its ability to enhance model generalization across diverse domains. However, its application for knowledge transfer between distinct legal domains remains largely unexplored. To address the challenges posed by lengthy and complex legal texts and the limited availability of large-scale annotated datasets, we propose JurisCTC, a novel model designed to improve the accuracy of Legal Judgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC facilitates effective knowledge transfer across various legal domains and employs contrastive learning to distinguish samples from different domains. Specifically, for the LJP task, we enable knowledge transfer between civil and criminal law domains. Compared to other models and specific large language models (LLMs), JurisCTC demonstrates notable advancements, achieving peak accuracies of 76.59% and 78.83%, respectively.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17264",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.775704Z"
  },
  {
    "id": "0d4663129641974b85a112b00bc7103f",
    "title": "Evaluating and Mitigating Bias in AI-Based Medical Text Generation",
    "slug": "evaluating-and-mitigating-bias-in-ai-based-medical-text-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Xiuying Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Artificial intelligence (AI) systems, particularly those based on deep learning models, have increasingly achieved expert-level performance in medical applications. However, there is growing concern that such AI systems may reflect and amplify human bias, and reduce the quality of their performance in historically under-served populations. The fairness issue has attracted considerable research interest in the medical imaging classification field, yet it remains understudied in the text generation domain. In this study, we investigate the fairness problem in text generation within the medical field and observe significant performance discrepancies across different races, sexes, and age groups, including intersectional groups, various model scales, and different evaluation metrics. To mitigate this fairness issue, we propose an algorithm that selectively optimizes those underperformed groups to reduce bias. The selection rules take into account not only word-level accuracy but also the pathology accuracy to the target reference, while ensuring that the entire process remains fully differentiable for effective model training. Our evaluations across multiple backbones, datasets, and modalities demonstrate that our proposed algorithm enhances fairness in text generation without compromising overall performance. Specifically, the disparities among various groups across different metrics were diminished by more than 30% with our algorithm, while the relative change in text generation accuracy was typically within 2%. By reducing the bias generated by deep learning models, our proposed approach can potentially alleviate concerns about the fairness and reliability of text generation diagnosis in medical domain.\nOur code is publicly available to facilitate further research at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17279",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.775924Z"
  },
  {
    "id": "100d121ba43fb99a2818e9abf47ab802",
    "title": "CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality",
    "slug": "cohemark:-a-novel-sentence-level-watermark-for-enhanced-text-quality",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Junyan Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Watermarking technology is a method used to trace the usage of content generated by large language models. Sentence-level watermarking aids in preserving the semantic integrity within individual sentences while maintaining greater robustness. However, many existing sentence-level watermarking techniques depend on arbitrary segmentation or generation processes to embed watermarks, which can limit the availability of appropriate sentences. This limitation, in turn, compromises the quality of the generated response. To address the challenge of balancing high text quality with robust watermark detection, we propose CoheMark, an advanced sentence-level watermarking technique that exploits the cohesive relationships between sentences for better logical fluency. The core methodology of CoheMark involves selecting sentences through trained fuzzy c-means clustering and applying specific next sentence selection criteria. Experimental evaluations demonstrate that CoheMark achieves strong watermark strength while exerting minimal impact on text quality.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17309",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.776148Z"
  },
  {
    "id": "0d6e9b6517b6be01bfb2c31fce1142b1",
    "title": "FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation",
    "slug": "fluke:-a-linguistically-driven-and-task-agnostic-framework-for-robustness-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yulia Otmakhova",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present FLUKE (Framework for LingUistically-driven and tasK-agnostic robustness Evaluation), a task-agnostic framework for assessing model robustness through systematic minimal variations of test data. FLUKE introduces controlled variations across linguistic levels - from orthography to dialect and style varieties - and leverages large language models (LLMs) with human validation to generate modifications. We demonstrate FLUKE's utility by evaluating both fine-tuned models and LLMs across four diverse NLP tasks, and reveal that (1) the impact of linguistic variations is highly task-dependent, with some tests being critical for certain tasks but irrelevant for others; (2) while LLMs have better overall robustness compared to fine-tuned models, they still exhibit significant brittleness to certain linguistic variations; (3) all models show substantial vulnerability to negation modifications across most tasks. These findings highlight the importance of systematic robustness testing for understanding model behaviors.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17311",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.776361Z"
  },
  {
    "id": "6ae2c8f40a019085e7a13cdd31001cb4",
    "title": "Bridging Cognition and Emotion: Empathy-Driven Multimodal Misinformation Detection",
    "slug": "bridging-cognition-and-emotion:-empathy-driven-multimodal-misinformation-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Zihan Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the digital era, social media has become a major conduit for information dissemination, yet it also facilitates the rapid spread of misinformation. Traditional misinformation detection methods primarily focus on surface-level features, overlooking the crucial roles of human empathy in the propagation process. To address this gap, we propose the Dual-Aspect Empathy Framework (DAE), which integrates cognitive and emotional empathy to analyze misinformation from both the creator and reader perspectives. By examining creators' cognitive strategies and emotional appeals, as well as simulating readers' cognitive judgments and emotional responses using Large Language Models (LLMs), DAE offers a more comprehensive and human-centric approach to misinformation detection. Moreover, we further introduce an empathy-aware filtering mechanism to enhance response authenticity and diversity. Experimental results on benchmark datasets demonstrate that DAE outperforms existing methods, providing a novel paradigm for multimodal misinformation detection.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17332",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.776568Z"
  },
  {
    "id": "c5f51ddf1e236c42a1010be74ea43d8a",
    "title": "M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction",
    "slug": "m-mre:-extending-the-mutual-reinforcement-effect-to-multimodal-information-extraction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Chengguang Gan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Mutual Reinforcement Effect (MRE) is an emerging subfield at the intersection of information extraction and model interpretability. MRE aims to leverage the mutual understanding between tasks of different granularities, enhancing the performance of both coarse-grained and fine-grained tasks through joint modeling. While MRE has been explored and validated in the textual domain, its applicability to visual and multimodal domains remains unexplored. In this work, we extend MRE to the multimodal information extraction domain for the first time. Specifically, we introduce a new task: Multimodal Mutual Reinforcement Effect (M-MRE), and construct a corresponding dataset to support this task. To address the challenges posed by M-MRE, we further propose a Prompt Format Adapter (PFA) that is fully compatible with various Large Vision-Language Models (LVLMs). Experimental results demonstrate that MRE can also be observed in the M-MRE task, a multimodal text-image understanding scenario. This provides strong evidence that MRE facilitates mutual gains across three interrelated tasks, confirming its generalizability beyond the textual domain.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17353",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.776802Z"
  },
  {
    "id": "c808b7d202049d57f280c8478a9a02c8",
    "title": "PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare",
    "slug": "patientdx:-merging-large-language-models-for-protecting-data-privacy-in-healthcare",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jose G. Moreno",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Fine-tuning of Large Language Models (LLMs) has become the default practice for improving model performance on a given task. However, performance improvement comes at the cost of training on vast amounts of annotated data which could be sensitive leading to significant data privacy concerns. In particular, the healthcare domain is one of the most sensitive domains exposed to data privacy issues. In this paper, we present PatientDx, a framework of model merging that allows the design of effective LLMs for health-predictive tasks without requiring fine-tuning nor adaptation on patient data. Our proposal is based on recently proposed techniques known as merging of LLMs and aims to optimize a building block merging strategy. PatientDx uses a pivotal model adapted to numerical reasoning and tunes hyperparameters on examples based on a performance metric but without training of the LLM on these data. Experiments using the mortality tasks of the MIMIC-IV dataset show improvements up to 7% in terms of AUROC when compared to initial models. Additionally, we confirm that when compared to fine-tuned models, our proposal is less prone to data leak problems without hurting performance. Finally, we qualitatively show the capabilities of our proposal through a case study. Our best model is publicly available at this https URL Jgmorenof/mistral\\_merged\\_0\\_4.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17360",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.777020Z"
  },
  {
    "id": "3eebeedb55661869c4dace0f3327a8ae",
    "title": "LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams",
    "slug": "livelongbench:-tackling-long-context-understanding-for-spoken-texts-from-live-streams",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yongxuan Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Long-context understanding poses significant challenges in natural language processing, particularly for real-world dialogues characterized by speech-based elements, high redundancy, and uneven information density. Although large language models (LLMs) achieve impressive results on existing benchmarks, these datasets fail to reflect the complexities of such texts, limiting their applicability to practical scenarios. To bridge this gap, we construct the first spoken long-text dataset, derived from live streams, designed to reflect the redundancy-rich and conversational nature of real-world scenarios. We construct tasks in three categories: retrieval-dependent, reasoning-dependent, and hybrid. We then evaluate both popular LLMs and specialized methods to assess their ability to understand long-contexts in these tasks. Our results show that current methods exhibit strong task-specific preferences and perform poorly on highly redundant inputs, with no single method consistently outperforming others. We propose a new baseline that better handles redundancy in spoken text and achieves strong performance across tasks. Our findings highlight key limitations of current methods and suggest future directions for improving long-context understanding. Finally, our benchmark fills a gap in evaluating long-context spoken language understanding and provides a practical foundation for developing real-world e-commerce systems. The code and benchmark are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17366",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.777227Z"
  },
  {
    "id": "b435c6b00ed524690c11d5218d457290",
    "title": "PicPersona-TOD : A Dataset for Personalizing Utterance Style in Task-Oriented Dialogue with Image Persona",
    "slug": "picpersona-tod-:-a-dataset-for-personalizing-utterance-style-in-task-oriented-dialogue-with-image-persona",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jihyun Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Task-Oriented Dialogue (TOD) systems are designed to fulfill user requests through natural language interactions, yet existing systems often produce generic, monotonic responses that lack individuality and fail to adapt to users' personal attributes. To address this, we introduce PicPersona-TOD, a novel dataset that incorporates user images as part of the persona, enabling personalized responses tailored to user-specific factors such as age or emotional context. This is facilitated by first impressions, dialogue policy-guided prompting, and the use of external knowledge to reduce hallucinations. Human evaluations confirm that our dataset enhances user experience, with personalized responses contributing to a more engaging interaction. Additionally, we introduce a new NLG model, Pictor, which not only personalizes responses, but also demonstrates robust performance across unseen domains this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17390",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.777432Z"
  },
  {
    "id": "f0289aade120f4e74308aeaf3c6cbdd8",
    "title": "Creating Targeted, Interpretable Topic Models with LLM-Generated Text Augmentation",
    "slug": "creating-targeted,-interpretable-topic-models-with-llm-generated-text-augmentation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Anna Lieb",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Unsupervised machine learning techniques, such as topic modeling and clustering, are often used to identify latent patterns in unstructured text data in fields such as political science and sociology. These methods overcome common concerns about reproducibility and costliness involved in the labor-intensive process of human qualitative analysis. However, two major limitations of topic models are their interpretability and their practicality for answering targeted, domain-specific social science research questions. In this work, we investigate opportunities for using LLM-generated text augmentation to improve the usefulness of topic modeling output. We use a political science case study to evaluate our results in a domain-specific application, and find that topic modeling using GPT-4 augmentations creates highly interpretable categories that can be used to investigate domain-specific research questions with minimal human guidance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17445",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.777646Z"
  },
  {
    "id": "53bb1bbe99526636879d39b6a8643530",
    "title": "Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation",
    "slug": "unified-attacks-to-large-language-model-watermarks:-spoofing-and-scrubbing-in-unauthorized-knowledge-distillation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Xin Yi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Watermarking has emerged as a critical technique for combating misinformation and protecting intellectual property in large language models (LLMs). A recent discovery, termed watermark radioactivity, reveals that watermarks embedded in teacher models can be inherited by student models through knowledge distillation. On the positive side, this inheritance allows for the detection of unauthorized knowledge distillation by identifying watermark traces in student models. However, the robustness of watermarks against scrubbing attacks and their unforgeability in the face of spoofing attacks under unauthorized knowledge distillation remain largely unexplored. Existing watermark attack methods either assume access to model internals or fail to simultaneously support both scrubbing and spoofing attacks. In this work, we propose Contrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified framework that enables bidirectional attacks under unauthorized knowledge distillation. Our approach employs contrastive decoding to extract corrupted or amplified watermark texts via comparing outputs from the student model and weakly watermarked references, followed by bidirectional distillation to train new student models capable of watermark removal and watermark forgery, respectively. Extensive experiments show that CDG-KD effectively performs attacks while preserving the general performance of the distilled model. Our findings underscore critical need for developing watermarking schemes that are robust and unforgeable.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17480",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.777859Z"
  },
  {
    "id": "e80919fb73e6ee66f6e9b4b83b686dde",
    "title": "HalluLens: LLM Hallucination Benchmark",
    "slug": "hallulens:-llm-hallucination-benchmark",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yejin Bang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) often generate responses that deviate from user input or training data, a phenomenon known as \"hallucination.\" These hallucinations undermine user trust and hinder the adoption of generative AI systems. Addressing hallucinations is essential for the advancement of LLMs. This paper introduces a comprehensive hallucination benchmark, incorporating both new extrinsic and existing intrinsic evaluation tasks, built upon clear taxonomy of hallucination. A major challenge in benchmarking hallucinations is the lack of a unified framework due to inconsistent definitions and categorizations. We disentangle LLM hallucination from \"factuality,\" proposing a clear taxonomy that distinguishes between extrinsic and intrinsic hallucinations, to promote consistency and facilitate research. Extrinsic hallucinations, where the generated content is not consistent with the training data, are increasingly important as LLMs evolve. Our benchmark includes dynamic test set generation to mitigate data leakage and ensure robustness against such leakage. We also analyze existing benchmarks, highlighting their limitations and saturation. The work aims to: (1) establish a clear taxonomy of hallucinations, (2) introduce new extrinsic hallucination tasks, with data that can be dynamically regenerated to prevent saturation by leakage, (3) provide a comprehensive analysis of existing benchmarks, distinguishing them from factuality evaluations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17550",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.778082Z"
  },
  {
    "id": "a41d05d2abd98b833f8e7937c430a95d",
    "title": "When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars",
    "slug": "when-does-metadata-conditioning-(not)-work-for-language-model-pre-training?-a-study-with-context-free-grammars",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Rei Higuchi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The ability to acquire latent semantics is one of the key properties that determines the performance of language models. One convenient approach to invoke this ability is to prepend metadata (e.g. URLs, domains, and styles) at the beginning of texts in the pre-training data, making it easier for the model to access latent semantics before observing the entire text. Previous studies have reported that this technique actually improves the performance of trained models in downstream tasks; however, this improvement has been observed only in specific downstream tasks, without consistent enhancement in average next-token prediction loss. To understand this phenomenon, we closely investigate how prepending metadata during pre-training affects model performance by examining its behavior using artificial data. Interestingly, we found that this approach produces both positive and negative effects on the downstream tasks. We demonstrate that the effectiveness of the approach depends on whether latent semantics can be inferred from the downstream task's prompt. Specifically, through investigations using data generated by probabilistic context-free grammars, we show that training with metadata helps improve model's performance when the given context is long enough to infer the latent semantics. In contrast, the technique negatively impacts performance when the context lacks the necessary information to make an accurate posterior inference.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17562",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.778309Z"
  },
  {
    "id": "2bc71d7a1da6a8374cad3291fba0cd17",
    "title": "DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training",
    "slug": "deepdistill:-enhancing-llm-reasoning-capabilities-via-large-scale-difficulty-graded-data-training",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Xiaoyu Tian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Although large language models (LLMs) have recently achieved remarkable performance on various complex reasoning benchmarks, the academic community still lacks an in-depth understanding of base model training processes and data quality. To address this, we construct a large-scale, difficulty-graded reasoning dataset containing approximately 3.34 million unique queries of varying difficulty levels and about 40 million distilled responses generated by multiple models over several passes. Leveraging pass rate and Coefficient of Variation (CV), we precisely select the most valuable training data to enhance reasoning capability. Notably, we observe a training pattern shift, indicating that reasoning-focused training based on base models requires higher learning rates for effective training. Using this carefully selected data, we significantly improve the reasoning capabilities of the base model, achieving a pass rate of 79.2\\% on the AIME2024 mathematical reasoning benchmark. This result surpasses most current distilled models and closely approaches state-of-the-art performance. We provide detailed descriptions of our data processing, difficulty assessment, and training methodology, and have publicly released all datasets and methods to promote rapid progress in open-source long-reasoning LLMs. The dataset is available at: this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17565",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.778535Z"
  },
  {
    "id": "08b44c6b5d228223f29a26399103a6d5",
    "title": "RAGAT-Mind: A Multi-Granular Modeling Approach for Rumor Detection Based on MindSpore",
    "slug": "ragat-mind:-a-multi-granular-modeling-approach-for-rumor-detection-based-on-mindspore",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Zhenkai Qin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As false information continues to proliferate across social media platforms, effective rumor detection has emerged as a pressing challenge in natural language processing. This paper proposes RAGAT-Mind, a multi-granular modeling approach for Chinese rumor detection, built upon the MindSpore deep learning framework. The model integrates TextCNN for local semantic extraction, bidirectional GRU for sequential context learning, Multi-Head Self-Attention for global dependency focusing, and Bidirectional Graph Convolutional Networks (BiGCN) for structural representation of word co-occurrence graphs. Experiments on the Weibo1-Rumor dataset demonstrate that RAGAT-Mind achieves superior classification performance, attaining 99.2% accuracy and a macro-F1 score of 0.9919. The results validate the effectiveness of combining hierarchical linguistic features with graph-based semantic structures. Furthermore, the model exhibits strong generalization and interpretability, highlighting its practical value for real-world rumor detection applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17574",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.778735Z"
  },
  {
    "id": "3167d82786f204fcf6b18621e6d63c59",
    "title": "Towards a comprehensive taxonomy of online abusive language informed by machine leaning",
    "slug": "towards-a-comprehensive-taxonomy-of-online-abusive-language-informed-by-machine-leaning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Samaneh Hosseini Moghaddam",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The proliferation of abusive language in online communications has posed significant risks to the health and wellbeing of individuals and communities. The growing concern regarding online abuse and its consequences necessitates methods for identifying and mitigating harmful content and facilitating continuous monitoring, moderation, and early intervention. This paper presents a taxonomy for distinguishing key characteristics of abusive language within online text. Our approach uses a systematic method for taxonomy development, integrating classification systems of 18 existing multi-label datasets to capture key characteristics relevant to online abusive language classification. The resulting taxonomy is hierarchical and faceted, comprising 5 categories and 17 dimensions. It classifies various facets of online abuse, including context, target, intensity, directness, and theme of abuse. This shared understanding can lead to more cohesive efforts, facilitate knowledge exchange, and accelerate progress in the field of online abuse detection and mitigation among researchers, policy makers, online platform owners, and other stakeholders.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17653",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.778944Z"
  },
  {
    "id": "3b83526e90837dd1bb22eeab58b1fa75",
    "title": "Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics",
    "slug": "evaluating-grounded-reasoning-by-code-assisted-large-language-models-for-mathematics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Zena Al-Khalili",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Assisting LLMs with code generation improved their performance on mathematical reasoning tasks. However, the evaluation of code-assisted LLMs is generally restricted to execution correctness, lacking a rigorous evaluation of their generated programs. In this work, we bridge this gap by conducting an in-depth analysis of code-assisted LLMs' generated programs in response to math reasoning tasks. Our evaluation focuses on the extent to which LLMs ground their programs to math rules, and how that affects their end performance. For this purpose, we assess the generations of five different LLMs, on two different math datasets, both manually and automatically. Our results reveal that the distribution of grounding depends on LLMs' capabilities and the difficulty of math problems. Furthermore, mathematical grounding is more effective for closed-source models, while open-source models fail to employ math rules in their solutions correctly. On MATH500, the percentage of grounded programs decreased to half, while the ungrounded generations doubled in comparison to ASDiv grade-school problems. Our work highlights the need for in-depth evaluation beyond execution accuracy metrics, toward a better understanding of code-assisted LLMs' capabilities and limits in the math domain.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17665",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.779146Z"
  },
  {
    "id": "e4946c543be26d06ee1041396e7cb55b",
    "title": "Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction",
    "slug": "data-driven-calibration-of-prediction-sets-in-large-vision-language-models-based-on-inductive-conformal-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yuanchang Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study addresses the critical challenge of hallucination mitigation in Large Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks through a Split Conformal Prediction (SCP) framework. While LVLMs excel in multi-modal reasoning, their outputs often exhibit hallucinated content with high confidence, posing risks in safety-critical applications. We propose a model-agnostic uncertainty quantification method that integrates dynamic threshold calibration and cross-modal consistency verification. By partitioning data into calibration and test sets, the framework computes nonconformity scores to construct prediction sets with statistical guarantees under user-defined risk levels ($\\alpha$). Key innovations include: (1) rigorous control of \\textbf{marginal coverage} to ensure empirical error rates remain strictly below $\\alpha$; (2) dynamic adjustment of prediction set sizes inversely with $\\alpha$, filtering low-confidence outputs; (3) elimination of prior distribution assumptions and retraining requirements. Evaluations on benchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces theoretical guarantees across all $\\alpha$ values. The framework achieves stable performance across varying calibration-to-test split ratios, underscoring its robustness for real-world deployment in healthcare, autonomous systems, and other safety-sensitive domains. This work bridges the gap between theoretical reliability and practical applicability in multi-modal AI systems, offering a scalable solution for hallucination detection and uncertainty-aware decision-making.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17671",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.779338Z"
  },
  {
    "id": "5fcf8cf38f6df5814fb6948802f1cc7d",
    "title": "Energy Considerations of Large Language Model Inference and Efficiency Optimizations",
    "slug": "energy-considerations-of-large-language-model-inference-and-efficiency-optimizations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jared Fernandez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As large language models (LLMs) scale in size and adoption, their computational and environmental costs continue to rise. Prior benchmarking efforts have primarily focused on latency reduction in idealized settings, often overlooking the diverse real-world inference workloads that shape energy use. In this work, we systematically analyze the energy implications of common inference efficiency optimizations across diverse Natural Language Processing (NLP) and generative Artificial Intelligence (AI) workloads, including conversational AI and code generation. We introduce a modeling approach that approximates real-world LLM workflows through a binning strategy for input-output token distributions and batch size variations. Our empirical analysis spans software frameworks, decoding strategies, GPU architectures, online and offline serving settings, and model parallelism configurations. We show that the effectiveness of inference optimizations is highly sensitive to workload geometry, software stack, and hardware accelerators, demonstrating that naive energy estimates based on FLOPs or theoretical GPU utilization significantly underestimate real-world energy consumption. Our findings reveal that the proper application of relevant inference efficiency optimizations can reduce total energy use by up to 73% from unoptimized baselines. These insights provide a foundation for sustainable LLM deployment and inform energy-efficient design strategies for future AI infrastructure.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17674",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.779558Z"
  },
  {
    "id": "1d580e9eb2e2dbc7c5c0c50794b143ec",
    "title": "Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks",
    "slug": "ensemble-bayesian-inference:-leveraging-small-language-models-to-achieve-llm-level-accuracy-in-profile-matching-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Haru-Tada Sato",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study explores the potential of small language model(SLM) ensembles to achieve accuracy comparable to proprietary large language models (LLMs). We propose Ensemble Bayesian Inference (EBI), a novel approach that applies Bayesian estimation to combine judgments from multiple SLMs, allowing them to exceed the performance limitations of individual models. Our experiments on diverse tasks(aptitude assessments and consumer profile analysis in both Japanese and English) demonstrate EBI's effectiveness. Notably, we analyze cases where incorporating models with negative Lift values into ensembles improves overall performance, and we examine the method's efficacy across different languages. These findings suggest new possibilities for constructing high-performance AI systems with limited computational resources and for effectively utilizing models with individually lower performance. Building on existing research on LLM performance evaluation, ensemble methods, and open-source LLM utilization, we discuss the novelty and significance of our approach.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17685",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.779766Z"
  },
  {
    "id": "fcfe7fdc335743fc268a105cbcf2cb65",
    "title": "Safety in Large Reasoning Models: A Survey",
    "slug": "safety-in-large-reasoning-models:-a-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Cheng Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Reasoning Models (LRMs) have exhibited extraordinary prowess in tasks like mathematics and coding, leveraging their advanced reasoning capabilities. Nevertheless, as these capabilities progress, significant concerns regarding their vulnerabilities and safety have arisen, which can pose challenges to their deployment and application in real-world settings. This paper presents a comprehensive survey of LRMs, meticulously exploring and summarizing the newly emerged safety risks, attacks, and defense strategies. By organizing these elements into a detailed taxonomy, this work aims to offer a clear and structured understanding of the current safety landscape of LRMs, facilitating future research and development to enhance the security and reliability of these powerful models.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17704",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.779970Z"
  },
  {
    "id": "1dde0a0b526659cd13fbc6dcefbc86a0",
    "title": "Multilingual Performance Biases of Large Language Models in Education",
    "slug": "multilingual-performance-biases-of-large-language-models-in-education",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Vansh Gupta",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) are increasingly being adopted in educational settings. These applications expand beyond English, though current LLMs remain primarily English-centric. In this work, we ascertain if their use in education settings in non-English languages is warranted. We evaluated the performance of popular LLMs on four educational tasks: identifying student misconceptions, providing targeted feedback, interactive tutoring, and grading translations in six languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to English. We find that the performance on these tasks somewhat corresponds to the amount of language represented in training data, with lower-resource languages having poorer task performance. Although the models perform reasonably well in most languages, the frequent performance drop from English is significant. Thus, we recommend that practitioners first verify that the LLM works well in the target language for their educational task before deployment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17720",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.780180Z"
  },
  {
    "id": "c3837ed60744217e3b7f20765a2aa992",
    "title": "Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT",
    "slug": "conversational-assistants-to-support-heart-failure-patients:-comparing-a-neurosymbolic-architecture-with-chatgpt",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Anuja Tayal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Conversational assistants are becoming more and more popular, including in healthcare, partly because of the availability and capabilities of Large Language Models. There is a need for controlled, probing evaluations with real stakeholders which can highlight advantages and disadvantages of more traditional architectures and those based on generative AI. We present a within-group user study to compare two versions of a conversational assistant that allows heart failure patients to ask about salt content in food. One version of the system was developed in-house with a neurosymbolic architecture, and one is based on ChatGPT. The evaluation shows that the in-house system is more accurate, completes more tasks and is less verbose than the one based on ChatGPT; on the other hand, the one based on ChatGPT makes fewer speech errors and requires fewer clarifications to complete the task. Patients show no preference for one over the other.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17753",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.780398Z"
  },
  {
    "id": "b22776cce68c7fd26f62997f1ebc0751",
    "title": "The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs",
    "slug": "the-sparse-frontier:-sparse-attention-trade-offs-in-transformer-llms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Piotr Nawrot",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Sparse attention offers a promising strategy to extend long-context capabilities in Transformer LLMs, yet its viability, its efficiency-accuracy trade-offs, and systematic scaling studies remain unexplored. To address this gap, we perform a careful comparison of training-free sparse attention methods at varying model scales, sequence lengths, and sparsity levels on a diverse collection of long-sequence tasks-including novel ones that rely on natural language while remaining controllable and easy to evaluate. Based on our experiments, we report a series of key findings: 1) an isoFLOPS analysis reveals that for very long sequences, larger and highly sparse models are preferable to smaller and dense ones. 2) The level of sparsity attainable while statistically guaranteeing accuracy preservation is higher during decoding than prefilling, and correlates with model size in the former. 3) There is no clear strategy that performs best across tasks and phases, with different units of sparsification or budget adaptivity needed for different scenarios. Even moderate sparsity levels often result in significant performance degradation on at least one task, highlighting that sparse attention is not a universal solution. 4) We introduce and validate novel scaling laws specifically tailored for sparse attention, providing evidence that our findings are likely to hold true beyond our range of experiments. Through these insights, we demonstrate that sparse attention is a key tool to enhance the capabilities of Transformer LLMs for processing longer sequences, but requires careful evaluation of trade-offs for performance-sensitive applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17768",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.780602Z"
  },
  {
    "id": "e1af0bd207880a72f9491218827e8d1a",
    "title": "A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions",
    "slug": "a-desideratum-for-conversational-agents:-capabilities,-challenges,-and-future-directions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Emre Can Acikgoz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advances in Large Language Models (LLMs) have propelled conversational AI from traditional dialogue systems into sophisticated agents capable of autonomous actions, contextual awareness, and multi-turn interactions with users. Yet, fundamental questions about their capabilities, limitations, and paths forward remain open. This survey paper presents a desideratum for next-generation Conversational Agents - what has been achieved, what challenges persist, and what must be done for more scalable systems that approach human-level intelligence. To that end, we systematically analyze LLM-driven Conversational Agents by organizing their capabilities into three primary dimensions: (i) Reasoning - logical, systematic thinking inspired by human intelligence for decision making, (ii) Monitor - encompassing self-awareness and user interaction monitoring, and (iii) Control - focusing on tool utilization and policy following. Building upon this, we introduce a novel taxonomy by classifying recent work on Conversational Agents around our proposed desideratum. We identify critical research gaps and outline key directions, including realistic evaluations, long-term multi-turn reasoning skills, self-evolution capabilities, collaborative and multi-agent task completion, personalization, and proactivity. This work aims to provide a structured foundation, highlight existing limitations, and offer insights into potential future research directions for Conversational Agents, ultimately advancing progress toward Artificial General Intelligence (AGI). We maintain a curated repository of papers at: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16939",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:15.780836Z"
  },
  {
    "id": "f34b4af627a687b8fda97668585ea4e1",
    "title": "(Im)possibility of Automated Hallucination Detection in Large Language Models",
    "slug": "(im)possibility-of-automated-hallucination-detection-in-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Amin Karbasi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Is automated hallucination detection possible? In this work, we introduce a theoretical framework to analyze the feasibility of automatically detecting hallucinations produced by large language models (LLMs). Inspired by the classical Gold-Angluin framework for language identification and its recent adaptation to language generation by Kleinberg and Mullainathan, we investigate whether an algorithm, trained on examples drawn from an unknown target language $K$ (selected from a countable collection) and given access to an LLM, can reliably determine whether the LLM's outputs are correct or constitute hallucinations.\nFirst, we establish an equivalence between hallucination detection and the classical task of language identification. We prove that any hallucination detection method can be converted into a language identification method, and conversely, algorithms solving language identification can be adapted for hallucination detection. Given the inherent difficulty of language identification, this implies that hallucination detection is fundamentally impossible for most language collections if the detector is trained using only correct examples from the target language.\nSecond, we show that the use of expert-labeled feedback, i.e., training the detector with both positive examples (correct statements) and negative examples (explicitly labeled incorrect statements), dramatically changes this conclusion. Under this enriched training regime, automated hallucination detection becomes possible for all countable language collections.\nThese results highlight the essential role of expert-labeled examples in training hallucination detectors and provide theoretical support for feedback-based methods, such as reinforcement learning with human feedback (RLHF), which have proven critical for reliable LLM deployment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17004",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:15.781039Z"
  },
  {
    "id": "a0ea91d9356add9ed8a23834a16af81a",
    "title": "SCALAR: A Part-of-speech Tagger for Identifiers",
    "slug": "scalar:-a-part-of-speech-tagger-for-identifiers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Christian D. Newman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The paper presents the Source Code Analysis and Lexical Annotation Runtime (SCALAR), a tool specialized for mapping (annotating) source code identifier names to their corresponding part-of-speech tag sequence (grammar pattern). SCALAR's internal model is trained using scikit-learn's GradientBoostingClassifier in conjunction with a manually-curated oracle of identifier names and their grammar patterns. This specializes the tagger to recognize the unique structure of the natural language used by developers to create all types of identifiers (e.g., function names, variable names etc.). SCALAR's output is compared with a previous version of the tagger, as well as a modern off-the-shelf part-of-speech tagger to show how it improves upon other taggers' output for annotating identifiers. The code is available on Github",
    "pdfUrl": "https://arxiv.org/pdf/2504.17038",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:15.781286Z"
  },
  {
    "id": "5c7ea31094c41eb4dd58897bcb396e6e",
    "title": "TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation",
    "slug": "timesoccer:-an-end-to-end-multimodal-large-language-model-for-soccer-commentary-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ling You",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Soccer is a globally popular sporting event, typically characterized by long matches and distinctive highlight moments. Recent advances in Multimodal Large Language Models (MLLMs) offer promising capabilities in temporal grounding and video understanding, soccer commentary generation often requires precise temporal localization and semantically rich descriptions over long-form video. However, existing soccer MLLMs often rely on the temporal a priori for caption generation, so they cannot process the soccer video end-to-end. While some traditional approaches follow a two-step paradigm that is complex and fails to capture the global context to achieve suboptimal performance. To solve the above issues, we present TimeSoccer, the first end-to-end soccer MLLM for Single-anchor Dense Video Captioning (SDVC) in full-match soccer videos. TimeSoccer jointly predicts timestamps and generates captions in a single pass, enabling global context modeling across 45-minute matches. To support long video understanding of soccer matches, we introduce MoFA-Select, a training-free, motion-aware frame compression module that adaptively selects representative frames via a coarse-to-fine strategy, and incorporates complementary training paradigms to strengthen the model's ability to handle long temporal sequences. Extensive experiments demonstrate that our TimeSoccer achieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-end form, generating high-quality commentary with accurate temporal alignment and strong semantic relevance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17365",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:15.781503Z"
  },
  {
    "id": "e343f1498347f73eb0cd13537fff7472",
    "title": "HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models",
    "slug": "hmi:-hierarchical-knowledge-management-for-efficient-multi-tenant-inference-in-pretrained-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jun Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The significant computational demands of pretrained language models (PLMs), which often require dedicated hardware, present a substantial challenge in serving them efficiently, especially in multi-tenant environments. To address this, we introduce HMI, a Hierarchical knowledge management-based Multi-tenant Inference system, designed to manage tenants with distinct PLMs resource-efficiently. Our approach is three-fold: Firstly, we categorize PLM knowledge into general, domain-specific, and task-specific. Leveraging insights on knowledge acquisition across different model layers, we construct hierarchical PLMs (hPLMs) by extracting and storing knowledge at different levels, significantly reducing GPU memory usage per tenant. Secondly, we establish hierarchical knowledge management for hPLMs generated by various tenants in HMI. We manage domain-specific knowledge with acceptable storage increases by constructing and updating domain-specific knowledge trees based on frequency. We manage task-specific knowledge within limited GPU memory through parameter swapping. Finally, we propose system optimizations to enhance resource utilization and inference throughput. These include fine-grained pipelining via hierarchical knowledge prefetching to overlap CPU and I/O operations with GPU computations, and optimizing parallel implementations with batched matrix multiplications. Our experimental results demonstrate that the proposed HMI can efficiently serve up to 10,000 hPLMs (hBERTs and hGPTs) on a single GPU, with only a negligible compromise in accuracy.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17449",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:15.781736Z"
  },
  {
    "id": "a117604ba715486cdfca95fc4752fa08",
    "title": "CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization",
    "slug": "cads:-a-systematic-literature-review-on-the-challenges-of-abstractive-dialogue-summarization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Frederic Kirstein",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Abstractive dialogue summarization is the task of distilling conversations into informative and concise summaries. Although reviews have been conducted on this topic, there is a lack of comprehensive work detailing the challenges of dialogue summarization, unifying the differing understanding of the task, and aligning proposed techniques, datasets, and evaluation metrics with the challenges. This article summarizes the research on Transformer-based abstractive summarization for English dialogues by systematically reviewing 1262 unique research papers published between 2019 and 2024, relying on the Semantic Scholar and DBLP databases. We cover the main challenges present in dialog summarization (i.e., language, structure, comprehension, speaker, salience, and factuality) and link them to corresponding techniques such as graph-based approaches, additional training tasks, and planning strategies, which typically overly rely on BART-based encoder-decoder models. We find that while some challenges, like language, have seen considerable progress, mainly due to training methods, others, such as comprehension, factuality, and salience, remain difficult and hold significant research opportunities. We investigate how these approaches are typically assessed, covering the datasets for the subdomains of dialogue (e.g., meeting, medical), the established automatic metrics and human evaluation approaches for assessing scores and annotator agreement. We observe that only a few datasets span across all subdomains. The ROUGE metric is the most used, while human evaluation is frequently reported without sufficient detail on inner-annotator agreement and annotation guidelines. Additionally, we discuss the possible implications of the recently explored large language models and conclude that despite a potential shift in relevance and difficulty, our described challenge taxonomy remains relevant.",
    "pdfUrl": "https://arxiv.org/pdf/2406.07494",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.781958Z"
  },
  {
    "id": "877a212471b3e2419cdbf4f905b8ec16",
    "title": "Synthetic Lyrics Detection Across Languages and Genres",
    "slug": "synthetic-lyrics-detection-across-languages-and-genres",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yanis Labrak",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In recent years, the use of large language models (LLMs) to generate music content, particularly lyrics, has gained in popularity. These advances provide valuable tools for artists and enhance their creative processes, but they also raise concerns about copyright violations, consumer satisfaction, and content spamming. Previous research has explored content detection in various domains. However, no work has focused on the text modality, lyrics, in music. To address this gap, we curated a diverse dataset of real and synthetic lyrics from multiple languages, music genres, and artists. The generation pipeline was validated using both humans and automated methods. We performed a thorough evaluation of existing synthetic text detection approaches on lyrics, a previously unexplored data type. We also investigated methods to adapt the best-performing features to lyrics through unsupervised domain adaptation. Following both music and industrial constraints, we examined how well these approaches generalize across languages, scale with data availability, handle multilingual language content, and perform on novel genres in few-shot settings. Our findings show promising results that could inform policy decisions around AI-generated music and enhance transparency for users.",
    "pdfUrl": "https://arxiv.org/pdf/2406.15231",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.782162Z"
  },
  {
    "id": "3aca5ea6c5ab9e4f6d675d79a83cf7c5",
    "title": "OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure",
    "slug": "opt-tree:-speculative-decoding-with-adaptive-draft-tree-structure",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jikai Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autoregressive language models demonstrate excellent performance in various scenarios. However, the inference efficiency is limited by its one-step-one-word generation mode, which has become a pressing problem recently as the models become increasingly larger. Speculative decoding employs a \"draft and then verify\" mechanism to allow multiple tokens to be generated in one step, realizing lossless acceleration. Existing methods mainly adopt fixed heuristic draft structures, which fail to adapt to different situations to maximize the acceptance length during verification. To alleviate this dilemma, we proposed OPT-Tree, an algorithm to construct adaptive and scalable draft trees. It searches the optimal tree structure that maximizes the mathematical expectation of the acceptance length in each decoding step. Experimental results reveal that OPT-Tree outperforms the existing draft structures and achieves a speed-up ratio of up to 3.2 compared with autoregressive decoding. If the draft model is powerful enough and the node budget is sufficient, it can generate more than ten tokens in a single step. Our code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2406.17276",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.782399Z"
  },
  {
    "id": "f31b3587adee2aa087652b80e7f6a0d3",
    "title": "LaMsS: When Large Language Models Meet Self-Skepticism",
    "slug": "lamss:-when-large-language-models-meet-self-skepticism",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yetao Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Hallucination is a major challenge for large language models (LLMs), preventing their further application in some fields. The skeptical thinking of humankind could be useful for LLMs to self-cognition, self-reflection and alleviate their hallucinations. Inspired by this consideration, we propose a novel approach called LaMsS, which combines the semantic understanding capability of LLMs with self-skepticism. By introducing a series of skepticism tokens and augmenting them into the vocabulary, we conduct both pertaining and finetuning, which allow the LLM to decode each normal token followed by a skeptical token, representing different skepticism levels. By calculating the response skepticism given a query, one can define a new self-aware LLM which is only willing to answer with relative lower skepticism level than the threshold. By examining the accuracy, AUC and AP of willingly answering questions, we demonstrate that LaMsS achieves better performance than baselines on both multi-choice questions and open-domain question-answering benchmarks, and can generalize to multi-task and out-of-domain settings. Our study sheds some lights on the self-skepticism modeling on further artificial intelligence. Project code and model checkpoints can be found in this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2409.06601",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.782622Z"
  },
  {
    "id": "889d3ae70aceec8a0f0d2f0db78a8833",
    "title": "Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse",
    "slug": "measuring-and-enhancing-trustworthiness-of-llms-in-rag-through-grounded-attributions-and-learning-to-refuse",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Maojia Song",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LLMs are an integral component of retrieval-augmented generation (RAG) systems. While many studies focus on evaluating the overall quality of end-to-end RAG systems, there is a gap in understanding the appropriateness of LLMs for the RAG task. To address this, we introduce Trust-Score, a holistic metric that evaluates the trustworthiness of LLMs within the RAG framework. Our results show that various prompting methods, such as in-context learning, fail to effectively adapt LLMs to the RAG task as measured by Trust-Score. Consequently, we propose Trust-Align, a method to align LLMs for improved Trust-Score performance. 26 out of 27 models aligned using Trust-Align substantially outperform competitive baselines on ASQA, QAMPARI, and ELI5. Specifically, in LLaMA-3-8b, Trust-Align outperforms FRONT on ASQA (up 12.56), QAMPARI (up 36.04), and ELI5 (up 17.69). Trust-Align also significantly enhances models' ability to correctly refuse and provide quality citations. We also demonstrate the effectiveness of Trust-Align across different open-weight models, including the LLaMA series (1b to 8b), Qwen-2.5 series (0.5b to 7b), and Phi3.5 (3.8b). We release our code at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2409.11242",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.782842Z"
  },
  {
    "id": "e71d71f02fcfb5980be89c74cfde3af6",
    "title": "Lab-AI: Using Retrieval Augmentation to Enhance Language Models for Personalized Lab Test Interpretation in Clinical Medicine",
    "slug": "lab-ai:-using-retrieval-augmentation-to-enhance-language-models-for-personalized-lab-test-interpretation-in-clinical-medicine",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Xiaoyu Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate interpretation of lab results is crucial in clinical medicine, yet most patient portals use universal normal ranges, ignoring conditional factors like age and gender. This study introduces Lab-AI, an interactive system that offers personalized normal ranges using retrieval-augmented generation (RAG) from credible health sources. Lab-AI has two modules: factor retrieval and normal range retrieval. We tested these on 122 lab tests: 40 with conditional factors and 82 without. For tests with factors, normal ranges depend on patient-specific information. Our results show GPT-4-turbo with RAG achieved a 0.948 F1 score for factor retrieval and 0.995 accuracy for normal range retrieval. GPT-4-turbo with RAG outperformed the best non-RAG system by 33.5% in factor retrieval and showed 132% and 100% improvements in question-level and lab-level performance, respectively, for normal range retrieval. These findings highlight Lab-AI's potential to enhance patient understanding of lab results.",
    "pdfUrl": "https://arxiv.org/pdf/2409.18986",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.783063Z"
  },
  {
    "id": "f6aaadbe666769c3ea543fd22cf0ca4d",
    "title": "Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?",
    "slug": "can-llms-really-learn-to-translate-a-low-resource-language-from-one-grammar-book?",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Seth Aycock",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Extremely low-resource (XLR) languages lack substantial corpora for training NLP models, motivating the use of all available resources such as dictionaries and grammar books. Machine Translation from One Book (Tanzer et al., 2024) suggests that prompting long-context LLMs with one grammar book enables English-Kalamang translation, an XLR language unseen by LLMs - a noteworthy case of linguistics helping an NLP task. We investigate the source of this translation ability, finding almost all improvements stem from the book's parallel examples rather than its grammatical explanations. We find similar results for Nepali and Guarani, seen low-resource languages, and we achieve performance comparable to an LLM with a grammar book by simply fine-tuning an encoder-decoder translation model. We then investigate where grammar books help by testing two linguistic tasks, grammaticality judgment and gloss prediction, and we explore what kind of grammatical knowledge helps by introducing a typological feature prompt that achieves leading results on these more relevant tasks. We thus emphasise the importance of task-appropriate data for XLR languages: parallel examples for translation, and grammatical data for linguistic tasks. As we find no evidence that long-context LLMs can make effective use of grammatical explanations for XLR translation, we conclude data collection for multilingual XLR tasks such as translation is best focused on parallel data over linguistic description.",
    "pdfUrl": "https://arxiv.org/pdf/2409.19151",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.783286Z"
  },
  {
    "id": "c2cce9a90a9295453d31b23d1a6808d9",
    "title": "TypedThinker: Diversify Large Language Model Reasoning with Typed Thinking",
    "slug": "typedthinker:-diversify-large-language-model-reasoning-with-typed-thinking",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Danqing Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) have demonstrated strong reasoning capabilities in solving complex problems. However, current approaches primarily enhance reasoning through the elaboration of thoughts while neglecting the diversity of reasoning types. LLMs typically employ deductive reasoning, proceeding step-by-step from given conditions, which limits their exploration during problem-solving. Our analysis reveals that certain problems are exclusively solvable through specific reasoning strategies like inductive, abductive, or analogical reasoning. However, incorporating diverse reasoning approaches presents two key challenges: identifying the appropriate reasoning type for each problem and exploiting this approach during problem-solving. Therefore, we propose the TypedThinker that predicts suitable reasoning types based on the problem and their previous effectiveness and provides relevant demonstrations to guide LLMs in applying these strategies. Experimental results show significant improvements across multiple benchmarks, with performance gains of 3.4% for Mistral 7B, 6.5% for LLaMA3 8B, and 7% for Qwen 2 7B on logical and mathematical reasoning tasks. TypedThinker enhances LLM reasoning without requiring knowledge distillation from larger models. It can be integrated into more advanced systems like GPT-4o or specialized models like MetaMath to diversify their reasoning approaches and improve their problem-solving capabilities.",
    "pdfUrl": "https://arxiv.org/pdf/2410.01952",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.783498Z"
  },
  {
    "id": "b222b309bb003b987f0dafcb3bb21174",
    "title": "Selective Attention Improves Transformer",
    "slug": "selective-attention-improves-transformer",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yaniv Leviathan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Unneeded elements in the attention's context degrade performance. We introduce Selective Attention, a simple parameter-free change to the standard attention mechanism which reduces attention to unneeded elements. Selective attention consistently improves language modeling and downstream task performance in a variety of model sizes and context lengths. For example, transformers trained with the language modeling objective on C4 with selective attention perform language modeling equivalently to standard transformers with ~2X more heads and parameters in their attention modules. Selective attention also allows decreasing the size of the attention's context buffer, leading to meaningful reductions in the memory and compute requirements during inference. For example, transformers trained on C4 with context sizes of 512, 1,024, and 2,048 need 16X, 25X, and 47X less memory for their attention module, respectively, when equipped with selective attention, as those without selective attention, with the same validation perplexity.",
    "pdfUrl": "https://arxiv.org/pdf/2410.02703",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.783710Z"
  },
  {
    "id": "c74582cc6c72813c46774517ac1fd281",
    "title": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation",
    "slug": "post-hoc-study-of-climate-microtargeting-on-social-media-ads-with-llms:-thematic-insights-and-fairness-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Tunazzina Islam",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Climate change communication on social media increasingly employs microtargeting strategies to effectively reach and influence specific demographic groups. This study presents a post-hoc analysis of microtargeting practices within climate campaigns by leveraging large language models (LLMs) to examine Facebook advertisements. Our analysis focuses on two key aspects: demographic targeting and fairness. We evaluate the ability of LLMs to accurately predict the intended demographic targets, such as gender and age group, achieving an overall accuracy of 88.55%. Furthermore, we instruct the LLMs to generate explanations for their classifications, providing transparent reasoning behind each decision. These explanations reveal the specific thematic elements used to engage different demographic segments, highlighting distinct strategies tailored to various audiences. Our findings show that young adults are primarily targeted through messages emphasizing activism and environmental consciousness, while women are engaged through themes related to caregiving roles and social advocacy. In addition to evaluating the effectiveness of LLMs in detecting microtargeted messaging, we conduct a comprehensive fairness analysis to identify potential biases in model predictions. Our findings indicate that while LLMs perform well overall, certain biases exist, particularly in the classification of senior citizens and male audiences. By showcasing the efficacy of LLMs in dissecting and explaining targeted communication strategies and by highlighting fairness concerns, this study provides a valuable framework for future research aimed at enhancing transparency, accountability, and inclusivity in social media-driven climate campaigns.",
    "pdfUrl": "https://arxiv.org/pdf/2410.05401",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.783917Z"
  },
  {
    "id": "aa93147ada402e6a7ea36ffc8ecf5678",
    "title": "Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies",
    "slug": "parameter-efficient-fine-tuning-in-large-models:-a-survey-of-methodologies",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Luping Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The large models, as predicted by scaling raw forecasts, have made groundbreaking progress in many fields, particularly in natural language generation tasks, where they have approached or even surpassed human levels. However, the unprecedented scale of their parameters brings significant computational and storage costs. These large models require substantial computational resources and GPU memory to operate. When adapting large models to specific downstream tasks, their massive parameter scale poses a significant challenge in fine-tuning on hardware platforms with limited computational power and GPU memory. To address this issue, Parameter-Efficient Fine-Tuning (PEFT) offers a practical solution by efficiently adjusting the parameters of large pre-trained models to suit various downstream tasks. Specifically, PEFT adjusts the parameters of pre-trained large models to adapt to specific tasks or domains, minimizing the introduction of additional parameters and the computational resources required. This review mainly introduces the preliminary knowledge of PEFT, the core ideas and principles of various PEFT algorithms, the applications of PEFT, and potential future research directions. By reading this review, we believe that interested parties can quickly grasp the PEFT methodology, thereby accelerating its development and innovation.",
    "pdfUrl": "https://arxiv.org/pdf/2410.19878",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.784136Z"
  },
  {
    "id": "2374792de2bb16f5ab0898d860155f5f",
    "title": "Estimating the Influence of Sequentially Correlated Literary Properties in Textual Classification: A Data-Centric Hypothesis-Testing Approach",
    "slug": "estimating-the-influence-of-sequentially-correlated-literary-properties-in-textual-classification:-a-data-centric-hypothesis-testing-approach",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Gideon Yoffe",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a data-centric hypothesis-testing framework to quantify the influence of sequentially correlated literary properties--such as thematic continuity--on textual classification tasks. Our method models label sequences as stochastic processes and uses an empirical autocovariance matrix to generate surrogate labelings that preserve sequential dependencies. This enables statistical testing to determine whether classification outcomes are primarily driven by thematic structure or by non-sequential features like authorial style. Applying this framework across a diverse corpus of English prose, we compare traditional (word n-grams and character k-mers) and neural (contrastively trained) embeddings in both supervised and unsupervised classification settings. Crucially, our method identifies when classifications are confounded by sequentially correlated similarity, revealing that supervised and neural models are more prone to false positives--mistaking shared themes and cross-genre differences for stylistic signals. In contrast, unsupervised models using traditional features often yield high true positive rates with minimal false positives, especially in genre-consistent settings. By disentangling sequential from non-sequential influences, our approach provides a principled way to assess and interpret classification reliability. This is particularly impactful for authorship attribution, forensic linguistics, and the analysis of redacted or composite texts, where conventional methods may conflate theme with style. Our results demonstrate that controlling for sequential correlation is essential for reducing false positives and ensuring that classification outcomes reflect genuine stylistic distinctions.",
    "pdfUrl": "https://arxiv.org/pdf/2411.04950",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.784352Z"
  },
  {
    "id": "a68b5f0a73064ddc97030bac1ebec31c",
    "title": "jina-clip-v2: Multilingual Multimodal Embeddings for Text and Images",
    "slug": "jina-clip-v2:-multilingual-multimodal-embeddings-for-text-and-images",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Andreas Koukounas",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Contrastive Language-Image Pretraining (CLIP) has been widely used for crossmodal information retrieval and multimodal understanding tasks. However, CLIP models are mainly optimized for crossmodal vision-language tasks and underperform in single-mode text tasks. Moreover, these models are often trained on English datasets and therefore lack multilingual understanding. Additionally, from a visual understanding perspective, previous CLIP-based models exhibit insufficient understanding of visually rich documents. In this work, we propose jina-clip-v2, a contrastive vision-language model trained on text pairs, triplets and image-text pairs via a multi-task and multi-stage contrastive learning paradigm in order to support both text-only and crossmodal tasks. We employ a multilingual text encoder and expand the training dataset to include multilingual texts from 29 non-English languages, including Hindi, Chinese, German, French, and others, as well as images of visually rich documents. We evaluate the model's performance and show that jina-clip-v2 achieves notable improvements over state-of-the-art CLIP-based models in zero-shot text-only retrieval, semantic textual similarity, and crossmodal retrieval tasks in both English and multilingual settings. jina-clip-v2 also provides for flexibility in embedding dimensionality, enabling users to select the granularity of the representations. jina-clip-v2 is publicly available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2412.08802",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.784593Z"
  },
  {
    "id": "431208a9bfeb0add3c76932d0e5b3aea",
    "title": "Context-Aware Neural Gradient Mapping for Fine-Grained Instruction Processing",
    "slug": "context-aware-neural-gradient-mapping-for-fine-grained-instruction-processing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "David Boldo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The integration of contextual embeddings into the optimization processes of large language models is an advancement in natural language processing. The Context-Aware Neural Gradient Mapping framework introduces a dynamic gradient adjustment mechanism, incorporating contextual embeddings directly into the optimization process. This approach facilitates real-time parameter adjustments, enhancing task-specific generalization even in the presence of sparse or noisy data inputs. The mathematical foundation of this framework relies on gradient descent modifications, where contextual embeddings are derived from a supplementary neural network trained to map input features to optimal adaptation gradients. By employing differential geometry principles, high-dimensional input dependencies are encoded into low-dimensional gradient manifolds, enabling efficient adaptation without necessitating the retraining of the entire model. Empirical evaluations demonstrate that the proposed framework consistently outperforms baseline models across various metrics, including accuracy, robustness to noise, and computational efficiency. The integration of context-specific embeddings allows for a more complex understanding of language, thereby improving the model's ability to handle diverse linguistic phenomena. Furthermore, the computational efficiency achieved through this method demonstrates its scalability for large-scale language models operating under diverse constraints.",
    "pdfUrl": "https://arxiv.org/pdf/2501.14936",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.784804Z"
  },
  {
    "id": "ef02efbec8847e61e8b3fcf5c7907653",
    "title": "Multilingual State Space Models for Structured Question Answering in Indic Languages",
    "slug": "multilingual-state-space-models-for-structured-question-answering-in-indic-languages",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Arpita Vats",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The diversity and complexity of Indic languages present unique challenges for natural language processing (NLP) tasks, particularly in the domain of question answering (QA).To address these challenges, this paper explores the application of State Space Models (SSMs),to build efficient and contextually aware QA systems tailored for Indic languages. SSMs are particularly suited for this task due to their ability to model long-term and short-term dependencies in sequential data, making them well-equipped to handle the rich morphology, complex syntax, and contextual intricacies characteristic of Indian languages. We evaluated multiple SSM architectures across diverse datasets representing various Indic languages and conducted a comparative analysis of their performance. Our results demonstrate that these models effectively capture linguistic subtleties, leading to significant improvements in question interpretation, context alignment, and answer generation. This work represents the first application of SSMs to question answering tasks in Indic languages, establishing a foundational benchmark for future research in this domain. We propose enhancements to existing SSM frameworks, optimizing their applicability to low-resource settings and multilingual scenarios prevalent in Indic languages.",
    "pdfUrl": "https://arxiv.org/pdf/2502.01673",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.785010Z"
  },
  {
    "id": "e63cec73c13553309a5c8138f5dc4528",
    "title": "Probabilistic Subspace Manifolds for Contextual Inference in Large Language Models",
    "slug": "probabilistic-subspace-manifolds-for-contextual-inference-in-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Christopher Nightingale",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Representing token embeddings as probability distributions over learned manifolds allows for more flexible contextual inference, reducing representational rigidity while enhancing semantic granularity. Comparative evaluations demonstrate that probabilistic embeddings improve neighborhood consistency and decrease redundancy, ensuring that token relationships remain more structurally coherent across fine-tuning iterations. The integration of probabilistic subspaces within attention mechanisms facilitates more adaptive contextual weighting, enabling models to capture latent dependencies that would otherwise be obscured in conventional embeddings. Experimental results highlight increased robustness against adversarial modifications, with probabilistic embeddings preserving contextual integrity even under perturbation-based evaluation scenarios. Performance assessments indicate that probabilistic representations achieve greater adaptability in domain-specific applications, mitigating the need for extensive retraining when shifting across linguistic domains. Computational trade-offs remain within operationally feasible limits, with marginal increases in inference latency balanced against the benefits of enhanced representation stability and contextual expressiveness. The capacity to encode structured uncertainty provides advantages in generative modeling tasks, particularly where maintaining coherence across extended sequences requires a representation framework capable of handling ambiguous or context-dependent linguistic constructs.",
    "pdfUrl": "https://arxiv.org/pdf/2502.05346",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.785238Z"
  },
  {
    "id": "d2edf207b5e8611c4c05fd6edb58d14d",
    "title": "Towards Reasoning Ability of Small Language Models",
    "slug": "towards-reasoning-ability-of-small-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Gaurav Srivastava",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reasoning has long been viewed as an emergent property of large language models (LLMs), appearing at or above a certain scale ($\\sim$100B parameters). However, recent studies challenge this assumption, showing that small language models (SLMs) can also achieve competitive reasoning performance. SLMs are increasingly favored for their efficiency and deployability. However, there is a lack of systematic study on the reasoning abilities of diverse SLMs, including those trained from scratch or derived from LLMs through quantization, pruning, and distillation. This raises a critical question: Can SLMs achieve reasoning abilities comparable to LLMs? In this work, we systematically survey, benchmark, and analyze 72 SLMs from six model families across 14 reasoning benchmarks. For reliable evaluation, we examine four evaluation methods and compare four LLM judges against human evaluations on 800 data points. We repeat all experiments three times to ensure a robust performance assessment. Additionally, we analyze the impact of different prompting strategies in small models. Beyond accuracy, we also evaluate model robustness under adversarial conditions and intermediate reasoning steps. Our findings challenge the assumption that scaling is the only way to achieve strong reasoning. Instead, we foresee a future where SLMs with strong reasoning capabilities can be developed through structured training or post-training compression. They can serve as efficient alternatives to LLMs for reasoning-intensive tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2502.11569",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.785437Z"
  },
  {
    "id": "ad06b2a15be8b70a3836715610a919db",
    "title": "PSCon: Product Search Through Conversations",
    "slug": "pscon:-product-search-through-conversations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jie Zou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Conversational Product Search ( CPS ) systems interact with users via natural language to offer personalized and context-aware product lists. However, most existing research on CPS is limited to simulated conversations, due to the lack of a real CPS dataset driven by human-like language. Moreover, existing conversational datasets for e-commerce are constructed for a particular market or a particular language and thus can not support cross-market and multi-lingual usage. In this paper, we propose a CPS data collection protocol and create a new CPS dataset, called PSCon, which assists product search through conversations with human-like language. The dataset is collected by a coached human-human data collection protocol and is available for dual markets and two languages. By formulating the task of CPS, the dataset allows for comprehensive and in-depth research on six subtasks: user intent detection, keyword extraction, system action prediction, question selection, item ranking, and response generation. Moreover, we present a concise analysis of the dataset and propose a benchmark model on the proposed CPS dataset. Our proposed dataset and model will be helpful for facilitating future research on CPS.",
    "pdfUrl": "https://arxiv.org/pdf/2502.13881",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.785660Z"
  },
  {
    "id": "a53f1695b06cadcee9ee468f75d5af34",
    "title": "Automatically Evaluating the Paper Reviewing Capability of Large Language Models",
    "slug": "automatically-evaluating-the-paper-reviewing-capability-of-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Hyungyu Shin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Peer review is essential for scientific progress, but it faces challenges such as reviewer shortages and growing workloads. Although Large Language Models (LLMs) show potential for providing assistance, research has reported significant limitations in the reviews they generate. While the insights are valuable, conducting the analysis is challenging due to the considerable time and effort required, especially given the rapid pace of LLM developments. To address the challenge, we developed an automatic evaluation pipeline to assess the LLMs' paper review capability by comparing them with expert-generated reviews. By constructing a dataset consisting of 676 OpenReview papers, we examined the agreement between LLMs and experts in their strength and weakness identifications. The results showed that LLMs lack balanced perspectives, significantly overlook novelty assessment when criticizing, and produce poor acceptance decisions. Our automated pipeline enables a scalable evaluation of LLMs' paper review capability over time.",
    "pdfUrl": "https://arxiv.org/pdf/2502.17086",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.785898Z"
  },
  {
    "id": "41d1f0b9432a2eea625b66a1685a6dc4",
    "title": "SemEval-2025 Task 11: Bridging the Gap in Text-Based Emotion Detection",
    "slug": "semeval-2025-task-11:-bridging-the-gap-in-text-based-emotion-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Shamsuddeen Hassan Muhammad",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present our shared task on text-based emotion detection, covering more than 30 languages from seven distinct language families. These languages are predominantly low-resource and are spoken across various continents. The data instances are multi-labeled with six emotional classes, with additional datasets in 11 languages annotated for emotion intensity. Participants were asked to predict labels in three tracks: (a) multilabel emotion detection, (b) emotion intensity score detection, and (c) cross-lingual emotion detection.\nThe task attracted over 700 participants. We received final submissions from more than 200 teams and 93 system description papers. We report baseline results, along with findings on the best-performing systems, the most common approaches, and the most effective methods across different tracks and languages. The datasets for this task are publicly available. The dataset is available at SemEval2025 Task 11 this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2503.07269",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.786181Z"
  },
  {
    "id": "7a15aa8aaab260dc466c9b56af3ea393",
    "title": "HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks",
    "slug": "hyperdas:-towards-automating-mechanistic-interpretability-with-hypernetworks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jiuding Sun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Mechanistic interpretability has made great strides in identifying neural network features (e.g., directions in hidden activation space) that mediate concepts(e.g., the birth year of a person) and enable predictable manipulation. Distributed alignment search (DAS) leverages supervision from counterfactual data to learn concept features within hidden states, but DAS assumes we can afford to conduct a brute force search over potential feature locations. To address this, we present HyperDAS, a transformer-based hypernetwork architecture that (1) automatically locates the token-positions of the residual stream that a concept is realized in and (2) constructs features of those residual stream vectors for the concept. In experiments with Llama3-8B, HyperDAS achieves state-of-the-art performance on the RAVEL benchmark for disentangling concepts in hidden states. In addition, we review the design decisions we made to mitigate the concern that HyperDAS (like all powerful interpretabilty methods) might inject new information into the target model rather than faithfully interpreting it.",
    "pdfUrl": "https://arxiv.org/pdf/2503.10894",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.786406Z"
  },
  {
    "id": "826a8a3bc6623e1619c75bfac1dbe0da",
    "title": "Shared Global and Local Geometry of Language Model Embeddings",
    "slug": "shared-global-and-local-geometry-of-language-model-embeddings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Andrew Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Researchers have recently suggested that models share common representations. In our work, we find that token embeddings of language models exhibit common geometric structure. First, we find ``global'' similarities: token embeddings often share similar relative orientations. Next, we characterize local geometry in two ways: (1) by using Locally Linear Embeddings, and (2) by defining a simple measure for the intrinsic dimension of each token embedding. Our intrinsic dimension demonstrates that token embeddings lie on a lower dimensional manifold. We qualitatively show that tokens with lower intrinsic dimensions often have semantically coherent clusters, while those with higher intrinsic dimensions do not. Both characterizations allow us to find similarities in the local geometry of token embeddings. Perhaps most surprisingly, we find that alignment in token embeddings persists through the hidden states of language models, allowing us to develop an application for interpretability. Namely, we introduce Emb2Emb, a simple method to transfer steering vectors from one language model to another, despite the two models having different dimensions.",
    "pdfUrl": "https://arxiv.org/pdf/2503.21073",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.786609Z"
  },
  {
    "id": "99b59399d8fd0c88c26856ce72527870",
    "title": "Cognitive Memory in Large Language Models",
    "slug": "cognitive-memory-in-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Lianlei Shan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper examines memory mechanisms in Large Language Models (LLMs), emphasizing their importance for context-rich responses, reduced hallucinations, and improved efficiency. It categorizes memory into sensory, short-term, and long-term, with sensory memory corresponding to input prompts, short-term memory processing immediate context, and long-term memory implemented via external databases or structures. The text-based memory section covers acquisition (selection and summarization), management (updating, accessing, storing, and resolving conflicts), and utilization (full-text search, SQL queries, semantic search). The KV cache-based memory section discusses selection methods (regularity-based summarization, score-based approaches, special token embeddings) and compression techniques (low-rank compression, KV merging, multimodal compression), along with management strategies like offloading and shared attention mechanisms. Parameter-based memory methods (LoRA, TTT, MoE) transform memories into model parameters to enhance efficiency, while hidden-state-based memory approaches (chunk mechanisms, recurrent transformers, Mamba model) improve long-text processing by combining RNN hidden states with current methods. Overall, the paper offers a comprehensive analysis of LLM memory mechanisms, highlighting their significance and future research directions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.02441",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.786818Z"
  },
  {
    "id": "0e0fb41ff9ab3ad433ab6573288f4afd",
    "title": "Not All Data Are Unlearned Equally",
    "slug": "not-all-data-are-unlearned-equally",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Aravind Krishnan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Machine unlearning is concerned with the task of removing knowledge learned from particular data points from a trained model. In the context of large language models (LLMs), unlearning has recently received increased attention, particularly for removing knowledge about named entities from models for privacy purposes. While various approaches have been proposed to address the unlearning problem, most existing approaches treat all data points to be unlearned equally, i.e., unlearning that Montreal is a city in Canada is treated exactly the same as unlearning the phone number of the first author of this paper. In this work, we show that this all data is equal assumption does not hold for LLM unlearning. We study how the success of unlearning depends on the frequency of the knowledge we want to unlearn in the pre-training data of a model and find that frequency strongly affects unlearning, i.e., more frequent knowledge is harder to unlearn. Additionally, we uncover a misalignment between probability and generation-based evaluations of unlearning and show that this problem worsens as models become larger. Overall, our experiments highlight the need for better evaluation practices and novel methods for LLM unlearning that take the training data of models into account.",
    "pdfUrl": "https://arxiv.org/pdf/2504.05058",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.787020Z"
  },
  {
    "id": "230affc0f08cdd7ffb4fd30ea9f2681c",
    "title": "Multilingual MFA: Forced Alignment on Low-Resource Related Languages",
    "slug": "multilingual-mfa:-forced-alignment-on-low-resource-related-languages",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Alessio Tosolini",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We compare the outcomes of multilingual and crosslingual training for related and unrelated Australian languages with similar phonological inventories. We use the Montreal Forced Aligner to train acoustic models from scratch and adapt a large English model, evaluating results against seen data, unseen data (seen language), and unseen data and language. Results indicate benefits of adapting the English baseline model for previously unseen languages.",
    "pdfUrl": "https://arxiv.org/pdf/2504.07315",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.787213Z"
  },
  {
    "id": "72bd6d86f8ee12665b1a4baa7c99c7e7",
    "title": "Transferable text data distillation by trajectory matching",
    "slug": "transferable-text-data-distillation-by-trajectory-matching",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Rong Yao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the realm of large language model (LLM), as the size of large models increases, it also brings higher training costs. There is a urgent need to minimize the data size in LLM training. Compared with data selection method, the data distillation method aims to synthesize a small number of data samples to achieve the training effect of the full data set and has better flexibility. Despite its successes in computer vision, the discreteness of text data has hitherto stymied its exploration in natural language processing (NLP). In this work, we proposed a method that involves learning pseudo prompt data based on trajectory matching and finding its nearest neighbor ID to achieve cross-architecture transfer. During the distillation process, we introduce a regularization loss to improve the robustness of our distilled data. To our best knowledge, this is the first data distillation work suitable for text generation tasks such as instruction tuning. Evaluations on two benchmarks, including ARC-Easy and MMLU instruction tuning datasets, established the superiority of our distillation approach over the SOTA data selection method LESS. Furthermore, our method demonstrates a good transferability over LLM structures (i.e., OPT to Llama).",
    "pdfUrl": "https://arxiv.org/pdf/2504.09818",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.787608Z"
  },
  {
    "id": "be01e84514424dddb5d83c2f18c00009",
    "title": "GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning",
    "slug": "geosense:-evaluating-identification-and-application-of-geometric-principles-in-multimodal-reasoning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Liangyu Xu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Geometry problem-solving (GPS), a challenging task requiring both visual comprehension and symbolic reasoning, effectively measures the reasoning capabilities of multimodal large language models (MLLMs). Humans exhibit strong reasoning ability in this task through accurate identification and adaptive application of geometric principles within visual contexts. However, existing benchmarks fail to jointly assess both dimensions of the human-like geometric reasoning mechanism in MLLMs, remaining a critical gap in assessing their ability to tackle GPS. To this end, we introduce GeoSense, the first comprehensive bilingual benchmark designed to systematically evaluate the geometric reasoning abilities of MLLMs through the lens of geometric principles. GeoSense features a five-level hierarchical framework of geometric principles spanning plane and solid geometry, an intricately annotated dataset of 1,789 problems, and an innovative evaluation strategy. Through extensive experiments on GeoSense with various open-source and closed-source MLLMs, we observe that Gemini-2.0-pro-flash performs best, achieving an overall score of $65.3$. Our in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities. These findings underscore GeoSense's potential to guide future advancements in MLLMs' geometric reasoning capabilities, paving the way for more robust and human-like reasoning in artificial intelligence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.12597",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.787866Z"
  },
  {
    "id": "296701f9484e84b8c4de62b7bb9ef66e",
    "title": "From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs",
    "slug": "from-large-to-super-tiny:-end-to-end-optimization-for-cost-efficient-llms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jiliang Ni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In recent years, Large Language Models (LLMs) have significantly advanced artificial intelligence by optimizing traditional Natural Language Processing (NLP) pipelines, improving performance and generalization. This has spurred their integration into various systems. Many NLP systems, including ours, employ a \"one-stage\" pipeline directly incorporating LLMs. While effective, this approach incurs substantial costs and latency due to the need for large model parameters to achieve satisfactory outcomes. This paper introduces a three-stage cost-efficient end-to-end LLM deployment pipeline-including prototyping, knowledge transfer, and model compression-to tackle the cost-performance dilemma in LLM-based frameworks. Our approach yields a super tiny model optimized for cost and performance in online systems, simplifying the system architecture. Initially, by transforming complex tasks into a function call-based LLM-driven pipeline, an optimal performance prototype system is constructed to produce high-quality data as a teacher model. The second stage combines techniques like rejection fine-tuning, reinforcement learning, and knowledge distillation to transfer knowledge to a smaller 0.5B student model, delivering effective performance at minimal cost. The final stage applies quantization and pruning to extremely compress models to 0.4B, achieving ultra-low latency and cost. The framework's modular design and cross-domain capabilities suggest potential applicability in other NLP areas.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13471",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.788098Z"
  },
  {
    "id": "6a1bdf44ec93c857609f59722cae52c2",
    "title": "Efficient Pretraining Length Scaling",
    "slug": "efficient-pretraining-length-scaling",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Bohong Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advances in large language models have demonstrated the effectiveness of length scaling during post-training, yet its potential in pre-training remains underexplored. We present the Parallel Hidden Decoding Transformer (\\textit{PHD}-Transformer), a novel framework that enables efficient length scaling during pre-training while maintaining inference efficiency. \\textit{PHD}-Transformer achieves this through an innovative KV cache management strategy that distinguishes between original tokens and hidden decoding tokens. By retaining only the KV cache of original tokens for long-range dependencies while immediately discarding hidden decoding tokens after use, our approach maintains the same KV cache size as the vanilla transformer while enabling effective length scaling. To further enhance performance, we introduce two optimized variants: \\textit{PHD-SWA} employs sliding window attention to preserve local dependencies, while \\textit{PHD-CSWA} implements chunk-wise sliding window attention to eliminate linear growth in pre-filling time. Extensive experiments demonstrate consistent improvements across multiple benchmarks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14992",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.788313Z"
  },
  {
    "id": "85b90d4fa9b28cd51ecda68c42b6bdc2",
    "title": "Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark",
    "slug": "can-large-language-models-help-multimodal-language-analysis?-mmla:-a-comprehensive-benchmark",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Hanlei Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Multimodal language analysis is a rapidly evolving field that leverages multiple modalities to enhance the understanding of high-level semantics underlying human conversational utterances. Despite its significance, little research has investigated the capability of multimodal large language models (MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce MMLA, a comprehensive benchmark specifically designed to address this gap. MMLA comprises over 61K multimodal utterances drawn from both staged and real-world scenarios, covering six core dimensions of multimodal semantics: intent, emotion, dialogue act, sentiment, speaking style, and communication behavior. We evaluate eight mainstream branches of LLMs and MLLMs using three methods: zero-shot inference, supervised fine-tuning, and instruction tuning. Extensive experiments reveal that even fine-tuned models achieve only about 60%~70% accuracy, underscoring the limitations of current MLLMs in understanding complex human language. We believe that MMLA will serve as a solid foundation for exploring the potential of large language models in multimodal language analysis and provide valuable resources to advance this field. The datasets and code are open-sourced at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16427",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:15.788539Z"
  },
  {
    "id": "add84aa839b3e1eb69df9cc6e03c31be",
    "title": "ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation",
    "slug": "real:-efficient-rlhf-training-of-large-language-models-with-parameter-reallocation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Zhiyu Mei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for empowering large language model (LLM) applications. Compared with the supervised training process of LLMs, the RLHF training process is much more sophisticated, requiring a diverse range of computation workloads with intricate dependencies between multiple LLM instances. Therefore, simply adopting the fixed parallelization strategies from supervised training for LLMs can be insufficient for RLHF and result in low training efficiency. To overcome this limitation, we propose a novel technique named parameter ReaLlocation, which dynamically adapts the parallelization strategies for different workloads during training by redistributing LLM parameters across the training cluster. Building upon this idea, we introduce ReaL, a pioneering system for efficient RLHF training. ReaL introduces the concept of an execution plan, which defines a fine-grained resource allocation and parallelization strategy particularly designed for RLHF training. Based on this concept, ReaL employs a tailored search algorithm with a lightweight run-time estimator to automatically discover an efficient execution plan for an instance of RLHF experiment. Subsequently, the runtime engine deploys the selected plan by effectively parallelizing computations and redistributing parameters. We evaluate ReaL on the LLaMA models with up to 70 billion parameters and 128 GPUs. The experimental results demonstrate that ReaL achieves speedups of up to $3.58\\times$ compared to baseline methods. Furthermore, the execution plans generated by ReaL exhibit an average of $81\\%$ performance improvement over heuristic approaches based on Megatron-LM in the long-context scenario. The source code of ReaL is publicly available at this https URL .",
    "pdfUrl": "https://arxiv.org/pdf/2406.14088",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:15.788760Z"
  },
  {
    "id": "96ae566923927b2406029800a8f9cad3",
    "title": "Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF",
    "slug": "regressing-the-relative-future:-efficient-policy-optimization-for-multi-turn-rlhf",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhaolin Gao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) have achieved remarkable success at tasks like summarization that involve a single turn of interaction. However, they can still struggle with multi-turn tasks like dialogue that require long-term planning. Previous works on multi-turn dialogue extend single-turn reinforcement learning from human feedback (RLHF) methods to the multi-turn setting by treating all prior dialogue turns as a long context. Such approaches suffer from covariate shift: the conversations in the training set have previous turns generated by some reference policy, which means that low training error may not necessarily correspond to good performance when the learner is actually in the conversation loop. In response, we introduce REgressing the RELative FUture (REFUEL), an efficient policy optimization approach designed to address multi-turn RLHF in LLMs. REFUEL employs a single model to estimate $Q$-values and trains on self-generated data, addressing the covariate shift issue. REFUEL frames the multi-turn RLHF problem as a sequence of regression tasks on iteratively collected datasets, enabling ease of implementation. Theoretically, we prove that REFUEL can match the performance of any policy covered by the training set. Empirically, we evaluate our algorithm by using Llama-3.1-70B-it to simulate a user in conversation with our model. REFUEL consistently outperforms state-of-the-art methods such as DPO and REBEL across various settings. Furthermore, despite having only 8 billion parameters, Llama-3-8B-it fine-tuned with REFUEL outperforms Llama-3.1-70B-it on long multi-turn dialogues. Implementation of REFUEL can be found at this https URL, and models trained by REFUEL can be found at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2410.04612",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:15.788992Z"
  },
  {
    "id": "a44ad10769288f8068a93cabf6d7fa12",
    "title": "CallNavi, A Challenge and Empirical Study on LLM Function Calling and Routing",
    "slug": "callnavi,-a-challenge-and-empirical-study-on-llm-function-calling-and-routing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Yewei Song",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "API-driven chatbot systems are increasingly integral to software engineering applications, yet their effectiveness hinges on accurately generating and executing API calls. This is particularly challenging in scenarios requiring multi-step interactions with complex parameterization and nested API dependencies. Addressing these challenges, this work contributes to the evaluation and assessment of AI-based software development through three key advancements: (1) the introduction of a novel dataset specifically designed for benchmarking API function selection, parameter generation, and nested API execution; (2) an empirical evaluation of state-of-the-art language models, analyzing their performance across varying task complexities in API function generation and parameter accuracy; and (3) a hybrid approach to API routing, combining general-purpose large language models for API selection with fine-tuned models and prompt engineering for parameter generation. These innovations significantly improve API execution in chatbot systems, offering practical methodologies for enhancing software design, testing, and operational workflows in real-world software engineering contexts.",
    "pdfUrl": "https://arxiv.org/pdf/2501.05255",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:15.789222Z"
  },
  {
    "id": "4bc1576379d550192ed099a6eb1733d9",
    "title": "Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?",
    "slug": "are-transformers-able-to-reason-by-connecting-separated-knowledge-in-training-data?",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Yutong Yin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Humans exhibit remarkable compositional reasoning by integrating knowledge from various sources. For example, if someone learns ( B = f(A) ) from one source and ( C = g(B) ) from another, they can deduce ( C=g(B)=g(f(A)) ) even without encountering ( ABC ) together, showcasing the generalization ability of human intelligence. In this paper, we introduce a synthetic learning task, \"FTCT\" (Fragmented at Training, Chained at Testing), to validate the potential of Transformers in replicating this skill and interpret its inner mechanism. In the training phase, data consist of separated knowledge fragments from an overall causal graph. During testing, Transformers must infer complete causal graph traces by integrating these fragments. Our findings demonstrate that few-shot Chain-of-Thought prompting enables Transformers to perform compositional reasoning on FTCT by revealing correct combinations of fragments, even if such combinations were absent in the training data. Furthermore, the emergence of compositional reasoning ability is strongly correlated with the model complexity and training-testing data similarity. We propose, both theoretically and empirically, that Transformers learn an underlying generalizable program from training, enabling effective compositional reasoning during testing.",
    "pdfUrl": "https://arxiv.org/pdf/2501.15857",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:15.789429Z"
  },
  {
    "id": "387c3494461a3b353446339a1e9340d5",
    "title": "Keyframe-oriented Vision Token Pruning: Enhancing Efficiency of Large Vision Language Models on Long-Form Video Processing",
    "slug": "keyframe-oriented-vision-token-pruning:-enhancing-efficiency-of-large-vision-language-models-on-long-form-video-processing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yudong Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Vision language models (VLMs) demonstrate strong capabilities in jointly processing visual and textual data. However, they often incur substantial computational overhead due to redundant visual information, particularly in long-form video scenarios. Existing approaches predominantly focus on either vision token pruning, which may overlook spatio-temporal dependencies, or keyframe selection, which identifies informative frames but discards others, thus disrupting contextual continuity. In this work, we propose KVTP (Keyframe-oriented Vision Token Pruning), a novel framework that overcomes the drawbacks of token pruning and keyframe selection. By adaptively assigning pruning rates based on frame relevance to the query, KVTP effectively retains essential contextual information while significantly reducing redundant computation. To thoroughly evaluate the long-form video understanding capacities of VLMs, we curated and reorganized subsets from VideoMME, EgoSchema, and NextQA into a unified benchmark named SparseKV-QA that highlights real-world scenarios with sparse but crucial events. Our experiments with VLMs of various scales show that KVTP can reduce token usage by 80% without compromising spatiotemporal and contextual consistency, significantly cutting computation while maintaining the performance. These results demonstrate our approach's effectiveness in efficient long-video processing, facilitating more scalable VLM deployment.",
    "pdfUrl": "https://arxiv.org/pdf/2503.10742",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:15.789651Z"
  },
  {
    "id": "23d675c0e57c192d7940da0966c27733",
    "title": "Looking beyond the next token",
    "slug": "looking-beyond-the-next-token",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Abitha Thankaraj",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The structure of causal language model training assumes that each token can be accurately predicted from the previous context. This contrasts with humans' natural writing and reasoning process, where goals are typically known before the exact argument or phrasings. While this mismatch has been well studied in the literature, the working assumption has been that architectural changes are needed to address this mismatch. We argue that rearranging and processing the training data sequences can allow models to more accurately imitate the true data-generating process, and does not require any other changes to the architecture or training infrastructure. We demonstrate that this technique, Trelawney, and the inference algorithms derived from it allow us to improve performance on several key benchmarks that span planning, algorithmic reasoning, and story generation tasks. Finally, our method naturally enables the generation of long-term goals at no additional cost. We investigate how using the model's goal-generation capability can further improve planning and reasoning. Additionally, we believe Trelawney could potentially open doors to new capabilities beyond the current language modeling paradigm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.11336",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:15.789855Z"
  },
  {
    "id": "41d621a353d4a5c65a552d445437d61c",
    "title": "Teaching Large Language Models to Reason through Learning and Forgetting",
    "slug": "teaching-large-language-models-to-reason-through-learning-and-forgetting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Tianwei Ni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Leveraging inference-time search in large language models has proven effective in further enhancing a trained model's capability to solve complex mathematical and reasoning problems. However, this approach significantly increases computational costs and inference time, as the model must generate and evaluate multiple candidate solutions to identify a viable reasoning path. To address this, we propose an effective approach that integrates search capabilities directly into the model by fine-tuning it using both successful (learning) and failed reasoning paths (forgetting) derived from diverse search methods. While fine-tuning the model with these data might seem straightforward, we identify a critical issue: the model's search capability tends to degrade rapidly if fine-tuning is performed naively. We show that this degradation can be substantially mitigated by employing a smaller learning rate. Extensive experiments on the challenging Game-of-24 and Countdown mathematical reasoning benchmarks show that our approach not only outperforms both standard fine-tuning and inference-time search baselines but also significantly reduces inference time by 180$\\times$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.11364",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:15.790073Z"
  },
  {
    "id": "e2d0942fe2d442f4813d5b418ac6b736",
    "title": "TALES: Text Adventure Learning Environment Suite",
    "slug": "tales:-text-adventure-learning-environment-suite",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Christopher Zhang Cui",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reasoning is an essential skill to enable Large Language Models (LLMs) to interact with the world. As tasks become more complex, they demand increasingly sophisticated and diverse reasoning capabilities for sequential decision-making, requiring structured reasoning over the context history to determine the next best action. We introduce TALES, a diverse collection of synthetic and human-written text-adventure games designed to challenge and evaluate diverse reasoning capabilities. We present results over a range of LLMs, open- and closed-weights, performing a qualitative analysis on the top performing models. Despite an impressive showing on synthetic games, even the top LLM-driven agents fail to achieve 15% on games designed for human enjoyment. Code and visualization of the experiments can be found at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14128",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:15.790281Z"
  },
  {
    "id": "e3faf48859b725074156ba2ca9e35254",
    "title": "Integrating Graph Theoretical Approaches in Cybersecurity Education CSCI-RTED",
    "slug": "integrating-graph-theoretical-approaches-in-cybersecurity-education-csci-rted",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Goksel Kucukkaya",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As cybersecurity threats continue to evolve, the need for advanced tools to analyze and understand complex cyber environments has become increasingly critical. Graph theory offers a powerful framework for modeling relationships within cyber ecosystems, making it highly applicable to cybersecurity. This paper focuses on the development of an enriched version of the widely recognized NSL-KDD dataset, incorporating graph-theoretical concepts to enhance its practical value. The enriched dataset provides a resource for students and professionals to engage in hands-on analysis, enabling them to explore graph-based methodologies for identifying network behavior and vulnerabilities. To validate the effectiveness of this dataset, we employed IBM Auto AI, demonstrating its capability in real-world applications such as classification and threat prediction. By addressing the need for graph-theoretical datasets, this study provides a practical tool for equipping future cybersecurity professionals with the skills necessary to confront complex cyber challenges.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17059",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.313732Z"
  },
  {
    "id": "90a7d59098bedf09affabd19404fad1a",
    "title": "Evaluating Argon2 Adoption and Effectiveness in Real-World Software",
    "slug": "evaluating-argon2-adoption-and-effectiveness-in-real-world-software",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Pascal Tippe",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Modern password hashing remains a critical defense against credential cracking, yet the transition from theoretically secure algorithms to robust real-world implementations remains fraught with challenges. This paper presents a dual analysis of Argon2, the Password Hashing Competition winner, combining attack simulations quantifying how parameter configurations impact guessing costs under realistic budgets, with the first large-scale empirical study of Argon2 adoption across public GitHub software repositories. Our economic model, validated against cryptocurrency mining benchmarks, demonstrates that OWASP's recommended 46 MiB configuration reduces compromise rates by 42.5% compared to SHA-256 at \\$1/account attack budgets for strong user passwords. However, memory-hardness exhibits diminishing returns as increasing allocations to RFC 9106's 2048 MiB provides just 23.3% (\\$1) and 17.7% (\\$20) additional protection despite 44.5 times greater memory demands. Crucially, both configurations fail to mitigate risks from weak passwords, with 96.9-99.8% compromise rates for RockYou-like credentials regardless of algorithm choice. Our repository analysis shows accelerating Argon2 adoption, yet weak configuration practices: 46.6% of deployments use weaker-than-OWASP parameters. Surprisingly, sensitive applications (password managers, encryption tools) show no stronger configurations than general software. Our findings highlight that a secure algorithm alone cannot ensure security, effective parameter guidance and developer education remain essential for realizing Argon2's theoretical advantages.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17121",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.313971Z"
  },
  {
    "id": "1f9ebbb86ef1e33f04f57e352ddacb2a",
    "title": "P$_\\ell$-Kyber: Packing $\\ell$ Plaintexts and Lattice Coding for Kyber",
    "slug": "p$_\\ell$-kyber:-packing-$\\ell$-plaintexts-and-lattice-coding-for-kyber",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Shuiyin Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, we propose a joint design of encoding and encryption processes for KEMs like Kyber, without assuming the independence of the decoding noise entries. Our design features two techniques: ciphertext packing and lattice packing. First, we extend the Peikert-Vaikuntanathan-Waters (PVW) method to the Kyber: $\\ell$ plaintexts are packed into a single ciphertext. This scheme is referred to as P$_\\ell$-Kyber. We prove that the P$_\\ell$-Kyber is IND-CCA secure under the M-LWE hardness assumption. We show that the decryption decoding noise entries across the $\\ell$ plaintexts (also known as layers) are mutually independent. Second, we propose a cross-layer lattice encoding scheme for the P$_\\ell$-Kyber, where every $\\ell$ cross-layer information symbols are encoded to a lattice point. This way we obtain a \\emph{coded} P$_\\ell$-Kyber, where the decoding noise entries for each lattice point are mutually independent. Therefore, the decryption failure rate (DFR) analysis does not require the assumption of independence among the decryption decoding noise entries. Both DFR and communication cost (CER) are greatly decreased thanks to ciphertext packing and lattice packing. Finally, we demonstrate that with $\\ell=24$ and Leech lattice encoder, the proposed coded P$_\\ell$-KYBER1024 achieves DFR $<2^{-281}$ and CER $ = 4.6$, i.e., a decrease of CER by $90\\%$ compared to KYBER1024.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17185",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.314187Z"
  },
  {
    "id": "0c4090b5f361c4e67c7387b423ec5aa2",
    "title": "Developing a Blockchain-Based Secure Digital Contents Distribution System",
    "slug": "developing-a-blockchain-based-secure-digital-contents-distribution-system",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Syed Mohiuddin Qadri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As digital content distribution expands rapidly through online platforms, securing digital media and protecting intellectual property has become increasingly complex. Traditional centralized systems, while widely adopted, suffer from vulnerabilities such as single points of failure and limited traceability of unauthorized access. This paper presents a blockchain-based secure digital content distribution system that integrates Sia, a decentralized storage network, and Skynet, a content delivery network, to enhance content protection and distribution. The proposed system employs a dual-layer architecture: off-chain for user authentication and on-chain for transaction validation using smart contracts and asymmetric encryption. By introducing a license issuance and secret block mechanism, the system ensures content authenticity, privacy, and controlled access. Experimental results demonstrate the feasibility and scalability of the system in securely distributing multimedia files. The proposed platform not only improves content security but also paves the way for future enhancements with decentralized applications and integrated royalty payment mechanisms.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17194",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.314387Z"
  },
  {
    "id": "9c78ab425d14c4cf4c0440c2325608f0",
    "title": "A Comment on \"e-PoS: Making PoS Decentralized and Fair\"",
    "slug": "a-comment-on-\"e-pos:-making-pos-decentralized-and-fair\"",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Suhyeon Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Proof-of-Stake (PoS) is a prominent Sybil control mechanism for blockchain-based systems. In \"e-PoS: Making PoS Decentralized and Fair,\" Saad et al. (TPDS'21) introduced a new Proof-of-Stake protocol, e-PoS, to enhance PoS applications' decentralization and fairness. In this comment paper, we address a misunderstanding in the work of Saad et al. The conventional Proof-of-Stake model that causes the fairness problem does not align with the general concept of Proof-of-Stake nor the Proof-of-Stake cryptocurrencies mentioned in their paper.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17256",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.314595Z"
  },
  {
    "id": "0776459bad41d54998b1fe8021d5fade",
    "title": "Contrastive Learning for Continuous Touch-Based Authentication",
    "slug": "contrastive-learning-for-continuous-touch-based-authentication",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Mengyu Qiao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Smart mobile devices have become indispensable in modern daily life, where sensitive information is frequently processed, stored, and transmitted-posing critical demands for robust security controls. Given that touchscreens are the primary medium for human-device interaction, continuous user authentication based on touch behavior presents a natural and seamless security solution. While existing methods predominantly adopt binary classification under single-modal learning settings, we propose a unified contrastive learning framework for continuous authentication in a non-disruptive manner. Specifically, the proposed method leverages a Temporal Masked Autoencoder to extract temporal patterns from raw multi-sensor data streams, capturing continuous motion and gesture dynamics. The pre-trained TMAE is subsequently integrated into a Siamese Temporal-Attentive Convolutional Network within a contrastive learning paradigm to model both sequential and cross-modal patterns. To further enhance performance, we incorporate multi-head attention and channel attention mechanisms to capture long-range dependencies and optimize inter-channel feature integration. Extensive experiments on public benchmarks and a self-collected dataset demonstrate that our approach outperforms state-of-the-art methods, offering a reliable and effective solution for user authentication on mobile devices.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17271",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.314791Z"
  },
  {
    "id": "324daa7f0f478d3d80334fd5ce9e501a",
    "title": "Proof of Useful Intelligence (PoUI): Blockchain Consensus Beyond Energy Waste",
    "slug": "proof-of-useful-intelligence-(poui):-blockchain-consensus-beyond-energy-waste",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Zan-Kai Chong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Blockchain technology enables secure, transparent data management in decentralized systems, supporting applications from cryptocurrencies like Bitcoin to tokenizing real-world assets like property. Its scalability and sustainability hinge on consensus mechanisms balancing security and efficiency. Proof of Work (PoW), used by Bitcoin, ensures security through energy-intensive computations but demands significant resources. Proof of Stake (PoS), as in Ethereum post-Merge, selects validators based on staked cryptocurrency, offering energy efficiency but risking centralization from wealth concentration. With AI models straining computational resources, we propose Proof of Useful Intelligence (PoUI), a hybrid consensus mechanism. In PoUI, workers perform AI tasks like language processing or image analysis to earn coins, which are staked to secure the network, blending security with practical utility. Decentralized nodes--job posters, market coordinators, workers, and validators --collaborate via smart contracts to manage tasks and rewards.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17539",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.314997Z"
  },
  {
    "id": "c628dd731ad766d26c79645d6b8ca111",
    "title": "Evaluating the Vulnerability of ML-Based Ethereum Phishing Detectors to Single-Feature Adversarial Perturbations",
    "slug": "evaluating-the-vulnerability-of-ml-based-ethereum-phishing-detectors-to-single-feature-adversarial-perturbations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Ahod Alghuried",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper explores the vulnerability of machine learning models to simple single-feature adversarial attacks in the context of Ethereum fraudulent transaction detection. Through comprehensive experimentation, we investigate the impact of various adversarial attack strategies on model performance metrics. Our findings, highlighting how prone those techniques are to simple attacks, are alarming, and the inconsistency in the attacks' effect on different algorithms promises ways for attack mitigation. We examine the effectiveness of different mitigation strategies, including adversarial training and enhanced feature selection, in enhancing model robustness and show their effectiveness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17684",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.315222Z"
  },
  {
    "id": "30dbe1f82a4b7925e4c7c611b3d00c26",
    "title": "User Profiles: The Achilles' Heel of Web Browsers",
    "slug": "user-profiles:-the-achilles'-heel-of-web-browsers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Dolire Francis Som",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Web browsers provide the security foundation for our online experiences. Significant research has been done into the security of browsers themselves, but relatively little investigation has been done into how they interact with the operating system or the file system. In this work, we provide the first systematic security study of browser profiles, the on-disk persistence layer of browsers, used for storing everything from users' authentication cookies and browser extensions to certificate trust decisions and device permissions. We show that, except for the Tor Browser, all modern browsers store sensitive data in home directories with little to no integrity or confidentiality controls. We show that security measures like password and cookie encryption can be easily bypassed. In addition, HTTPS can be sidestepped entirely by deploying malicious root certificates within users' browser profiles. The Public Key Infrastructure (PKI), the backbone of the secure Web. HTTPS can be fully bypassed with the deployment of custom potentially malicious root certificates. More worryingly, we show how these powerful attacks can be fully mounted directly from web browsers themselves, through the File System Access API, a recent feature added by Chromium browsers that enables a website to directly manipulate a user's file system via JavaScript. In a series of case studies, we demonstrate how an attacker can install malicious browser extensions, inject additional root certificates, hijack HTTPS traffic, and enable websites to access hardware devices like the camera and GPS. Based on our findings, we argue that researchers and browser vendors need to develop and deploy more secure mechanisms for protecting users' browser data against file system attackers.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17692",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.315424Z"
  },
  {
    "id": "5381171c08837df12674d14c7136156b",
    "title": "Identity Control Plane: The Unifying Layer for Zero Trust Infrastructure",
    "slug": "identity-control-plane:-the-unifying-layer-for-zero-trust-infrastructure",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Surya Teja Avirneni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces the Identity Control Plane (ICP), an architectural framework for enforcing identity-aware Zero Trust access across human users, workloads, and automation systems. The ICP model unifies SPIFFE-based workload identity, OIDC/SAML user identity, and scoped automation credentials via broker-issued transaction tokens. We propose a composable enforcement layer using ABAC policy engines (e.g., OPA, Cedar), aligned with IETF WIMSE drafts and OAuth transaction tokens. The paper includes architectural components, integration patterns, use cases, a comparative analysis with current models, and theorized performance metrics. A FedRAMP and SLSA compliance mapping is also presented. This is a theoretical infrastructure architecture paper intended for security researchers and platform architects. No prior version of this work has been published.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17759",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.315622Z"
  },
  {
    "id": "f43b92fa5a693b306adffb801f9aae5b",
    "title": "Silenzio: Secure Non-Interactive Outsourced MLP Training",
    "slug": "silenzio:-secure-non-interactive-outsourced-mlp-training",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Jonas Sander",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Outsourcing the ML training to cloud providers presents a compelling opportunity for resource constrained clients, while it simultaneously bears inherent privacy risks, especially for highly sensitive training data. We introduce Silenzio, the first fully non-interactive outsourcing scheme for the training of multi-layer perceptrons that achieves 128 bit security using FHE. Unlike traditional MPC based protocols that necessitate interactive communication between the client and server(s) or non-collusion assumptions among multiple servers, Silenzio enables the fire-and-forget paradigm without such assumptions. In this approach, the client encrypts the training data once, and the cloud server performs the training without any further interaction.\nSilenzio operates over low bitwidth integers - never exceeding 8 bit - to mitigate the computational overhead of FHE. Our approach features a novel low-bitwidth matrix multiplication that leverages input-dependent residue number systems and a Karatsuba-inspired multiplication routine, ensuring that no intermediate FHE-processed value overflows 8 bit. Starting from an RNS-to-MRNS conversion process, we propose an efficient block-scaling mechanism, which approximately shifts encrypted tensor values to the user-specified most significant bits. To instantiate the backpropagation of the error, Silenzio introduces a low-bitwidth and TFHE friendly gradient computation for the cross entropy loss.\nImplemented using the state-of-the-art Concrete library, we evaluate Silenzio on standard MLP training tasks regarding runtime as well as model performance and achieve similar classification accuracy as MLPs trained using standard PyTorch with 32 bit floating-point computations. Our open-source implementation represents a significant advancement in privacy-preserving ML, providing a new baseline for secure and non-interactive outsourced MLP training.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17785",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.315823Z"
  },
  {
    "id": "6ee377a5ca9b24d8efaec61fcb886674",
    "title": "Steering the CensorShip: Uncovering Representation Vectors for LLM \"Thought\" Control",
    "slug": "steering-the-censorship:-uncovering-representation-vectors-for-llm-\"thought\"-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Hannah Cyberey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) have transformed the way we access information. These models are often tuned to refuse to comply with requests that are considered harmful and to produce responses that better align with the preferences of those who control the models. To understand how this \"censorship\" works. We use representation engineering techniques to study open-weights safety-tuned models. We present a method for finding a refusal--compliance vector that detects and controls the level of censorship in model outputs. We also analyze recent reasoning LLMs, distilled from DeepSeek-R1, and uncover an additional dimension of censorship through \"thought suppression\". We show a similar approach can be used to find a vector that suppresses the model's reasoning process, allowing us to remove censorship by applying the negative multiples of this vector",
    "pdfUrl": "https://arxiv.org/pdf/2504.17130",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:16.316025Z"
  },
  {
    "id": "17d72407b45202249b781448188624a5",
    "title": "Automatically Generating Rules of Malicious Software Packages via Large Language Model",
    "slug": "automatically-generating-rules-of-malicious-software-packages-via-large-language-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "XiangRui Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Today's security tools predominantly rely on predefined rules crafted by experts, making them poorly adapted to the emergence of software supply chain attacks. To tackle this limitation, we propose a novel tool, RuleLLM, which leverages large language models (LLMs) to automate rule generation for OSS ecosystems. RuleLLM extracts metadata and code snippets from malware as its input, producing YARA and Semgrep rules that can be directly deployed in software development. Specifically, the rule generation task involves three subtasks: crafting rules, refining rules, and aligning rules. To validate RuleLLM's effectiveness, we implemented a prototype system and conducted experiments on the dataset of 1,633 malicious packages. The results are promising that RuleLLM generated 763 rules (452 YARA and 311 Semgrep) with a precision of 85.2\\% and a recall of 91.8\\%, outperforming state-of-the-art (SOTA) tools and scored-based approaches. We further analyzed generated rules and proposed a rule taxonomy: 11 categories and 38 subcategories.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17198",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:16.316251Z"
  },
  {
    "id": "205180aa6eecb55a31ac05fc0b15b6e4",
    "title": "Breaking the Flow and the Bank: Stealthy Cyberattacks on Water Network Hydraulics",
    "slug": "breaking-the-flow-and-the-bank:-stealthy-cyberattacks-on-water-network-hydraulics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Abdallah Alalem Albustami",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As water distribution networks (WDNs) become increasingly connected with digital infrastructures, they face greater exposure to cyberattacks that threaten their operational integrity. Stealthy False Data Injection Attacks (SFDIAs) are particularly concerning, as they manipulate sensor data to compromise system operations while avoiding detection. While existing studies have focused on either detection methods or specific attack formulations, the relationship between attack sophistication, system knowledge requirements, and achievable impact remains unexplored. This paper presents a systematic analysis of sensor attacks against WDNs, investigating different combinations of physical constraints, state monitoring requirements, and intrusion detection evasion conditions. We propose several attack formulations that range from tailored strategies satisfying both physical and detection constraints to simpler measurement manipulations. The proposed attacks are simple and local -- requiring knowledge only of targeted sensors and their hydraulic connections -- making them scalable and practical. Through case studies on Net1 and Net3 benchmark networks, we demonstrate how these attacks can persistently increase operational costs and alter water flows while remaining undetected by monitoring systems for extended periods. The analysis provides utilities with insights for vulnerability assessment and motivates the development of protection strategies that combine physical and statistical security mechanisms.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17211",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:16.316473Z"
  },
  {
    "id": "3832b9b58a81c253d518510694906ffa",
    "title": "Enhancing Variational Autoencoders with Smooth Robust Latent Encoding",
    "slug": "enhancing-variational-autoencoders-with-smooth-robust-latent-encoding",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hyomin Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Variational Autoencoders (VAEs) have played a key role in scaling up diffusion-based generative models, as in Stable Diffusion, yet questions regarding their robustness remain largely underexplored. Although adversarial training has been an established technique for enhancing robustness in predictive models, it has been overlooked for generative models due to concerns about potential fidelity degradation by the nature of trade-offs between performance and robustness. In this work, we challenge this presumption, introducing Smooth Robust Latent VAE (SRL-VAE), a novel adversarial training framework that boosts both generation quality and robustness. In contrast to conventional adversarial training, which focuses on robustness only, our approach smooths the latent space via adversarial perturbations, promoting more generalizable representations while regularizing with originality representation to sustain original fidelity. Applied as a post-training step on pre-trained VAEs, SRL-VAE improves image robustness and fidelity with minimal computational overhead. Experiments show that SRL-VAE improves both generation quality, in image reconstruction and text-guided image editing, and robustness, against Nightshade attacks and image editing attacks. These results establish a new paradigm, showing that adversarial training, once thought to be detrimental to generative models, can instead enhance both fidelity and robustness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17219",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:16.316694Z"
  },
  {
    "id": "d3ee006c7341b38f4e9ce3829f0bba27",
    "title": "Wolves in the Repository: A Software Engineering Analysis of the XZ Utils Supply Chain Attack",
    "slug": "wolves-in-the-repository:-a-software-engineering-analysis-of-the-xz-utils-supply-chain-attack",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Piotr Przymus",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The digital economy runs on Open Source Software (OSS), with an estimated 90\\% of modern applications containing open-source components. While this widespread adoption has revolutionized software development, it has also created critical security vulnerabilities, particularly in essential but under-resourced projects. This paper examines a sophisticated attack on the XZ Utils project (CVE-2024-3094), where attackers exploited not just code, but the entire open-source development process to inject a backdoor into a fundamental Linux compression library. Our analysis reveals a new breed of supply chain attack that manipulates software engineering practices themselves -- from community management to CI/CD configurations -- to establish legitimacy and maintain long-term control. Through a comprehensive examination of GitHub events and development artifacts, we reconstruct the attack timeline, analyze the evolution of attacker tactics. Our findings demonstrate how attackers leveraged seemingly beneficial contributions to project infrastructure and maintenance to bypass traditional security measures. This work extends beyond traditional security analysis by examining how software engineering practices themselves can be weaponized, offering insights for protecting the open-source ecosystem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17473",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:16.316887Z"
  },
  {
    "id": "93e79b4813f1bbadd872233ddb41b72e",
    "title": "From Randomized Response to Randomized Index: Answering Subset Counting Queries with Local Differential Privacy",
    "slug": "from-randomized-response-to-randomized-index:-answering-subset-counting-queries-with-local-differential-privacy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Qingqing Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Local Differential Privacy (LDP) is the predominant privacy model for safeguarding individual data privacy. Existing perturbation mechanisms typically require perturbing the original values to ensure acceptable privacy, which inevitably results in value distortion and utility deterioration. In this work, we propose an alternative approach -- instead of perturbing values, we apply randomization to indexes of values while ensuring rigorous LDP guarantees. Inspired by the deniability of randomized indexes, we present CRIAD for answering subset counting queries on set-value data. By integrating a multi-dummy, multi-sample, and multi-group strategy, CRIAD serves as a fully scalable solution that offers flexibility across various privacy requirements and domain sizes, and achieves more accurate query results than any existing methods. Through comprehensive theoretical analysis and extensive experimental evaluations, we validate the effectiveness of CRIAD and demonstrate its superiority over traditional value-perturbation mechanisms.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17523",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:16.317114Z"
  },
  {
    "id": "16cb6ab95ba1eac9ff847e170091ac03",
    "title": "Quantum Autoencoder for Multivariate Time Series Anomaly Detection",
    "slug": "quantum-autoencoder-for-multivariate-time-series-anomaly-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Kilian Tscharke",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Anomaly Detection (AD) defines the task of identifying observations or events that deviate from typical - or normal - patterns, a critical capability in IT security for recognizing incidents such as system misconfigurations, malware infections, or cyberattacks. In enterprise environments like SAP HANA Cloud systems, this task often involves monitoring high-dimensional, multivariate time series (MTS) derived from telemetry and log data. With the advent of quantum machine learning offering efficient calculations in high-dimensional latent spaces, many avenues open for dealing with such complex data. One approach is the Quantum Autoencoder (QAE), an emerging and promising method with potential for application in both data compression and AD. However, prior applications of QAEs to time series AD have been restricted to univariate data, limiting their relevance for real-world enterprise systems. In this work, we introduce a novel QAE-based framework designed specifically for MTS AD towards enterprise scale. We theoretically develop and experimentally validate the architecture, demonstrating that our QAE achieves performance competitive with neural-network-based autoencoders while requiring fewer trainable parameters. We evaluate our model on datasets that closely reflect SAP system telemetry and show that the proposed QAE is a viable and efficient alternative for semisupervised AD in real-world enterprise settings.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17548",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:16.317337Z"
  },
  {
    "id": "6de23002ebad47cc72d7032bd74fefd4",
    "title": "STCL:Curriculum learning Strategies for deep learning image steganography models",
    "slug": "stcl:curriculum-learning-strategies-for-deep-learning-image-steganography-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Fengchun Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Aiming at the problems of poor quality of steganographic images and slow network convergence of image steganography models based on deep learning, this paper proposes a Steganography Curriculum Learning training strategy (STCL) for deep learning image steganography models. So that only easy images are selected for training when the model has poor fitting ability at the initial stage, and gradually expand to more difficult images, the strategy includes a difficulty evaluation strategy based on the teacher model and an knee point-based training scheduling strategy. Firstly, multiple teacher models are trained, and the consistency of the quality of steganographic images under multiple teacher models is used as the difficulty score to construct the training subsets from easy to difficult. Secondly, a training control strategy based on knee points is proposed to reduce the possibility of overfitting on small training sets and accelerate the training process. Experimental results on three large public datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed image steganography scheme is able to improve the model performance under multiple algorithmic frameworks, which not only has a high PSNR, SSIM score, and decoding accuracy, but also the steganographic images generated by the model under the training of the STCL strategy have a low steganography analysis scores. You can find our code at \\href{this https URL}{this https URL}.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17609",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:16.317540Z"
  },
  {
    "id": "17e010d0056066f3e74d6dc0d3ca8c1e",
    "title": "Near-Term Pseudorandom and Pseudoresource Quantum States",
    "slug": "near-term-pseudorandom-and-pseudoresource-quantum-states",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Andrew Tanggara",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A pseudorandom quantum state (PRS) is an ensemble of quantum states indistinguishable from Haar-random states to observers with efficient quantum computers. It allows one to substitute the costly Haar-random state with efficiently preparable PRS as a resource for cryptographic protocols, while also finding applications in quantum learning theory, black hole physics, many-body thermalization, quantum foundations, and quantum chaos. All existing constructions of PRS equate the notion of efficiency to quantum computers which runtime is bounded by a polynomial in its input size. In this work, we relax the notion of efficiency for PRS with respect to observers with near-term quantum computers implementing algorithms with runtime that scales slower than polynomial-time. We introduce the $\\mathbf{T}$-PRS which is indistinguishable to quantum algorithms with runtime $\\mathbf{T}(n)$ that grows slower than polynomials in the input size $n$. We give a set of reasonable conditions that a $\\mathbf{T}$-PRS must satisfy and give two constructions by using quantum-secure pseudorandom functions and pseudorandom functions. For $\\mathbf{T}(n)$ being linearithmic, linear, polylogarithmic, and logarithmic function, we characterize the amount of quantum resources a $\\mathbf{T}$-PRS must possess, particularly on its coherence, entanglement, and magic. Our quantum resource characterization applies generally to any two state ensembles that are indistinguishable to observers with computational power $\\mathbf{T}(n)$, giving a general necessary condition of whether a low-resource ensemble can mimic a high-resource ensemble, forming a $\\mathbf{T}$-pseudoresource pair. We demonstate how the necessary amount of resource decreases as the observer's computational power is more restricted, giving a $\\mathbf{T}$-pseudoresource pair with larger resource gap for more computationally limited observers.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17650",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:16.317769Z"
  },
  {
    "id": "a80e143e272ed717d1d35a05efdfb750",
    "title": "A Systematic Study on the Design of Odd-Sized Highly Nonlinear Boolean Functions via Evolutionary Algorithms",
    "slug": "a-systematic-study-on-the-design-of-odd-sized-highly-nonlinear-boolean-functions-via-evolutionary-algorithms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "Claude Carlet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper focuses on the problem of evolving Boolean functions of odd sizes with high nonlinearity, a property of cryptographic relevance. Despite its simple formulation, this problem turns out to be remarkably difficult. We perform a systematic evaluation by considering three solution encodings and four problem instances, analyzing how well different types of evolutionary algorithms behave in finding a maximally nonlinear Boolean function. Our results show that genetic programming generally outperforms other evolutionary algorithms, although it falls short of the best-known results achieved by ad-hoc heuristics. Interestingly, by adding local search and restricting the space to rotation symmetric Boolean functions, we show that a genetic algorithm with the bitstring encoding manages to evolve a $9$-variable Boolean function with nonlinearity 241.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17666",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:16.317978Z"
  },
  {
    "id": "8c7ba59c17df8e9fd736adaa06f1180f",
    "title": "Siren -- Advancing Cybersecurity through Deception and Adaptive Analysis",
    "slug": "siren----advancing-cybersecurity-through-deception-and-adaptive-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Samhruth Ananthanarayanan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Siren represents a pioneering research effort aimed at fortifying cybersecurity through strategic integration of deception, machine learning, and proactive threat analysis. Drawing inspiration from mythical sirens, this project employs sophisticated methods to lure potential threats into controlled environments. The system features a dynamic machine learning model for realtime analysis and classification, ensuring continuous adaptability to emerging cyber threats. The architectural framework includes a link monitoring proxy, a purpose-built machine learning model for dynamic link analysis, and a honeypot enriched with simulated user interactions to intensify threat engagement. Data protection within the honeypot is fortified with probabilistic encryption. Additionally, the incorporation of simulated user activity extends the system's capacity to capture and learn from potential attackers even after user disengagement. Overall, Siren introduces a paradigm shift in cybersecurity, transforming traditional defense mechanisms into proactive systems that actively engage and learn from potential adversaries. The research strives to enhance user protection while yielding valuable insights for ongoing refinement in response to the evolving landscape of cybersecurity threats.",
    "pdfUrl": "https://arxiv.org/pdf/2406.06225",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.318186Z"
  },
  {
    "id": "3d30d5f79356713fa9f8c7ee9c34c177",
    "title": "MapComp: A Secure View-based Collaborative Analytics Framework for Join-Group-Aggregation",
    "slug": "mapcomp:-a-secure-view-based-collaborative-analytics-framework-for-join-group-aggregation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Xinyu Peng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces MapComp, a novel view-based framework to facilitate join-group-aggregation (JGA) queries for secure collaborative analytics. Through specially crafted materialized views for join and novel design of group-aggregation (GA) protocols, MapComp removes duplicated join workload and expedites subsequent GA, improving the efficiency of JGA query execution. To support continuous data updates, our materialized view offers payload-independence feature and brings in significant efficiency improvement of view refreshing with free MPC overhead. This feature also allows further acceleration for GA, where we devise multiple novel protocols that outperform prior works. Our rigorous experiments demonstrate a significant advantage of MapComp, achieving up to a 308.9x efficiency improvement compared to the baseline in the real-world query simulation.",
    "pdfUrl": "https://arxiv.org/pdf/2408.01246",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.318415Z"
  },
  {
    "id": "99f022d6babca06b58c74d4e57fc3175",
    "title": "JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit",
    "slug": "jailbreaklens:-interpreting-jailbreak-mechanism-in-the-lens-of-representation-and-circuit",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Zeqing He",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Despite the outstanding performance of Large language Models (LLMs) in diverse tasks, they are vulnerable to jailbreak attacks, wherein adversarial prompts are crafted to bypass their security mechanisms and elicit unexpected responses. Although jailbreak attacks are prevalent, the understanding of their underlying mechanisms remains limited. Recent studies have explained typical jailbreaking behavior (e.g., the degree to which the model refuses to respond) of LLMs by analyzing representation shifts in their latent space caused by jailbreak prompts or identifying key neurons that contribute to the success of jailbreak attacks. However, these studies neither explore diverse jailbreak patterns nor provide a fine-grained explanation from the failure of circuit to the changes of representational, leaving significant gaps in uncovering the jailbreak mechanism. In this paper, we propose JailbreakLens, an interpretation framework that analyzes jailbreak mechanisms from both representation (which reveals how jailbreaks alter the model's harmfulness perception) and circuit perspectives~(which uncovers the causes of these deceptions by identifying key circuits contributing to the vulnerability), tracking their evolution throughout the entire response generation process. We then conduct an in-depth evaluation of jailbreak behavior on five mainstream LLMs under seven jailbreak strategies. Our evaluation reveals that jailbreak prompts amplify components that reinforce affirmative responses while suppressing those that produce refusal. This manipulation shifts model representations toward safe clusters to deceive the LLM, leading it to provide detailed responses instead of refusals. Notably, we find a strong and consistent correlation between representation deception and activation shift of key circuits across diverse jailbreak methods and multiple LLMs.",
    "pdfUrl": "https://arxiv.org/pdf/2411.11114",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.318642Z"
  },
  {
    "id": "d5f9d9de22cff93102e0b5be6875bdcf",
    "title": "Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs",
    "slug": "generating-privacy-preserving-personalized-advice-with-zero-knowledge-proofs-and-llms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Hiroki Watanabe",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) are increasingly utilized in domains such as finance, healthcare, and interpersonal relationships to provide advice tailored to user traits and contexts. However, this personalization often relies on sensitive data, raising critical privacy concerns and necessitating data minimization. To address these challenges, we propose a framework that integrates zero-knowledge proof (ZKP) technology, specifically zkVM, with LLM-based chatbots. This integration enables privacy-preserving data sharing by verifying user traits without disclosing sensitive information. Our research introduces both an architecture and a prompting strategy for this approach. Through empirical evaluation, we clarify the current constraints and performance limitations of both zkVM and the proposed prompting strategy, thereby demonstrating their practical feasibility in real-world scenarios.",
    "pdfUrl": "https://arxiv.org/pdf/2502.06425",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.318839Z"
  },
  {
    "id": "13d8b19b972900ee55849f3d3ef29a50",
    "title": "CRAFT: Characterizing and Root-Causing Fault Injection Threats at Pre-Silicon",
    "slug": "craft:-characterizing-and-root-causing-fault-injection-threats-at-pre-silicon",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Arsalan Ali Malik",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Fault injection attacks represent a class of threats that can compromise embedded systems across multiple layers of abstraction, such as system software, instruction set architecture (ISA), microarchitecture, and physical implementation. Early detection of these vulnerabilities and understanding their root causes, along with their propagation from the physical layer to the system software, is critical to secure the cyberinfrastructure. This work presents a comprehensive methodology for conducting controlled fault injection attacks at the pre-silicon level and an analysis of the underlying system for root-causing behavior. As the driving application, we use the clock glitch attacks in AI/ML applications for critical misclassification. Our study aims to characterize and diagnose the impact of faults within the RISC-V instruction set and pipeline stages, while tracing fault propagation from the circuit level to the AI/ML application software. This analysis resulted in discovering two new vulnerabilities through controlled clock glitch parameters. First, we reveal a novel method for causing instruction skips, thereby preventing the loading of critical values from memory. This can cause disruption and affect program continuity and correctness. Second, we demonstrate an attack that converts legal instructions into illegal ones, thereby diverting control flow in a manner exploitable by attackers. Our work underscores the complexity of fault injection attack exploits and emphasizes the importance of preemptive security analysis.",
    "pdfUrl": "https://arxiv.org/pdf/2503.03877",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.319041Z"
  },
  {
    "id": "b47e0b84a950d05c3ebcac21656883c9",
    "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent",
    "slug": "cheatagent:-attacking-llm-empowered-recommender-systems-via-llm-agent",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Liang-bo Ning",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13192",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.319260Z"
  },
  {
    "id": "6c53a0b28ed1d2410044ea14cef8a21a",
    "title": "Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks",
    "slug": "building-trustworthy-multimodal-ai:-a-review-of-fairness,-transparency,-and-ethics-in-vision-language-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Mohammad Saleh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Objective: This review explores the trustworthiness of multimodal artificial intelligence (AI) systems, specifically focusing on vision-language tasks. It addresses critical challenges related to fairness, transparency, and ethical implications in these systems, providing a comparative analysis of key tasks such as Visual Question Answering (VQA), image captioning, and visual dialogue. Background: Multimodal models, particularly vision-language models, enhance artificial intelligence (AI) capabilities by integrating visual and textual data, mimicking human learning processes. Despite significant advancements, the trustworthiness of these models remains a crucial concern, particularly as AI systems increasingly confront issues regarding fairness, transparency, and ethics. Methods: This review examines research conducted from 2017 to 2024 focusing on forenamed core vision-language tasks. It employs a comparative approach to analyze these tasks through the lens of trustworthiness, underlining fairness, explainability, and ethics. This study synthesizes findings from recent literature to identify trends, challenges, and state-of-the-art solutions. Results: Several key findings were highlighted. Transparency: Explainability of vision language tasks is important for user trust. Techniques, such as attention maps and gradient-based methods, have successfully addressed this issue. Fairness: Bias mitigation in VQA and visual dialogue systems is essential for ensuring unbiased outcomes across diverse demographic groups. Ethical Implications: Addressing biases in multilingual models and ensuring ethical data handling is critical for the responsible deployment of vision-language systems. Conclusion: This study underscores the importance of integrating fairness, transparency, and ethical considerations in developing vision-language models within a unified framework.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13199",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.319462Z"
  },
  {
    "id": "b0e8ad2b2beb8f876303d2eb19e00669",
    "title": "vApps: Verifiable Applications at Internet Scale",
    "slug": "vapps:-verifiable-applications-at-internet-scale",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Isaac Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Blockchain technology promises a decentralized, trustless, and interoperable infrastructure. However, widespread adoption remains hindered by issues such as limited scalability, high transaction costs, and the complexity of maintaining coherent verification logic across different blockchain layers. This paper introduces Verifiable Applications (vApps), a novel development framework designed to streamline the creation and deployment of verifiable blockchain computing applications. vApps offer a unified Rust-based Domain-Specific Language (DSL) within a comprehensive SDK, featuring modular abstractions for verification, proof generation, and inter-chain connectivity. This eases the developer's burden in securing diverse software components, allowing them to focus on application logic. The DSL also ensures that applications can automatically take advantage of specialized precompiles and hardware acceleration to achieve consistently high performance with minimal developer effort, as demonstrated by benchmark results for zero-knowledge virtual machines (zkVMs). Experiments show that native Rust execution eliminates interpretation overhead, delivering up to an 832x cycle count improvement compared to EVM-based approaches. Precompiled circuits can accelerate the proof by more than 95%, while GPU acceleration increases throughput by up to 30x and recursion compresses the proof size by up to 230x, enabling succinct and efficient verification. The framework also supports seamless integration with the Web2 and Web3 systems, enabling developers to focus solely on their application logic. Through modular architecture, robust security guarantees, and composability, vApps pave the way toward a trust-minimized and verifiable Internet-scale application environment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14809",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.319693Z"
  },
  {
    "id": "85b59614c136282e53c7d114488fb22c",
    "title": "Automated Static Vulnerability Detection via a Holistic Neuro-symbolic Approach",
    "slug": "automated-static-vulnerability-detection-via-a-holistic-neuro-symbolic-approach",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Penghui Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Static vulnerability detection is still a challenging problem and demands excessive human efforts, e.g., manual curation of good vulnerability patterns. None of prior works, including classic program analysis or Large Language Model (LLM)-based approaches, have fully automated such vulnerability pattern generations with reasonable detection accuracy. In this paper, we design and implement, MoCQ, a novel holistic neuro-symbolic framework that combines the complementary strengths of LLMs and classical static analysis to enable scalable vulnerability detection. The key insight is that MoCQ leverages an LLM to automatically extract vulnerability patterns and translate them into detection queries, and then on static analysis to refine such queries in a feedback loop and eventually execute them for analyzing large codebases and mining vulnerabilities. We evaluate MoCQ on seven types of vulnerabilities spanning two programming languages. We found MoCQ-generated queries uncovered at least 12 patterns that were missed by experts. On a ground truth dataset, MoCQ achieved comparable precision and recall compared to expert-crafted queries. Moreover, MoCQ has identified seven previously unknown vulnerabilities in real-world applications, demonstrating its practical effectiveness. We have responsibly disclosed them to the corresponding developers.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16057",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.319908Z"
  },
  {
    "id": "86976e2a9f60b43daa8156ecea445ba0",
    "title": "AI-Based Vulnerability Analysis of NFT Smart Contracts",
    "slug": "ai-based-vulnerability-analysis-of-nft-smart-contracts",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Xin Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "With the rapid growth of the NFT market, the security of smart contracts has become crucial. However, existing AI-based detection models for NFT contract vulnerabilities remain limited due to their complexity, while traditional manual methods are time-consuming and costly. This study proposes an AI-driven approach to detect vulnerabilities in NFT smart contracts.\nWe collected 16,527 public smart contract codes, classifying them into five vulnerability categories: Risky Mutable Proxy, ERC-721 Reentrancy, Unlimited Minting, Missing Requirements, and Public Burn. Python-processed data was structured into training/test sets. Using the CART algorithm with Gini coefficient evaluation, we built initial decision trees for feature extraction. A random forest model was implemented to improve robustness through random data/feature sampling and multitree integration. GridSearch hyperparameter tuning further optimized the model, with 3D visualizations demonstrating parameter impacts on vulnerability detection.\nResults show the random forest model excels in detecting all five vulnerabilities. For example, it identifies Risky Mutable Proxy by analyzing authorization mechanisms and state modifications, while ERC-721 Reentrancy detection relies on external call locations and lock mechanisms. The ensemble approach effectively reduces single-tree overfitting, with stable performance improvements after parameter tuning. This method provides an efficient technical solution for automated NFT contract detection and lays groundwork for scaling AI applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16113",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:16.320113Z"
  },
  {
    "id": "295aa11f54de52f51978448e2e9183e0",
    "title": "Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable Random Walks",
    "slug": "honeybee:-byzantine-tolerant-decentralized-peer-sampling-with-verifiable-random-walks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Yunqi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and table consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\\geq50\\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes.",
    "pdfUrl": "https://arxiv.org/pdf/2402.16201",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:16.320318Z"
  },
  {
    "id": "ec318b0dd1ca00933195b48e13cc2591",
    "title": "Aegis: Tethering a Blockchain with Primary-Chain Stake",
    "slug": "aegis:-tethering-a-blockchain-with-primary-chain-stake",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Yogev Bar-On",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Blockchains implement decentralized monetary systems and applications. Recent advancements enable what we call tethering a blockchain to a primary blockchain, securing the tethered chain by nodes that post primary-chain tokens as collateral. The collateral ensures nodes behave as intended, until they withdraw it. Unlike a Proof of Stake blockchain which uses its own token as collateral, using primary-chain tokens shields the tethered chain from the volatility of its own token.\nState-of-the-art tethered blockchains either rely on centralization, or make extreme assumptions: that all communication is synchronous, that operators remain correct even post-withdrawal, or that withdrawals can be indefinitely delayed by tethered-chain failures.\nWe prove that with partial synchrony, there is no solution to the problem. However, under the standard assumptions that communication with the primary chain is synchronous and communication among the tethered chain nodes is partially synchronous, there is a solution. We present a tethered-chain protocol called Aegis. Aegis uses references from its blocks to primary blocks to define committees, checkpoints on the primary chain to perpetuate decisions, and resets to establish new committees when previous ones become obsolete. It ensures safety at all times and rapid progress when latency among Aegis nodes is low.",
    "pdfUrl": "https://arxiv.org/pdf/2406.05904",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:16.320527Z"
  },
  {
    "id": "a4d651fe7d0b21a6c0c84a1ac9ef75b7",
    "title": "GraphRAG under Fire",
    "slug": "graphrag-under-fire",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jiacheng Liang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "GraphRAG advances retrieval-augmented generation (RAG) by structuring external knowledge as multi-scale knowledge graphs, enabling language models to integrate both broad context and granular details in their generation. While GraphRAG has demonstrated success across domains, its security implications remain largely unexplored. To bridge this gap, this work examines GraphRAG's vulnerability to poisoning attacks, uncovering an intriguing security paradox: compared to conventional RAG, GraphRAG's graph-based indexing and retrieval enhance resilience against simple poisoning attacks; yet, the same features also create new attack surfaces. We present GRAGPoison, a novel attack that exploits shared relations in the underlying knowledge graph to craft poisoning text capable of compromising multiple queries simultaneously. GRAGPoison employs three key strategies: i) relation injection to introduce false knowledge, ii) relation enhancement to amplify poisoning influence, and iii) narrative generation to embed malicious content within coherent text. Empirical evaluation across diverse datasets and models shows that GRAGPoison substantially outperforms existing attacks in terms of effectiveness (up to 98\\% success rate) and scalability (using less than 68\\% poisoning text) on various GraphRAG-based systems. We also explore potential defensive measures and their limitations, identifying promising directions for future research.",
    "pdfUrl": "https://arxiv.org/pdf/2501.14050",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:16.320744Z"
  },
  {
    "id": "5416677dc4be72a2ac37bb3c7c29811c",
    "title": "Review of Demographic Fairness in Face Recognition",
    "slug": "review-of-demographic-fairness-in-face-recognition",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ketan Kotwal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Demographic fairness in face recognition (FR) has emerged as a critical area of research, given its impact on fairness, equity, and reliability across diverse applications. As FR technologies are increasingly deployed globally, disparities in performance across demographic groups-- such as race, ethnicity, and gender-- have garnered significant attention. These biases not only compromise the credibility of FR systems but also raise ethical concerns, especially when these technologies are employed in sensitive domains. This review consolidates extensive research efforts providing a comprehensive overview of the multifaceted aspects of demographic fairness in FR.\nWe systematically examine the primary causes, datasets, assessment metrics, and mitigation approaches associated with demographic disparities in FR. By categorizing key contributions in these areas, this work provides a structured approach to understanding and addressing the complexity of this issue. Finally, we highlight current advancements and identify emerging challenges that need further investigation. This article aims to provide researchers with a unified perspective on the state-of-the-art while emphasizing the critical need for equitable and trustworthy FR systems.",
    "pdfUrl": "https://arxiv.org/pdf/2502.02309",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:16.321232Z"
  },
  {
    "id": "b30e7cf48784864708a3694f7c77567c",
    "title": "\"I'm not for sale\" -- Perceptions and limited awareness of privacy risks by digital natives about location data",
    "slug": "\"i'm-not-for-sale\"----perceptions-and-limited-awareness-of-privacy-risks-by-digital-natives-about-location-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Antoine Boutet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Although mobile devices benefit users in their daily lives in numerous ways, they also raise several privacy concerns. For instance, they can reveal sensitive information that can be inferred from location data. This location data is shared through service providers as well as mobile applications. Understanding how and with whom users share their location data -- as well as users' perception of the underlying privacy risks --, are important notions to grasp in order to design usable privacy-enhancing technologies. In this work, we perform a quantitative and qualitative analysis of smartphone users' awareness, perception and self-reported behavior towards location data-sharing through a survey of n=99 young adult participants (i.e., digital natives). We compare stated practices with actual behaviors to better understand their mental models, and survey participants' understanding of privacy risks before and after the inspection of location traces and the information that can be inferred therefrom.\nOur empirical results show that participants have risky privacy practices: about 54% of participants underestimate the number of mobile applications to which they have granted access to their data, and 33% forget or do not think of revoking access to their data. Also, by using a demonstrator to perform inferences from location data, we observe that slightly more than half of participants (57%) are surprised by the extent of potentially inferred information, and that 47% intend to reduce access to their data via permissions as a result of using the demonstrator. Last, a majority of participants have little knowledge of the tools to better protect themselves, but are nonetheless willing to follow suggestions to improve privacy (51%). Educating people, including digital natives, about privacy risks through transparency tools seems a promising approach.",
    "pdfUrl": "https://arxiv.org/pdf/2502.11658",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:16.321677Z"
  },
  {
    "id": "20d53c106006fe8a682234d1a886f22f",
    "title": "EditLord: Learning Code Transformation Rules for Code Editing",
    "slug": "editlord:-learning-code-transformation-rules-for-code-editing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Weichen Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Code editing is a foundational task in software development, where its effectiveness depends on whether it introduces desired code property changes without changing the original code's intended functionality. Existing approaches often formulate code editing as an implicit end-to-end task, omitting the fact that code-editing procedures inherently consist of discrete and explicit steps. Thus, they suffer from suboptimal performance and lack of robustness and generalization. We introduce EditLord, a code editing framework that makes the code transformation steps explicit. Our key insight is to employ a language model (LM) as an inductive learner to extract code editing rules from the training code pairs as concise meta-rule sets. Such rule sets will be manifested for each training sample to augment them for finetuning or assist in prompting- and iterative-based code editing. EditLordoutperforms the state-of-the-art by an average of 22.7% in editing performance and 58.1% in robustness while achieving 20.2% higher functional correctness across critical software engineering and security applications, LM models, and editing modes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15284",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:16.322142Z"
  },
  {
    "id": "dae4b069b57b31eec40e03f04d87a5f0",
    "title": "A Study on Mixup-Inspired Augmentation Methods for Software Vulnerability Detection",
    "slug": "a-study-on-mixup-inspired-augmentation-methods-for-software-vulnerability-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Seyed Shayan Daneshvar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Various deep learning (DL) methods have recently been utilized to detect software vulnerabilities. Real-world software vulnerability datasets are rare and hard to acquire, as there is no simple metric for classifying vulnerability. Such datasets are heavily imbalanced, and none of the current datasets are considered huge for DL models. To tackle these problems, a recent work has tried to augment the dataset using the source code and generate realistic single-statement vulnerabilities, which is not quite practical and requires manual checking of the generated vulnerabilities. In this paper, we aim to explore the augmentation of vulnerabilities at the representation level to help current models learn better, which has never been done before to the best of our knowledge. We implement and evaluate five augmentation techniques that augment the embedding of the data and have recently been used for code search, which is a completely different software engineering task. We also introduced a conditioned version of those augmentation methods, which ensures the augmentation does not change the vulnerable section of the vector representation. We show that such augmentation methods can be helpful and increase the F1-score by up to 9.67%, yet they cannot beat Random Oversampling when balancing datasets, which increases the F1-score by 10.82%.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15632",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:16.322665Z"
  },
  {
    "id": "93558fb81e5b2faacc0a42c80dde6067",
    "title": "Dense Air Pollution Estimation from Sparse in-situ Measurements and Satellite Data",
    "slug": "dense-air-pollution-estimation-from-sparse-in-situ-measurements-and-satellite-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ruben Gonzalez Avils",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper addresses the critical environmental challenge of estimating ambient Nitrogen Dioxide (NO$_2$) concentrations, a key issue in public health and environmental policy. Existing methods for satellite-based air pollution estimation model the relationship between satellite and in-situ measurements at select point locations. While these approaches have advanced our ability to provide air quality estimations on a global scale, they come with inherent limitations. The most notable limitation is the computational intensity required for generating comprehensive estimates over extensive areas. Motivated by these limitations, this study introduces a novel dense estimation technique. Our approach seeks to balance the accuracy of high-resolution estimates with the practicality of computational constraints, thereby enabling efficient and scalable global environmental assessment. By utilizing a uniformly random offset sampling strategy, our method disperses the ground truth data pixel location evenly across a larger patch. At inference, the dense estimation method can then generate a grid of estimates in a single step, significantly reducing the computational resources required to provide estimates for larger areas. Notably, our approach also surpasses the results of existing point-wise methods by a significant margin of $9.45\\%$, achieving a Mean Absolute Error (MAE) of $4.98\\ \\mu\\text{g}/\\text{m}^3$. This demonstrates both high accuracy and computational efficiency, highlighting the applicability of our method for global environmental assessment. Furthermore, we showcase the method's adaptability and robustness by applying it to diverse geographic regions. Our method offers a viable solution to the computational challenges of large-scale environmental monitoring.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17039",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.019833Z"
  },
  {
    "id": "450a5db653676d16c351d735ea367f39",
    "title": "DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs",
    "slug": "dymu:-dynamic-merging-and-virtual-unmerging-for-efficient-vlms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhenhailong Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present DyMU, an efficient, training-free framework that dynamically reduces the computational burden of vision-language models (VLMs) while maintaining high task performance. Our approach comprises two key components. First, Dynamic Token Merging (DToMe) reduces the number of visual token embeddings by merging similar tokens based on image complexity, addressing the inherent inefficiency of fixed-length outputs in vision transformers. Second, Virtual Token Unmerging (VTU) simulates the expected token sequence for large language models (LLMs) by efficiently reconstructing the attention dynamics of a full sequence, thus preserving the downstream performance without additional fine-tuning. Unlike previous approaches, our method dynamically adapts token compression to the content of the image and operates completely training-free, making it readily applicable to most state-of-the-art VLM architectures. Extensive experiments on image and video understanding tasks demonstrate that DyMU can reduce the average visual token count by 32%-85% while achieving comparable performance to full-length models across diverse VLM architectures, including the recently popularized AnyRes-based visual encoders. Furthermore, through qualitative analyses, we demonstrate that DToMe effectively adapts token reduction based on image complexity and, unlike existing systems, provides users more control over computational costs. Project page: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17040",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.020090Z"
  },
  {
    "id": "1e3a0493b6c1e214cddc7fa34caa8c9a",
    "title": "PPS-Ctrl: Controllable Sim-to-Real Translation for Colonoscopy Depth Estimation",
    "slug": "pps-ctrl:-controllable-sim-to-real-translation-for-colonoscopy-depth-estimation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Xinqi Xiong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate depth estimation enhances endoscopy navigation and diagnostics, but obtaining ground-truth depth in clinical settings is challenging. Synthetic datasets are often used for training, yet the domain gap limits generalization to real data. We propose a novel image-to-image translation framework that preserves structure while generating realistic textures from clinical data. Our key innovation integrates Stable Diffusion with ControlNet, conditioned on a latent representation extracted from a Per-Pixel Shading (PPS) map. PPS captures surface lighting effects, providing a stronger structural constraint than depth maps. Experiments show our approach produces more realistic translations and improves depth estimation over GAN-based MI-CycleGAN. Our code is publicly accessible at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17067",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.020302Z"
  },
  {
    "id": "29645924818788e6183fe5863c2fd53e",
    "title": "Distilling semantically aware orders for autoregressive image generation",
    "slug": "distilling-semantically-aware-orders-for-autoregressive-image-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Rishav Pramanik",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autoregressive patch-based image generation has recently shown competitive results in terms of image quality and scalability. It can also be easily integrated and scaled within Vision-Language models. Nevertheless, autoregressive models require a defined order for patch generation. While a natural order based on the dictation of the words makes sense for text generation, there is no inherent generation order that exists for image generation. Traditionally, a raster-scan order (from top-left to bottom-right) guides autoregressive image generation models. In this paper, we argue that this order is suboptimal, as it fails to respect the causality of the image content: for instance, when conditioned on a visual description of a sunset, an autoregressive model may generate clouds before the sun, even though the color of clouds should depend on the color of the sun and not the inverse. In this work, we show that first by training a model to generate patches in any-given-order, we can infer both the content and the location (order) of each patch during generation. Secondly, we use these extracted orders to finetune the any-given-order model to produce better-quality images. Through our experiments, we show on two datasets that this new generation method produces better images than the traditional raster-scan approach, with similar training costs and no extra annotations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17069",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.020543Z"
  },
  {
    "id": "c07eba1e5f935ea32a543c111a3f3159",
    "title": "Scene-Aware Location Modeling for Data Augmentation in Automotive Object Detection",
    "slug": "scene-aware-location-modeling-for-data-augmentation-in-automotive-object-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Jens Petersen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Generative image models are increasingly being used for training data augmentation in vision tasks. In the context of automotive object detection, methods usually focus on producing augmented frames that look as realistic as possible, for example by replacing real objects with generated ones. Others try to maximize the diversity of augmented frames, for example by pasting lots of generated objects onto existing backgrounds. Both perspectives pay little attention to the locations of objects in the scene. Frame layouts are either reused with little or no modification, or they are random and disregard realism entirely. In this work, we argue that optimal data augmentation should also include realistic augmentation of layouts. We introduce a scene-aware probabilistic location model that predicts where new objects can realistically be placed in an existing scene. By then inpainting objects in these locations with a generative model, we obtain much stronger augmentation performance than existing approaches. We set a new state of the art for generative data augmentation on two automotive object detection tasks, achieving up to $2.8\\times$ higher gains than the best competing approach ($+1.4$ vs. $+0.5$ mAP boost). We also demonstrate significant improvements for instance segmentation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17076",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.020787Z"
  },
  {
    "id": "780eb65df52baa6efe4089f70a02b997",
    "title": "Transferring Spatial Filters via Tangent Space Alignment in Motor Imagery BCIs",
    "slug": "transferring-spatial-filters-via-tangent-space-alignment-in-motor-imagery-bcis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Tekin Gunasar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a method to improve subject transfer in motor imagery BCIs by aligning covariance matrices on a Riemannian manifold, followed by computing a new common spatial patterns (CSP) based spatial filter. We explore various ways to integrate information from multiple subjects and show improved performance compared to standard CSP. Across three datasets, our method shows marginal improvements over standard CSP; however, when training data are limited, the improvements become more significant.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17111",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.020979Z"
  },
  {
    "id": "67cc77bf0debdae34e6da952404039d0",
    "title": "Latent Video Dataset Distillation",
    "slug": "latent-video-dataset-distillation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ning Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dataset distillation has demonstrated remarkable effectiveness in high-compression scenarios for image datasets. While video datasets inherently contain greater redundancy, existing video dataset distillation methods primarily focus on compression in the pixel space, overlooking advances in the latent space that have been widely adopted in modern text-to-image and text-to-video models. In this work, we bridge this gap by introducing a novel video dataset distillation approach that operates in the latent space using a state-of-the-art variational encoder. Furthermore, we employ a diversity-aware data selection strategy to select both representative and diverse samples. Additionally, we introduce a simple, training-free method to further compress the distilled latent dataset. By combining these techniques, our approach achieves a new state-of-the-art performance in dataset distillation, outperforming prior methods on all datasets, e.g. on HMDB51 IPC 1, we achieve a 2.6% performance increase; on MiniUCF IPC 5, we achieve a 7.8% performance increase.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17132",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.021192Z"
  },
  {
    "id": "cef86af2d7ff09bd69452f367efe9427",
    "title": "A Comprehensive Review on RNA Subcellular Localization Prediction",
    "slug": "a-comprehensive-review-on-rna-subcellular-localization-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Cece Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The subcellular localization of RNAs, including long non-coding RNAs (lncRNAs), messenger RNAs (mRNAs), microRNAs (miRNAs) and other smaller RNAs, plays a critical role in determining their biological functions. For instance, lncRNAs are predominantly associated with chromatin and act as regulators of gene transcription and chromatin structure, while mRNAs are distributed across the nucleus and cytoplasm, facilitating the transport of genetic information for protein synthesis. Understanding RNA localization sheds light on processes like gene expression regulation with spatial and temporal precision. However, traditional wet lab methods for determining RNA localization, such as in situ hybridization, are often time-consuming, resource-demanding, and costly. To overcome these challenges, computational methods leveraging artificial intelligence (AI) and machine learning (ML) have emerged as powerful alternatives, enabling large-scale prediction of RNA subcellular localization. This paper provides a comprehensive review of the latest advancements in AI-based approaches for RNA subcellular localization prediction, covering various RNA types and focusing on sequence-based, image-based, and hybrid methodologies that combine both data types. We highlight the potential of these methods to accelerate RNA research, uncover molecular pathways, and guide targeted disease treatments. Furthermore, we critically discuss the challenges in AI/ML approaches for RNA subcellular localization, such as data scarcity and lack of benchmarks, and opportunities to address them. This review aims to serve as a valuable resource for researchers seeking to develop innovative solutions in the field of RNA subcellular localization and beyond.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17162",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.021413Z"
  },
  {
    "id": "ee15f04f59782848c66525130b5d127c",
    "title": "PhysioSync: Temporal and Cross-Modal Contrastive Learning Inspired by Physiological Synchronization for EEG-Based Emotion Recognition",
    "slug": "physiosync:-temporal-and-cross-modal-contrastive-learning-inspired-by-physiological-synchronization-for-eeg-based-emotion-recognition",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Kai Cui",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Electroencephalography (EEG) signals provide a promising and involuntary reflection of brain activity related to emotional states, offering significant advantages over behavioral cues like facial expressions. However, EEG signals are often noisy, affected by artifacts, and vary across individuals, complicating emotion recognition. While multimodal approaches have used Peripheral Physiological Signals (PPS) like GSR to complement EEG, they often overlook the dynamic synchronization and consistent semantics between the modalities. Additionally, the temporal dynamics of emotional fluctuations across different time resolutions in PPS remain underexplored. To address these challenges, we propose PhysioSync, a novel pre-training framework leveraging temporal and cross-modal contrastive learning, inspired by physiological synchronization phenomena. PhysioSync incorporates Cross-Modal Consistency Alignment (CM-CA) to model dynamic relationships between EEG and complementary PPS, enabling emotion-related synchronizations across modalities. Besides, it introduces Long- and Short-Term Temporal Contrastive Learning (LS-TCL) to capture emotional synchronization at different temporal resolutions within modalities. After pre-training, cross-resolution and cross-modal features are hierarchically fused and fine-tuned to enhance emotion recognition. Experiments on DEAP and DREAMER datasets demonstrate PhysioSync's advanced performance under uni-modal and cross-modal conditions, highlighting its effectiveness for EEG-centered emotion recognition.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17163",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.021641Z"
  },
  {
    "id": "aeaca6ea02995bef665200c219058100",
    "title": "A Genealogy of Multi-Sensor Foundation Models in Remote Sensing",
    "slug": "a-genealogy-of-multi-sensor-foundation-models-in-remote-sensing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Kevin Lane",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Foundation models have garnered increasing attention for representation learning in remote sensing, primarily adopting approaches that have demonstrated success in computer vision with minimal domain-specific modification. However, the development and application of foundation models in this field are still burgeoning, as there are a variety of competing approaches that each come with significant benefits and drawbacks. This paper examines these approaches along with their roots in the computer vision field in order to characterize potential advantages and pitfalls while outlining future directions to further improve remote sensing-specific foundation models. We discuss the quality of the learned representations and methods to alleviate the need for massive compute resources. We place emphasis on the multi-sensor aspect of Earth observations, and the extent to which existing approaches leverage multiple sensors in training foundation models in relation to multi-modal foundation models. Finally, we identify opportunities for further harnessing the vast amounts of unlabeled, seasonal, and multi-sensor remote sensing observations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17177",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.021846Z"
  },
  {
    "id": "5827951398332e70355bf13065a366e8",
    "title": "We'll Fix it in Post: Improving Text-to-Video Generation with Neuro-Symbolic Feedback",
    "slug": "we'll-fix-it-in-post:-improving-text-to-video-generation-with-neuro-symbolic-feedback",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Minkyu Choi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Current text-to-video (T2V) generation models are increasingly popular due to their ability to produce coherent videos from textual prompts. However, these models often struggle to generate semantically and temporally consistent videos when dealing with longer, more complex prompts involving multiple objects or sequential events. Additionally, the high computational costs associated with training or fine-tuning make direct improvements impractical. To overcome these limitations, we introduce \\(\\projectname\\), a novel zero-training video refinement pipeline that leverages neuro-symbolic feedback to automatically enhance video generation, achieving superior alignment with the prompts. Our approach first derives the neuro-symbolic feedback by analyzing a formal video representation and pinpoints semantically inconsistent events, objects, and their corresponding frames. This feedback then guides targeted edits to the original video. Extensive empirical evaluations on both open-source and proprietary T2V models demonstrate that \\(\\projectname\\) significantly enhances temporal and logical alignment across diverse prompts by almost $40\\%$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17180",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.022059Z"
  },
  {
    "id": "f0a04435b5a3d9d0ecda6df2132b9255",
    "title": "Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation",
    "slug": "perspective-aware-reasoning-in-vision-language-models-via-mental-imagery-simulation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Phillip Y. Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present a framework for perspective-aware reasoning in vision-language models (VLMs) through mental imagery simulation. Perspective-taking, the ability to perceive an environment or situation from an alternative viewpoint, is a key benchmark for human-level visual understanding, essential for environmental interaction and collaboration with autonomous agents. Despite advancements in spatial reasoning within VLMs, recent research has shown that modern VLMs significantly lack perspective-aware reasoning capabilities and exhibit a strong bias toward egocentric interpretations. To bridge the gap between VLMs and human perception, we focus on the role of mental imagery, where humans perceive the world through abstracted representations that facilitate perspective shifts. Motivated by this, we propose a framework for perspective-aware reasoning, named Abstract Perspective Change (APC), that effectively leverages vision foundation models, such as object detection, segmentation, and orientation estimation, to construct scene abstractions and enable perspective transformations. Our experiments on synthetic and real-image benchmarks, compared with various VLMs, demonstrate significant improvements in perspective-aware reasoning with our framework, further outperforming fine-tuned spatial reasoning models and novel-view-synthesis-based approaches.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17207",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.022293Z"
  },
  {
    "id": "b7df9c50c78c46845136ae66ea05a656",
    "title": "MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing",
    "slug": "mcaf:-efficient-agent-based-video-understanding-framework-through-multimodal-coarse-to-fine-attention-focusing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Shiwen Cao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Even in the era of rapid advances in large models, video understanding, particularly long videos, remains highly challenging. Compared with textual or image-based information, videos commonly contain more information with redundancy, requiring large models to strategically allocate attention at a global level for accurate comprehension. To address this, we propose MCAF, an agent-based, training-free framework perform video understanding through Multimodal Coarse-to-fine Attention Focusing. The key innovation lies in its ability to sense and prioritize segments of the video that are highly relevant to the understanding task. First, MCAF hierarchically concentrates on highly relevant frames through multimodal information, enhancing the correlation between the acquired contextual information and the query. Second, it employs a dilated temporal expansion mechanism to mitigate the risk of missing crucial details when extracting information from these concentrated frames. In addition, our framework incorporates a self-reflection mechanism utilizing the confidence level of the model's responses as feedback. By iteratively applying these two creative focusing strategies, it adaptively adjusts attention to capture highly query-connected context and thus improves response accuracy. MCAF outperforms comparable state-of-the-art methods on average. On the EgoSchema dataset, it achieves a remarkable 5% performance gain over the leading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms the current state-of-the-art standard by 0.2% and 0.3% respectively. On the Video-MME dataset, which features videos averaging nearly an hour in length, MCAF also outperforms other agent-based methods.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17213",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.022503Z"
  },
  {
    "id": "6d6b0fb33959a2c07532155a60718843",
    "title": "Towards Generalizable Deepfake Detection with Spatial-Frequency Collaborative Learning and Hierarchical Cross-Modal Fusion",
    "slug": "towards-generalizable-deepfake-detection-with-spatial-frequency-collaborative-learning-and-hierarchical-cross-modal-fusion",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Mengyu Qiao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid evolution of deep generative models poses a critical challenge to deepfake detection, as detectors trained on forgery-specific artifacts often suffer significant performance degradation when encountering unseen forgeries. While existing methods predominantly rely on spatial domain analysis, frequency domain operations are primarily limited to feature-level augmentation, leaving frequency-native artifacts and spatial-frequency interactions insufficiently exploited. To address this limitation, we propose a novel detection framework that integrates multi-scale spatial-frequency analysis for universal deepfake detection. Our framework comprises three key components: (1) a local spectral feature extraction pipeline that combines block-wise discrete cosine transform with cascaded multi-scale convolutions to capture subtle spectral artifacts; (2) a global spectral feature extraction pipeline utilizing scale-invariant differential accumulation to identify holistic forgery distribution patterns; and (3) a multi-stage cross-modal fusion mechanism that incorporates shallow-layer attention enhancement and deep-layer dynamic modulation to model spatial-frequency interactions. Extensive evaluations on widely adopted benchmarks demonstrate that our method outperforms state-of-the-art deepfake detection methods in both accuracy and generalizability.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17223",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.022717Z"
  },
  {
    "id": "8bcd2d9bab1ed4da184ff3612c209df4",
    "title": "Visual and textual prompts for enhancing emotion recognition in video",
    "slug": "visual-and-textual-prompts-for-enhancing-emotion-recognition-in-video",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhifeng Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Vision Large Language Models (VLLMs) exhibit promising potential for multi-modal understanding, yet their application to video-based emotion recognition remains limited by insufficient spatial and contextual awareness. Traditional approaches, which prioritize isolated facial features, often neglect critical non-verbal cues such as body language, environmental context, and social interactions, leading to reduced robustness in real-world scenarios. To address this gap, we propose Set-of-Vision-Text Prompting (SoVTP), a novel framework that enhances zero-shot emotion recognition by integrating spatial annotations (e.g., bounding boxes, facial landmarks), physiological signals (facial action units), and contextual cues (body posture, scene dynamics, others' emotions) into a unified prompting strategy. SoVTP preserves holistic scene information while enabling fine-grained analysis of facial muscle movements and interpersonal dynamics. Extensive experiments show that SoVTP achieves substantial improvements over existing visual prompting methods, demonstrating its effectiveness in enhancing VLLMs' video emotion recognition capabilities.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17224",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.022950Z"
  },
  {
    "id": "f53792e0a18dc6d29971518a40f71e78",
    "title": "Range Image-Based Implicit Neural Compression for LiDAR Point Clouds",
    "slug": "range-image-based-implicit-neural-compression-for-lidar-point-clouds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Akihiro Kuwabara",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper presents a novel scheme to efficiently compress Light Detection and Ranging~(LiDAR) point clouds, enabling high-precision 3D scene archives, and such archives pave the way for a detailed understanding of the corresponding 3D scenes. We focus on 2D range images~(RIs) as a lightweight format for representing 3D LiDAR observations. Although conventional image compression techniques can be adapted to improve compression efficiency for RIs, their practical performance is expected to be limited due to differences in bit precision and the distinct pixel value distribution characteristics between natural images and RIs. We propose a novel implicit neural representation~(INR)--based RI compression method that effectively handles floating-point valued pixels. The proposed method divides RIs into depth and mask images and compresses them using patch-wise and pixel-wise INR architectures with model pruning and quantization, respectively. Experiments on the KITTI dataset show that the proposed method outperforms existing image, point cloud, RI, and INR-based compression methods in terms of 3D reconstruction and detection quality at low bitrates and decoding latency.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17229",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.023156Z"
  },
  {
    "id": "6b3d80561c721c89c82759281913da42",
    "title": "Scene Perceived Image Perceptual Score (SPIPS): combining global and local perception for image quality assessment",
    "slug": "scene-perceived-image-perceptual-score-(spips):-combining-global-and-local-perception-for-image-quality-assessment",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhiqiang Lao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid advancement of artificial intelligence and widespread use of smartphones have resulted in an exponential growth of image data, both real (camera-captured) and virtual (AI-generated). This surge underscores the critical need for robust image quality assessment (IQA) methods that accurately reflect human visual perception. Traditional IQA techniques primarily rely on spatial features - such as signal-to-noise ratio, local structural distortions, and texture inconsistencies - to identify artifacts. While effective for unprocessed or conventionally altered images, these methods fall short in the context of modern image post-processing powered by deep neural networks (DNNs). The rise of DNN-based models for image generation, enhancement, and restoration has significantly improved visual quality, yet made accurate assessment increasingly complex. To address this, we propose a novel IQA approach that bridges the gap between deep learning methods and human perception. Our model disentangles deep features into high-level semantic information and low-level perceptual details, treating each stream separately. These features are then combined with conventional IQA metrics to provide a more comprehensive evaluation framework. This hybrid design enables the model to assess both global context and intricate image details, better reflecting the human visual process, which first interprets overall structure before attending to fine-grained elements. The final stage employs a multilayer perceptron (MLP) to map the integrated features into a concise quality score. Experimental results demonstrate that our method achieves improved consistency with human perceptual judgments compared to existing IQA models.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17234",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.023490Z"
  },
  {
    "id": "516996b746f9c3d77816a8ecd1ed5e29",
    "title": "DIVE: Inverting Conditional Diffusion Models for Discriminative Tasks",
    "slug": "dive:-inverting-conditional-diffusion-models-for-discriminative-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yinqi Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Diffusion models have shown remarkable progress in various generative tasks such as image and video generation. This paper studies the problem of leveraging pretrained diffusion models for performing discriminative tasks. Specifically, we extend the discriminative capability of pretrained frozen generative diffusion models from the classification task to the more complex object detection task, by \"inverting\" a pretrained layout-to-image diffusion model. To this end, a gradient-based discrete optimization approach for replacing the heavy prediction enumeration process, and a prior distribution model for making more accurate use of the Bayes' rule, are proposed respectively. Empirical results show that this method is on par with basic discriminative object detection baselines on COCO dataset. In addition, our method can greatly speed up the previous diffusion-based method for classification without sacrificing accuracy. Code and models are available at this https URL .",
    "pdfUrl": "https://arxiv.org/pdf/2504.17253",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.023766Z"
  },
  {
    "id": "db1ccdb2ffa997464d2cf3fccc1bbdc3",
    "title": "Precision Neural Network Quantization via Learnable Adaptive Modules",
    "slug": "precision-neural-network-quantization-via-learnable-adaptive-modules",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Wenqiang Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Quantization Aware Training (QAT) is a neural network quantization technique that compresses model size and improves operational efficiency while effectively maintaining model performance. The paradigm of QAT is to introduce fake quantization operators during the training process, allowing the model to autonomously compensate for information loss caused by quantization. Making quantization parameters trainable can significantly improve the performance of QAT, but at the cost of compromising the flexibility during inference, especially when dealing with activation values with substantially different distributions. In this paper, we propose an effective learnable adaptive neural network quantization method, called Adaptive Step Size Quantization (ASQ), to resolve this conflict. Specifically, the proposed ASQ method first dynamically adjusts quantization scaling factors through a trained module capable of accommodating different activations. Then, to address the rigid resolution issue inherent in Power of Two (POT) quantization, we propose an efficient non-uniform quantization scheme. We utilize the Power Of Square root of Two (POST) as the basis for exponential quantization, effectively handling the bell-shaped distribution of neural network weights across various bit-widths while maintaining computational efficiency through a Look-Up Table method (LUT). Extensive experimental results demonstrate that the proposed ASQ method is superior to the state-of-the-art QAT approaches. Notably that the ASQ is even competitive compared to full precision baselines, with its 4-bit quantized ResNet34 model improving accuracy by 1.2\\% on ImageNet.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17263",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.024003Z"
  },
  {
    "id": "738063babc81964f4d10d87352ec03dd",
    "title": "Towards Generalized and Training-Free Text-Guided Semantic Manipulation",
    "slug": "towards-generalized-and-training-free-text-guided-semantic-manipulation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yu Hong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Text-guided semantic manipulation refers to semantically editing an image generated from a source prompt to match a target prompt, enabling the desired semantic changes (e.g., addition, removal, and style transfer) while preserving irrelevant contents. With the powerful generative capabilities of the diffusion model, the task has shown the potential to generate high-fidelity visual content. Nevertheless, existing methods either typically require time-consuming fine-tuning (inefficient), fail to accomplish multiple semantic manipulations (poorly extensible), and/or lack support for different modality tasks (limited generalizability). Upon further investigation, we find that the geometric properties of noises in the diffusion model are strongly correlated with the semantic changes. Motivated by this, we propose a novel $\\textit{GTF}$ for text-guided semantic manipulation, which has the following attractive capabilities: 1) $\\textbf{Generalized}$: our $\\textit{GTF}$ supports multiple semantic manipulations (e.g., addition, removal, and style transfer) and can be seamlessly integrated into all diffusion-based methods (i.e., Plug-and-play) across different modalities (i.e., modality-agnostic); and 2) $\\textbf{Training-free}$: $\\textit{GTF}$ produces high-fidelity results via simply controlling the geometric relationship between noises without tuning or optimization. Our extensive experiments demonstrate the efficacy of our approach, highlighting its potential to advance the state-of-the-art in semantics manipulation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17269",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.024224Z"
  },
  {
    "id": "1fc9bad6f6f416aeb5f2649bb3769ae1",
    "title": "EdgePoint2: Compact Descriptors for Superior Efficiency and Accuracy",
    "slug": "edgepoint2:-compact-descriptors-for-superior-efficiency-and-accuracy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Haodi Yao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The field of keypoint extraction, which is essential for vision applications like Structure from Motion (SfM) and Simultaneous Localization and Mapping (SLAM), has evolved from relying on handcrafted methods to leveraging deep learning techniques. While deep learning approaches have significantly improved performance, they often incur substantial computational costs, limiting their deployment in real-time edge applications. Efforts to create lightweight neural networks have seen some success, yet they often result in trade-offs between efficiency and accuracy. Additionally, the high-dimensional descriptors generated by these networks poses challenges for distributed applications requiring efficient communication and coordination, highlighting the need for compact yet competitively accurate descriptors. In this paper, we present EdgePoint2, a series of lightweight keypoint detection and description neural networks specifically tailored for edge computing applications on embedded system. The network architecture is optimized for efficiency without sacrificing accuracy. To train compact descriptors, we introduce a combination of Orthogonal Procrustes loss and similarity loss, which can serve as a general approach for hypersphere embedding distillation tasks. Additionally, we offer 14 sub-models to satisfy diverse application requirements. Our experiments demonstrate that EdgePoint2 consistently achieves state-of-the-art (SOTA) accuracy and efficiency across various challenging scenarios while employing lower-dimensional descriptors (32/48/64). Beyond its accuracy, EdgePoint2 offers significant advantages in flexibility, robustness, and versatility. Consequently, EdgePoint2 emerges as a highly competitive option for visual tasks, especially in contexts demanding adaptability to diverse computational and communication constraints.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17280",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.024441Z"
  },
  {
    "id": "2d7ddba2c10de89aded82990605525ee",
    "title": "Advanced Segmentation of Diabetic Retinopathy Lesions Using DeepLabv3+",
    "slug": "advanced-segmentation-of-diabetic-retinopathy-lesions-using-deeplabv3+",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Meher Boulaabi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "To improve the segmentation of diabetic retinopathy lesions (microaneurysms, hemorrhages, exudates, and soft exudates), we implemented a binary segmentation method specific to each type of lesion. As post-segmentation, we combined the individual model outputs into a single image to better analyze the lesion types. This approach facilitated parameter optimization and improved accuracy, effectively overcoming challenges related to dataset limitations and annotation complexity. Specific preprocessing steps included cropping and applying contrast-limited adaptive histogram equalization to the L channel of the LAB image. Additionally, we employed targeted data augmentation techniques to further refine the model's efficacy. Our methodology utilized the DeepLabv3+ model, achieving a segmentation accuracy of 99%. These findings highlight the efficacy of innovative strategies in advancing medical image analysis, particularly in the precise segmentation of diabetic retinopathy lesions. The IDRID dataset was utilized to validate and demonstrate the robustness of our approach.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17306",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.024649Z"
  },
  {
    "id": "39bf6fe8cbb78588eda29b51748f6cc5",
    "title": "DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model",
    "slug": "dimt25@icdar2025:-hw-tsc's-end-to-end-document-image-machine-translation-system-leveraging-large-vision-language-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhanglin Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper presents the technical solution proposed by Huawei Translation Service Center (HW-TSC) for the \"End-to-End Document Image Machine Translation for Complex Layouts\" competition at the 19th International Conference on Document Analysis and Recognition (DIMT25@ICDAR2025). Leveraging state-of-the-art open-source large vision-language model (LVLM), we introduce a training framework that combines multi-task learning with perceptual chain-of-thought to develop a comprehensive end-to-end document translation system. During the inference phase, we apply minimum Bayesian decoding and post-processing strategies to further enhance the system's translation capabilities. Our solution uniquely addresses both OCR-based and OCR-free document image translation tasks within a unified framework. This paper systematically details the training methods, inference strategies, LVLM base models, training data, experimental setups, and results, demonstrating an effective approach to document image machine translation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17315",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.024884Z"
  },
  {
    "id": "596b5118ad291ff45223e3db24bfd86e",
    "title": "TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos",
    "slug": "timechat-online:-80%-visual-tokens-are-naturally-redundant-in-streaming-videos",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Linli Yao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid growth of online video platforms, particularly live streaming services, has created an urgent need for real-time video understanding systems. These systems must process continuous video streams and respond to user queries instantaneously, presenting unique challenges for current Video Large Language Models (VideoLLMs). While existing VideoLLMs excel at processing complete videos, they face significant limitations in streaming scenarios due to their inability to handle dense, redundant frames efficiently. We introduce TimeChat-Online, a novel online VideoLLM that revolutionizes real-time video interaction. At its core lies our innovative Differential Token Drop (DTD) module, which addresses the fundamental challenge of visual redundancy in streaming videos. Drawing inspiration from human visual perception's Change Blindness phenomenon, DTD preserves meaningful temporal changes while filtering out static, redundant content between frames. Remarkably, our experiments demonstrate that DTD achieves an 82.8% reduction in video tokens while maintaining 98% performance on StreamingBench, revealing that over 80% of visual content in streaming videos is naturally redundant without requiring language guidance. To enable seamless real-time interaction, we present TimeChat-Online-139K, a comprehensive streaming video dataset featuring diverse interaction patterns including backward-tracing, current-perception, and future-responding scenarios. TimeChat-Online's unique Proactive Response capability, naturally achieved through continuous monitoring of video scene transitions via DTD, sets it apart from conventional approaches. Our extensive evaluation demonstrates TimeChat-Online's superior performance on streaming benchmarks (StreamingBench and OvOBench) and maintaining competitive results on long-form video tasks such as Video-MME and MLVU.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17343",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.025136Z"
  },
  {
    "id": "07861829a6c8df77eff0316c75735fbc",
    "title": "DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition",
    "slug": "drc:-enhancing-personalized-image-generation-via-disentangled-representation-composition",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yiyan Xu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Personalized image generation has emerged as a promising direction in multimodal content creation. It aims to synthesize images tailored to individual style preferences (e.g., color schemes, character appearances, layout) and semantic intentions (e.g., emotion, action, scene contexts) by leveraging user-interacted history images and multimodal instructions. Despite notable progress, existing methods -- whether based on diffusion models, large language models, or Large Multimodal Models (LMMs) -- struggle to accurately capture and fuse user style preferences and semantic intentions. In particular, the state-of-the-art LMM-based method suffers from the entanglement of visual features, leading to Guidance Collapse, where the generated images fail to preserve user-preferred styles or reflect the specified semantics.\nTo address these limitations, we introduce DRC, a novel personalized image generation framework that enhances LMMs through Disentangled Representation Composition. DRC explicitly extracts user style preferences and semantic intentions from history images and the reference image, respectively, to form user-specific latent instructions that guide image generation within LMMs. Specifically, it involves two critical learning stages: 1) Disentanglement learning, which employs a dual-tower disentangler to explicitly separate style and semantic features, optimized via a reconstruction-driven paradigm with difficulty-aware importance sampling; and 2) Personalized modeling, which applies semantic-preserving augmentations to effectively adapt the disentangled representations for robust personalized generation. Extensive experiments on two benchmarks demonstrate that DRC shows competitive performance while effectively mitigating the guidance collapse issue, underscoring the importance of disentangled representation learning for controllable and effective personalized image generation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17349",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.025360Z"
  },
  {
    "id": "3c7817a40d7fd8b93d2ab16b1f20d043",
    "title": "I-INR: Iterative Implicit Neural Representations",
    "slug": "i-inr:-iterative-implicit-neural-representations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ali Haider",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Implicit Neural Representations (INRs) have revolutionized signal processing and computer vision by modeling signals as continuous, differentiable functions parameterized by neural networks. However, their inherent formulation as a regression problem makes them prone to regression to the mean, limiting their ability to capture fine details, retain high-frequency information, and handle noise effectively. To address these challenges, we propose Iterative Implicit Neural Representations (I-INRs) a novel plug-and-play framework that enhances signal reconstruction through an iterative refinement process. I-INRs effectively recover high-frequency details, improve robustness to noise, and achieve superior reconstruction quality. Our framework seamlessly integrates with existing INR architectures, delivering substantial performance gains across various tasks. Extensive experiments show that I-INRs outperform baseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision applications such as image restoration, image denoising, and object occupancy prediction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17364",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.025587Z"
  },
  {
    "id": "5c7ea31094c41eb4dd58897bcb396e6e",
    "title": "TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation",
    "slug": "timesoccer:-an-end-to-end-multimodal-large-language-model-for-soccer-commentary-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ling You",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Soccer is a globally popular sporting event, typically characterized by long matches and distinctive highlight moments. Recent advances in Multimodal Large Language Models (MLLMs) offer promising capabilities in temporal grounding and video understanding, soccer commentary generation often requires precise temporal localization and semantically rich descriptions over long-form video. However, existing soccer MLLMs often rely on the temporal a priori for caption generation, so they cannot process the soccer video end-to-end. While some traditional approaches follow a two-step paradigm that is complex and fails to capture the global context to achieve suboptimal performance. To solve the above issues, we present TimeSoccer, the first end-to-end soccer MLLM for Single-anchor Dense Video Captioning (SDVC) in full-match soccer videos. TimeSoccer jointly predicts timestamps and generates captions in a single pass, enabling global context modeling across 45-minute matches. To support long video understanding of soccer matches, we introduce MoFA-Select, a training-free, motion-aware frame compression module that adaptively selects representative frames via a coarse-to-fine strategy, and incorporates complementary training paradigms to strengthen the model's ability to handle long temporal sequences. Extensive experiments demonstrate that our TimeSoccer achieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-end form, generating high-quality commentary with accurate temporal alignment and strong semantic relevance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17365",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.025812Z"
  },
  {
    "id": "2c0785a1fde9cdaadd889a0aa5ac71ee",
    "title": "Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset",
    "slug": "highly-accurate-and-diverse-traffic-data:-the-deepscenario-open-3d-dataset",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Oussema Dhaouadi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet, traditional datasets are usually captured by fixed sensors mounted on a car and are susceptible to occlusion. Additionally, such an approach can precisely reconstruct the dynamic environment in the close vicinity of the measurement vehicle only, while neglecting objects that are further away. In this paper, we introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality, occlusion-free dataset of 6 degrees of freedom bounding box trajectories acquired through a novel monocular camera drone tracking pipeline. Our dataset includes more than 175,000 trajectories of 14 types of traffic participants and significantly exceeds existing datasets in terms of diversity and scale, containing many unprecedented scenarios such as complex vehicle-pedestrian interaction on highly populated urban streets and comprehensive parking maneuvers from entry to exit. DSC3D dataset was captured in five various locations in Europe and the United States and include: a parking lot, a crowded inner-city, a steep urban intersection, a federal highway, and a suburban intersection. Our 3D trajectory dataset aims to enhance autonomous driving systems by providing detailed environmental 3D representations, which could lead to improved obstacle interactions and safety. We demonstrate its utility across multiple applications including motion prediction, motion planning, scenario mining, and generative reactive traffic agents. Our interactive online visualization platform and the complete dataset are publicly available at this http URL, facilitating research in motion prediction, behavior modeling, and safety validation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17371",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.026041Z"
  },
  {
    "id": "3e8a95646552a65fce42e57876dd350d",
    "title": "SDVPT: Semantic-Driven Visual Prompt Tuning for Open-World Object Counting",
    "slug": "sdvpt:-semantic-driven-visual-prompt-tuning-for-open-world-object-counting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yiming Zhao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Open-world object counting leverages the robust text-image alignment of pre-trained vision-language models (VLMs) to enable counting of arbitrary categories in images specified by textual queries. However, widely adopted naive fine-tuning strategies concentrate exclusively on text-image consistency for categories contained in training, which leads to limited generalizability for unseen categories. In this work, we propose a plug-and-play Semantic-Driven Visual Prompt Tuning framework (SDVPT) that transfers knowledge from the training set to unseen categories with minimal overhead in parameters and inference time. First, we introduce a two-stage visual prompt learning strategy composed of Category-Specific Prompt Initialization (CSPI) and Topology-Guided Prompt Refinement (TGPR). The CSPI generates category-specific visual prompts, and then TGPR distills latent structural patterns from the VLM's text encoder to refine these prompts. During inference, we dynamically synthesize the visual prompts for unseen categories based on the semantic correlation between unseen and training categories, facilitating robust text-image alignment for unseen categories. Extensive experiments integrating SDVPT with all available open-world object counting models demonstrate its effectiveness and adaptability across three widely used datasets: FSC-147, CARPK, and PUCPR+.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17395",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.026279Z"
  },
  {
    "id": "2c467a27ba95a81f3bc77459529fb4f7",
    "title": "Fine-tune Smarter, Not Harder: Parameter-Efficient Fine-Tuning for Geospatial Foundation Models",
    "slug": "fine-tune-smarter,-not-harder:-parameter-efficient-fine-tuning-for-geospatial-foundation-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Francesc Marti-Escofet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Earth observation (EO) is crucial for monitoring environmental changes, responding to disasters, and managing natural resources. In this context, foundation models facilitate remote sensing image analysis to retrieve relevant geoinformation accurately and efficiently. However, as these models grow in size, fine-tuning becomes increasingly challenging due to the associated computational resources and costs, limiting their accessibility and scalability. Furthermore, full fine-tuning can lead to forgetting pre-trained features and even degrade model generalization. To address this, Parameter-Efficient Fine-Tuning (PEFT) techniques offer a promising solution. In this paper, we conduct extensive experiments with various foundation model architectures and PEFT techniques to evaluate their effectiveness on five different EO datasets. Our results provide a comprehensive comparison, offering insights into when and how PEFT methods support the adaptation of pre-trained geospatial models. We demonstrate that PEFT techniques match or even exceed full fine-tuning performance and enhance model generalisation to unseen geographic regions, while reducing training time and memory requirements. Additional experiments investigate the effect of architecture choices such as the decoder type or the use of metadata, suggesting UNet decoders and fine-tuning without metadata as the recommended configuration. We have integrated all evaluated foundation models and techniques into the open-source package TerraTorch to support quick, scalable, and cost-effective model adaptation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17397",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.026499Z"
  },
  {
    "id": "3123c72f13390e6fd602bcbd63f9bf35",
    "title": "S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in LiDAR-Based Collective Perception",
    "slug": "s2s-net:-addressing-the-domain-gap-of-heterogeneous-sensor-systems-in-lidar-based-collective-perception",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Sven Teufel",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Collective Perception (CP) has emerged as a promising approach to overcome the limitations of individual perception in the context of autonomous driving. Various approaches have been proposed to realize collective perception; however, the Sensor2Sensor domain gap that arises from the utilization of different sensor systems in Connected and Automated Vehicles (CAVs) remains mostly unaddressed. This is primarily due to the paucity of datasets containing heterogeneous sensor setups among the CAVs. The recently released SCOPE datasets address this issue by providing data from three different LiDAR sensors for each CAV. This study is the first to tackle the Sensor2Sensor domain gap in vehicle to vehicle (V2V) collective perception. First, we present our sensor-domain robust architecture S2S-Net. Then an in-depth analysis of the Sensor2Sensor domain adaptation capabilities of S2S-Net on the SCOPE dataset is conducted. S2S-Net demonstrates the capability to maintain very high performance in unseen sensor domains and achieved state-of-the-art results on the SCOPE dataset.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17399",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.026701Z"
  },
  {
    "id": "d040e770551526dde4a98bf1daf5a94f",
    "title": "StereoMamba: Real-time and Robust Intraoperative Stereo Disparity Estimation via Long-range Spatial Dependencies",
    "slug": "stereomamba:-real-time-and-robust-intraoperative-stereo-disparity-estimation-via-long-range-spatial-dependencies",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Xu Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Stereo disparity estimation is crucial for obtaining depth information in robot-assisted minimally invasive surgery (RAMIS). While current deep learning methods have made significant advancements, challenges remain in achieving an optimal balance between accuracy, robustness, and inference speed. To address these challenges, we propose the StereoMamba architecture, which is specifically designed for stereo disparity estimation in RAMIS. Our approach is based on a novel Feature Extraction Mamba (FE-Mamba) module, which enhances long-range spatial dependencies both within and across stereo images. To effectively integrate multi-scale features from FE-Mamba, we then introduce a novel Multidimensional Feature Fusion (MFF) module. Experiments against the state-of-the-art on the ex-vivo SCARED benchmark demonstrate that StereoMamba achieves superior performance on EPE of 2.64 px and depth MAE of 2.55 mm, the second-best performance on Bad2 of 41.49% and Bad3 of 26.99%, while maintaining an inference speed of 21.28 FPS for a pair of high-resolution images (1280*1024), striking the optimum balance between accuracy, robustness, and efficiency. Furthermore, by comparing synthesized right images, generated from warping left images using the generated disparity maps, with the actual right image, StereoMamba achieves the best average SSIM (0.8970) and PSNR (16.0761), exhibiting strong zero-shot generalization on the in-vivo RIS2017 and StereoMIS datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17401",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.026927Z"
  },
  {
    "id": "b72ba79890f22c2829d28f97e9b1a8ec",
    "title": "3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models",
    "slug": "3dv-ton:-textured-3d-guided-consistent-video-try-on-via-diffusion-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Min Wei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Video try-on replaces clothing in videos with target garments. Existing methods struggle to generate high-quality and temporally consistent results when handling complex clothing patterns and diverse body poses. We present 3DV-TON, a novel diffusion-based framework for generating high-fidelity and temporally consistent video try-on results. Our approach employs generated animatable textured 3D meshes as explicit frame-level guidance, alleviating the issue of models over-focusing on appearance fidelity at the expanse of motion coherence. This is achieved by enabling direct reference to consistent garment texture movements throughout video sequences. The proposed method features an adaptive pipeline for generating dynamic 3D guidance: (1) selecting a keyframe for initial 2D image try-on, followed by (2) reconstructing and animating a textured 3D mesh synchronized with original video poses. We further introduce a robust rectangular masking strategy that successfully mitigates artifact propagation caused by leaking clothing information during dynamic human and garment movements. To advance video try-on research, we introduce HR-VVT, a high-resolution benchmark dataset containing 130 videos with diverse clothing types and scenarios. Quantitative and qualitative results demonstrate our superior performance over existing methods. The project page is at this link this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17414",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.027140Z"
  },
  {
    "id": "2e04a47a5a23e3a59d810fc96190015c",
    "title": "Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs",
    "slug": "breaking-the-modality-barrier:-universal-embedding-learning-with-multimodal-llms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Tiancheng Gu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Contrastive Language-Image Pre-training (CLIP) framework has become a widely used approach for multimodal representation learning, particularly in image-text retrieval and clustering. However, its efficacy is constrained by three key limitations: (1) text token truncation, (2) isolated image-text encoding, and (3) deficient compositionality due to bag-of-words behavior. While recent Multimodal Large Language Models (MLLMs) have demonstrated significant advances in generalized vision-language understanding, their potential for learning transferable multimodal representations remains this http URL this work, we present UniME (Universal Multimodal Embedding), a novel two-stage framework that leverages MLLMs to learn discriminative representations for diverse downstream tasks. In the first stage, we perform textual discriminative knowledge distillation from a powerful LLM-based teacher model to enhance the embedding capability of the MLLM language component. In the second stage, we introduce hard negative enhanced instruction tuning to further advance discriminative representation learning. Specifically, we initially mitigate false negative contamination and then sample multiple hard negatives per instance within each batch, forcing the model to focus on challenging samples. This approach not only improves discriminative power but also enhances instruction-following ability in downstream tasks. We conduct extensive experiments on the MMEB benchmark and multiple retrieval tasks, including short and long caption retrieval and compositional retrieval. Results demonstrate that UniME achieves consistent performance improvement across all tasks, exhibiting superior discriminative and compositional capabilities.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17432",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.027400Z"
  },
  {
    "id": "ab65fdcaef7f5ec8d8f3fa47980ba7e7",
    "title": "Predict-Optimize-Distill: A Self-Improving Cycle for 4D Object Understanding",
    "slug": "predict-optimize-distill:-a-self-improving-cycle-for-4d-object-understanding",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Mingxuan Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Humans can resort to long-form inspection to build intuition on predicting the 3D configurations of unseen objects. The more we observe the object motion, the better we get at predicting its 3D state immediately. Existing systems either optimize underlying representations from multi-view observations or train a feed-forward predictor from supervised datasets. We introduce Predict-Optimize-Distill (POD), a self-improving framework that interleaves prediction and optimization in a mutually reinforcing cycle to achieve better 4D object understanding with increasing observation time. Given a multi-view object scan and a long-form monocular video of human-object interaction, POD iteratively trains a neural network to predict local part poses from RGB frames, uses this predictor to initialize a global optimization which refines output poses through inverse rendering, then finally distills the results of optimization back into the model by generating synthetic self-labeled training data from novel viewpoints. Each iteration improves both the predictive model and the optimized motion trajectory, creating a virtuous cycle that bootstraps its own training data to learn about the pose configurations of an object. We also introduce a quasi-multiview mining strategy for reducing depth ambiguity by leveraging long video. We evaluate POD on 14 real-world and 5 synthetic objects with various joint types, including revolute and prismatic joints as well as multi-body configurations where parts detach or reattach independently. POD demonstrates significant improvement over a pure optimization baseline which gets stuck in local minima, particularly for longer videos. We also find that POD's performance improves with both video length and successive iterations of the self-improving cycle, highlighting its ability to scale performance with additional observations and looped refinement.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17441",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.027627Z"
  },
  {
    "id": "349c01e3e8e2f22a2c2e72f8f96d8b24",
    "title": "FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding",
    "slug": "frag:-frame-selection-augmented-generation-for-long-video-and-long-document-understanding",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "De-An Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "There has been impressive progress in Large Multimodal Models (LMMs). Recent works extend these models to long inputs, including multi-page documents and long videos. However, the model size and performance of these long context models are still limited due to the computational cost in both training and inference. In this work, we explore an orthogonal direction and process long inputs without long context LMMs. We propose Frame Selection Augmented Generation (FRAG), where the model first selects relevant frames within the input, and then only generates the final outputs based on the selected frames. The core of the selection process is done by scoring each frame independently, which does not require long context processing. The frames with the highest scores are then selected by a simple Top-K selection. We show that this frustratingly simple framework is applicable to both long videos and multi-page documents using existing LMMs without any fine-tuning. We consider two models, LLaVA-OneVision and InternVL2, in our experiments and show that FRAG consistently improves the performance and achieves state-of-the-art performances for both long video and long document understanding. For videos, FRAG substantially improves InternVL2-76B by 5.8% on MLVU and 3.7% on Video-MME. For documents, FRAG achieves over 20% improvements on MP-DocVQA compared with recent LMMs specialized in long document understanding. Code is available at: this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17447",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.027839Z"
  },
  {
    "id": "026b72964ff499a2e2d3a7a8d196db12",
    "title": "Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks",
    "slug": "unveiling-hidden-vulnerabilities-in-digital-human-generation-via-adversarial-attacks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhiying Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Expressive human pose and shape estimation (EHPS) is crucial for digital human generation, especially in applications like live streaming. While existing research primarily focuses on reducing estimation errors, it largely neglects robustness and security aspects, leaving these systems vulnerable to adversarial attacks. To address this significant challenge, we propose the \\textbf{Tangible Attack (TBA)}, a novel framework designed to generate adversarial examples capable of effectively compromising any digital human generation model. Our approach introduces a \\textbf{Dual Heterogeneous Noise Generator (DHNG)}, which leverages Variational Autoencoders (VAE) and ControlNet to produce diverse, targeted noise tailored to the original image features. Additionally, we design a custom \\textbf{adversarial loss function} to optimize the noise, ensuring both high controllability and potent disruption. By iteratively refining the adversarial sample through multi-gradient signals from both the noise and the state-of-the-art EHPS model, TBA substantially improves the effectiveness of adversarial attacks. Extensive experiments demonstrate TBA's superiority, achieving a remarkable 41.0\\% increase in estimation error, with an average improvement of approximately 17.0\\%. These findings expose significant security vulnerabilities in current EHPS models and highlight the need for stronger defenses in digital human generation systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17457",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.028080Z"
  },
  {
    "id": "a8cd9dd9e5b36afd1d9c8004d934b4fa",
    "title": "Enhanced Sample Selection with Confidence Tracking: Identifying Correctly Labeled yet Hard-to-Learn Samples in Noisy Data",
    "slug": "enhanced-sample-selection-with-confidence-tracking:-identifying-correctly-labeled-yet-hard-to-learn-samples-in-noisy-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Weiran Pan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a novel sample selection method for image classification in the presence of noisy labels. Existing methods typically consider small-loss samples as correctly labeled. However, some correctly labeled samples are inherently difficult for the model to learn and can exhibit high loss similar to mislabeled samples in the early stages of training. Consequently, setting a threshold on per-sample loss to select correct labels results in a trade-off between precision and recall in sample selection: a lower threshold may miss many correctly labeled hard-to-learn samples (low recall), while a higher threshold may include many mislabeled samples (low precision). To address this issue, our goal is to accurately distinguish correctly labeled yet hard-to-learn samples from mislabeled ones, thus alleviating the trade-off dilemma. We achieve this by considering the trends in model prediction confidence rather than relying solely on loss values. Empirical observations show that only for correctly labeled samples, the model's prediction confidence for the annotated labels typically increases faster than for any other classes. Based on this insight, we propose tracking the confidence gaps between the annotated labels and other classes during training and evaluating their trends using the Mann-Kendall Test. A sample is considered potentially correctly labeled if all its confidence gaps tend to increase. Our method functions as a plug-and-play component that can be seamlessly integrated into existing sample selection techniques. Experiments on several standard benchmarks and real-world datasets demonstrate that our method enhances the performance of existing methods for learning with noisy labels.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17474",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.028279Z"
  },
  {
    "id": "d67c2c776d71c664a4098b53f2e8489c",
    "title": "RefVNLI: Towards Scalable Evaluation of Subject-driven Text-to-image Generation",
    "slug": "refvnli:-towards-scalable-evaluation-of-subject-driven-text-to-image-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Aviv Slobodkin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Subject-driven text-to-image (T2I) generation aims to produce images that align with a given textual description, while preserving the visual identity from a referenced subject image. Despite its broad downstream applicability -- ranging from enhanced personalization in image generation to consistent character representation in video rendering -- progress in this field is limited by the lack of reliable automatic evaluation. Existing methods either assess only one aspect of the task (i.e., textual alignment or subject preservation), misalign with human judgments, or rely on costly API-based evaluation. To address this, we introduce RefVNLI, a cost-effective metric that evaluates both textual alignment and subject preservation in a single prediction. Trained on a large-scale dataset derived from video-reasoning benchmarks and image perturbations, RefVNLI outperforms or matches existing baselines across multiple benchmarks and subject categories (e.g., \\emph{Animal}, \\emph{Object}), achieving up to 6.4-point gains in textual alignment and 8.5-point gains in subject consistency. It also excels with lesser-known concepts, aligning with human preferences at over 87\\% accuracy.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17502",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.028526Z"
  },
  {
    "id": "1b97177bfd683f2070adb657919dc17a",
    "title": "Mamba-Sea: A Mamba-based Framework with Global-to-Local Sequence Augmentation for Generalizable Medical Image Segmentation",
    "slug": "mamba-sea:-a-mamba-based-framework-with-global-to-local-sequence-augmentation-for-generalizable-medical-image-segmentation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zihan Cheng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "To segment medical images with distribution shifts, domain generalization (DG) has emerged as a promising setting to train models on source domains that can generalize to unseen target domains. Existing DG methods are mainly based on CNN or ViT architectures. Recently, advanced state space models, represented by Mamba, have shown promising results in various supervised medical image segmentation. The success of Mamba is primarily owing to its ability to capture long-range dependencies while keeping linear complexity with input sequence length, making it a promising alternative to CNNs and ViTs. Inspired by the success, in the paper, we explore the potential of the Mamba architecture to address distribution shifts in DG for medical image segmentation. Specifically, we propose a novel Mamba-based framework, Mamba-Sea, incorporating global-to-local sequence augmentation to improve the model's generalizability under domain shift issues. Our Mamba-Sea introduces a global augmentation mechanism designed to simulate potential variations in appearance across different sites, aiming to suppress the model's learning of domain-specific information. At the local level, we propose a sequence-wise augmentation along input sequences, which perturbs the style of tokens within random continuous sub-sequences by modeling and resampling style statistics associated with domain shifts. To our best knowledge, Mamba-Sea is the first work to explore the generalization of Mamba for medical image segmentation, providing an advanced and promising Mamba-based architecture with strong robustness to domain shifts. Remarkably, our proposed method is the first to surpass a Dice coefficient of 90% on the Prostate dataset, which exceeds previous SOTA of 88.61%. The code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17515",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.028766Z"
  },
  {
    "id": "032699c5a7cfe087836a90b8f0d14d90",
    "title": "Towards One-Stage End-to-End Table Structure Recognition with Parallel Regression for Diverse Scenarios",
    "slug": "towards-one-stage-end-to-end-table-structure-recognition-with-parallel-regression-for-diverse-scenarios",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Anyi Xiao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Table structure recognition aims to parse tables in unstructured data into machine-understandable formats. Recent methods address this problem through a two-stage process or optimized one-stage approaches. However, these methods either require multiple networks to be serially trained and perform more time-consuming sequential decoding, or rely on complex post-processing algorithms to parse the logical structure of tables. They struggle to balance cross-scenario adaptability, robustness, and computational efficiency. In this paper, we propose a one-stage end-to-end table structure parsing network called TableCenterNet. This network unifies the prediction of table spatial and logical structure into a parallel regression task for the first time, and implicitly learns the spatial-logical location mapping laws of cells through a synergistic architecture of shared feature extraction layers and task-specific decoding. Compared with two-stage methods, our method is easier to train and faster to infer. Experiments on benchmark datasets show that TableCenterNet can effectively parse table structures in diverse scenarios and achieve state-of-the-art performance on the TableGraph-24k dataset. Code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17522",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.028962Z"
  },
  {
    "id": "1e4299a98b864b717d1011022519881d",
    "title": "ESDiff: Encoding Strategy-inspired Diffusion Model with Few-shot Learning for Color Image Inpainting",
    "slug": "esdiff:-encoding-strategy-inspired-diffusion-model-with-few-shot-learning-for-color-image-inpainting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Junyan Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Image inpainting is a technique used to restore missing or damaged regions of an image. Traditional methods primarily utilize information from adjacent pixels for reconstructing missing areas, while they struggle to preserve complex details and structures. Simultaneously, models based on deep learning necessitate substantial amounts of training data. To address this challenge, an encoding strategy-inspired diffusion model with few-shot learning for color image inpainting is proposed in this paper. The main idea of this novel encoding strategy is the deployment of a \"virtual mask\" to construct high-dimensional objects through mutual perturbations between channels. This approach enables the diffusion model to capture diverse image representations and detailed features from limited training samples. Moreover, the encoding strategy leverages redundancy between channels, integrates with low-rank methods during iterative inpainting, and incorporates the diffusion model to achieve accurate information output. Experimental results indicate that our method exceeds current techniques in quantitative metrics, and the reconstructed images quality has been improved in aspects of texture and structural integrity, leading to more precise and coherent results.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17524",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.029176Z"
  },
  {
    "id": "3f71c18019a1b037c3dd1efd6b7376d6",
    "title": "Text-to-Image Alignment in Denoising-Based Models through Step Selection",
    "slug": "text-to-image-alignment-in-denoising-based-models-through-step-selection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Paul Grimal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Visual generative AI models often encounter challenges related to text-image alignment and reasoning limitations. This paper presents a novel method for selectively enhancing the signal at critical denoising steps, optimizing image generation based on input semantics. Our approach addresses the shortcomings of early-stage signal modifications, demonstrating that adjustments made at later stages yield superior results. We conduct extensive experiments to validate the effectiveness of our method in producing semantically aligned images on Diffusion and Flow Matching model, achieving state-of-the-art performance. Our results highlight the importance of a judicious choice of sampling stage to improve performance and overall image alignment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17525",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.029378Z"
  },
  {
    "id": "d3b342d0e4b04e4528452d4b81a1bade",
    "title": "An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm",
    "slug": "an-explainable-nature-inspired-framework-for-monkeypox-diagnosis:-xception-features-combined-with-ngboost-and-african-vultures-optimization-algorithm",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ahmadreza Shateri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The recent global spread of monkeypox, particularly in regions where it has not historically been prevalent, has raised significant public health concerns. Early and accurate diagnosis is critical for effective disease management and control. In response, this study proposes a novel deep learning-based framework for the automated detection of monkeypox from skin lesion images, leveraging the power of transfer learning, dimensionality reduction, and advanced machine learning techniques. We utilize the newly developed Monkeypox Skin Lesion Dataset (MSLD), which includes images of monkeypox, chickenpox, and measles, to train and evaluate our models. The proposed framework employs the Xception architecture for deep feature extraction, followed by Principal Component Analysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting (NGBoost) algorithm for classification. To optimize the model's performance and generalization, we introduce the African Vultures Optimization Algorithm (AVOA) for hyperparameter tuning, ensuring efficient exploration of the parameter space. Our results demonstrate that the proposed AVOA-NGBoost model achieves state-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72% and an AUC of 97.47%. Additionally, we enhance model interpretability using Grad-CAM and LIME techniques, providing insights into the decision-making process and highlighting key features influencing classification. This framework offers a highly precise and efficient diagnostic tool, potentially aiding healthcare providers in early detection and diagnosis, particularly in resource-constrained environments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17540",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.029597Z"
  },
  {
    "id": "a63945636ea4cc9803512c077506f75f",
    "title": "When Gaussian Meets Surfel: Ultra-fast High-fidelity Radiance Field Rendering",
    "slug": "when-gaussian-meets-surfel:-ultra-fast-high-fidelity-radiance-field-rendering",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Keyang Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce Gaussian-enhanced Surfels (GESs), a bi-scale representation for radiance field rendering, wherein a set of 2D opaque surfels with view-dependent colors represent the coarse-scale geometry and appearance of scenes, and a few 3D Gaussians surrounding the surfels supplement fine-scale appearance details. The rendering with GESs consists of two passes -- surfels are first rasterized through a standard graphics pipeline to produce depth and color maps, and then Gaussians are splatted with depth testing and color accumulation on each pixel order independently. The optimization of GESs from multi-view images is performed through an elaborate coarse-to-fine procedure, faithfully capturing rich scene appearance. The entirely sorting-free rendering of GESs not only achieves very fast rates, but also produces view-consistent images, successfully avoiding popping artifacts under view changes. The basic GES representation can be easily extended to achieve anti-aliasing in rendering (Mip-GES), boosted rendering speeds (Speedy-GES) and compact storage (Compact-GES), and reconstruct better scene geometries by replacing 3D Gaussians with 2D Gaussians (2D-GES). Experimental results show that GESs advance the state-of-the-arts as a compelling representation for ultra-fast high-fidelity radiance field rendering.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17545",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.029795Z"
  },
  {
    "id": "8e60d7b4c054c53ea70891d463198dde",
    "title": "A Comprehensive Survey of Knowledge-Based Vision Question Answering Systems: The Lifecycle of Knowledge in Visual Reasoning Task",
    "slug": "a-comprehensive-survey-of-knowledge-based-vision-question-answering-systems:-the-lifecycle-of-knowledge-in-visual-reasoning-task",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Jiaqi Deng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Knowledge-based Vision Question Answering (KB-VQA) extends general Vision Question Answering (VQA) by not only requiring the understanding of visual and textual inputs but also extensive range of knowledge, enabling significant advancements across various real-world applications. KB-VQA introduces unique challenges, including the alignment of heterogeneous information from diverse modalities and sources, the retrieval of relevant knowledge from noisy or large-scale repositories, and the execution of complex reasoning to infer answers from the combined context. With the advancement of Large Language Models (LLMs), KB-VQA systems have also undergone a notable transformation, where LLMs serve as powerful knowledge repositories, retrieval-augmented generators and strong reasoners. Despite substantial progress, no comprehensive survey currently exists that systematically organizes and reviews the existing KB-VQA methods. This survey aims to fill this gap by establishing a structured taxonomy of KB-VQA approaches, and categorizing the systems into main stages: knowledge representation, knowledge retrieval, and knowledge reasoning. By exploring various knowledge integration techniques and identifying persistent challenges, this work also outlines promising future research directions, providing a foundation for advancing KB-VQA models and their applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17547",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.030008Z"
  },
  {
    "id": "9651dbc157c840ef90337997a3db7a68",
    "title": "Unsupervised Urban Land Use Mapping with Street View Contrastive Clustering and a Geographical Prior",
    "slug": "unsupervised-urban-land-use-mapping-with-street-view-contrastive-clustering-and-a-geographical-prior",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Lin Che",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Urban land use classification and mapping are critical for urban planning, resource management, and environmental monitoring. Existing remote sensing techniques often lack precision in complex urban environments due to the absence of ground-level details. Unlike aerial perspectives, street view images provide a ground-level view that captures more human and social activities relevant to land use in complex urban scenes. Existing street view-based methods primarily rely on supervised classification, which is challenged by the scarcity of high-quality labeled data and the difficulty of generalizing across diverse urban landscapes. This study introduces an unsupervised contrastive clustering model for street view images with a built-in geographical prior, to enhance clustering performance. When combined with a simple visual assignment of the clusters, our approach offers a flexible and customizable solution to land use mapping, tailored to the specific needs of urban planners. We experimentally show that our method can generate land use maps from geotagged street view image datasets of two cities. As our methodology relies on the universal spatial coherence of geospatial data (\"Tobler's law\"), it can be adapted to various settings where street view images are available, to enable scalable, unsupervised land use mapping and updating. The code will be available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17551",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.030227Z"
  },
  {
    "id": "6661a63f2d228ce0da87ca465a2174b5",
    "title": "Occlusion-Aware Self-Supervised Monocular Depth Estimation for Weak-Texture Endoscopic Images",
    "slug": "occlusion-aware-self-supervised-monocular-depth-estimation-for-weak-texture-endoscopic-images",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zebo Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a self-supervised monocular depth estimation network tailored for endoscopic scenes, aiming to infer depth within the gastrointestinal tract from monocular images. Existing methods, though accurate, typically assume consistent illumination, which is often violated due to dynamic lighting and occlusions caused by GI motility. These variations lead to incorrect geometric interpretations and unreliable self-supervised signals, degrading depth reconstruction quality. To address this, we introduce an occlusion-aware self-supervised framework. First, we incorporate an occlusion mask for data augmentation, generating pseudo-labels by simulating viewpoint-dependent occlusion scenarios. This enhances the model's ability to learn robust depth features under partial visibility. Second, we leverage semantic segmentation guided by non-negative matrix factorization, clustering convolutional activations to generate pseudo-labels in texture-deprived regions, thereby improving segmentation accuracy and mitigating information loss from lighting changes. Experimental results on the SCARED dataset show that our method achieves state-of-the-art performance in self-supervised depth estimation. Additionally, evaluations on the Endo-SLAM and SERV-CT datasets demonstrate strong generalization across diverse endoscopic environments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17582",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.030420Z"
  },
  {
    "id": "58a74b3411dbd4ce446ce3d5b9464817",
    "title": "Tamper-evident Image using JPEG Fixed Points",
    "slug": "tamper-evident-image-using-jpeg-fixed-points",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhaofeng Si",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "An intriguing phenomenon about JPEG compression has been observed since two decades ago- after repeating JPEG compression and decompression, it leads to a stable image that does not change anymore, which is a fixed point. In this work, we prove the existence of fixed points in the essential JPEG procedures. We analyze JPEG compression and decompression processes, revealing the existence of fixed points that can be reached within a few iterations. These fixed points are diverse and preserve the image's visual quality, ensuring minimal distortion. This result is used to develop a method to create a tamper-evident image from the original authentic image, which can expose tampering operations by showing deviations from the fixed point image.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17594",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.030620Z"
  },
  {
    "id": "16f5bb80ad392202fcc1fd42e67bf752",
    "title": "RGB-D Tracking via Hierarchical Modality Aggregation and Distribution Network",
    "slug": "rgb-d-tracking-via-hierarchical-modality-aggregation-and-distribution-network",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Boyue Xu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The integration of dual-modal features has been pivotal in advancing RGB-Depth (RGB-D) tracking. However, current trackers are less efficient and focus solely on single-level features, resulting in weaker robustness in fusion and slower speeds that fail to meet the demands of real-world applications. In this paper, we introduce a novel network, denoted as HMAD (Hierarchical Modality Aggregation and Distribution), which addresses these challenges. HMAD leverages the distinct feature representation strengths of RGB and depth modalities, giving prominence to a hierarchical approach for feature distribution and fusion, thereby enhancing the robustness of RGB-D tracking. Experimental results on various RGB-D datasets demonstrate that HMAD achieves state-of-the-art performance. Moreover, real-world experiments further validate HMAD's capacity to effectively handle a spectrum of tracking challenges in real-time scenarios.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17595",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.030832Z"
  },
  {
    "id": "6de23002ebad47cc72d7032bd74fefd4",
    "title": "STCL:Curriculum learning Strategies for deep learning image steganography models",
    "slug": "stcl:curriculum-learning-strategies-for-deep-learning-image-steganography-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Fengchun Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Aiming at the problems of poor quality of steganographic images and slow network convergence of image steganography models based on deep learning, this paper proposes a Steganography Curriculum Learning training strategy (STCL) for deep learning image steganography models. So that only easy images are selected for training when the model has poor fitting ability at the initial stage, and gradually expand to more difficult images, the strategy includes a difficulty evaluation strategy based on the teacher model and an knee point-based training scheduling strategy. Firstly, multiple teacher models are trained, and the consistency of the quality of steganographic images under multiple teacher models is used as the difficulty score to construct the training subsets from easy to difficult. Secondly, a training control strategy based on knee points is proposed to reduce the possibility of overfitting on small training sets and accelerate the training process. Experimental results on three large public datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed image steganography scheme is able to improve the model performance under multiple algorithmic frameworks, which not only has a high PSNR, SSIM score, and decoding accuracy, but also the steganographic images generated by the model under the training of the STCL strategy have a low steganography analysis scores. You can find our code at \\href{this https URL}{this https URL}.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17609",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.031033Z"
  },
  {
    "id": "920c700b3be1fc3137f6946bb6b3a889",
    "title": "Enhancing CNNs robustness to occlusions with bioinspired filters for border completion",
    "slug": "enhancing-cnns-robustness-to-occlusions-with-bioinspired-filters-for-border-completion",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Catarina P. Coutinho",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We exploit the mathematical modeling of the visual cortex mechanism for border completion to define custom filters for CNNs. We see a consistent improvement in performance, particularly in accuracy, when our modified LeNet 5 is tested with occluded MNIST images.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17619",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.031245Z"
  },
  {
    "id": "5a31909be218f208883e1952c0a3579b",
    "title": "Improving Open-World Object Localization by Discovering Background",
    "slug": "improving-open-world-object-localization-by-discovering-background",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ashish Singh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Our work addresses the problem of learning to localize objects in an open-world setting, i.e., given the bounding box information of a limited number of object classes during training, the goal is to localize all objects, belonging to both the training and unseen classes in an image, during inference. Towards this end, recent work in this area has focused on improving the characterization of objects either explicitly by proposing new objective functions (localization quality) or implicitly using object-centric auxiliary-information, such as depth information, pixel/region affinity map etc. In this work, we address this problem by incorporating background information to guide the learning of the notion of objectness. Specifically, we propose a novel framework to discover background regions in an image and train an object proposal network to not detect any objects in these regions. We formulate the background discovery task as that of identifying image regions that are not discriminative, i.e., those that are redundant and constitute low information content. We conduct experiments on standard benchmarks to showcase the effectiveness of our proposed approach and observe significant improvements over the previous state-of-the-art approaches for this task.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17626",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.031462Z"
  },
  {
    "id": "d1fc37227f814c2c7c3f17d2354873c4",
    "title": "A Guide to Structureless Visual Localization",
    "slug": "a-guide-to-structureless-visual-localization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Vojtech Panek",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Visual localization algorithms, i.e., methods that estimate the camera pose of a query image in a known scene, are core components of many applications, including self-driving cars and augmented / mixed reality systems. State-of-the-art visual localization algorithms are structure-based, i.e., they store a 3D model of the scene and use 2D-3D correspondences between the query image and 3D points in the model for camera pose estimation. While such approaches are highly accurate, they are also rather inflexible when it comes to adjusting the underlying 3D model after changes in the scene. Structureless localization approaches represent the scene as a database of images with known poses and thus offer a much more flexible representation that can be easily updated by adding or removing images. Although there is a large amount of literature on structure-based approaches, there is significantly less work on structureless methods. Hence, this paper is dedicated to providing the, to the best of our knowledge, first comprehensive discussion and comparison of structureless methods. Extensive experiments show that approaches that use a higher degree of classical geometric reasoning generally achieve higher pose accuracy. In particular, approaches based on classical absolute or semi-generalized relative pose estimation outperform very recent methods based on pose regression by a wide margin. Compared with state-of-the-art structure-based approaches, the flexibility of structureless methods comes at the cost of (slightly) lower pose accuracy, indicating an interesting direction for future work.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17636",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.031679Z"
  },
  {
    "id": "fbcf32ad5b5bb4b5adbca5e89d12b2f2",
    "title": "CLIPSE -- a minimalistic CLIP-based image search engine for research",
    "slug": "clipse----a-minimalistic-clip-based-image-search-engine-for-research",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Steve Gring",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A brief overview of CLIPSE, a self-hosted image search engine with the main application of research, is provided. In general, CLIPSE uses CLIP embeddings to process the images and also the text queries. The overall framework is designed with simplicity to enable easy extension and usage. Two benchmark scenarios are described and evaluated, covering indexing and querying time. It is shown that CLIPSE is capable of handling smaller datasets; for larger datasets, a distributed approach with several instances should be considered.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17643",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.031866Z"
  },
  {
    "id": "d93171ca30e5c696615253e30cd4e7ce",
    "title": "DiMeR: Disentangled Mesh Reconstruction Model",
    "slug": "dimer:-disentangled-mesh-reconstruction-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Lutao Jiang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "With the advent of large-scale 3D datasets, feed-forward 3D generative models, such as the Large Reconstruction Model (LRM), have gained significant attention and achieved remarkable success. However, we observe that RGB images often lead to conflicting training objectives and lack the necessary clarity for geometry reconstruction. In this paper, we revisit the inductive biases associated with mesh reconstruction and introduce DiMeR, a novel disentangled dual-stream feed-forward model for sparse-view mesh reconstruction. The key idea is to disentangle both the input and framework into geometry and texture parts, thereby reducing the training difficulty for each part according to the Principle of Occam's Razor. Given that normal maps are strictly consistent with geometry and accurately capture surface variations, we utilize normal maps as exclusive input for the geometry branch to reduce the complexity between the network's input and output. Moreover, we improve the mesh extraction algorithm to introduce 3D ground truth supervision. As for texture branch, we use RGB images as input to obtain the textured mesh. Overall, DiMeR demonstrates robust capabilities across various tasks, including sparse-view reconstruction, single-image-to-3D, and text-to-3D. Numerous experiments show that DiMeR significantly outperforms previous methods, achieving over 30% improvement in Chamfer Distance on the GSO and OmniObject3D dataset.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17670",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.032098Z"
  },
  {
    "id": "88765d23adf4c2dfe707219885d0dd81",
    "title": "PICO: Reconstructing 3D People In Contact with Objects",
    "slug": "pico:-reconstructing-3d-people-in-contact-with-objects",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Alpr Cseke",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recovering 3D Human-Object Interaction (HOI) from single color images is challenging due to depth ambiguities, occlusions, and the huge variation in object shape and appearance. Thus, past work requires controlled settings such as known object shapes and contacts, and tackles only limited object classes. Instead, we need methods that generalize to natural images and novel object classes. We tackle this in two main ways: (1) We collect PICO-db, a new dataset of natural images uniquely paired with dense 3D contact on both body and object meshes. To this end, we use images from the recent DAMON dataset that are paired with contacts, but these contacts are only annotated on a canonical 3D body. In contrast, we seek contact labels on both the body and the object. To infer these given an image, we retrieve an appropriate 3D object mesh from a database by leveraging vision foundation models. Then, we project DAMON's body contact patches onto the object via a novel method needing only 2 clicks per patch. This minimal human input establishes rich contact correspondences between bodies and objects. (2) We exploit our new dataset of contact correspondences in a novel render-and-compare fitting method, called PICO-fit, to recover 3D body and object meshes in interaction. PICO-fit infers contact for the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-db for that object, and uses the contact to iteratively fit the 3D body and object meshes to image evidence via optimization. Uniquely, PICO-fit works well for many object categories that no existing method can tackle. This is crucial to enable HOI understanding to scale in the wild. Our data and code are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17695",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.032325Z"
  },
  {
    "id": "f2f6206e1bec64239909b8ba0adcbc74",
    "title": "Hierarchical and Multimodal Data for Daily Activity Understanding",
    "slug": "hierarchical-and-multimodal-data-for-daily-activity-understanding",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ghazal Kaviani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Daily Activity Recordings for Artificial Intelligence (DARai, pronounced \"Dahr-ree\") is a multimodal, hierarchically annotated dataset constructed to understand human activities in real-world settings. DARai consists of continuous scripted and unscripted recordings of 50 participants in 10 different environments, totaling over 200 hours of data from 20 sensors including multiple camera views, depth and radar sensors, wearable inertial measurement units (IMUs), electromyography (EMG), insole pressure sensors, biomonitor sensors, and gaze tracker.\nTo capture the complexity in human activities, DARai is annotated at three levels of hierarchy: (i) high-level activities (L1) that are independent tasks, (ii) lower-level actions (L2) that are patterns shared between activities, and (iii) fine-grained procedures (L3) that detail the exact execution steps for actions. The dataset annotations and recordings are designed so that 22.7% of L2 actions are shared between L1 activities and 14.2% of L3 procedures are shared between L2 actions. The overlap and unscripted nature of DARai allows counterfactual activities in the dataset.\nExperiments with various machine learning models showcase the value of DARai in uncovering important challenges in human-centered applications. Specifically, we conduct unimodal and multimodal sensor fusion experiments for recognition, temporal localization, and future action anticipation across all hierarchical annotation levels. To highlight the limitations of individual sensors, we also conduct domain-variant experiments that are enabled by DARai's multi-sensor and counterfactual activity design setup.\nThe code, documentation, and dataset are available at the dedicated DARai website: this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17696",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.032557Z"
  },
  {
    "id": "203a3f73f68432bd7394b03bf9a84267",
    "title": "Generative Fields: Uncovering Hierarchical Feature Control for StyleGAN via Inverted Receptive Fields",
    "slug": "generative-fields:-uncovering-hierarchical-feature-control-for-stylegan-via-inverted-receptive-fields",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhuo He",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "StyleGAN has demonstrated the ability of GANs to synthesize highly-realistic faces of imaginary people from random noise. One limitation of GAN-based image generation is the difficulty of controlling the features of the generated image, due to the strong entanglement of the low-dimensional latent space. Previous work that aimed to control StyleGAN with image or text prompts modulated sampling in W latent space, which is more expressive than Z latent space. However, W space still has restricted expressivity since it does not control the feature synthesis directly; also the feature embedding in W space requires a pre-training process to reconstruct the style signal, limiting its application. This paper introduces the concept of \"generative fields\" to explain the hierarchical feature synthesis in StyleGAN, inspired by the receptive fields of convolution neural networks (CNNs). Additionally, we propose a new image editing pipeline for StyleGAN using generative field theory and the channel-wise style latent space S, utilizing the intrinsic structural feature of CNNs to achieve disentangled control of feature synthesis at synthesis time.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17712",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.032759Z"
  },
  {
    "id": "37fd46e884d66b7b943756a025b27094",
    "title": "DPMambaIR:All-in-One Image Restoration via Degradation-Aware Prompt State Space Model",
    "slug": "dpmambair:all-in-one-image-restoration-via-degradation-aware-prompt-state-space-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhanwen Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "All-in-One image restoration aims to address multiple image degradation problems using a single model, significantly reducing training costs and deployment complexity compared to traditional methods that design dedicated models for each degradation type. Existing approaches typically rely on Degradation-specific models or coarse-grained degradation prompts to guide image restoration. However, they lack fine-grained modeling of degradation information and face limitations in balancing multi-task conflicts. To overcome these limitations, we propose DPMambaIR, a novel All-in-One image restoration framework. By integrating a Degradation-Aware Prompt State Space Model (DP-SSM) and a High-Frequency Enhancement Block (HEB), DPMambaIR enables fine-grained modeling of complex degradation information and efficient global integration, while mitigating the loss of high-frequency details caused by task competition. Specifically, the DP-SSM utilizes a pre-trained degradation extractor to capture fine-grained degradation features and dynamically incorporates them into the state space modeling process, enhancing the model's adaptability to diverse degradation types. Concurrently, the HEB supplements high-frequency information, effectively addressing the loss of critical details, such as edges and textures, in multi-task image restoration scenarios. Extensive experiments on a mixed dataset containing seven degradation types show that DPMambaIR achieves the best performance, with 27.69dB and 0.893 in PSNR and SSIM, respectively. These results highlight the potential and superiority of DPMambaIR as a unified solution for All-in-One image restoration.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17732",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.032967Z"
  },
  {
    "id": "b7fa5d587e20d2112f4471cf18b9b463",
    "title": "EgoCHARM: Resource-Efficient Hierarchical Activity Recognition using an Egocentric IMU Sensor",
    "slug": "egocharm:-resource-efficient-hierarchical-activity-recognition-using-an-egocentric-imu-sensor",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Akhil Padmanabha",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Human activity recognition (HAR) on smartglasses has various use cases, including health/fitness tracking and input for context-aware AI assistants. However, current approaches for egocentric activity recognition suffer from low performance or are resource-intensive. In this work, we introduce a resource (memory, compute, power, sample) efficient machine learning algorithm, EgoCHARM, for recognizing both high level and low level activities using a single egocentric (head-mounted) Inertial Measurement Unit (IMU). Our hierarchical algorithm employs a semi-supervised learning strategy, requiring primarily high level activity labels for training, to learn generalizable low level motion embeddings that can be effectively utilized for low level activity recognition. We evaluate our method on 9 high level and 3 low level activities achieving 0.826 and 0.855 F1 scores on high level and low level activity recognition respectively, with just 63k high level and 22k low level model parameters, allowing the low level encoder to be deployed directly on current IMU chips with compute. Lastly, we present results and insights from a sensitivity analysis and highlight the opportunities and limitations of activity recognition using egocentric IMUs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17735",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.033180Z"
  },
  {
    "id": "4fe456ea8f828b68b4cfead943575002",
    "title": "Step1X-Edit: A Practical Framework for General Image Editing",
    "slug": "step1x-edit:-a-practical-framework-for-general-image-editing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Shiyu Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In recent years, image editing models have witnessed remarkable and rapid development. The recent unveiling of cutting-edge multimodal models such as GPT-4o and Gemini2 Flash has introduced highly promising image editing capabilities. These models demonstrate an impressive aptitude for fulfilling a vast majority of user-driven editing requirements, marking a significant advancement in the field of image manipulation. However, there is still a large gap between the open-source algorithm with these closed-source models. Thus, in this paper, we aim to release a state-of-the-art image editing model, called Step1X-Edit, which can provide comparable performance against the closed-source models like GPT-4o and Gemini2 Flash. More specifically, we adopt the Multimodal LLM to process the reference image and the user's editing instruction. A latent embedding has been extracted and integrated with a diffusion image decoder to obtain the target image. To train the model, we build a data generation pipeline to produce a high-quality dataset. For evaluation, we develop the GEdit-Bench, a novel benchmark rooted in real-world user instructions. Experimental results on GEdit-Bench demonstrate that Step1X-Edit outperforms existing open-source baselines by a substantial margin and approaches the performance of leading proprietary models, thereby making significant contributions to the field of image editing.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17761",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.033473Z"
  },
  {
    "id": "09eb3cf224cbedc9f2d545e34cc842d5",
    "title": "The Fourth Monocular Depth Estimation Challenge",
    "slug": "the-fourth-monocular-depth-estimation-challenge",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Anton Obukhov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper presents the results of the fourth edition of the Monocular Depth Estimation Challenge (MDEC), which focuses on zero-shot generalization to the SYNS-Patches benchmark, a dataset featuring challenging environments in both natural and indoor settings. In this edition, we revised the evaluation protocol to use least-squares alignment with two degrees of freedom to support disparity and affine-invariant predictions. We also revised the baselines and included popular off-the-shelf methods: Depth Anything v2 and Marigold. The challenge received a total of 24 submissions that outperformed the baselines on the test set; 10 of these included a report describing their approach, with most leading methods relying on affine-invariant predictions. The challenge winners improved the 3D F-Score over the previous edition's best result, raising it from 22.58% to 23.05%.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17787",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.033889Z"
  },
  {
    "id": "3145964fe5ab5bd4785d889dff7dd643",
    "title": "Dynamic Camera Poses and Where to Find Them",
    "slug": "dynamic-camera-poses-and-where-to-find-them",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Chris Rockwell",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Annotating camera poses on dynamic Internet videos at scale is critical for advancing fields like realistic video generation and simulation. However, collecting such a dataset is difficult, as most Internet videos are unsuitable for pose estimation. Furthermore, annotating dynamic Internet videos present significant challenges even for state-of-theart methods. In this paper, we introduce DynPose-100K, a large-scale dataset of dynamic Internet videos annotated with camera poses. Our collection pipeline addresses filtering using a carefully combined set of task-specific and generalist models. For pose estimation, we combine the latest techniques of point tracking, dynamic masking, and structure-from-motion to achieve improvements over the state-of-the-art approaches. Our analysis and experiments demonstrate that DynPose-100K is both large-scale and diverse across several key attributes, opening up avenues for advancements in various downstream applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17788",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.034113Z"
  },
  {
    "id": "91aa23eb16f7c44dc87fcd76e473ac05",
    "title": "Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models",
    "slug": "token-shuffle:-towards-high-resolution-image-generation-with-autoregressive-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Xu Ma",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autoregressive (AR) models, long dominant in language generation, are increasingly applied to image synthesis but are often considered less competitive than Diffusion-based models. A primary limitation is the substantial number of image tokens required for AR models, which constrains both training and inference efficiency, as well as image resolution. To address this, we present Token-Shuffle, a novel yet simple method that reduces the number of image tokens in Transformer. Our key insight is the dimensional redundancy of visual vocabularies in Multimodal Large Language Models (MLLMs), where low-dimensional visual codes from visual encoder are directly mapped to high-dimensional language vocabularies. Leveraging this, we consider two key operations: token-shuffle, which merges spatially local tokens along channel dimension to decrease the input token number, and token-unshuffle, which untangles the inferred tokens after Transformer blocks to restore the spatial arrangement for output. Jointly training with textual prompts, our strategy requires no additional pretrained text-encoder and enables MLLMs to support extremely high-resolution image synthesis in a unified next-token prediction way while maintaining efficient training and inference. For the first time, we push the boundary of AR text-to-image generation to a resolution of 2048x2048 with gratifying generation performance. In GenAI-benchmark, our 2.7B model achieves 0.77 overall score on hard prompts, outperforming AR models LlamaGen by 0.18 and diffusion models LDM by 0.15. Exhaustive large-scale human evaluations also demonstrate our prominent image generation ability in terms of text-alignment, visual flaw, and visual appearance. We hope that Token-Shuffle can serve as a foundational design for efficient high-resolution image generation within MLLMs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17789",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.034395Z"
  },
  {
    "id": "71da74e13beb4c9ecfb43428d37ddf61",
    "title": "LiDPM: Rethinking Point Diffusion for Lidar Scene Completion",
    "slug": "lidpm:-rethinking-point-diffusion-for-lidar-scene-completion",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Tetiana Martyniuk",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Training diffusion models that work directly on lidar points at the scale of outdoor scenes is challenging due to the difficulty of generating fine-grained details from white noise over a broad field of view. The latest works addressing scene completion with diffusion models tackle this problem by reformulating the original DDPM as a local diffusion process. It contrasts with the common practice of operating at the level of objects, where vanilla DDPMs are currently used. In this work, we close the gap between these two lines of work. We identify approximations in the local diffusion formulation, show that they are not required to operate at the scene level, and that a vanilla DDPM with a well-chosen starting point is enough for completion. Finally, we demonstrate that our method, LiDPM, leads to better results in scene completion on SemanticKITTI. The project page is this https URL .",
    "pdfUrl": "https://arxiv.org/pdf/2504.17791",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.034617Z"
  },
  {
    "id": "2f04694a80e004ca454d74bb3f17455a",
    "title": "Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness",
    "slug": "multifaceted-evaluation-of-audio-visual-capability-for-mllms:-effectiveness,-efficiency,-generalizability-and-robustness",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multimedia (cs.MM)",
    "author": {
      "name": "Yusheng Zhao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Multi-modal large language models (MLLMs) have recently achieved great success in processing and understanding information from diverse modalities (e.g., text, audio, and visual signals). Despite their growing popularity, there remains a lack of comprehensive evaluation measuring the audio-visual capabilities of these models, especially in diverse scenarios (e.g., distribution shifts and adversarial attacks). In this paper, we present a multifaceted evaluation of the audio-visual capability of MLLMs, focusing on four key dimensions: effectiveness, efficiency, generalizability, and robustness. Through extensive experiments, we find that MLLMs exhibit strong zero-shot and few-shot generalization abilities, enabling them to achieve great performance with limited data. However, their success relies heavily on the vision modality, which impairs performance when visual input is corrupted or missing. Additionally, while MLLMs are susceptible to adversarial samples, they demonstrate greater robustness compared to traditional models. The experimental results and our findings provide insights into the audio-visual capabilities of MLLMs, highlighting areas for improvement and offering guidance for future research.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16936",
    "tags": [
      "Multimedia (cs.MM)"
    ],
    "createdAt": "2025-04-25T15:49:18.034841Z"
  },
  {
    "id": "84e782f1ac88b1e346b415d015891709",
    "title": "Can deep neural networks learn biological vision?",
    "slug": "can-deep-neural-networks-learn-biological-vision?",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neurons and Cognition (q-bio.NC)",
    "author": {
      "name": "Drew Linsley",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deep neural networks (DNNs) once showed increasing alignment with primate neural responses as they improved on computer vision benchmarks. This trend raised the exciting possibility that better models of biological vision would come as a byproduct of the deep learning revolution in artificial intelligence. However, the trend has reversed over recent years as DNNs have scaled to human or superhuman recognition accuracy, a divergence that may stem from modern DNNs learning to rely on different visual features than primates to solve tasks. Where will better computational models of biological vision come from? We propose that vision science must break from artificial intelligence to develop algorithms that are designed with biological visual systems in mind instead of internet data benchmarks. We predict that the next generation of deep learning models of biological vision will be trained with data diets, training routines, and objectives that are closer to those that shape human vision than those that are in use today.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16940",
    "tags": [
      "Neurons and Cognition (q-bio.NC)"
    ],
    "createdAt": "2025-04-25T15:49:18.035039Z"
  },
  {
    "id": "aff718660d6028699b3a93012e4c9d3c",
    "title": "S2Vec: Self-Supervised Geospatial Embeddings",
    "slug": "s2vec:-self-supervised-geospatial-embeddings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Shushman Choudhury",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Scalable general-purpose representations of the built environment are crucial for geospatial artificial intelligence applications. This paper introduces S2Vec, a novel self-supervised framework for learning such geospatial embeddings. S2Vec uses the S2 Geometry library to partition large areas into discrete S2 cells, rasterizes built environment feature vectors within cells as images, and applies masked autoencoding on these rasterized images to encode the feature vectors. This approach yields task-agnostic embeddings that capture local feature characteristics and broader spatial relationships. We evaluate S2Vec on three large-scale socioeconomic prediction tasks, showing its competitive performance against state-of-the-art image-based embeddings. We also explore the benefits of combining S2Vec embeddings with image-based embeddings downstream, showing that such multimodal fusion can often improve performance. Our results highlight how S2Vec can learn effective general-purpose geospatial representations and how it can complement other data modalities in geospatial artificial intelligence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16942",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:18.035270Z"
  },
  {
    "id": "415c6f34ca176b6fa352fc8e703e9311",
    "title": "Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications",
    "slug": "unsupervised-time-series-signal-analysis-with-autoencoders-and-vision-transformers:-a-review-of-architectures-and-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hossein Ahmadi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid growth of unlabeled time-series data in domains such as wireless communications, radar, biomedical engineering, and the Internet of Things (IoT) has driven advancements in unsupervised learning. This review synthesizes recent progress in applying autoencoders and vision transformers for unsupervised signal analysis, focusing on their architectures, applications, and emerging trends. We explore how these models enable feature extraction, anomaly detection, and classification across diverse signal types, including electrocardiograms, radar waveforms, and IoT sensor data. The review highlights the strengths of hybrid architectures and self-supervised learning, while identifying challenges in interpretability, scalability, and domain generalization. By bridging methodological innovations and practical applications, this work offers a roadmap for developing robust, adaptive models for signal intelligence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16972",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:18.035474Z"
  },
  {
    "id": "69dbf2f95b69f4d99ccd3bce64ffd11c",
    "title": "Seeing The Words: Evaluating AI-generated Biblical Art",
    "slug": "seeing-the-words:-evaluating-ai-generated-biblical-art",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Hidde Makimei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The past years witnessed a significant amount of Artificial Intelligence (AI) tools that can generate images from texts. This triggers the discussion of whether AI can generate accurate images using text from the Bible with respect to the corresponding biblical contexts and backgrounds. Despite some existing attempts at a small scale, little work has been done to systematically evaluate these generated images. In this work, we provide a large dataset of over 7K images using biblical text as prompts. These images were evaluated with multiple neural network-based tools on various aspects. We provide an assessment of accuracy and some analysis from the perspective of religion and aesthetics. Finally, we discuss the use of the generated images and reflect on the performance of the AI generators.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16974",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:18.035686Z"
  },
  {
    "id": "bf2a280b9366954b5997e2130743fb35",
    "title": "Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline",
    "slug": "automating-tumor-infiltrating-lymphocyte-assessment-in-breast-cancer-histopathology-images-using-qupath:-a-transparent-and-accessible-machine-learning-pipeline",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantitative Methods (q-bio.QM)",
    "author": {
      "name": "Masoud Tafavvoghi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs) assessment pipeline within QuPath, demonstrating the potential of easily accessible tools to perform complex tasks in a fully automatic fashion. First, we trained a pixel classifier to segment tumor, tumor-associated stroma, and other tissue compartments in breast cancer H&E-stained whole-slide images (WSI) to isolate tumor-associated stroma for subsequent analysis. Next, we applied a pre-trained StarDist deep learning model in QuPath for cell detection and used the extracted cell features to train a binary classifier distinguishing TILs from other cells. To evaluate our TILs assessment pipeline, we calculated the TIL density in each WSI and categorized them as low, medium, or high TIL levels. Our pipeline was evaluated against pathologist-assigned TIL scores, achieving a Cohen's kappa of 0.71 on the external test set, corroborating previous research findings. These results confirm that existing software can offer a practical solution for the assessment of TILs in H&E-stained WSIs of breast cancer.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16979",
    "tags": [
      "Quantitative Methods (q-bio.QM)"
    ],
    "createdAt": "2025-04-25T15:49:18.035910Z"
  },
  {
    "id": "3cb0ad0ed8807999977727088f97967a",
    "title": "ePBR: Extended PBR Materials in Image Synthesis",
    "slug": "epbr:-extended-pbr-materials-in-image-synthesis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Graphics (cs.GR)",
    "author": {
      "name": "Yu Guo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Realistic indoor or outdoor image synthesis is a core challenge in computer vision and graphics. The learning-based approach is easy to use but lacks physical consistency, while traditional Physically Based Rendering (PBR) offers high realism but is computationally expensive. Intrinsic image representation offers a well-balanced trade-off, decomposing images into fundamental components (intrinsic channels) such as geometry, materials, and illumination for controllable synthesis. However, existing PBR materials struggle with complex surface models, particularly high-specular and transparent surfaces. In this work, we extend intrinsic image representations to incorporate both reflection and transmission properties, enabling the synthesis of transparent materials such as glass and windows. We propose an explicit intrinsic compositing framework that provides deterministic, interpretable image synthesis. With the Extended PBR (ePBR) Materials, we can effectively edit the materials with precise controls.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17062",
    "tags": [
      "Graphics (cs.GR)"
    ],
    "createdAt": "2025-04-25T15:49:18.036134Z"
  },
  {
    "id": "54b63462d0908033f1d281ca16505a45",
    "title": "Anatomy-constrained modelling of image-derived input functions in dynamic PET using multi-organ segmentation",
    "slug": "anatomy-constrained-modelling-of-image-derived-input-functions-in-dynamic-pet-using-multi-organ-segmentation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Valentin Langer",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate kinetic analysis of [$^{18}$F]FDG distribution in dynamic positron emission tomography (PET) requires anatomically constrained modelling of image-derived input functions (IDIFs). Traditionally, IDIFs are obtained from the aorta, neglecting anatomical variations and complex vascular contributions. This study proposes a multi-organ segmentation-based approach that integrates IDIFs from the aorta, portal vein, pulmonary artery, and ureters. Using high-resolution CT segmentations of the liver, lungs, kidneys, and bladder, we incorporate organ-specific blood supply sources to improve kinetic modelling. Our method was evaluated on dynamic [$^{18}$F]FDG PET data from nine patients, resulting in a mean squared error (MSE) reduction of $13.39\\%$ for the liver and $10.42\\%$ for the lungs. These initial results highlight the potential of multiple IDIFs in improving anatomical modelling and fully leveraging dynamic PET imaging. This approach could facilitate the integration of tracer kinetic modelling into clinical routine.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17114",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:18.036344Z"
  },
  {
    "id": "6d1a944f6f75fab30cfc8bfbc07bf42f",
    "title": "Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET",
    "slug": "physiological-neural-representation-for-personalised-tracer-kinetic-parameter-estimation-from-dynamic-pet",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Kartikay Tehlan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables non-invasive quantification of glucose metabolism through kinetic analysis, often modelled by the two-tissue compartment model (TCKM). However, voxel-wise kinetic parameter estimation using conventional methods is computationally intensive and limited by spatial resolution. Deep neural networks (DNNs) offer an alternative but require large training datasets and significant computational resources. To address these limitations, we propose a physiological neural representation based on implicit neural representations (INRs) for personalized kinetic parameter estimation. INRs, which learn continuous functions, allow for efficient, high-resolution parametric imaging with reduced data requirements. Our method also integrates anatomical priors from a 3D CT foundation model to enhance robustness and precision in kinetic modelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset and compare it to state-of-the-art DNNs. Results demonstrate superior spatial resolution, lower mean-squared error, and improved anatomical consistency, particularly in tumour and highly vascularized regions. Our findings highlight the potential of INRs for personalized, data-efficient tracer kinetic modelling, enabling applications in tumour characterization, segmentation, and prognostic assessment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17122",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:18.036543Z"
  },
  {
    "id": "f7e6ee346e69e11dec819132edc3d22d",
    "title": "OUI Need to Talk About Weight Decay: A New Perspective on Overfitting Detection",
    "slug": "oui-need-to-talk-about-weight-decay:-a-new-perspective-on-overfitting-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Alberto Fernndez-Hernndez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce the Overfitting-Underfitting Indicator (OUI), a novel tool for monitoring the training dynamics of Deep Neural Networks (DNNs) and identifying optimal regularization hyperparameters. Specifically, we validate that OUI can effectively guide the selection of the Weight Decay (WD) hyperparameter by indicating whether a model is overfitting or underfitting during training without requiring validation data. Through experiments on DenseNet-BC-100 with CIFAR- 100, EfficientNet-B0 with TinyImageNet and ResNet-34 with ImageNet-1K, we show that maintaining OUI within a prescribed interval correlates strongly with improved generalization and validation scores. Notably, OUI converges significantly faster than traditional metrics such as loss or accuracy, enabling practitioners to identify optimal WD (hyperparameter) values within the early stages of training. By leveraging OUI as a reliable indicator, we can determine early in training whether the chosen WD value leads the model to underfit the training data, overfit, or strike a well-balanced trade-off that maximizes validation scores. This enables more precise WD tuning for optimal performance on the tested datasets and DNNs. All code for reproducing these experiments is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17160",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:18.036759Z"
  },
  {
    "id": "10536ca35011acc43f303910cb696ecc",
    "title": "AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models",
    "slug": "authentication:-identifying-rare-failure-modes-in-autonomous-vehicle-perception-systems-using-adversarially-guided-diffusion-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Mohammad Zarei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autonomous Vehicles (AVs) rely on artificial intelligence (AI) to accurately detect objects and interpret their surroundings. However, even when trained using millions of miles of real-world data, AVs are often unable to detect rare failure modes (RFMs). The problem of RFMs is commonly referred to as the \"long-tail challenge\", due to the distribution of data including many instances that are very rarely seen. In this paper, we present a novel approach that utilizes advanced generative and explainable AI techniques to aid in understanding RFMs. Our methods can be used to enhance the robustness and reliability of AVs when combined with both downstream model training and testing. We extract segmentation masks for objects of interest (e.g., cars) and invert them to create environmental masks. These masks, combined with carefully crafted text prompts, are fed into a custom diffusion model. We leverage the Stable Diffusion inpainting model guided by adversarial noise optimization to generate images containing diverse environments designed to evade object detection models and expose vulnerabilities in AI systems. Finally, we produce natural language descriptions of the generated RFMs that can guide developers and policymakers to improve the safety and reliability of AV systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17179",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:18.036974Z"
  },
  {
    "id": "2db535dab7f7a4b99959939e62fb4c44",
    "title": "Group Downsampling with Equivariant Anti-aliasing",
    "slug": "group-downsampling-with-equivariant-anti-aliasing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Md Ashiqur Rahman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Downsampling layers are crucial building blocks in CNN architectures, which help to increase the receptive field for learning high-level features and reduce the amount of memory/computation in the model. In this work, we study the generalization of the uniform downsampling layer for group equivariant architectures, e.g., G-CNNs. That is, we aim to downsample signals (feature maps) on general finite groups with anti-aliasing. This involves the following: (a) Given a finite group and a downsampling rate, we present an algorithm to form a suitable choice of subgroup. (b) Given a group and a subgroup, we study the notion of bandlimited-ness and propose how to perform anti-aliasing. Notably, our method generalizes the notion of downsampling based on classical sampling theory. When the signal is on a cyclic group, i.e., periodic, our method recovers the standard downsampling of an ideal low-pass filter followed by a subsampling operation. Finally, we conducted experiments on image classification tasks demonstrating that the proposed downsampling operation improves accuracy, better preserves equivariance, and reduces model size when incorporated into G-equivariant networks",
    "pdfUrl": "https://arxiv.org/pdf/2504.17258",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:18.037192Z"
  },
  {
    "id": "939e40318bd4d436f29eb7d08ea54038",
    "title": "Class-Conditional Distribution Balancing for Group Robust Classification",
    "slug": "class-conditional-distribution-balancing-for-group-robust-classification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Miaoyun Zhao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Spurious correlations that lead models to correct predictions for the wrong reasons pose a critical challenge for robust real-world generalization. Existing research attributes this issue to group imbalance and addresses it by maximizing group-balanced or worst-group accuracy, which heavily relies on expensive bias annotations. A compromise approach involves predicting bias information using extensively pretrained foundation models, which requires large-scale data and becomes impractical for resource-limited rare domains. To address these challenges, we offer a novel perspective by reframing the spurious correlations as imbalances or mismatches in class-conditional distributions, and propose a simple yet effective robust learning method that eliminates the need for both bias annotations and predictions. With the goal of reducing the mutual information between spurious factors and label information, our method leverages a sample reweighting strategy to achieve class-conditional distribution balancing, which automatically highlights minority groups and classes, effectively dismantling spurious correlations and producing a debiased data distribution for classification. Extensive experiments and analysis demonstrate that our approach consistently delivers state-of-the-art performance, rivaling methods that rely on bias supervision.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17314",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:18.037398Z"
  },
  {
    "id": "c5f51ddf1e236c42a1010be74ea43d8a",
    "title": "M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction",
    "slug": "m-mre:-extending-the-mutual-reinforcement-effect-to-multimodal-information-extraction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Chengguang Gan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Mutual Reinforcement Effect (MRE) is an emerging subfield at the intersection of information extraction and model interpretability. MRE aims to leverage the mutual understanding between tasks of different granularities, enhancing the performance of both coarse-grained and fine-grained tasks through joint modeling. While MRE has been explored and validated in the textual domain, its applicability to visual and multimodal domains remains unexplored. In this work, we extend MRE to the multimodal information extraction domain for the first time. Specifically, we introduce a new task: Multimodal Mutual Reinforcement Effect (M-MRE), and construct a corresponding dataset to support this task. To address the challenges posed by M-MRE, we further propose a Prompt Format Adapter (PFA) that is fully compatible with various Large Vision-Language Models (LVLMs). Experimental results demonstrate that MRE can also be observed in the M-MRE task, a multimodal text-image understanding scenario. This provides strong evidence that MRE facilitates mutual gains across three interrelated tasks, confirming its generalizability beyond the textual domain.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17353",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:18.037617Z"
  },
  {
    "id": "28d3a69e0a4a8e38dbdd48af8f288955",
    "title": "A Spatially-Aware Multiple Instance Learning Framework for Digital Pathology",
    "slug": "a-spatially-aware-multiple-instance-learning-framework-for-digital-pathology",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Hassan Keshvarikhojasteh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Multiple instance learning (MIL) is a promising approach for weakly supervised classification in pathology using whole slide images (WSIs). However, conventional MIL methods such as Attention-Based Deep Multiple Instance Learning (ABMIL) typically disregard spatial interactions among patches that are crucial to pathological diagnosis. Recent advancements, such as Transformer based MIL (TransMIL), have incorporated spatial context and inter-patch relationships. However, it remains unclear whether explicitly modeling patch relationships yields similar performance gains in ABMIL, which relies solely on Multi-Layer Perceptrons (MLPs). In contrast, TransMIL employs Transformer-based layers, introducing a fundamental architectural shift at the cost of substantially increased computational complexity. In this work, we enhance the ABMIL framework by integrating interaction-aware representations to address this question. Our proposed model, Global ABMIL (GABMIL), explicitly captures inter-instance dependencies while preserving computational efficiency. Experimental results on two publicly available datasets for tumor subtyping in breast and lung cancers demonstrate that GABMIL achieves up to a 7 percentage point improvement in AUPRC and a 5 percentage point increase in the Kappa score over ABMIL, with minimal or no additional computational overhead. These findings underscore the importance of incorporating patch interactions within MIL frameworks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17379",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:18.037838Z"
  },
  {
    "id": "8050e94f36f06c6541c7e0fa37ac4557",
    "title": "The effects of Hessian eigenvalue spectral density type on the applicability of Hessian analysis to generalization capability assessment of neural networks",
    "slug": "the-effects-of-hessian-eigenvalue-spectral-density-type-on-the-applicability-of-hessian-analysis-to-generalization-capability-assessment-of-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Nikita Gabdullin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Hessians of neural network (NN) contain essential information about the curvature of NN loss landscapes which can be used to estimate NN generalization capabilities. We have previously proposed generalization criteria that rely on the observation that Hessian eigenvalue spectral density (HESD) behaves similarly for a wide class of NNs. This paper further studies their applicability by investigating factors that can result in different types of HESD. We conduct a wide range of experiments showing that HESD mainly has positive eigenvalues (MP-HESD) for NN training and fine-tuning with various optimizers on different datasets with different preprocessing and augmentation procedures. We also show that mainly negative HESD (MN-HESD) is a consequence of external gradient manipulation, indicating that the previously proposed Hessian analysis methodology cannot be applied in such cases. We also propose criteria and corresponding conditions to determine HESD type and estimate NN generalization potential. These HESD types and previously proposed generalization criteria are combined into a unified HESD analysis methodology. Finally, we discuss how HESD changes during training, and show the occurrence of quasi-singular (QS) HESD and its influence on the proposed methodology and on the conventional assumptions about the relation between Hessian eigenvalues and NN loss landscape curvature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17618",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:18.038034Z"
  },
  {
    "id": "7e4e0bcb396a3ef699a4e5b5660c969d",
    "title": "Beyond Labels: Zero-Shot Diabetic Foot Ulcer Wound Segmentation with Self-attention Diffusion Models and the Potential for Text-Guided Customization",
    "slug": "beyond-labels:-zero-shot-diabetic-foot-ulcer-wound-segmentation-with-self-attention-diffusion-models-and-the-potential-for-text-guided-customization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Abderrachid Hamrani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Diabetic foot ulcers (DFUs) pose a significant challenge in healthcare, requiring precise and efficient wound assessment to enhance patient outcomes. This study introduces the Attention Diffusion Zero-shot Unsupervised System (ADZUS), a novel text-guided diffusion model that performs wound segmentation without relying on labeled training data. Unlike conventional deep learning models, which require extensive annotation, ADZUS leverages zero-shot learning to dynamically adapt segmentation based on descriptive prompts, offering enhanced flexibility and adaptability in clinical applications. Experimental evaluations demonstrate that ADZUS surpasses traditional and state-of-the-art segmentation models, achieving an IoU of 86.68\\% and the highest precision of 94.69\\% on the chronic wound dataset, outperforming supervised approaches such as FUSegNet. Further validation on a custom-curated DFU dataset reinforces its robustness, with ADZUS achieving a median DSC of 75\\%, significantly surpassing FUSegNet's 45\\%. The model's text-guided segmentation capability enables real-time customization of segmentation outputs, allowing targeted analysis of wound characteristics based on clinical descriptions. Despite its competitive performance, the computational cost of diffusion-based inference and the need for potential fine-tuning remain areas for future improvement. ADZUS represents a transformative step in wound segmentation, providing a scalable, efficient, and adaptable AI-driven solution for medical imaging.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17628",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:18.038260Z"
  },
  {
    "id": "2635971a1de91b76163a038a7737c2ac",
    "title": "Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction",
    "slug": "aerial-image-classification-in-scarce-and-unconstrained-environments-via-conformal-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Farhad Pourkamali-Anaraki",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper presents a comprehensive empirical analysis of conformal prediction methods on a challenging aerial image dataset featuring diverse events in unconstrained environments. Conformal prediction is a powerful post-hoc technique that takes the output of any classifier and transforms it into a set of likely labels, providing a statistical guarantee on the coverage of the true label. Unlike evaluations on standard benchmarks, our study addresses the complexities of data-scarce and highly variable real-world settings. We investigate the effectiveness of leveraging pretrained models (MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to generate informative prediction sets. To further evaluate the impact of calibration, we consider two parallel pipelines (with and without temperature scaling) and assess performance using two key metrics: empirical coverage and average prediction set size. This setup allows us to systematically examine how calibration choices influence the trade-off between reliability and efficiency. Our findings demonstrate that even with relatively small labeled samples and simple nonconformity scores, conformal prediction can yield valuable uncertainty estimates for complex tasks. Moreover, our analysis reveals that while temperature scaling is often employed for calibration, it does not consistently lead to smaller prediction sets, underscoring the importance of careful consideration in its application. Furthermore, our results highlight the significant potential of model compression techniques within the conformal prediction pipeline for deployment in resource-constrained environments. Based on our observations, we advocate for future research to delve into the impact of noisy or ambiguous labels on conformal prediction performance and to explore effective model reduction strategies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17655",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:18.038455Z"
  },
  {
    "id": "8c307911f3454941d9066256ce2f03ff",
    "title": "BIM-Constrained Optimization for Accurate Localization and Deviation Correction in Construction Monitoring",
    "slug": "bim-constrained-optimization-for-accurate-localization-and-deviation-correction-in-construction-monitoring",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Asier Bikandi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Augmented reality (AR) applications for construction monitoring rely on real-time environmental tracking to visualize architectural elements. However, construction sites present significant challenges for traditional tracking methods due to featureless surfaces, dynamic changes, and drift accumulation, leading to misalignment between digital models and the physical world. This paper proposes a BIM-aware drift correction method to address these challenges. Instead of relying solely on SLAM-based localization, we align ``as-built\" detected planes from the real-world environment with ``as-planned\" architectural planes in BIM. Our method performs robust plane matching and computes a transformation (TF) between SLAM (S) and BIM (B) origin frames using optimization techniques, minimizing drift over time. By incorporating BIM as prior structural knowledge, we can achieve improved long-term localization and enhanced AR visualization accuracy in noisy construction environments. The method is evaluated through real-world experiments, showing significant reductions in drift-induced errors and optimized alignment consistency. On average, our system achieves a reduction of 52.24% in angular deviations and a reduction of 60.8% in the distance error of the matched walls compared to the initial manual alignment by the user.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17693",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:18.038667Z"
  },
  {
    "id": "b2fa132e3ef37209c0fd07c20959782e",
    "title": "Plasma State Monitoring and Disruption Characterization using Multimodal VAEs",
    "slug": "plasma-state-monitoring-and-disruption-characterization-using-multimodal-vaes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Plasma Physics (physics.plasm-ph)",
    "author": {
      "name": "Yoeri Poels",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "When a plasma disrupts in a tokamak, significant heat and electromagnetic loads are deposited onto the surrounding device components. These forces scale with plasma current and magnetic field strength, making disruptions one of the key challenges for future devices. Unfortunately, disruptions are not fully understood, with many different underlying causes that are difficult to anticipate. Data-driven models have shown success in predicting them, but they only provide limited interpretability. On the other hand, large-scale statistical analyses have been a great asset to understanding disruptive patterns. In this paper, we leverage data-driven methods to find an interpretable representation of the plasma state for disruption characterization. Specifically, we use a latent variable model to represent diagnostic measurements as a low-dimensional, latent representation. We build upon the Variational Autoencoder (VAE) framework, and extend it for (1) continuous projections of plasma trajectories; (2) a multimodal structure to separate operating regimes; and (3) separation with respect to disruptive regimes. Subsequently, we can identify continuous indicators for the disruption rate and the disruptivity based on statistical properties of measurement data. The proposed method is demonstrated using a dataset of approximately 1600 TCV discharges, selecting for flat-top disruptions or regular terminations. We evaluate the method with respect to (1) the identified disruption risk and its correlation with other plasma properties; (2) the ability to distinguish different types of disruptions; and (3) downstream analyses. For the latter, we conduct a demonstrative study on identifying parameters connected to disruptions using counterfactual-like analysis. Overall, the method can adequately identify distinct operating regimes characterized by varying proximity to disruptions in an interpretable manner.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17710",
    "tags": [
      "Plasma Physics (physics.plasm-ph)"
    ],
    "createdAt": "2025-04-25T15:49:18.038893Z"
  },
  {
    "id": "b53723b0cd3055d810272f384041da44",
    "title": "CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos",
    "slug": "casualhdrsplat:-robust-high-dynamic-range-3d-gaussian-splatting-from-casually-captured-videos",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Graphics (cs.GR)",
    "author": {
      "name": "Shucheng Gong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, photo-realistic novel view synthesis from multi-view images, such as neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered widespread attention due to their superior performance. However, most works rely on low dynamic range (LDR) images, which limits the capturing of richer scene details. Some prior works have focused on high dynamic range (HDR) scene reconstruction, typically require capturing of multi-view sharp images with different exposure times at fixed camera positions during exposure times, which is time-consuming and challenging in practice. For a more flexible data acquisition, we propose a one-stage method: \\textbf{CasualHDRSplat} to easily and robustly reconstruct the 3D HDR scene from casually captured videos with auto-exposure enabled, even in the presence of severe motion blur and varying unknown exposure time. \\textbf{CasualHDRSplat} contains a unified differentiable physical imaging model which first applies continuous-time trajectory constraint to imaging process so that we can jointly optimize exposure time, camera response function (CRF), camera poses, and sharp 3D HDR scene. Extensive experiments demonstrate that our approach outperforms existing methods in terms of robustness and rendering quality. Our source code will be available at this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17728",
    "tags": [
      "Graphics (cs.GR)"
    ],
    "createdAt": "2025-04-25T15:49:18.039123Z"
  },
  {
    "id": "f54cafd087c13266da2cd8ebcca65557",
    "title": "ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization",
    "slug": "arf-plus:-controlling-perceptual-factors-in-artistic-radiance-fields-for-3d-scene-stylization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Wenzhao Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The radiance fields style transfer is an emerging field that has recently gained popularity as a means of 3D scene stylization, thanks to the outstanding performance of neural radiance fields in 3D reconstruction and view synthesis. We highlight a research gap in radiance fields style transfer, the lack of sufficient perceptual controllability, motivated by the existing concept in the 2D image style transfer. In this paper, we present ARF-Plus, a 3D neural style transfer framework offering manageable control over perceptual factors, to systematically explore the perceptual controllability in 3D scene stylization. Four distinct types of controls - color preservation control, (style pattern) scale control, spatial (selective stylization area) control, and depth enhancement control - are proposed and integrated into this framework. Results from real-world datasets, both quantitative and qualitative, show that the four types of controls in our ARF-Plus framework successfully accomplish their corresponding perceptual controls when stylizing 3D scenes. These techniques work well for individual style inputs as well as for the simultaneous application of multiple styles within a scene. This unlocks a realm of limitless possibilities, allowing customized modifications of stylization effects and flexible merging of the strengths of different styles, ultimately enabling the creation of novel and eye-catching stylistic effects on 3D scenes.",
    "pdfUrl": "https://arxiv.org/pdf/2308.12452",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.039470Z"
  },
  {
    "id": "fae9d29dfa7c4d6713f1481f63fa73ca",
    "title": "Event-based Continuous Color Video Decompression from Single Frames",
    "slug": "event-based-continuous-color-video-decompression-from-single-frames",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ziyun Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present ContinuityCam, a novel approach to generate a continuous video from a single static RGB image and an event camera stream. Conventional cameras struggle with high-speed motion capture due to bandwidth and dynamic range limitations. Event cameras are ideal sensors to solve this problem because they encode compressed change information at high temporal resolution. In this work, we tackle the problem of event-based continuous color video decompression, pairing single static color frames and event data to reconstruct temporally continuous videos. Our approach combines continuous long-range motion modeling with a neural synthesis model, enabling frame prediction at arbitrary times within the events. Our method only requires an initial image, thus increasing the robustness to sudden motions, light changes, minimizing the prediction latency, and decreasing bandwidth usage. We also introduce a novel single-lens beamsplitter setup that acquires aligned images and events, and a novel and challenging Event Extreme Decompression Dataset (E2D2) that tests the method in various lighting and motion profiles. We thoroughly evaluate our method by benchmarking color frame reconstruction, outperforming the baseline methods by 3.61 dB in PSNR and by 33% decrease in LPIPS, as well as showing superior results on two downstream tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2312.00113",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.039696Z"
  },
  {
    "id": "780b851eb1377243a9830ee11252c3d3",
    "title": "Fast OMP for Exact Recovery and Sparse Approximation",
    "slug": "fast-omp-for-exact-recovery-and-sparse-approximation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Huiyuan Yu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Orthogonal Matching Pursuit (OMP) has been a powerful method in sparse signal recovery and approximation. However OMP suffers computational issue when the signal has large number of non-zeros. This paper advances OMP in two fronts: it offers a fast algorithm for the orthogonal projection of the input signal at each iteration, and a new selection criterion for making the greedy choice, which reduces the number of iterations it takes to recover the signal. The proposed modifications to OMP directly reduce the computational complexity. Experiment results show significant improvement over the classical OMP in computation time. The paper also provided a sufficient condition for exact recovery under the new greedy choice criterion. For general signals that may not have sparse representations, the paper provides a bound for the approximation error. The approximation error is at the same order as OMP but is obtained within fewer iterations and less time.",
    "pdfUrl": "https://arxiv.org/pdf/2404.00146",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.039921Z"
  },
  {
    "id": "209372f1ccd220f80663a0f407699f6c",
    "title": "ObjectAdd: Adding Objects into Image via a Training-Free Diffusion Modification Fashion",
    "slug": "objectadd:-adding-objects-into-image-via-a-training-free-diffusion-modification-fashion",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ziyue Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce ObjectAdd, a training-free diffusion modification method to add user-expected objects into user-specified area. The motive of ObjectAdd stems from: first, describing everything in one prompt can be difficult, and second, users often need to add objects into the generated image. To accommodate with real world, our ObjectAdd maintains accurate image consistency after adding objects with technical innovations in: (1) embedding-level concatenation to ensure correct text embedding coalesce; (2) object-driven layout control with latent and attention injection to ensure objects accessing user-specified area; (3) prompted image inpainting in an attention refocusing & object expansion fashion to ensure rest of the image stays the same. With a text-prompted image, our ObjectAdd allows users to specify a box and an object, and achieves: (1) adding object inside the box area; (2) exact content outside the box area; (3) flawless fusion between the two areas",
    "pdfUrl": "https://arxiv.org/pdf/2404.17230",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.040138Z"
  },
  {
    "id": "44d56ae073cd2a51570a62bf6c7a3a25",
    "title": "AI in Lung Health: Benchmarking Detection and Diagnostic Models Across Multiple CT Scan Datasets",
    "slug": "ai-in-lung-health:-benchmarking-detection-and-diagnostic-models-across-multiple-ct-scan-datasets",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Fakrul Islam Tushar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Lung cancer remains the leading cause of cancer-related mortality worldwide, and early detection through low-dose computed tomography (LDCT) has shown significant promise in reducing death rates. With the growing integration of artificial intelligence (AI) into medical imaging, the development and evaluation of robust AI models require access to large, well-annotated datasets. In this study, we introduce the utility of Duke Lung Cancer Screening (DLCS) Dataset, the largest open-access LDCT dataset with over 2,000 scans and 3,000 expert-verified nodules. We benchmark deep learning models for both 3D nodule detection and lung cancer classification across internal and external datasets including LUNA16, LUNA25, and NLST-3D+. For detection, we develop two MONAI-based RetinaNet models (DLCSDmD and LUNA16-mD), evaluated using the Competition Performance Metric (CPM). For classification, we compare five models, including state-of-the-art pretrained models (Models Genesis, Med3D), a selfsupervised foundation model (FMCB), a randomly initialized ResNet50, and proposed a novel Strategic Warm-Start++ (SWS++) model. SWS++ uses curated candidate patches to pretrain a classification backbone within the same detection pipeline, enabling task-relevant feature learning. Our models demonstrated strong generalizability, with SWS++ achieving comparable or superior performance to existing foundational models across multiple datasets (AUC: 0.71 to 0.90). All code, models, and data are publicly released to promote reproducibility and collaboration. This work establishes a standardized benchmarking resource for lung cancer AI research, supporting future efforts in model development, validation, and clinical translation.",
    "pdfUrl": "https://arxiv.org/pdf/2405.04605",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.040362Z"
  },
  {
    "id": "ad4bf695fa4de810bdf2e88737c7fda8",
    "title": "Discrete Cosine Transform Based Decorrelated Attention for Vision Transformers",
    "slug": "discrete-cosine-transform-based-decorrelated-attention-for-vision-transformers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Hongyi Pan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Central to the Transformer architectures' effectiveness is the self-attention mechanism, a function that maps queries, keys, and values into a high-dimensional vector space. However, training the attention weights of queries, keys, and values is non-trivial from a state of random initialization. In this paper, we propose two methods. (i) We first address the initialization problem of Vision Transformers by introducing a simple, yet highly innovative, initialization approach utilizing discrete cosine transform (DCT) coefficients. Our proposed DCT-based \\textit{attention} initialization marks a significant gain compared to traditional initialization strategies; offering a robust foundation for the attention mechanism. Our experiments reveal that the DCT-based initialization enhances the accuracy of Vision Transformers in classification tasks. (ii) We also recognize that since DCT effectively decorrelates image information in the frequency domain, this decorrelation is useful for compression because it allows the quantization step to discard many of the higher-frequency components. Based on this observation, we propose a novel DCT-based compression technique for the attention function of Vision Transformers. Since high-frequency DCT coefficients usually correspond to noise, we truncate the high-frequency DCT components of the input patches. Our DCT-based compression reduces the size of weight matrices for queries, keys, and values. While maintaining the same level of accuracy, our DCT compressed Swin Transformers obtain a considerable decrease in the computational overhead.",
    "pdfUrl": "https://arxiv.org/pdf/2405.13901",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.040566Z"
  },
  {
    "id": "3ae2c8fff5247109dbf768ec57c56aad",
    "title": "RSEND: Retinex-based Squeeze and Excitation Network with Dark Region Detection for Efficient Low Light Image Enhancement",
    "slug": "rsend:-retinex-based-squeeze-and-excitation-network-with-dark-region-detection-for-efficient-low-light-image-enhancement",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Jingcheng Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Images captured under low-light scenarios often suffer from low quality. Previous CNN-based deep learning methods often involve using Retinex theory. Nevertheless, most of them cannot perform well in more complicated datasets like LOL-v2 while consuming too much computational resources. Besides, some of these methods require sophisticated training at different stages, making the procedure even more time-consuming and tedious. In this paper, we propose a more accurate, concise, and one-stage Retinex theory based framework, RSEND. RSEND first divides the low-light image into the illumination map and reflectance map, then captures the important details in the illumination map and performs light enhancement. After this step, it refines the enhanced gray-scale image and does element-wise matrix multiplication with the reflectance map. By denoising the output it has from the previous step, it obtains the final result. In all the steps, RSEND utilizes Squeeze and Excitation network to better capture the details. Comprehensive quantitative and qualitative experiments show that our Efficient Retinex model significantly outperforms other CNN-based models, achieving a PSNR improvement ranging from 0.44 dB to 4.2 dB in different datasets and even outperforms transformer-based models in the LOL-v2-real dataset.",
    "pdfUrl": "https://arxiv.org/pdf/2406.09656",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.040774Z"
  },
  {
    "id": "c11dcca2b653943ac04708a6709e76f8",
    "title": "DDU-Net: A Domain Decomposition-Based CNN for High-Resolution Image Segmentation on Multiple GPUs",
    "slug": "ddu-net:-a-domain-decomposition-based-cnn-for-high-resolution-image-segmentation-on-multiple-gpus",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Corn Verburg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The segmentation of ultra-high resolution images poses challenges such as loss of spatial information or computational inefficiency. In this work, a novel approach that combines encoder-decoder architectures with domain decomposition strategies to address these challenges is proposed. Specifically, a domain decomposition-based U-Net (DDU-Net) architecture is introduced, which partitions input images into non-overlapping patches that can be processed independently on separate devices. A communication network is added to facilitate inter-patch information exchange to enhance the understanding of spatial context. Experimental validation is performed on a synthetic dataset that is designed to measure the effectiveness of the communication network. Then, the performance is tested on the DeepGlobe land cover classification dataset as a real-world benchmark data set. The results demonstrate that the approach, which includes inter-patch communication for images divided into $16\\times16$ non-overlapping subimages, achieves a $2-3\\,\\%$ higher intersection over union (IoU) score compared to the same network without inter-patch communication. The performance of the network which includes communication is equivalent to that of a baseline U-Net trained on the full image, showing that our model provides an effective solution for segmenting ultra-high-resolution images while preserving spatial context. The code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2407.21266",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.040985Z"
  },
  {
    "id": "50bbd3df57819030c1b5bd9bcc60dda0",
    "title": "Lumina-mGPT: Illuminate Flexible Photorealistic Text-to-Image Generation with Multimodal Generative Pretraining",
    "slug": "lumina-mgpt:-illuminate-flexible-photorealistic-text-to-image-generation-with-multimodal-generative-pretraining",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Dongyang Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present Lumina-mGPT, a family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. By initializing from multimodal Generative PreTraining (mGPT), we demonstrate that decoder-only Autoregressive (AR) model can achieve image generation performance comparable to modern diffusion models with high efficiency through Flexible Progressive Supervised Fine-tuning (FP-SFT). Equipped with our proposed Unambiguous image Representation (UniRep), Lumina-mGPT can flexibly generate high-quality images of varying aspect ratios. Building on the strong image generation capabilities, we further explore Ominiponent Supervised Fine-tuning (Omni-SFT), an initial attempt to elevate Lumina-mGPT into a unified multi-modal generalist. The resulting model demonstrates versatile multimodal capabilities, including visual generation tasks like text-to-image/multiview generation and controllable generation, visual recognition tasks like segmentation and depth estimation, and vision-language tasks like multi-turn visual question answering, showing the rosy potential of the technical direction. Codes and checkpoints are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2408.02657",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.041227Z"
  },
  {
    "id": "6b8e20bd14523f4f325924626b0972ee",
    "title": "Set2Seq Transformer: Temporal and Positional-Aware Set Representations for Sequential Multiple-Instance Learning",
    "slug": "set2seq-transformer:-temporal-and-positional-aware-set-representations-for-sequential-multiple-instance-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Athanasios Efthymiou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Sequential multiple-instance learning involves learning representations of sets distributed across discrete timesteps. In many real-world applications, modeling both the internal structure of sets and their temporal relationships across time is essential for capturing complex underlying patterns. However, existing methods either focus on learning set representations at a static level, ignoring temporal dynamics, or treat sequences as ordered lists of individual elements, lacking explicit mechanisms to represent sets. In this work, we propose Set2Seq Transformer, a novel architecture that jointly models permutation-invariant set structure and temporal dependencies by learning temporal and positional-aware representations of sets within a sequence in an end-to-end multimodal manner. We evaluate our Set2Seq Transformer on two tasks that require modeling both set structure alongside temporal and positional patterns, but differ significantly in domain, modality, and objective. First, we consider a fine-art analysis task, modeling artists' oeuvres for predicting artistic success using a novel dataset, WikiArt-Seq2Rank. Second, we utilize our Set2Seq Transformer for a short-term wildfire danger forecasting task. Through extensive experimentation, we show that our Set2Seq Transformer significantly improves over traditional static multiple-instance learning methods by effectively learning permutation-invariant set, temporal, and positional-aware representations across diverse domains, modalities, and tasks. We will release both the dataset and model implementations on GitHub.",
    "pdfUrl": "https://arxiv.org/pdf/2408.03404",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.041448Z"
  },
  {
    "id": "102520f5db328f3c53d405ddcc868468",
    "title": "AgentsCoMerge: Large Language Model Empowered Collaborative Decision Making for Ramp Merging",
    "slug": "agentscomerge:-large-language-model-empowered-collaborative-decision-making-for-ramp-merging",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Senkang Hu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Ramp merging is one of the bottlenecks in traffic systems, which commonly cause traffic congestion, accidents, and severe carbon emissions. In order to address this essential issue and enhance the safety and efficiency of connected and autonomous vehicles (CAVs) at multi-lane merging zones, we propose a novel collaborative decision-making framework, named AgentsCoMerge, to leverage large language models (LLMs). Specifically, we first design a scene observation and understanding module to allow an agent to capture the traffic environment. Then we propose a hierarchical planning module to enable the agent to make decisions and plan trajectories based on the observation and the agent's own state. In addition, in order to facilitate collaboration among multiple agents, we introduce a communication module to enable the surrounding agents to exchange necessary information and coordinate their actions. Finally, we develop a reinforcement reflection guided training paradigm to further enhance the decision-making capability of the framework. Extensive experiments are conducted to evaluate the performance of our proposed method, demonstrating its superior efficiency and effectiveness for multi-agent collaborative decision-making under various ramp merging scenarios.",
    "pdfUrl": "https://arxiv.org/pdf/2408.03624",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.041669Z"
  },
  {
    "id": "8f9728d0763df16617be8b453aa5365b",
    "title": "Contrastive Learning with Synthetic Positives",
    "slug": "contrastive-learning-with-synthetic-positives",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Dewen Zeng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Contrastive learning with the nearest neighbor has proved to be one of the most efficient self-supervised learning (SSL) techniques by utilizing the similarity of multiple instances within the same class. However, its efficacy is constrained as the nearest neighbor algorithm primarily identifies \"easy\" positive pairs, where the representations are already closely located in the embedding space. In this paper, we introduce a novel approach called Contrastive Learning with Synthetic Positives (CLSP) that utilizes synthetic images, generated by an unconditional diffusion model, as the additional positives to help the model learn from diverse positives. Through feature interpolation in the diffusion model sampling process, we generate images with distinct backgrounds yet similar semantic content to the anchor image. These images are considered \"hard\" positives for the anchor image, and when included as supplementary positives in the contrastive loss, they contribute to a performance improvement of over 2% and 1% in linear evaluation compared to the previous NNCLR and All4One methods across multiple benchmark datasets such as CIFAR10, achieving state-of-the-art methods. On transfer learning benchmarks, CLSP outperforms existing SSL frameworks on 6 out of 8 downstream datasets. We believe CLSP establishes a valuable baseline for future SSL studies incorporating synthetic data in the training process.",
    "pdfUrl": "https://arxiv.org/pdf/2408.16965",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.041885Z"
  },
  {
    "id": "1fd8c98555a408ce08247a4ce35fa9ad",
    "title": "On the Generalizability of Foundation Models for Crop Type Mapping",
    "slug": "on-the-generalizability-of-foundation-models-for-crop-type-mapping",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yi-Chia Chang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Foundation models pre-trained using self-supervised learning have shown powerful transfer learning capabilities on various downstream tasks, including language understanding, text generation, and image recognition. The Earth observation (EO) field has produced several foundation models pre-trained directly on multispectral satellite imagery for applications like precision agriculture, wildfire and drought monitoring, and natural disaster response. However, few studies have investigated the ability of these models to generalize to new geographic locations, and potential concerns of geospatial bias -- models trained on data-rich developed nations not transferring well to data-scarce developing nations -- remain. We investigate the ability of popular EO foundation models to transfer to new geographic regions in the agricultural domain, where differences in farming practices and class imbalance make transfer learning particularly challenging. We first select five crop classification datasets across five continents, normalizing for dataset size and harmonizing classes to focus on four major cereal grains: maize, soybean, rice, and wheat. We then compare three popular foundation models, pre-trained on SSL4EO-S12, SatlasPretrain, and ImageNet, using in-distribution (ID) and out-of-distribution (OOD) evaluation. Experiments show that pre-trained weights designed explicitly for Sentinel-2, such as SSL4EO-S12, outperform general pre-trained weights like ImageNet. Furthermore, while only 100 labeled images are sufficient for achieving high overall accuracy, 900 images are required to achieve high average accuracy due to class imbalance. All harmonized datasets and experimental code are open-source and available for download.",
    "pdfUrl": "https://arxiv.org/pdf/2409.09451",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.042108Z"
  },
  {
    "id": "f8db3a2cde23eb635d8e2dace734a956",
    "title": "DiffKillR: Killing and Recreating Diffeomorphisms for Cell Annotation in Dense Microscopy Images",
    "slug": "diffkillr:-killing-and-recreating-diffeomorphisms-for-cell-annotation-in-dense-microscopy-images",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Chen Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The proliferation of digital microscopy images, driven by advances in automated whole slide scanning, presents significant opportunities for biomedical research and clinical diagnostics. However, accurately annotating densely packed information in these images remains a major challenge. To address this, we introduce DiffKillR, a novel framework that reframes cell annotation as the combination of archetype matching and image registration tasks. DiffKillR employs two complementary neural networks: one that learns a diffeomorphism-invariant feature space for robust cell matching and another that computes the precise warping field between cells for annotation mapping. Using a small set of annotated archetypes, DiffKillR efficiently propagates annotations across large microscopy images, reducing the need for extensive manual labeling. More importantly, it is suitable for any type of pixel-level annotation. We will discuss the theoretical properties of DiffKillR and validate it on three microscopy tasks, demonstrating its advantages over existing supervised, semi-supervised, and unsupervised methods. The code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2410.03058",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.042347Z"
  },
  {
    "id": "3e8432bcdc49f41f51cfe3ca34bff5ab",
    "title": "PhysFlow: Unleashing the Potential of Multi-modal Foundation Models and Video Diffusion for 4D Dynamic Physical Scene Simulation",
    "slug": "physflow:-unleashing-the-potential-of-multi-modal-foundation-models-and-video-diffusion-for-4d-dynamic-physical-scene-simulation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhuoman Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Realistic simulation of dynamic scenes requires accurately capturing diverse material properties and modeling complex object interactions grounded in physical principles. However, existing methods are constrained to basic material types with limited predictable parameters, making them insufficient to represent the complexity of real-world materials. We introduce PhysFlow, a novel approach that leverages multi-modal foundation models and video diffusion to achieve enhanced 4D dynamic scene simulation. Our method utilizes multi-modal models to identify material types and initialize material parameters through image queries, while simultaneously inferring 3D Gaussian splats for detailed scene representation. We further refine these material parameters using video diffusion with a differentiable Material Point Method (MPM) and optical flow guidance rather than render loss or Score Distillation Sampling (SDS) loss. This integrated framework enables accurate prediction and realistic simulation of dynamic interactions in real-world scenarios, advancing both accuracy and flexibility in physics-based simulations.",
    "pdfUrl": "https://arxiv.org/pdf/2411.14423",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.042578Z"
  },
  {
    "id": "143127003becc76d28022b904d971d31",
    "title": "Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification",
    "slug": "neuro-symbolic-evaluation-of-text-to-video-models-using-formal-verification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "S. P. Sharan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advancements in text-to-video models such as Sora, Gen-3, MovieGen, and CogVideoX are pushing the boundaries of synthetic video generation, with adoption seen in fields like robotics, autonomous driving, and entertainment. As these models become prevalent, various metrics and benchmarks have emerged to evaluate the quality of the generated videos. However, these metrics emphasize visual quality and smoothness, neglecting temporal fidelity and text-to-video alignment, which are crucial for safety-critical applications. To address this gap, we introduce NeuS-V, a novel synthetic video evaluation metric that rigorously assesses text-to-video alignment using neuro-symbolic formal verification techniques. Our approach first converts the prompt into a formally defined Temporal Logic (TL) specification and translates the generated video into an automaton representation. Then, it evaluates the text-to-video alignment by formally checking the video automaton against the TL specification. Furthermore, we present a dataset of temporally extended prompts to evaluate state-of-the-art video generation models against our benchmark. We find that NeuS-V demonstrates a higher correlation by over 5x with human evaluations when compared to existing metrics. Our evaluation further reveals that current video generation models perform poorly on these temporally complex prompts, highlighting the need for future work in improving text-to-video generation capabilities.",
    "pdfUrl": "https://arxiv.org/pdf/2411.16718",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.042796Z"
  },
  {
    "id": "a08ef15a12c2c50bcc19963486166e34",
    "title": "Improved implicit diffusion model with knowledge distillation to estimate the spatial distribution density of carbon stock in remote sensing imagery",
    "slug": "improved-implicit-diffusion-model-with-knowledge-distillation-to-estimate-the-spatial-distribution-density-of-carbon-stock-in-remote-sensing-imagery",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhenyu Yu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The forest serves as the most significant terrestrial carbon stock mechanism, effectively reducing atmospheric CO2 concentrations and mitigating climate change. Remote sensing provides high data accuracy and enables large-scale observations. Optical images facilitate long-term monitoring, which is crucial for future carbon stock estimation studies. This study focuses on Huize County, Qujing City, Yunnan Province, China, utilizing GF-1 WFV satellite imagery. The KD-VGG and KD-UNet modules were introduced for initial feature extraction, and the improved implicit diffusion model (IIDM) was proposed. The results showed: (1) The VGG module improved initial feature extraction, improving accuracy, and reducing inference time with optimized model parameters. (2) The Cross-attention + MLPs module enabled effective feature fusion, establishing critical relationships between global and local features, achieving high-accuracy estimation. (3) The IIDM model, a novel contribution, demonstrated the highest estimation accuracy with an RMSE of 12.17%, significantly improving by 41.69% to 42.33% compared to the regression model. In carbon stock estimation, the generative model excelled in extracting deeper features, significantly outperforming other models, demonstrating the feasibility of AI-generated content in quantitative remote sensing. The 16-meter resolution estimates provide a robust basis for tailoring forest carbon sink regulations, enhancing regional carbon stock management.",
    "pdfUrl": "https://arxiv.org/pdf/2411.17973",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.042998Z"
  },
  {
    "id": "5c0b173898b5c56a7cc25c11e848b81e",
    "title": "Machine Learning-Based Automated Assessment of Intracorporeal Suturing in Laparoscopic Fundoplication",
    "slug": "machine-learning-based-automated-assessment-of-intracorporeal-suturing-in-laparoscopic-fundoplication",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Shekhar Madhav Khairnar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Automated assessment of surgical skills using artificial intelligence (AI) provides trainees with instantaneous feedback. After bimanual tool motions are captured, derived kinematic metrics are reliable predictors of performance in laparoscopic tasks. Implementing automated tool tracking requires time-intensive human annotation. We developed AI-based tool tracking using the Segment Anything Model (SAM) to eliminate the need for human annotators. Here, we describe a study evaluating the usefulness of our tool tracking model in automated assessment during a laparoscopic suturing task in the fundoplication procedure. An automated tool tracking model was applied to recorded videos of Nissen fundoplication on porcine bowel. Surgeons were grouped as novices (PGY1-2) and experts (PGY3-5, attendings). The beginning and end of each suturing step were segmented, and motions of the left and right tools were extracted. A low-pass filter with a 24 Hz cut-off frequency removed noise. Performance was assessed using supervised and unsupervised models, and an ablation study compared results. Kinematic features--RMS velocity, RMS acceleration, RMS jerk, total path length, and Bimanual Dexterity--were extracted and analyzed using Logistic Regression, Random Forest, Support Vector Classifier, and XGBoost. PCA was performed for feature reduction. For unsupervised learning, a Denoising Autoencoder (DAE) model with classifiers, such as a 1-D CNN and traditional models, was trained. Data were extracted for 28 participants (9 novices, 19 experts). Supervised learning with PCA and Random Forest achieved an accuracy of 0.795 and an F1 score of 0.778. The unsupervised 1-D CNN achieved superior results with an accuracy of 0.817 and an F1 score of 0.806, eliminating the need for kinematic feature computation. We demonstrated an AI model capable of automated performance classification, independent of human annotation.",
    "pdfUrl": "https://arxiv.org/pdf/2412.16195",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.043222Z"
  },
  {
    "id": "602b40f8ab70444384598d986ee23ecb",
    "title": "3D-LLaVA: Towards Generalist 3D LMMs with Omni Superpoint Transformer",
    "slug": "3d-llava:-towards-generalist-3d-lmms-with-omni-superpoint-transformer",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Jiajun Deng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Current 3D Large Multimodal Models (3D LMMs) have shown tremendous potential in 3D-vision-based dialogue and reasoning. However, how to further enhance 3D LMMs to achieve fine-grained scene understanding and facilitate flexible human-agent interaction remains a challenging problem. In this work, we introduce 3D-LLaVA, a simple yet highly powerful 3D LMM designed to act as an intelligent assistant in comprehending, reasoning, and interacting with the 3D world. Unlike existing top-performing methods that rely on complicated pipelines-such as offline multi-view feature extraction or additional task-specific heads-3D-LLaVA adopts a minimalist design with integrated architecture and only takes point clouds as input. At the core of 3D-LLaVA is a new Omni Superpoint Transformer (OST), which integrates three functionalities: (1) a visual feature selector that converts and selects visual tokens, (2) a visual prompt encoder that embeds interactive visual prompts into the visual token space, and (3) a referring mask decoder that produces 3D masks based on text description. This versatile OST is empowered by the hybrid pretraining to obtain perception priors and leveraged as the visual connector that bridges the 3D data to the LLM. After performing unified instruction tuning, our 3D-LLaVA reports impressive results on various benchmarks.",
    "pdfUrl": "https://arxiv.org/pdf/2501.01163",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.043450Z"
  },
  {
    "id": "7d0bc5b8a54249f4a496b74a95de906f",
    "title": "Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting",
    "slug": "large-image-object-detection-for-fine-grained-recognition-of-punches-patterns-in-medieval-panel-painting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Josh Bruegger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The attribution of the author of an art piece is typically a laborious manual process, usually relying on subjective evaluations of expert figures. However, there are some situations in which quantitative features of the artwork can support these evaluations. The extraction of these features can sometimes be automated, for instance, with the use of Machine Learning (ML) techniques. An example of these features is represented by repeated, mechanically impressed patterns, called punches, present chiefly in 13th and 14th-century panel paintings from Tuscany. Previous research in art history showcased a strong connection between the shapes of punches and specific artists or workshops, suggesting the possibility of using these quantitative cues to support the attribution. In the present work, we first collect a dataset of large-scale images of these panel paintings. Then, using YOLOv10, a recent and popular object detection model, we train a ML pipeline to perform object detection on the punches contained in the images. Due to the large size of the images, the detection procedure is split across multiple frames by adopting a sliding-window approach with overlaps, after which the predictions are combined for the whole image using a custom non-maximal suppression routine. Our results indicate how art historians working in the field can reliably use our method for the identification and extraction of punches.",
    "pdfUrl": "https://arxiv.org/pdf/2501.12489",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.043678Z"
  },
  {
    "id": "e90ab141725feb895796e95de97ef012",
    "title": "LinPrim: Linear Primitives for Differentiable Volumetric Rendering",
    "slug": "linprim:-linear-primitives-for-differentiable-volumetric-rendering",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Nicolas von Ltzow",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Volumetric rendering has become central to modern novel view synthesis methods, which use differentiable rendering to optimize 3D scene representations directly from observed views. While many recent works build on NeRF or 3D Gaussians, we explore an alternative volumetric scene representation. More specifically, we introduce two new scene representations based on linear primitives - octahedra and tetrahedra - both of which define homogeneous volumes bounded by triangular faces. To optimize these primitives, we present a differentiable rasterizer that runs efficiently on GPUs, allowing end-to-end gradient-based optimization while maintaining real-time rendering capabilities. Through experiments on real-world datasets, we demonstrate comparable performance to state-of-the-art volumetric methods while requiring fewer primitives to achieve similar reconstruction fidelity. Our findings deepen the understanding of 3D representations by providing insights into the fidelity and performance characteristics of transparent polyhedra and suggest that adopting novel primitives can expand the available design space.",
    "pdfUrl": "https://arxiv.org/pdf/2501.16312",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.043900Z"
  },
  {
    "id": "5416677dc4be72a2ac37bb3c7c29811c",
    "title": "Review of Demographic Fairness in Face Recognition",
    "slug": "review-of-demographic-fairness-in-face-recognition",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ketan Kotwal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Demographic fairness in face recognition (FR) has emerged as a critical area of research, given its impact on fairness, equity, and reliability across diverse applications. As FR technologies are increasingly deployed globally, disparities in performance across demographic groups-- such as race, ethnicity, and gender-- have garnered significant attention. These biases not only compromise the credibility of FR systems but also raise ethical concerns, especially when these technologies are employed in sensitive domains. This review consolidates extensive research efforts providing a comprehensive overview of the multifaceted aspects of demographic fairness in FR.\nWe systematically examine the primary causes, datasets, assessment metrics, and mitigation approaches associated with demographic disparities in FR. By categorizing key contributions in these areas, this work provides a structured approach to understanding and addressing the complexity of this issue. Finally, we highlight current advancements and identify emerging challenges that need further investigation. This article aims to provide researchers with a unified perspective on the state-of-the-art while emphasizing the critical need for equitable and trustworthy FR systems.",
    "pdfUrl": "https://arxiv.org/pdf/2502.02309",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.044102Z"
  },
  {
    "id": "44008ed06f3db940e0822d0843d457e6",
    "title": "Disentangling Visual Transformers: Patch-level Interpretability for Image Classification",
    "slug": "disentangling-visual-transformers:-patch-level-interpretability-for-image-classification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Guillaume Jeanneret",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Visual transformers have achieved remarkable performance in image classification tasks, but this performance gain has come at the cost of interpretability. One of the main obstacles to the interpretation of transformers is the self-attention mechanism, which mixes visual information across the whole image in a complex way. In this paper, we propose Hindered Transformer (HiT), a novel interpretable by design architecture inspired by visual transformers. Our proposed architecture rethinks the design of transformers to better disentangle patch influences at the classification stage. Ultimately, HiT can be interpreted as a linear combination of patch-level information. We show that the advantages of our approach in terms of explicability come with a reasonable trade-off in performance, making it an attractive alternative for applications where interpretability is paramount.",
    "pdfUrl": "https://arxiv.org/pdf/2502.17196",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.044310Z"
  },
  {
    "id": "768971be5e61e4ff78ac1531fa97ed74",
    "title": "HierarQ: Task-Aware Hierarchical Q-Former for Enhanced Video Understanding",
    "slug": "hierarq:-task-aware-hierarchical-q-former-for-enhanced-video-understanding",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Shehreen Azad",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Despite advancements in multimodal large language models (MLLMs), current approaches struggle in medium-to-long video understanding due to frame and context length limitations. As a result, these models often depend on frame sampling, which risks missing key information over time and lacks task-specific relevance. To address these challenges, we introduce HierarQ, a task-aware hierarchical Q-Former based framework that sequentially processes frames to bypass the need for frame sampling, while avoiding LLM's context length limitations. We introduce a lightweight two-stream language-guided feature modulator to incorporate task awareness in video understanding, with the entity stream capturing frame-level object information within a short context and the scene stream identifying their broader interactions over longer period of time. Each stream is supported by dedicated memory banks which enables our proposed Hierachical Querying transformer (HierarQ) to effectively capture short and long-term context. Extensive evaluations on 10 video benchmarks across video understanding, question answering, and captioning tasks demonstrate HierarQ's state-of-the-art performance across most datasets, proving its robustness and efficiency for comprehensive video analysis.",
    "pdfUrl": "https://arxiv.org/pdf/2503.08585",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.044513Z"
  },
  {
    "id": "3fbc80e4081326b58c82538704c8a138",
    "title": "Dynamic Pyramid Network for Efficient Multimodal Large Language Model",
    "slug": "dynamic-pyramid-network-for-efficient-multimodal-large-language-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Hao Ai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Multimodal large language models (MLLMs) have demonstrated impressive performance in various vision-language (VL) tasks, but their expensive computations still limit the real-world application. To address this issue, recent efforts aim to compress the visual features to save the computational costs of MLLMs. However, direct visual compression methods, e.g. efficient projectors, inevitably destroy the visual semantics in MLLM, especially in difficult samples. To overcome this shortcoming, we propose a novel dynamic pyramid network (DPN) for efficient MLLMs. Specifically, DPN formulates MLLM as a hierarchical structure where visual features are gradually compressed with increasing depth. In this case, even with a high compression ratio, fine-grained visual information can still be perceived in shallow layers. To maximize the benefit of DPN, we further propose an innovative Dynamic Pooling Experts (DPE) that can dynamically choose the optimal visual compression rate according to input features. With this design, harder samples will be assigned larger computations, thus preserving the model performance. To validate our approach, we conduct extensive experiments on two popular MLLMs and ten benchmarks. Experimental results show that DPN can save up to 56% average FLOPs on LLaVA while further achieving +0.74% performance gains. Besides, the generalization ability of DPN is also validated on the existing high-resolution MLLM called LLaVA-HR. The source code will be released at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2503.20322",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.044742Z"
  },
  {
    "id": "59a55308a3cc81a86ef257e765e68805",
    "title": "How Well Can Vison-Language Models Understand Humans' Intention? An Open-ended Theory of Mind Question Evaluation Benchmark",
    "slug": "how-well-can-vison-language-models-understand-humans'-intention?-an-open-ended-theory-of-mind-question-evaluation-benchmark",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ximing Wen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Vision Language Models (VLMs) have demonstrated strong reasoning capabilities in Visual Question Answering (VQA) tasks; however, their ability to perform Theory of Mind (ToM) tasks, such as inferring human intentions, beliefs, and mental states, remains underexplored. We propose an open-ended question framework to evaluate VLMs' performance across diverse categories of ToM tasks. We curated and annotated a benchmark dataset of 30 images and evaluated the performance of four VLMs of varying sizes. Our results show that the GPT-4 model outperformed all the others, with only one smaller model, GPT-4o-mini, achieving comparable performance. We observed that VLMs often struggle to infer intentions in complex scenarios such as bullying or cheating. Our findings reveal that smaller models can sometimes infer correct intentions despite relying on incorrect visual cues. The dataset is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2503.22093",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.044950Z"
  },
  {
    "id": "878703f7d64525802838da0836ea7abf",
    "title": "FMNV: A Dataset of Media-Published News Videos for Fake News Detection",
    "slug": "fmnv:-a-dataset-of-media-published-news-videos-for-fake-news-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yihao Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "News media, particularly video-based platforms, have become deeply embedded in daily life, concurrently amplifying risks of misinformation dissemination. Consequently, multimodal fake news detection has garnered significant research attention. However, existing datasets predominantly comprise user-generated videos characterized by crude editing and limited public engagement, whereas professionally crafted fake news videos disseminated by media outlets, often politically or virally motivated-pose substantially greater societal harm. To address this gap, we construct FMNV, a novel dataset exclusively composed of news videos published by media organizations. Through empirical analysis of existing datasets and our curated collection, we categorize fake news videos into four distinct types. Building upon this taxonomy, we employ Large Language Models (LLMs) to automatically generate deceptive content by manipulating authentic media-published news videos. Furthermore, we propose FMNVD, a baseline model featuring a dual-stream architecture integrating CLIP and Faster R-CNN for video feature extraction, enhanced by co-attention mechanisms for feature refinement and multimodal aggregation. Comparative experiments demonstrate both the generalization capability of FMNV across multiple baselines and the superior detection efficacy of FMNVD. This work establishes critical benchmarks for detecting high-impact fake news in media ecosystems while advancing methodologies for cross-modal inconsistency analysis.",
    "pdfUrl": "https://arxiv.org/pdf/2504.07687",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.045151Z"
  },
  {
    "id": "6c31cb8d1d88b86363af97205829d399",
    "title": "Causal Disentanglement for Robust Long-tail Medical Image Generation",
    "slug": "causal-disentanglement-for-robust-long-tail-medical-image-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Weizhi Nie",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Counterfactual medical image generation effectively addresses data scarcity and enhances the interpretability of medical images. However, due to the complex and diverse pathological features of medical images and the imbalanced class distribution in medical data, generating high-quality and diverse medical images from limited data is significantly challenging. Additionally, to fully leverage the information in limited data, such as anatomical structure information and generate more structurally stable medical images while avoiding distortion or inconsistency. In this paper, in order to enhance the clinical relevance of generated data and improve the interpretability of the model, we propose a novel medical image generation framework, which generates independent pathological and structural features based on causal disentanglement and utilizes text-guided modeling of pathological features to regulate the generation of counterfactual images. First, we achieve feature separation through causal disentanglement and analyze the interactions between features. Here, we introduce group supervision to ensure the independence of pathological and identity features. Second, we leverage a diffusion model guided by pathological findings to model pathological features, enabling the generation of diverse counterfactual images. Meanwhile, we enhance accuracy by leveraging a large language model to extract lesion severity and location from medical reports. Additionally, we improve the performance of the latent diffusion model on long-tailed categories through initial noise optimization.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14450",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.045380Z"
  },
  {
    "id": "7617028c3cd59488139d3f7c1b67a529",
    "title": "Shifts in Doctors' Eye Movements Between Real and AI-Generated Medical Images",
    "slug": "shifts-in-doctors'-eye-movements-between-real-and-ai-generated-medical-images",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "David C Wong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Eye-tracking analysis plays a vital role in medical imaging, providing key insights into how radiologists visually interpret and diagnose clinical cases. In this work, we first analyze radiologists' attention and agreement by measuring the distribution of various eye-movement patterns, including saccades direction, amplitude, and their joint distribution. These metrics help uncover patterns in attention allocation and diagnostic strategies. Furthermore, we investigate whether and how doctors' gaze behavior shifts when viewing authentic (Real) versus deep-learning-generated (Fake) images. To achieve this, we examine fixation bias maps, focusing on first, last, short, and longest fixations independently, along with detailed saccades patterns, to quantify differences in gaze distribution and visual saliency between authentic and synthetic images.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15007",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.045680Z"
  },
  {
    "id": "e938deb50a28b0a4b88672c29446f82f",
    "title": "Vidi: Large Multimodal Models for Video Understanding and Editing",
    "slug": "vidi:-large-multimodal-models-for-video-understanding-and-editing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Vidi Team",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Humans naturally share information with those they are connected to, and video has become one of the dominant mediums for communication and expression on the Internet. To support the creation of high-quality large-scale video content, a modern pipeline requires a comprehensive understanding of both the raw input materials (e.g., the unedited footage captured by cameras) and the editing components (e.g., visual effects). In video editing scenarios, models must process multiple modalities (e.g., vision, audio, text) with strong background knowledge and handle flexible input lengths (e.g., hour-long raw videos), which poses significant challenges for traditional models. In this report, we introduce Vidi, a family of Large Multimodal Models (LMMs) for a wide range of video understand editing scenarios. The first release focuses on temporal retrieval, i.e., identifying the time ranges within the input videos corresponding to a given text query, which plays a critical role in intelligent editing. The model is capable of processing hour-long videos with strong temporal understanding capability, e.g., retrieve time ranges for certain queries. To support a comprehensive evaluation in real-world scenarios, we also present the VUE-TR benchmark, which introduces five key advancements. 1) Video duration: significantly longer than videos of existing temporal retrival datasets, 2) Audio support: includes audio-based queries, 3) Query format: diverse query lengths/formats, 4) Annotation quality: ground-truth time ranges are manually annotated. 5) Evaluation metric: a refined IoU metric to support evaluation over multiple time ranges. Remarkably, Vidi significantly outperforms leading proprietary models, e.g., GPT-4o and Gemini, on the temporal retrieval task, indicating its superiority in video editing scenarios.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15681",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.045963Z"
  },
  {
    "id": "7187c2820e26c0bb1a10a88ccd6cb4aa",
    "title": "Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models",
    "slug": "meta-entity-driven-triplet-mining-for-aligning-medical-vision-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Saban Ozturk",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Diagnostic imaging relies on interpreting both images and radiology reports, but the growing data volumes place significant pressure on medical experts, yielding increased errors and workflow backlogs. Medical vision-language models (med-VLMs) have emerged as a powerful framework to efficiently process multimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit their performance hinges on how well image and text representations are aligned. Existing alignment methods, predominantly based on contrastive learning, prioritize separation between disease classes over segregation of fine-grained pathology attributes like location, size or severity, leading to suboptimal representations. Here, we propose MedTrim (Meta-entity-driven Triplet mining), a novel method that enhances image-text alignment through multimodal triplet learning synergistically guided by disease class as well as adjectival and directional pathology descriptors. Unlike common alignment methods that separate broad disease classes, MedTrim leverages structured meta-entity information to preserve subtle but clinically significant intra-class variations. For this purpose, we first introduce an ontology-based entity recognition module that extracts pathology-specific meta-entities from CXR reports, as annotations on pathology attributes are rare in public datasets. For refined sample selection in triplet mining, we then introduce a novel score function that captures an aggregate measure of inter-sample similarity based on disease classes and adjectival/directional descriptors. Lastly, we introduce a multimodal triplet alignment objective for explicit within- and cross-modal alignment between samples sharing detailed pathology characteristics. Our demonstrations indicate that MedTrim improves performance in downstream retrieval and classification tasks compared to state-of-the-art alignment methods.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15929",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.046188Z"
  },
  {
    "id": "f452ce27f2276f05a4ed0e1ca706214d",
    "title": "Marginalized Generalized IoU (MGIoU): A Unified Objective Function for Optimizing Any Convex Parametric Shapes",
    "slug": "marginalized-generalized-iou-(mgiou):-a-unified-objective-function-for-optimizing-any-convex-parametric-shapes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Duy-Tho Le",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Optimizing the similarity between parametric shapes is crucial for numerous computer vision tasks, where Intersection over Union (IoU) stands as the canonical measure. However, existing optimization methods exhibit significant shortcomings: regression-based losses like L1/L2 lack correlation with IoU, IoU-based losses are unstable and limited to simple shapes, and task-specific methods are computationally intensive and not generalizable accross domains. As a result, the current landscape of parametric shape objective functions has become scattered, with each domain proposing distinct IoU approximations. To address this, we unify the parametric shape optimization objective functions by introducing Marginalized Generalized IoU (MGIoU), a novel loss function that overcomes these challenges by projecting structured convex shapes onto their unique shape Normals to compute one-dimensional normalized GIoU. MGIoU offers a simple, efficient, fully differentiable approximation strongly correlated with IoU. We then extend MGIoU to MGIoU+ that supports optimizing unstructured convex shapes. Together, MGIoU and MGIoU+ unify parametric shape optimization across diverse applications. Experiments on standard benchmarks demonstrate that MGIoU and MGIoU+ consistently outperform existing losses while reducing loss computation latency by 10-40x. Additionally, MGIoU and MGIoU+ satisfy metric properties and scale-invariance, ensuring robustness as an objective function. We further propose MGIoU- for minimizing overlaps in tasks like collision-free trajectory prediction. Code is available at this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.16443",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.046412Z"
  },
  {
    "id": "7b8676cc4bd57eab8de3f554bf63ba3b",
    "title": "V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations",
    "slug": "v$^2$r-bench:-holistically-evaluating-lvlm-robustness-to-fundamental-visual-variations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhiyuan Fan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Vision Language Models (LVLMs) excel in various vision-language tasks. Yet, their robustness to visual variations in position, scale, orientation, and context that objects in natural scenes inevitably exhibit due to changes in viewpoint and environment remains largely underexplored. To bridge this gap, we introduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating Visual Variation Robustness of LVLMs, which encompasses automated evaluation dataset generation and principled metrics for thorough robustness assessment. Through extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability to visual variations, in which even advanced models that excel at complex vision-language tasks significantly underperform on simple tasks such as object recognition. Interestingly, these models exhibit a distinct visual position bias that contradicts theories of effective receptive fields, and demonstrate a human-like visual acuity threshold. To identify the source of these vulnerabilities, we present a systematic framework for component-level analysis, featuring a novel visualization approach for aligned visual features. Results show that these vulnerabilities stem from error accumulation in the pipeline architecture and inadequate multimodal alignment. Complementary experiments with synthetic data further demonstrate that these limitations are fundamentally architectural deficiencies, scoring the need for architectural innovations in future LVLM designs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16727",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:18.046618Z"
  },
  {
    "id": "a025d8badf7212fe6105ba6aa0b2d9bd",
    "title": "Diffusion Models Are Real-Time Game Engines",
    "slug": "diffusion-models-are-real-time-game-engines",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Dani Valevski",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present GameNGen, the first game engine powered entirely by a neural model that also enables real-time interaction with a complex environment over long trajectories at high quality. When trained on the classic game DOOM, GameNGen extracts gameplay and uses it to generate a playable environment that can interactively simulate new trajectories. GameNGen runs at 20 frames per second on a single TPU and remains stable over extended multi-minute play sessions. Next frame prediction achieves a PSNR of 29.4, comparable to lossy JPEG compression. Human raters are only slightly better than random chance at distinguishing short clips of the game from clips of the simulation, even after 5 minutes of auto-regressive generation. GameNGen is trained in two phases: (1) an RL-agent learns to play the game and the training sessions are recorded, and (2) a diffusion model is trained to produce the next frame, conditioned on the sequence of past frames and actions. Conditioning augmentations help ensure stable auto-regressive generation over long trajectories, and decoder fine-tuning improves the fidelity of visual details and text.",
    "pdfUrl": "https://arxiv.org/pdf/2408.14837",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:18.046840Z"
  },
  {
    "id": "dc1195f0bc760c8ea1194638566b5f01",
    "title": "Continuous and complete liver vessel segmentation with graph-attention guided diffusion",
    "slug": "continuous-and-complete-liver-vessel-segmentation-with-graph-attention-guided-diffusion",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Xiaotong Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Improving connectivity and completeness are the most challenging aspects of liver vessel segmentation, especially for small vessels. These challenges require both learning the continuous vessel geometry and focusing on small vessel detection. However, current methods do not explicitly address these two aspects and cannot generalize well when constrained by inconsistent annotations. Here, we take advantage of the generalization of the diffusion model and explicitly integrate connectivity and completeness in our diffusion-based segmentation model. Specifically, we use a graph-attention module that adds knowledge about vessel geometry. Additionally, we perform the graph-attention at multiple-scales, thus focusing on small liver vessels. Our method outperforms five state-of-the-art medical segmentation methods on two public datasets: 3D-ircadb-01 and LiVS.",
    "pdfUrl": "https://arxiv.org/pdf/2411.00617",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:18.047055Z"
  },
  {
    "id": "a68b5f0a73064ddc97030bac1ebec31c",
    "title": "jina-clip-v2: Multilingual Multimodal Embeddings for Text and Images",
    "slug": "jina-clip-v2:-multilingual-multimodal-embeddings-for-text-and-images",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Andreas Koukounas",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Contrastive Language-Image Pretraining (CLIP) has been widely used for crossmodal information retrieval and multimodal understanding tasks. However, CLIP models are mainly optimized for crossmodal vision-language tasks and underperform in single-mode text tasks. Moreover, these models are often trained on English datasets and therefore lack multilingual understanding. Additionally, from a visual understanding perspective, previous CLIP-based models exhibit insufficient understanding of visually rich documents. In this work, we propose jina-clip-v2, a contrastive vision-language model trained on text pairs, triplets and image-text pairs via a multi-task and multi-stage contrastive learning paradigm in order to support both text-only and crossmodal tasks. We employ a multilingual text encoder and expand the training dataset to include multilingual texts from 29 non-English languages, including Hindi, Chinese, German, French, and others, as well as images of visually rich documents. We evaluate the model's performance and show that jina-clip-v2 achieves notable improvements over state-of-the-art CLIP-based models in zero-shot text-only retrieval, semantic textual similarity, and crossmodal retrieval tasks in both English and multilingual settings. jina-clip-v2 also provides for flexibility in embedding dimensionality, enabling users to select the granularity of the representations. jina-clip-v2 is publicly available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2412.08802",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:18.047296Z"
  },
  {
    "id": "ba9ee4c5d16f9f155de949be5cc8998f",
    "title": "QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning",
    "slug": "quart-online:-latency-free-large-multimodal-language-model-for-quadruped-robot-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Xinyang Tong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper addresses the inherent inference latency challenges associated with deploying multimodal large language models (MLLM) in quadruped vision-language-action (QUAR-VLA) tasks. Our investigation reveals that conventional parameter reduction techniques ultimately impair the performance of the language foundation model during the action instruction tuning phase, making them unsuitable for this purpose. We introduce a novel latency-free quadruped MLLM model, dubbed QUART-Online, designed to enhance inference efficiency without degrading the performance of the language foundation model. By incorporating Action Chunk Discretization (ACD), we compress the original action representation space, mapping continuous action values onto a smaller set of discrete representative vectors while preserving critical information. Subsequently, we fine-tune the MLLM to integrate vision, language, and compressed actions into a unified semantic space. Experimental results demonstrate that QUART-Online operates in tandem with the existing MLLM system, achieving real-time inference in sync with the underlying controller frequency, significantly boosting the success rate across various tasks by 65%. Our project page is this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2412.15576",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:18.047555Z"
  },
  {
    "id": "d6c0daab53c1a2f71244f47b85b50acb",
    "title": "Weak-to-Strong Diffusion with Reflection",
    "slug": "weak-to-strong-diffusion-with-reflection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Lichen Bai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The goal of diffusion generative models is to align the learned distribution with the real data distribution through gradient score matching. However, inherent limitations in training data quality, modeling strategies, and architectural design lead to inevitable gap between generated outputs and real data. To reduce this gap, we propose Weak-to-Strong Diffusion (W2SD), a novel framework that utilizes the estimated difference between existing weak and strong models (i.e., weak-to-strong difference) to bridge the gap between an ideal model and a strong model. By employing a reflective operation that alternates between denoising and inversion with weak-to-strong difference, we theoretically understand that W2SD steers latent variables along sampling trajectories toward regions of the real data distribution. W2SD is highly flexible and broadly applicable, enabling diverse improvements through the strategic selection of weak-to-strong model pairs (e.g., DreamShaper vs. SD1.5, good experts vs. bad experts in MoE). Extensive experiments demonstrate that W2SD significantly improves human preference, aesthetic quality, and prompt adherence, achieving SOTA performance across various modalities (e.g., image, video), architectures (e.g., UNet-based, DiT-based, MoE), and benchmarks. For example, Juggernaut-XL with W2SD can improve with the HPSv2 winning rate up to 90% over the original results. Moreover, the performance gains achieved by W2SD markedly outweigh its additional computational overhead, while the cumulative improvements from different weak-to-strong difference further solidify its practical utility and deployability.",
    "pdfUrl": "https://arxiv.org/pdf/2502.00473",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:18.047773Z"
  },
  {
    "id": "9bf4499be9a2d2ae0c0e56c223a45ce8",
    "title": "Variational Self-Supervised Learning",
    "slug": "variational-self-supervised-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Mehmet Can Yavuz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present Variational Self-Supervised Learning (VSSL), a novel framework that combines variational inference with self-supervised learning to enable efficient, decoder-free representation learning. Unlike traditional VAEs that rely on input reconstruction via a decoder, VSSL symmetrically couples two encoders with Gaussian outputs. A momentum-updated teacher network defines a dynamic, data-dependent prior, while the student encoder produces an approximate posterior from augmented views. The reconstruction term in the ELBO is replaced with a cross-view denoising objective, preserving the analytical tractability of Gaussian KL divergence. We further introduce cosine-based formulations of KL and log-likelihood terms to enhance semantic alignment in high-dimensional latent spaces. Experiments on CIFAR-10, CIFAR-100, and ImageNet-100 show that VSSL achieves competitive or superior performance to leading self-supervised methods, including BYOL and MoCo V3. VSSL offers a scalable, probabilistically grounded approach to learning transferable representations without generative reconstruction, bridging the gap between variational modeling and modern self-supervised techniques.",
    "pdfUrl": "https://arxiv.org/pdf/2504.04318",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:18.047977Z"
  },
  {
    "id": "c6c39fcee5409910d74721fd93f96225",
    "title": "OmniMamba4D: Spatio-temporal Mamba for longitudinal CT lesion segmentation",
    "slug": "omnimamba4d:-spatio-temporal-mamba-for-longitudinal-ct-lesion-segmentation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Justin Namuk Kim",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate segmentation of longitudinal CT scans is important for monitoring tumor progression and evaluating treatment responses. However, existing 3D segmentation models solely focus on spatial information. To address this gap, we propose OmniMamba4D, a novel segmentation model designed for 4D medical images (3D images over time). OmniMamba4D utilizes a spatio-temporal tetra-orientated Mamba block to effectively capture both spatial and temporal features. Unlike traditional 3D models, which analyze single-time points, OmniMamba4D processes 4D CT data, providing comprehensive spatio-temporal information on lesion progression. Evaluated on an internal dataset comprising of 3,252 CT scans, OmniMamba4D achieves a competitive Dice score of 0.682, comparable to state-of-the-arts (SOTA) models, while maintaining computational efficiency and better detecting disappeared lesions. This work demonstrates a new framework to leverage spatio-temporal information for longitudinal CT lesion segmentation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.09655",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:18.048204Z"
  },
  {
    "id": "ba5cb64200038dee26175bfd7fd0c056",
    "title": "Putting the Segment Anything Model to the Test with 3D Knee MRI - A Comparison with State-of-the-Art Performance",
    "slug": "putting-the-segment-anything-model-to-the-test-with-3d-knee-mri---a-comparison-with-state-of-the-art-performance",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Oliver Mills",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Menisci are cartilaginous tissue found within the knee that contribute to joint lubrication and weight dispersal. Damage to menisci can lead to onset and progression of knee osteoarthritis (OA), a condition that is a leading cause of disability, and for which there are few effective therapies. Accurate automated segmentation of menisci would allow for earlier detection and treatment of meniscal abnormalities, as well as shedding more light on the role the menisci play in OA pathogenesis. Focus in this area has mainly used variants of convolutional networks, but there has been no attempt to utilise recent large vision transformer segmentation models. The Segment Anything Model (SAM) is a so-called foundation segmentation model, which has been found useful across a range of different tasks due to the large volume of data used for training the model. In this study, SAM was adapted to perform fully-automated segmentation of menisci from 3D knee magnetic resonance images. A 3D U-Net was also trained as a baseline. It was found that, when fine-tuning only the decoder, SAM was unable to compete with 3D U-Net, achieving a Dice score of $0.81\\pm0.03$, compared to $0.87\\pm0.03$, on a held-out test set. When fine-tuning SAM end-to-end, a Dice score of $0.87\\pm0.03$ was achieved. The performance of both the end-to-end trained SAM configuration and the 3D U-Net were comparable to the winning Dice score ($0.88\\pm0.03$) in the IWOAI Knee MRI Segmentation Challenge 2019. Performance in terms of the Hausdorff Distance showed that both configurations of SAM were inferior to 3D U-Net in matching the meniscus morphology. Results demonstrated that, despite its generalisability, SAM was unable to outperform a basic 3D U-Net in meniscus segmentation, and may not be suitable for similar 3D medical image segmentation tasks also involving fine anatomical structures with low contrast and poorly-defined boundaries.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13340",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:18.048416Z"
  },
  {
    "id": "b4696d9c7ac3d39d598b73dd59889d7c",
    "title": "Latent Representations for Visual Proprioception in Inexpensive Robots",
    "slug": "latent-representations-for-visual-proprioception-in-inexpensive-robots",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Sahara Sheikholeslami",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Robotic manipulation requires explicit or implicit knowledge of the robot's joint positions. Precise proprioception is standard in high-quality industrial robots but is often unavailable in inexpensive robots operating in unstructured environments. In this paper, we ask: to what extent can a fast, single-pass regression architecture perform visual proprioception from a single external camera image, available even in the simplest manipulation settings? We explore several latent representations, including CNNs, VAEs, ViTs, and bags of uncalibrated fiducial markers, using fine-tuning techniques adapted to the limited data available. We evaluate the achievable accuracy through experiments on an inexpensive 6-DoF robot.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14634",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:18.048612Z"
  },
  {
    "id": "642a50e82c4b00ec4d09e0a65caf12fb",
    "title": "A New Graph Grammar Formalism for Robust Syntactic Pattern Recognition",
    "slug": "a-new-graph-grammar-formalism-for-robust-syntactic-pattern-recognition",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Formal Languages and Automata Theory (cs.FL)",
    "author": {
      "name": "Peter Fletcher",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "I introduce a formalism for representing the syntax of recursively structured graph-like patterns. It does not use production rules, like a conventional graph grammar, but represents the syntactic structure in a more direct and declarative way. The grammar and the pattern are both represented as networks, and parsing is seen as the construction of a homomorphism from the pattern to the grammar. The grammars can represent iterative, hierarchical and nested recursive structure in more than one dimension.\nThis supports a highly parallel style of parsing, in which all aspects of pattern recognition (feature detection, segmentation, parsing, filling in missing symbols, top-down and bottom-up inference) are integrated into a single process, to exploit the synergy between them.\nThe emphasis of this paper is on underlying theoretical issues, but I also give some example runs to illustrate the error-tolerant parsing of complex recursively structured patterns of 50-1000 symbols, involving variability in geometric relationships, blurry and indistinct symbols, overlapping symbols, cluttered images, and erased patches.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15975",
    "tags": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "createdAt": "2025-04-25T15:49:18.048823Z"
  },
  {
    "id": "572f459531805e66c3f6dc8b1f53e311",
    "title": "Flexibility of German gas-fired generation: evidence from clustering empirical operation",
    "slug": "flexibility-of-german-gas-fired-generation:-evidence-from-clustering-empirical-operation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Chiara Fusar Bassini",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A key input to energy models are assumptions about the flexibility of power generation units, i.e., how quickly and often they can start up. These assumptions are usually calibrated on the technical characteristics of the units, such as installed capacity or technology type. However, even if power generation units technically can dispatch flexibly, service obligations and market incentives may constrain their operation. Here, we cluster over 60% of German national gas generation (generation units of 100 MWp or above) based on their empirical flexibility. We process the hourly dispatch of sample units between 2019 and 2023 using a novel deep learning approach, that transforms time series into easy-to-cluster representations. We identify two clusters of peaker units and two clusters of non-peaker units, whose different empirical flexibility is quantified by cluster-level ramp rates. Non-peaker units, around half of the sample, are empirically less flexible than peakers, and make up for more than 83% of sample must-run generation. Regulatory changes addressing the low market responsiveness of non-peakers are needed to unlock their flexibility.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16943",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.532629Z"
  },
  {
    "id": "65beaf9f86c348786ee7ea82f6d28973",
    "title": "Intrinsic Barriers to Explaining Deep Foundation Models",
    "slug": "intrinsic-barriers-to-explaining-deep-foundation-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Zhen Tan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deep Foundation Models (DFMs) offer unprecedented capabilities but their increasing complexity presents profound challenges to understanding their internal workings-a critical need for ensuring trust, safety, and accountability. As we grapple with explaining these systems, a fundamental question emerges: Are the difficulties we face merely temporary hurdles, awaiting more sophisticated analytical techniques, or do they stem from \\emph{intrinsic barriers} deeply rooted in the nature of these large-scale models themselves? This paper delves into this critical question by examining the fundamental characteristics of DFMs and scrutinizing the limitations encountered by current explainability methods when confronted with this inherent challenge. We probe the feasibility of achieving satisfactory explanations and consider the implications for how we must approach the verification and governance of these powerful technologies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16948",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.532842Z"
  },
  {
    "id": "58b79d26bf907bf8f4e1ff9b5b29e549",
    "title": "Social sustainability through engagement in a training context with tools such as the Native Podcast and Facebook social network",
    "slug": "social-sustainability-through-engagement-in-a-training-context-with-tools-such-as-the-native-podcast-and-facebook-social-network",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Danielle Mbambe Bebey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The social dimension of sustainability seems to have been a notion rarely addressed in the literature (Dubois et al., 2001) until the early 2000s. The EUTIC 2023 symposium provides an opportunity to take up this topical issue. To this end, we are presenting an engagement process that is part of a sustainable development dynamic, based on digital tools inspired by everyday life, for applications in the context of training, with a view to lifelong learning. Our work, which stems from the information and communication sciences, is rooted in a multi-disciplinary approach that we believe can be echoed in a variety of disciplines, but which it is interesting to challenge, hence the purpose of this contribution.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16964",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.533044Z"
  },
  {
    "id": "893bb0c28a5bdf101a26111919f7ad6a",
    "title": "Structuring Competency-Based Courses Through Skill Trees",
    "slug": "structuring-competency-based-courses-through-skill-trees",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Hildo Bijl",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Computer science education has seen two important trends. One has been a shift from raw theory towards skills: competency-based teaching. Another has been increasing student numbers, with as a result more automation in teaching. When automating education, it is crucial to properly structure courses, both to manage digitalized educational resources and to facilitate automated coaching algorithms. Currently existing structuring methodologies are focused around theory and not around skills, and are incapable of modeling the dependency links between skills. Because of this, a new didactic framework is needed.\nThis paper presents a new method of structuring educational contents around skills: something that a student is expected to be able to do. It defines Skill Trees that show dependencies between skills, and subsequently couples these to Concept Trees that contain intuitive ideas/notional machines. Due to the algorithmic nature of computer science, this step-wise approach is especially well-suited to this field of education. Next to formal definitions on Skill Trees and Concept Trees, guidelines are given on how to design them and how to plan a course using them.\nThe Skill Trees framework has been applied to improve the structure of a university database course. Student interviews indicated reduced confusion/stress and less study time required for students to meet their desired skill level.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16966",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.533240Z"
  },
  {
    "id": "7c0979c0f9f2667bf4c420dc85f7b835",
    "title": "Engineering the Law-Machine Learning Translation Problem: Developing Legally Aligned Models",
    "slug": "engineering-the-law-machine-learning-translation-problem:-developing-legally-aligned-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Mathias Hanson",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Organizations developing machine learning-based (ML) technologies face the complex challenge of achieving high predictive performance while respecting the law. This intersection between ML and the law creates new complexities. As ML model behavior is inferred from training data, legal obligations cannot be operationalized in source code directly. Rather, legal obligations require \"indirect\" operationalization. However, choosing context-appropriate operationalizations presents two compounding challenges: (1) laws often permit multiple valid operationalizations for a given legal obligation-each with varying degrees of legal adequacy; and, (2) each operationalization creates unpredictable trade-offs among the different legal obligations and with predictive performance. Evaluating these trade-offs requires metrics (or heuristics), which are in turn difficult to validate against legal obligations. Current methodologies fail to fully address these interwoven challenges as they either focus on legal compliance for traditional software or on ML model development without adequately considering legal complexities. In response, we introduce a five-stage interdisciplinary framework that integrates legal and ML-technical analysis during ML model development. This framework facilitates designing ML models in a legally aligned way and identifying high-performing models that are legally justifiable. Legal reasoning guides choices for operationalizations and evaluation metrics, while ML experts ensure technical feasibility, performance optimization and an accurate interpretation of metric values. This framework bridges the gap between more conceptual analysis of law and ML models' need for deterministic specifications. We illustrate its application using a case study in the context of anti-money laundering.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16969",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.533440Z"
  },
  {
    "id": "69dbf2f95b69f4d99ccd3bce64ffd11c",
    "title": "Seeing The Words: Evaluating AI-generated Biblical Art",
    "slug": "seeing-the-words:-evaluating-ai-generated-biblical-art",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Hidde Makimei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The past years witnessed a significant amount of Artificial Intelligence (AI) tools that can generate images from texts. This triggers the discussion of whether AI can generate accurate images using text from the Bible with respect to the corresponding biblical contexts and backgrounds. Despite some existing attempts at a small scale, little work has been done to systematically evaluate these generated images. In this work, we provide a large dataset of over 7K images using biblical text as prompts. These images were evaluated with multiple neural network-based tools on various aspects. We provide an assessment of accuracy and some analysis from the perspective of religion and aesthetics. Finally, we discuss the use of the generated images and reflect on the performance of the AI generators.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16974",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.533641Z"
  },
  {
    "id": "29a8d316ab8f2f403b7ce237fdf4d62f",
    "title": "Approaches to Responsible Governance of GenAI in Organizations",
    "slug": "approaches-to-responsible-governance-of-genai-in-organizations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Dhari Gandhi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid evolution of Generative AI (GenAI) has introduced unprecedented opportunities while presenting complex challenges around ethics, accountability, and societal impact. This paper draws on a literature review, established governance frameworks, and industry roundtable discussions to identify core principles for integrating responsible GenAI governance into diverse organizational structures. Our objective is to provide actionable recommendations for a balanced, risk-based governance approach that enables both innovation and oversight. Findings emphasize the need for adaptable risk assessment tools, continuous monitoring practices, and cross-sector collaboration to establish trustworthy GenAI. These insights provide a structured foundation and Responsible GenAI Guide (ResAI) for organizations to align GenAI initiatives with ethical, legal, and operational best practices.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17044",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.533842Z"
  },
  {
    "id": "637848ba8ad19bec0d7017aa723be179",
    "title": "Mapping Trafficking Networks: A Data-Driven Approach to Disrupt Human Trafficking Post Russia-Ukraine Conflict",
    "slug": "mapping-trafficking-networks:-a-data-driven-approach-to-disrupt-human-trafficking-post-russia-ukraine-conflict",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Murat Ozer",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study proposes a prototype for locating important individuals and financial exchanges in networks of people trafficking that have grown during the conflict between Russia and Ukraine. It focuses on the role of digital platforms, cryptocurrencies, and the dark web in facilitating these operations. The research maps trafficking networks and identifies key players and financial flows by utilizing open-source intelligence (OSINT), social network analysis (SNA), and blockchain analysis. The results show how cryptocurrencies are used for anonymous transactions and imply that upsetting central coordinators may cause wider networks to become unstable. In order to combat human trafficking, the study emphasizes the significance of real-time data sharing between international law enforcement. It also identifies future directions for the development of improved monitoring tools and cooperative platforms.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17050",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.534060Z"
  },
  {
    "id": "babc40196c2bcdecbf5c9a132be31213",
    "title": "Cyber Value At Risk Model for IoT Ecosystems",
    "slug": "cyber-value-at-risk-model-for-iot-ecosystems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Goksel Kucukkaya",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Internet of Things (IoT) presents unique cybersecurity challenges due to its interconnected nature and diverse application domains. This paper explores the application of Cyber Value-at-Risk (Cy-VaR) models to assess and mitigate cybersecurity risks in IoT environments. Cy-VaR, rooted in Value at Risk principles, provides a framework to quantify the potential financial impacts of cybersecurity incidents. Initially developed to evaluate overall risk exposure across scenarios, our approach extends Cy-VaR to consider specific IoT layers: perception, network, and application. Each layer encompasses distinct functionalities and vulnerabilities, from sensor data acquisition (perception layer) to secure data transmission (network layer) and application-specific services (application layer). By calculating Cy- VaR for each layer and scenario, organizations can prioritize security investments effectively. This paper discusses methodologies and models, including scenario-based Cy-VaR and layer-specific risk assessments, emphasizing their application in enhancing IoT cybersecurity resilience.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17054",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.534258Z"
  },
  {
    "id": "3330951c9ad19818a43f1871219abd8e",
    "title": "Evaluating energy inefficiency in energy-poor households in India: A frontier analysis approach",
    "slug": "evaluating-energy-inefficiency-in-energy-poor-households-in-india:-a-frontier-analysis-approach",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Vallary Gupta",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Energy-poor households often compromise their thermal comfort and refrain from operating mechanical cooling devices to avoid high electricity bills. This is compounded by certain behavioral practices like retention of older, less efficient appliances, resulting in missed energy savings. Thus, the need to enhance efficiency becomes critical in these households. However, due to a lack of comprehensive data in India, little is understood about their electricity consumption patterns and usage efficiency. Estimating inefficiency and assessing its determinants is crucial for improving their quality of life. This study measures the inefficiency in electricity consumption due to household practices and appliances in social housing in Mumbai, India. It considers technological determinants in addition to socio-economic variables. The study employs primary data collected from rehabilitation housing and slums in Mumbai. Stochastic frontier analysis, a parametric approach, is applied to estimate indicators of electricity consumption and inefficiency. While household size and workforce participation significantly affect consumption behavior in rehabilitation housing, it is limited to the workforce in slums. The ownership of appliances, except for washing machines in slums, also exhibits considerable impacts. The mean efficiency scores of 83% and 91% for rehabilitation housing and slums, respectively, empirically quantify the potential savings achievable. Factors that positively influence inefficiency include the duration of operating refrigerators, washing machines, iron, and AC. These results hold implications for enhancing the uptake of efficient appliances in addition to accelerating energy efficiency retrofits in the region. Policies should focus on awareness and the development of appliance markets through incentives.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17056",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.534461Z"
  },
  {
    "id": "ba9807226073304704ee0d66835f4e71",
    "title": "Cybernetic Governance in a Coliving House",
    "slug": "cybernetic-governance-in-a-coliving-house",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Daniel Kronovet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We report an 18-month field experiment in distributed digital institutions: a nine-bedroom Los Angeles coliving house that runs without managers, while sustaining 98% occupancy and below-market rents.\nDrawing on Elinor Ostrom's commons theory, we outline design principles and three digital mechanisms that form the institutional core: 1) A continuous-auction chore scheduler turns regenerative labor into a time-indexed points market; residents meet a 100-point monthly obligation by claiming tasks whose value rises linearly with neglect. 2) A pairwise-preference layer lets participants asynchronously reprioritize tasks, translating meta-governance into low-cognition spot inputs. 3) A symbolic \"hearts\" ledger tracks norm compliance through automated enforcement, lightweight challenges, and peer-awarded karma. Together, these mechanisms operationalize cybernetic principles--human sensing, machine bookkeeping, real-time feedback--while minimizing dependence on privileged roles.\nOur exploratory data (567 chore claims, 255 heart events, and 551 group purchases) show that such tooling can sustain reliable commons governance without continuous leadership, offering a transferable design palette for online communities, coliving houses, and other digitally mediated collectives.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17113",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.534697Z"
  },
  {
    "id": "2ab7b769012e85eadb0baca57870a4b4",
    "title": "AI for Accessible Education: Personalized Audio-Based Learning for Blind Students",
    "slug": "ai-for-accessible-education:-personalized-audio-based-learning-for-blind-students",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Crystal Yang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Blind and visually impaired (BVI) students face significant challenges in traditional educational settings. While screen readers and braille materials offer some accessibility, they often lack interactivity and real-time adaptability to individual learning needs. This paper presents Audemy, an AI-powered audio-based learning platform designed to provide personalized, accessible, and engaging educational experiences for BVI students. Audemy uses adaptive learning techniques to customize content based on student accuracy, pacing preferences, and engagement patterns. The platform has been iteratively developed with input from over 20 educators specializing in accessibility and currently serves over 2,000 BVI students. Educator insights show key considerations for accessible AI, including the importance of engagement, intuitive design, compatibility with existing assistive technologies, and the role of positive reinforcement in maintaining student motivation. Beyond accessibility, this paper explores the ethical implications of AI in education, emphasizing data privacy, security, and transparency. Audemy demonstrates how AI can empower BVI students with personalized and equitable learning opportunities, advancing the broader goal of inclusive education.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17117",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.534891Z"
  },
  {
    "id": "b52bc1d1c0bd52fd2355ec944bf7ce8d",
    "title": "Utilizing Dynamic Time Warping for Pandemic Surveillance: Understanding the Relationship between Google Trends Network Metrics and COVID-19 Incidences",
    "slug": "utilizing-dynamic-time-warping-for-pandemic-surveillance:-understanding-the-relationship-between-google-trends-network-metrics-and-covid-19-incidences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Michael T. Lopez II",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The premise of network statistics derived from Google Trends data to foresee COVID-19 disease progression is gaining momentum in infodemiology. This approach was applied in Metro Manila, National Capital Region, Philippines. Through dynamic time warping (DTW), the temporal alignment was quantified between network metrics and COVID-19 case trajectories, and systematically explored 320 parameter configurations including two network metrics (network density and clustering coefficient), two data preprocessing methods (Rescaling Daily Data and MSV), multiple thresholds, two correlation window sizes, and Sakoe-Chiba band constraints. Results from the Kruskal-Wallis tests revealed that five of the six parameters significantly influenced alignment quality, with the disease comparison type (active cases vs. confirmed cases) demonstrating the strongest effect. The optimal configuration, which is using the network density statistic with a Rescaling Daily Data transformation, a threshold of 0.8, a 15-day window, and a 50-day radius constraint, achieved a DTW score of 36.30. This indicated substantial temporal alignment with the COVID-19 confirmed cases data. The discoveries demonstrate that network metrics rooted from online search behavior can serve as complementary indicators for epidemic surveillance in urban locations like Metro Manila. This strategy leverages the Philippines' extensive online usage during the pandemic to provide potentially valuable early signals of disease spread, and offers a supplementary tool for public health monitoring in resource-limited situations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17146",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.535105Z"
  },
  {
    "id": "e4fa5f27ec8ff7892ffdbb4441d291bd",
    "title": "How Jungian Cognitive Functions Explain MBTI Type Prevalence in Computer Industry Careers",
    "slug": "how-jungian-cognitive-functions-explain-mbti-type-prevalence-in-computer-industry-careers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Arya VarastehNezhad",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study investigates the relationship between Carl Jung's cognitive functions and success in computer industry careers by analyzing the distribution of Myers-Briggs Type Indicator (MBTI) types among professionals in the field. Building on Carl Jung's theory of psychological types, which categorizes human cognition into four primary functions, Sensing, Intuition, Thinking, and Feeling, this study investigates how these functions, when combined with the attitudes of Extraversion and Introversion, influence personality types and career choices in the tech sector. Through a comprehensive analysis of data from 30 studies spanning multiple countries and decades, encompassing 18,264 individuals in computer-related professions, we identified the most prevalent cognitive functions and their combinations. After normalizing the data against general population distributions, our findings showed that individual Jungian functions (Te, Ni, Ti, Ne), dual function combinations (Ni-Te, Ti-Ne, Si-Te, Ni-Fe), and MBTI types (INTJ, ENTJ, INTP, ENTP, ISTJ, INFJ, ESTJ, ESTP) had significantly higher representation compared to general population norms. The paper addresses gaps in the existing literature by providing a more nuanced understanding of how cognitive functions impact job performance and team dynamics, offering insights for career guidance, team composition, and professional development in the computer industry, and a deeper understanding of how cognitive preferences influence career success in technology-related fields.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17248",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.535305Z"
  },
  {
    "id": "764bd430921766674defcd732f03a341",
    "title": "Building Sustainable and Trustworthy Indigenous Knowledge Preservation Ecosystem",
    "slug": "building-sustainable-and-trustworthy-indigenous-knowledge-preservation-ecosystem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Siguo Bi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper focuses on the essential global issue of protecting and transmitting indigenous knowledge. It reveals the challenges in this area and proposes a sustainable supply chain framework for indigenous knowledge. The paper reviews existing technological solutions and identifies technical challenges and gaps. It then introduces cutting-edge technologies to protect and disseminate indigenous knowledge more effectively. The paper also discusses how the proposed framework can address real-world challenges in protecting and transmitting indigenous knowledge, and explores future research applications of the proposed solutions. Finally, it addresses open issues and provides a detailed analysis, offering promising research directions for the protection and transmission of indigenous knowledge worldwide.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17281",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.535501Z"
  },
  {
    "id": "149def33290ceda331ad6be297a8ddcd",
    "title": "Towards User-Centred Design of AI-Assisted Decision-Making in Law Enforcement",
    "slug": "towards-user-centred-design-of-ai-assisted-decision-making-in-law-enforcement",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Vesna Nowack",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Artificial Intelligence (AI) has become an important part of our everyday lives, yet user requirements for designing AI-assisted systems in law enforcement remain unclear. To address this gap, we conducted qualitative research on decision-making within a law enforcement agency. Our study aimed to identify limitations of existing practices, explore user requirements and understand the responsibilities that humans expect to undertake in these systems.\nParticipants in our study highlighted the need for a system capable of processing and analysing large volumes of data efficiently to help in crime detection and prevention. Additionally, the system should satisfy requirements for scalability, accuracy, justification, trustworthiness and adaptability to be adopted in this domain. Participants also emphasised the importance of having end users review the input data that might be challenging for AI to interpret, and validate the generated output to ensure the system's accuracy. To keep up with the evolving nature of the law enforcement domain, end users need to help the system adapt to the changes in criminal behaviour and government guidance, and technical experts need to regularly oversee and monitor the system. Furthermore, user-friendly human interaction with the system is essential for its adoption and some of the participants confirmed they would be happy to be in the loop and provide necessary feedback that the system can learn from. Finally, we argue that it is very unlikely that the system will ever achieve full automation due to the dynamic and complex nature of the law enforcement domain.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17393",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.535737Z"
  },
  {
    "id": "cfe8182bd3f04e78ebc4a1a423e11a1f",
    "title": "MindFlow: A Network Traffic Anomaly Detection Model Based on MindSpore",
    "slug": "mindflow:-a-network-traffic-anomaly-detection-model-based-on-mindspore",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Qiuyan Xiang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "With the wide application of IoT and industrial IoT technologies, the network structure is becoming more and more complex, and the traffic scale is growing rapidly, which makes the traditional security protection mechanism face serious challenges in dealing with high-frequency, diversified, and stealthy cyber-attacks. To address this problem, this study proposes MindFlow, a multi-dimensional dynamic traffic prediction and anomaly detection system combining convolutional neural network (CNN) and bi-directional long and short-term memory network (BiLSTM) architectures based on the MindSpore framework, and conducts systematic experiments on the NF-BoT-IoT dataset. The experimental results show that the proposed model achieves 99% in key metrics such as accuracy, precision, recall and F1 score, effectively verifying its accuracy and robustness in network intrusion detection.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17678",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.535954Z"
  },
  {
    "id": "e3faf48859b725074156ba2ca9e35254",
    "title": "Integrating Graph Theoretical Approaches in Cybersecurity Education CSCI-RTED",
    "slug": "integrating-graph-theoretical-approaches-in-cybersecurity-education-csci-rted",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Goksel Kucukkaya",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As cybersecurity threats continue to evolve, the need for advanced tools to analyze and understand complex cyber environments has become increasingly critical. Graph theory offers a powerful framework for modeling relationships within cyber ecosystems, making it highly applicable to cybersecurity. This paper focuses on the development of an enriched version of the widely recognized NSL-KDD dataset, incorporating graph-theoretical concepts to enhance its practical value. The enriched dataset provides a resource for students and professionals to engage in hands-on analysis, enabling them to explore graph-based methodologies for identifying network behavior and vulnerabilities. To validate the effectiveness of this dataset, we employed IBM Auto AI, demonstrating its capability in real-world applications such as classification and threat prediction. By addressing the need for graph-theoretical datasets, this study provides a practical tool for equipping future cybersecurity professionals with the skills necessary to confront complex cyber challenges.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17059",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:19.536152Z"
  },
  {
    "id": "26a0fa6d2730d30b7780ca8b2bb4dbf2",
    "title": "Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching",
    "slug": "whence-is-a-model-fair?-fixing-fairness-bugs-via-propensity-score-matching",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Kewen Peng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Fairness-aware learning aims to mitigate discrimination against specific protected social groups (e.g., those categorized by gender, ethnicity, age) while minimizing predictive performance loss. Despite efforts to improve fairness in machine learning, prior studies have shown that many models remain unfair when measured against various fairness metrics. In this paper, we examine whether the way training and testing data are sampled affects the reliability of reported fairness metrics. Since training and test sets are often randomly sampled from the same population, bias present in the training data may still exist in the test data, potentially skewing fairness assessments. To address this, we propose FairMatch, a post-processing method that applies propensity score matching to evaluate and mitigate bias. FairMatch identifies control and treatment pairs with similar propensity scores in the test set and adjusts decision thresholds for different subgroups accordingly. For samples that cannot be matched, we perform probabilistic calibration using fairness-aware loss functions. Experimental results demonstrate that our approach can (a) precisely locate subsets of the test data where the model is unbiased, and (b) significantly reduce bias on the remaining data. Overall, propensity score matching offers a principled way to improve both fairness evaluation and mitigation, without sacrificing predictive performance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17066",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:19.536354Z"
  },
  {
    "id": "1c9a7f5ffea3bb21796b14ad6e23b374",
    "title": "Agree to Disagree? A Meta-Evaluation of LLM Misgendering",
    "slug": "agree-to-disagree?-a-meta-evaluation-of-llm-misgendering",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Arjun Subramonian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Numerous methods have been proposed to measure LLM misgendering, including probability-based evaluations (e.g., automatically with templatic sentences) and generation-based evaluations (e.g., with automatic heuristics or human validation). However, it has gone unexamined whether these evaluation methods have convergent validity, that is, whether their results align. Therefore, we conduct a systematic meta-evaluation of these methods across three existing datasets for LLM misgendering. We propose a method to transform each dataset to enable parallel probability- and generation-based evaluation. Then, by automatically evaluating a suite of 6 models from 3 families, we find that these methods can disagree with each other at the instance, dataset, and model levels, conflicting on 20.2% of evaluation instances. Finally, with a human evaluation of 2400 LLM generations, we show that misgendering behaviour is complex and goes far beyond pronouns, which automatic evaluations are not currently designed to capture, suggesting essential disagreement with human evaluations. Based on our findings, we provide recommendations for future evaluations of LLM misgendering. Our results are also more widely relevant, as they call into question broader methodological conventions in LLM evaluation, which often assume that different evaluation methods agree.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17075",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:19.536570Z"
  },
  {
    "id": "6ee377a5ca9b24d8efaec61fcb886674",
    "title": "Steering the CensorShip: Uncovering Representation Vectors for LLM \"Thought\" Control",
    "slug": "steering-the-censorship:-uncovering-representation-vectors-for-llm-\"thought\"-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Hannah Cyberey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) have transformed the way we access information. These models are often tuned to refuse to comply with requests that are considered harmful and to produce responses that better align with the preferences of those who control the models. To understand how this \"censorship\" works. We use representation engineering techniques to study open-weights safety-tuned models. We present a method for finding a refusal--compliance vector that detects and controls the level of censorship in model outputs. We also analyze recent reasoning LLMs, distilled from DeepSeek-R1, and uncover an additional dimension of censorship through \"thought suppression\". We show a similar approach can be used to find a vector that suppresses the model's reasoning process, allowing us to remove censorship by applying the negative multiples of this vector",
    "pdfUrl": "https://arxiv.org/pdf/2504.17130",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:19.536754Z"
  },
  {
    "id": "fb0232e1c3d77bf1301817e1975e5b82",
    "title": "Improving Human-Autonomous Vehicle Interaction in Complex Systems",
    "slug": "improving-human-autonomous-vehicle-interaction-in-complex-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Robert Kaufman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Unresolved questions about how autonomous vehicles (AVs) should meet the informational needs of riders hinder real-world adoption. Complicating our ability to satisfy rider needs is that different people, goals, and driving contexts have different criteria for what constitutes interaction success. Unfortunately, most human-AV research and design today treats all people and situations uniformly. It is crucial to understand how an AV should communicate to meet rider needs, and how communications should change when the human-AV complex system changes. I argue that understanding the relationships between different aspects of the human-AV system can help us build improved and adaptable AV communications. I support this argument using three empirical studies. First, I identify optimal communication strategies that enhance driving performance, confidence, and trust for learning in extreme driving environments. Findings highlight the need for task-sensitive, modality-appropriate communications tuned to learner cognitive limits and goals. Next, I highlight the consequences of deploying faulty communication systems and demonstrate the need for context-sensitive communications. Third, I use machine learning (ML) to illuminate personal factors predicting trust in AVs, emphasizing the importance of tailoring designs to individual traits and concerns. Together, this dissertation supports the necessity of transparent, adaptable, and personalized AV systems that cater to individual needs, goals, and contextual demands. By considering the complex system within which human-AV interactions occur, we can deliver valuable insights for designers, researchers, and policymakers. This dissertation also provides a concrete domain to study theories of human-machine joint action and situational awareness, and can be used to guide future human-AI interaction research. [shortened for arxiv]",
    "pdfUrl": "https://arxiv.org/pdf/2504.17170",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:19.536942Z"
  },
  {
    "id": "f8ee19fc956ec673e0ec830c1e7b71a3",
    "title": "SimFLEX: a methodology for comparative analysis of urban areas for implementing new on-demand feeder bus services",
    "slug": "simflex:-a-methodology-for-comparative-analysis-of-urban-areas-for-implementing-new-on-demand-feeder-bus-services",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Physics and Society (physics.soc-ph)",
    "author": {
      "name": "Hanna Vasiutina",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "On-demand feeder bus services present an innovative solution to urban mobility challenges, yet their success depends on thorough assessment and strategic planning. Despite their potential, a comprehensive framework for evaluating feasibility and identifying suitable service areas remains underdeveloped. Simulation Framework for Feeder Location Evaluation (SimFLEX) uses spatial, demographic, and transport-specific data to run microsimulations and compute key performance indicators (KPIs), including service attractiveness, waiting time reduction, and added value. SimFLEX employs multiple replications to estimate demand and mode choices and integrates OpenTripPlanner (OTP) for public transport routing and ExMAS for calculating shared trip attributes and KPIs. For each demand scenario, we model the traveler learning process using the method of successive averages (MSA), stabilizing the system. After stabilization, we calculate KPIs for comparative and sensitivity analyzes. We applied SimFLEX to compare two remote urban areas in Krakow, Poland - Bronowice and Skotniki - the candidates for service launch. Our analysis revealed notable differences between analyzed areas: Skotniki exhibited higher service attractiveness (up to 30%) and added value (up to 7%), while Bronowice showed greater potential for reducing waiting times (by nearly 77%). To assess the reliability of our model output, we conducted a sensitivity analysis across a range of alternative-specific constants (ASC). The results consistently confirmed Skotniki as the superior candidate for service implementation. SimFLEX can be instrumental for policymakers to estimate new service performance in the considered area, publicly available and applicable to various use cases. It can integrate alternative models and approaches, making it a versatile tool for policymakers and urban planners to enhance urban mobility.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17538",
    "tags": [
      "Physics and Society (physics.soc-ph)"
    ],
    "createdAt": "2025-04-25T15:49:19.537143Z"
  },
  {
    "id": "08b44c6b5d228223f29a26399103a6d5",
    "title": "RAGAT-Mind: A Multi-Granular Modeling Approach for Rumor Detection Based on MindSpore",
    "slug": "ragat-mind:-a-multi-granular-modeling-approach-for-rumor-detection-based-on-mindspore",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Zhenkai Qin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As false information continues to proliferate across social media platforms, effective rumor detection has emerged as a pressing challenge in natural language processing. This paper proposes RAGAT-Mind, a multi-granular modeling approach for Chinese rumor detection, built upon the MindSpore deep learning framework. The model integrates TextCNN for local semantic extraction, bidirectional GRU for sequential context learning, Multi-Head Self-Attention for global dependency focusing, and Bidirectional Graph Convolutional Networks (BiGCN) for structural representation of word co-occurrence graphs. Experiments on the Weibo1-Rumor dataset demonstrate that RAGAT-Mind achieves superior classification performance, attaining 99.2% accuracy and a macro-F1 score of 0.9919. The results validate the effectiveness of combining hierarchical linguistic features with graph-based semantic structures. Furthermore, the model exhibits strong generalization and interpretability, highlighting its practical value for real-world rumor detection applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17574",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:19.537334Z"
  },
  {
    "id": "f59a73ac5f7a1c1cf8533819a23c1814",
    "title": "The Malicious Technical Ecosystem: Exposing Limitations in Technical Governance of AI-Generated Non-Consensual Intimate Images of Adults",
    "slug": "the-malicious-technical-ecosystem:-exposing-limitations-in-technical-governance-of-ai-generated-non-consensual-intimate-images-of-adults",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Michelle L. Ding",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we adopt a survivor-centered approach to locate and dissect the role of sociotechnical AI governance in preventing AI-Generated Non-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as \"deep fake pornography.\" We identify a \"malicious technical ecosystem\" or \"MTE,\" comprising of open-source face-swapping models and nearly 200 \"nudifying\" software programs that allow non-technical users to create AIG-NCII within minutes. Then, using the National Institute of Standards and Technology (NIST) AI 100-4 report as a reflection of current synthetic content governance methods, we show how the current landscape of practices fails to effectively regulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining these gaps.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17663",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:19.537534Z"
  },
  {
    "id": "f92b79f2f515f43f82c99a29d18ad795",
    "title": "Regulatory Markets for AI Safety",
    "slug": "regulatory-markets-for-ai-safety",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Jack Clark",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a new model for regulation to achieve AI safety: global regulatory markets. We first sketch the model in general terms and provide an overview of the costs and benefits of this approach. We then demonstrate how the model might work in practice: responding to the risk of adversarial attacks on AI models employed in commercial drones.",
    "pdfUrl": "https://arxiv.org/pdf/2001.00078",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.537717Z"
  },
  {
    "id": "55e7a69cab2e28c9e08da7a0cfd38b8c",
    "title": "Welzijn.AI: Developing Responsible Conversational AI for Elderly Care through Stakeholder Involvement",
    "slug": "welzijn.ai:-developing-responsible-conversational-ai-for-elderly-care-through-stakeholder-involvement",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Bram van Dijk",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present this http URL as new digital solution for monitoring (mental) well-being in elderly populations, and illustrate how development of systems like this http URL can align with guidelines on responsible AI development. Three evaluations with different stakeholders were designed to disclose new perspectives on the strengths, weaknesses, design characteristics, and value requirements of this http URL. Evaluations concerned expert panels and involved patient federations, general practitioners, researchers, and the elderly themselves. Panels concerned interviews, a co-creation session, and feedback on a proof-of-concept implementation. Interview results were summarized in terms of this http URL's strengths, weaknesses, opportunities and threats. The co-creation session ranked a variety of value requirements of this http URL with the Hundred Dollar Method. User evaluation comprised analysing proportions of (dis)agreement on statements targeting this http URL's design characteristics, and ranking desired social characteristics. Experts in the panel interviews acknowledged this http URL's potential to combat loneliness and extract patterns from elderly behaviour. The proof-of-concept evaluation complemented the design characteristics most appealing to the elderly to potentially achieve this: empathetic and varying interactions. Stakeholders also link the technology to the implementation context: it could help activate an individual's social network, but support should also be available to empower users. Yet, non-elderly and elderly experts also disclose challenges in properly understanding the application; non-elderly experts also highlight issues concerning privacy. In sum, incorporating all stakeholder perspectives in system development remains challenging. Still, our results benefit researchers, policy makers, and health professionals that aim to improve elderly care with technology.",
    "pdfUrl": "https://arxiv.org/pdf/2502.07983",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.537919Z"
  },
  {
    "id": "b30e7cf48784864708a3694f7c77567c",
    "title": "\"I'm not for sale\" -- Perceptions and limited awareness of privacy risks by digital natives about location data",
    "slug": "\"i'm-not-for-sale\"----perceptions-and-limited-awareness-of-privacy-risks-by-digital-natives-about-location-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Antoine Boutet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Although mobile devices benefit users in their daily lives in numerous ways, they also raise several privacy concerns. For instance, they can reveal sensitive information that can be inferred from location data. This location data is shared through service providers as well as mobile applications. Understanding how and with whom users share their location data -- as well as users' perception of the underlying privacy risks --, are important notions to grasp in order to design usable privacy-enhancing technologies. In this work, we perform a quantitative and qualitative analysis of smartphone users' awareness, perception and self-reported behavior towards location data-sharing through a survey of n=99 young adult participants (i.e., digital natives). We compare stated practices with actual behaviors to better understand their mental models, and survey participants' understanding of privacy risks before and after the inspection of location traces and the information that can be inferred therefrom.\nOur empirical results show that participants have risky privacy practices: about 54% of participants underestimate the number of mobile applications to which they have granted access to their data, and 33% forget or do not think of revoking access to their data. Also, by using a demonstrator to perform inferences from location data, we observe that slightly more than half of participants (57%) are surprised by the extent of potentially inferred information, and that 47% intend to reduce access to their data via permissions as a result of using the demonstrator. Last, a majority of participants have little knowledge of the tools to better protect themselves, but are nonetheless willing to follow suggestions to improve privacy (51%). Educating people, including digital natives, about privacy risks through transparency tools seems a promising approach.",
    "pdfUrl": "https://arxiv.org/pdf/2502.11658",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.538110Z"
  },
  {
    "id": "746c83d2e7d10dcc3f6a05f74b9289d6",
    "title": "Evaluating DAO Sustainability and Longevity Through On-Chain Governance Metrics",
    "slug": "evaluating-dao-sustainability-and-longevity-through-on-chain-governance-metrics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Silvio Meneguzzo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Decentralised Autonomous Organisations (DAOs) automate governance and resource allocation through smart contracts, aiming to shift decision-making to distributed token holders. However, many DAOs face sustainability challenges linked to limited user participation, concentrated voting power, and technical design constraints. This paper addresses these issues by identifying research gaps in DAO evaluation and introducing a framework of Key Performance Indicators (KPIs) that capture governance efficiency, financial robustness, decentralisation, and community engagement. We apply the framework to a custom-built dataset of real-world DAOs constructed from on-chain data and analysed using non-parametric methods. The results reveal recurring governance patterns, including low participation rates and high proposer concentration, which may undermine long-term viability. The proposed KPIs offer a replicable, data-driven method for assessing DAO governance structures and identifying potential areas for improvement. These findings support a multidimensional approach to evaluating decentralised systems and provide practical tools for researchers and practitioners working to improve the resilience and effectiveness of DAO-based governance models.",
    "pdfUrl": "https://arxiv.org/pdf/2504.11341",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.538301Z"
  },
  {
    "id": "293f13bbc9cfdbbdeac33bd936647eb9",
    "title": "Bare Minimum Mitigations for Autonomous AI Development",
    "slug": "bare-minimum-mitigations-for-autonomous-ai-development",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Joshua Clymer",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Artificial intelligence (AI) is advancing rapidly, with the potential for significantly automating AI research and development itself in the near future. In 2024, international scientists, including Turing Award recipients, warned of risks from autonomous AI research and development (R&D), suggesting a red line such that no AI system should be able to improve itself or other AI systems without explicit human approval and assistance. However, the criteria for meaningful human approval remain unclear, and there is limited analysis on the specific risks of autonomous AI R&D, how they arise, and how to mitigate them. In this brief paper, we outline how these risks may emerge and propose four minimum safeguard recommendations applicable when AI agents significantly automate or accelerate AI development.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15416",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.538534Z"
  },
  {
    "id": "656bb71b17f80eeb0f33d21b42f27e6f",
    "title": "Trends in AI Supercomputers",
    "slug": "trends-in-ai-supercomputers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Konstantin F. Pilz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Frontier AI development relies on powerful AI supercomputers, yet analysis of these systems is limited. We create a dataset of 500 AI supercomputers from 2019 to 2025 and analyze key trends in performance, power needs, hardware cost, ownership, and global distribution. We find that the computational performance of AI supercomputers has doubled every nine months, while hardware acquisition cost and power needs both doubled every year. The leading system in March 2025, xAI's Colossus, used 200,000 AI chips, had a hardware cost of \\$7B, and required 300 MW of power, as much as 250,000 households. As AI supercomputers evolved from tools for science to industrial machines, companies rapidly expanded their share of total AI supercomputer performance, while the share of governments and academia diminished. Globally, the United States accounts for about 75% of total performance in our dataset, with China in second place at 15%. If the observed trends continue, the leading AI supercomputer in 2030 will achieve $2\\times10^{22}$ 16-bit FLOP/s, use two million AI chips, have a hardware cost of \\$200 billion, and require 9 GW of power. Our analysis provides visibility into the AI supercomputer landscape, allowing policymakers to assess key AI trends like resource needs, ownership, and national competitiveness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16026",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:19.538725Z"
  },
  {
    "id": "e8a28888fff426f76bf5eb7800384dcc",
    "title": "Online posting effects: Unveiling the non-linear journeys of users in depression communities on Reddit",
    "slug": "online-posting-effects:-unveiling-the-non-linear-journeys-of-users-in-depression-communities-on-reddit",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Virginia Morini",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Social media platforms have become pivotal as self-help forums, enabling individuals to share personal experiences and seek support. However, on topics as sensitive as depression, what are the consequences of online self-disclosure? Here, we delve into the dynamics of mental health discourse on various Reddit boards focused on depression. To this aim, we introduce a data-informed framework reconstructing online dynamics from 303k users interacting over two years. Through user-generated content, we identify 4 distinct clusters representing different psychological states. Our analysis unveils online posting effects: a user can transition to another psychological state after online exposure to peers' emotional/semantic content. As described by conditional Markov chains and different levels of social exposure, users' transitions reveal navigation through both positive and negative phases in a spiral rather than a linear progression. Interpreted in light of psychological literature, related particularly to the Patient Health Engagement (PHE) model, our findings can provide evidence that the type and layout of online social interactions have an impact on users' \"journeys\" when posting about depression.",
    "pdfUrl": "https://arxiv.org/pdf/2311.17684",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:19.539063Z"
  },
  {
    "id": "c74582cc6c72813c46774517ac1fd281",
    "title": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation",
    "slug": "post-hoc-study-of-climate-microtargeting-on-social-media-ads-with-llms:-thematic-insights-and-fairness-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Tunazzina Islam",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Climate change communication on social media increasingly employs microtargeting strategies to effectively reach and influence specific demographic groups. This study presents a post-hoc analysis of microtargeting practices within climate campaigns by leveraging large language models (LLMs) to examine Facebook advertisements. Our analysis focuses on two key aspects: demographic targeting and fairness. We evaluate the ability of LLMs to accurately predict the intended demographic targets, such as gender and age group, achieving an overall accuracy of 88.55%. Furthermore, we instruct the LLMs to generate explanations for their classifications, providing transparent reasoning behind each decision. These explanations reveal the specific thematic elements used to engage different demographic segments, highlighting distinct strategies tailored to various audiences. Our findings show that young adults are primarily targeted through messages emphasizing activism and environmental consciousness, while women are engaged through themes related to caregiving roles and social advocacy. In addition to evaluating the effectiveness of LLMs in detecting microtargeted messaging, we conduct a comprehensive fairness analysis to identify potential biases in model predictions. Our findings indicate that while LLMs perform well overall, certain biases exist, particularly in the classification of senior citizens and male audiences. By showcasing the efficacy of LLMs in dissecting and explaining targeted communication strategies and by highlighting fairness concerns, this study provides a valuable framework for future research aimed at enhancing transparency, accountability, and inclusivity in social media-driven climate campaigns.",
    "pdfUrl": "https://arxiv.org/pdf/2410.05401",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:19.539274Z"
  },
  {
    "id": "a158ca1367967d454e53c7613307f254",
    "title": "Investigating the Relationship Between Debiasing and Artifact Removal using Saliency Maps",
    "slug": "investigating-the-relationship-between-debiasing-and-artifact-removal-using-saliency-maps",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Lukasz Sztukiewicz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The widespread adoption of machine learning systems has raised critical concerns about fairness and bias, making mitigating harmful biases essential for AI development. In this paper, we investigate the relationship between debiasing and removing artifacts in neural networks for computer vision tasks. First, we introduce a set of novel XAI-based metrics that analyze saliency maps to assess shifts in a model's decision-making process. Then, we demonstrate that successful debiasing methods systematically redirect model focus away from protected attributes. Finally, we show that techniques originally developed for artifact removal can be effectively repurposed for improving fairness. These findings provide evidence for the existence of a bidirectional connection between ensuring fairness and removing artifacts corresponding to protected attributes.",
    "pdfUrl": "https://arxiv.org/pdf/2503.00234",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:19.539487Z"
  },
  {
    "id": "cacbb7c157ae957fd9d9a890faf96ab5",
    "title": "Beyond authorship: Analyzing contributions in PLOS ONE and the challenges of appropriate attribution",
    "slug": "beyond-authorship:-analyzing-contributions-in-plos-one-and-the-challenges-of-appropriate-attribution",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Digital Libraries (cs.DL)",
    "author": {
      "name": "Abdelghani Maddi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study aims to evaluate the accuracy of authorship attributions in scientific publications, focusing on the fairness and precision of individual contributions within academic works. The study analyzes 81,823 publications from the journal PLOS ONE, covering the period from January 2018 to June 2023. It examines the authorship attributions within these publications to try and determine the prevalence of inappropriate authorship. It also investigates the demographic and professional profiles of affected authors, exploring trends and potential factors contributing to inaccuracies in authorship. Surprisingly, 9.14% of articles feature at least one author with inappropriate authorship, affecting over 14,000 individuals (2.56% of the sample). Inappropriate authorship is more concentrated in Asia, Africa, and specific European countries like Italy. Established researchers with significant publication records and those affiliated with companies or nonprofits show higher instances of potential monetary authorship. Our findings are based on contributions as declared by the authors, which implies a degree of trust in their transparency. However, this reliance on self-reporting may introduce biases or inaccuracies into the dataset. Further research could employ additional verification methods to enhance the reliability of the findings. These findings have significant implications for journal publishers, highlighting the necessity for robust control mechanisms to ensure the integrity of authorship attributions. Moreover, researchers must exercise discernment in determining when to acknowledge a contributor and when to include them in the author list. Addressing these issues is crucial for maintaining the credibility and fairness of academic publications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.06314",
    "tags": [
      "Digital Libraries (cs.DL)"
    ],
    "createdAt": "2025-04-25T15:49:19.539680Z"
  },
  {
    "id": "b0e8ad2b2beb8f876303d2eb19e00669",
    "title": "vApps: Verifiable Applications at Internet Scale",
    "slug": "vapps:-verifiable-applications-at-internet-scale",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Isaac Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Blockchain technology promises a decentralized, trustless, and interoperable infrastructure. However, widespread adoption remains hindered by issues such as limited scalability, high transaction costs, and the complexity of maintaining coherent verification logic across different blockchain layers. This paper introduces Verifiable Applications (vApps), a novel development framework designed to streamline the creation and deployment of verifiable blockchain computing applications. vApps offer a unified Rust-based Domain-Specific Language (DSL) within a comprehensive SDK, featuring modular abstractions for verification, proof generation, and inter-chain connectivity. This eases the developer's burden in securing diverse software components, allowing them to focus on application logic. The DSL also ensures that applications can automatically take advantage of specialized precompiles and hardware acceleration to achieve consistently high performance with minimal developer effort, as demonstrated by benchmark results for zero-knowledge virtual machines (zkVMs). Experiments show that native Rust execution eliminates interpretation overhead, delivering up to an 832x cycle count improvement compared to EVM-based approaches. Precompiled circuits can accelerate the proof by more than 95%, while GPU acceleration increases throughput by up to 30x and recursion compresses the proof size by up to 230x, enabling succinct and efficient verification. The framework also supports seamless integration with the Web2 and Web3 systems, enabling developers to focus solely on their application logic. Through modular architecture, robust security guarantees, and composability, vApps pave the way toward a trust-minimized and verifiable Internet-scale application environment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14809",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:19.539903Z"
  },
  {
    "id": "ec0c518b558d85c5f1379bf1491ea55a",
    "title": "Transactional Cloud Applications: Status Quo, Challenges, and Opportunities",
    "slug": "transactional-cloud-applications:-status-quo,-challenges,-and-opportunities",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Rodrigo Laigner",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Transactional cloud applications such as payment, booking, reservation systems, and complex business workflows are currently being rewritten for deployment in the cloud. This migration to the cloud is happening mainly for reasons of cost and scalability. Over the years, application developers have used different migration approaches, such as microservice frameworks, actors, and stateful dataflow systems.\nThe migration to the cloud has brought back data management challenges traditionally handled by database management systems. Those challenges include ensuring state consistency, maintaining durability, and managing the application lifecycle. At the same time, the shift to a distributed computing infrastructure introduced new issues, such as message delivery, task scheduling, containerization, and (auto)scaling.\nAlthough the data management community has made progress in developing analytical and transactional database systems, transactional cloud applications have received little attention in database research. This tutorial aims to highlight recent trends in the area and discusses open research challenges for the data management community.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17106",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:19.801132Z"
  },
  {
    "id": "919fa58ef464af1c9cd1757cc7717593",
    "title": "How to Grow an LSM-tree? Towards Bridging the Gap Between Theory and Practice",
    "slug": "how-to-grow-an-lsm-tree?-towards-bridging-the-gap-between-theory-and-practice",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Dingheng Mo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LSM-tree based key-value stores are widely adopted as the data storage backend in modern big data applications. The LSM-tree grows with data ingestion, by either adding levels with fixed level capacities (dubbed as vertical scheme) or increasing level capacities with fixed number of levels (dubbed as horizontal scheme). The vertical scheme leads the trend in recent system designs in RocksDB, LevelDB, and WiredTiger, whereas the horizontal scheme shows a decline in being adopted in the industry. The growth scheme profoundly impacts the LSM system performance in various aspects such as read, write and space costs. This paper attempts to give a new insight into a fundamental design question -- how to grow an LSM-tree to attain more desirable performance?\nOur analysis highlights the limitations of the vertical scheme in achieving an optimal read-write trade-off and the horizontal scheme in managing space cost effectively. Building on the analysis, we present a novel approach, Vertiorizon, which combines the strengths of both the vertical and horizontal schemes to achieve a superior balance between lookup, update, and space costs. Its adaptive design makes it highly compatible with a wide spectrum of workloads. Compared to the vertical scheme, Vertiorizon significantly improves the read-write performance trade-off. In contrast to the horizontal scheme, Vertiorizon greatly extends the trade-off range by a non-trivial generalization of Bentley and Saxe's theory, while substantially reducing space costs. When integrated with RocksDB, Vertiorizon demonstrates better write performance than the vertical scheme, while incurring about six times less additional space cost compared to the horizontal scheme.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17178",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:19.801356Z"
  },
  {
    "id": "22ae069ea908d5e2d3607e2e38b07ef6",
    "title": "Evaluating Learned Query Performance Prediction Models at LinkedIn: Challenges, Opportunities, and Findings",
    "slug": "evaluating-learned-query-performance-prediction-models-at-linkedin:-challenges,-opportunities,-and-findings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Chujun Song",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advancements in learning-based query performance prediction models have demonstrated remarkable efficacy. However, these models are predominantly validated using synthetic datasets focused on cardinality or latency estimations. This paper explores the application of these models to LinkedIn's complex real-world OLAP queries executed on Trino, addressing four primary research questions: (1) How do these models perform on real-world industrial data with limited information? (2) Can these models generalize to new tasks, such as CPU time prediction and classification? (3) What additional information available from the query plan could be utilized by these models to enhance their performance? (4) What are the theoretical performance limits of these models given the available data? To address these questions, we evaluate several models-including TLSTM, TCNN, QueryFormer, and XGBoost, against the industrial query workload at LinkedIn, and extend our analysis to CPU time regression and classification tasks. We also propose a multi-task learning approach to incorporate underutilized operator-level metrics that could enhance model understanding. Additionally, we empirically analyze the inherent upper bound that can be achieved from the models.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17181",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:19.801574Z"
  },
  {
    "id": "91f12f4732b76b37384600a3c1c11195",
    "title": "High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services",
    "slug": "high-fidelity-and-complex-test-data-generation-for-real-world-sql-code-generation-services",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Shivasankari Kannan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The demand for high-fidelity test data is paramount in industrial settings where access to production data is largely restricted. Traditional data generation methods often fall short, struggling with low-fidelity and the ability to model complex data structures and semantic relationships that are critical for testing complex SQL code generation services like Natural Language to SQL (NL2SQL). In this paper, we address the critical need for generating syntactically correct and semantically ``meaningful'' mock data for complex schema that includes columns with nested structures that we frequently encounter in Google SQL code generation workloads. We highlight the limitations of existing approaches used in production, particularly their inability to handle large and complex schema, as well as the lack of semantically coherent test data that lead to limited test coverage. We demonstrate that by leveraging Large Language Models (LLMs) and incorporating strategic pre- and post-processing steps, we can generate realistic high-fidelity test data that adheres to complex structural constraints and maintains semantic integrity to the test targets (SQL queries/functions). This approach supports comprehensive testing of complex SQL queries involving joins, aggregations, and even deeply nested subqueries, ensuring robust evaluation of SQL code generation services, like NL2SQL and SQL Code Assistant services. Our results demonstrate the practical utility of an out-of-the-box LLM (\\textit{gemini}) based test data generation for industrial SQL code generation services where generating realistic test data is essential due to the frequent unavailability of production datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17203",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:19.801787Z"
  },
  {
    "id": "2aee07e66a64a8b17271fe5ecfe4217c",
    "title": "Storing and Querying Evolving Graphs in NoSQL Storage Models",
    "slug": "storing-and-querying-evolving-graphs-in-nosql-storage-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Alexandros Spitalas",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper investigates advanced storage models for evolving graphs, focusing on the efficient management of historical data and the optimization of global query performance. Evolving graphs, which represent dynamic relationships between entities over time, present unique challenges in preserving their complete history while supporting complex analytical queries. We first do a fast review of the current state of the art focusing mainly on distributed historical graph databases to provide the context of our proposals. We investigate the im- plementation of an enhanced vertex-centric storage model in MongoDB that prioritizes space efficiency by leveraging in-database query mechanisms to minimize redundant data and reduce storage costs. To ensure broad applicability, we employ datasets, some of which are generated with the LDBC SNB generator, appropriately post-processed to utilize both snapshot- and interval-based representations. Our experimental results both in centralized and distributed infrastructures, demonstrate significant improvements in query performance, particularly for resource-intensive global queries that traditionally suffer from inefficiencies in entity-centric frameworks. The proposed model achieves these gains by optimizing memory usage, reducing client involvement, and exploiting the computational capabilities of MongoDB. By addressing key bottlenecks in the storage and processing of evolving graphs, this study demonstrates a step toward a robust and scalable framework for managing dynamic graph data. This work contributes to the growing field of temporal graph analytics by enabling more efficient ex- ploration of historical data and facilitating real-time insights into the evolution of complex networks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17438",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:19.801991Z"
  },
  {
    "id": "93e79b4813f1bbadd872233ddb41b72e",
    "title": "From Randomized Response to Randomized Index: Answering Subset Counting Queries with Local Differential Privacy",
    "slug": "from-randomized-response-to-randomized-index:-answering-subset-counting-queries-with-local-differential-privacy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Qingqing Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Local Differential Privacy (LDP) is the predominant privacy model for safeguarding individual data privacy. Existing perturbation mechanisms typically require perturbing the original values to ensure acceptable privacy, which inevitably results in value distortion and utility deterioration. In this work, we propose an alternative approach -- instead of perturbing values, we apply randomization to indexes of values while ensuring rigorous LDP guarantees. Inspired by the deniability of randomized indexes, we present CRIAD for answering subset counting queries on set-value data. By integrating a multi-dummy, multi-sample, and multi-group strategy, CRIAD serves as a fully scalable solution that offers flexibility across various privacy requirements and domain sizes, and achieves more accurate query results than any existing methods. Through comprehensive theoretical analysis and extensive experimental evaluations, we validate the effectiveness of CRIAD and demonstrate its superiority over traditional value-perturbation mechanisms.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17523",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:19.802200Z"
  },
  {
    "id": "a7d4b3664c2c038482f1091445bd2765",
    "title": "CHASe: Client Heterogeneity-Aware Data Selection for Effective Federated Active Learning",
    "slug": "chase:-client-heterogeneity-aware-data-selection-for-effective-federated-active-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jun Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Active learning (AL) reduces human annotation costs for machine learning systems by strategically selecting the most informative unlabeled data for annotation, but performing it individually may still be insufficient due to restricted data diversity and annotation budget. Federated Active Learning (FAL) addresses this by facilitating collaborative data selection and model training, while preserving the confidentiality of raw data samples. Yet, existing FAL methods fail to account for the heterogeneity of data distribution across clients and the associated fluctuations in global and local model parameters, adversely affecting model accuracy. To overcome these challenges, we propose CHASe (Client Heterogeneity-Aware Data Selection), specifically designed for FAL. CHASe focuses on identifying those unlabeled samples with high epistemic variations (EVs), which notably oscillate around the decision boundaries during training. To achieve both effectiveness and efficiency, \\model{} encompasses techniques for 1) tracking EVs by analyzing inference inconsistencies across training epochs, 2) calibrating decision boundaries of inaccurate models with a new alignment loss, and 3) enhancing data selection efficiency via a data freeze and awaken mechanism with subset sampling. Experiments show that CHASe surpasses various established baselines in terms of effectiveness and efficiency, validated across diverse datasets, model complexities, and heterogeneous federation settings.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17448",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:19.802404Z"
  },
  {
    "id": "c01a743d3cfc9b890ab39841b429e227",
    "title": "Seamless Data Migration between Database Schemas with DAMI-Framework: An Empirical Study on Developer Experience",
    "slug": "seamless-data-migration-between-database-schemas-with-dami-framework:-an-empirical-study-on-developer-experience",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Delfina Ramos-Vidal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many businesses depend on legacy systems, which often use outdated technology that complicates maintenance and updates. Therefore, software modernization is essential, particularly data migration between different database schemas. Established methodologies, like model transformation and ETL tools, facilitate this migration; they require deep knowledge of database languages and both the source and target schemas. This necessity renders data migration an error-prone and cognitively demanding task. Our objective is to alleviate developers' workloads during schema evolution through our DAMI-Framework. This framework incorporates a domain-specific language (DSL) and a parser to facilitate data migration between database schemas. DAMI-DSL simplifies schema mapping while the parser automates SQL script generation. We assess developer experience in data migration by conducting an empirical evaluation with 21 developers to assess their experiences using our DSL versus traditional SQL. The study allows us to measure their perceptions of the DSL properties and user experience. The participants praised DAMI-DSL for its readability and ease of use. The findings indicate that our DSL reduces data migration efforts compared to SQL scripts.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17662",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:19.802619Z"
  },
  {
    "id": "12526f6e295ffbb2311c6d47cbc2103d",
    "title": "HotStuff-1: Linear Consensus with One-Phase Speculation",
    "slug": "hotstuff-1:-linear-consensus-with-one-phase-speculation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Dakai Kang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces HotStuff-1, a BFT consensus protocol that improves the latency of HotStuff-2 by two network hops while maintaining linear communication complexity against faults. Furthermore, HotStuff-1 incorporates an incentive-compatible leader rotation design that motivates leaders to propose transactions promptly. HotStuff-1 achieves a reduction of two network hops by speculatively sending clients early confirmations, after one phase of the protocol. Introducing speculation into streamlined protocols is challenging because, unlike stable-leader protocols, these protocols cannot stop the consensus and recover from failures. Thus, we identify prefix speculation dilemma in the context of streamlined protocols; HotStuff-1 is the first streamlined protocol to resolve it. HotStuff-1 embodies an additional mechanism, slotting, that thwarts delays caused by (1) rationally-incentivized leaders and (2) malicious leaders inclined to sabotage other's progress. The slotting mechanism allows leaders to dynamically drive as many decisions as allowed by network transmission delays before view timers expire, thus mitigating both threats.",
    "pdfUrl": "https://arxiv.org/pdf/2408.04728",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:19.802820Z"
  },
  {
    "id": "e91a04161d79f70ba38770fb720c4a84",
    "title": "Rel: A Programming Language for Relational Data",
    "slug": "rel:-a-programming-language-for-relational-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Molham Aref",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "From the moment of their inception, languages for relational data have been described as sublanguages embedded in a host programming language. Rel is a new relational language whose key design goal is to go beyond this paradigm with features that allow for programming in the large, making it possible to fully describe end to end application semantics. With the new approach we can model the semantics of entire enterprise applications relationally, which helps significantly reduce architecture complexity and avoid the well-known impedance mismatch problem. This paradigm shift is enabled by 50 years of database research, making it possible to revisit the sublanguage/host language paradigm, starting from the fundamental principles. We present the main features of Rel: those that give it the power to express traditional query language operations and those that are designed to grow the language and allow programming in the large.",
    "pdfUrl": "https://arxiv.org/pdf/2504.10323",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:19.803053Z"
  },
  {
    "id": "74246e1da17cedd098de0d241e94e759",
    "title": "SQL-Factory: A Multi-Agent Framework for High-Quality and Large-Scale SQL Generation",
    "slug": "sql-factory:-a-multi-agent-framework-for-high-quality-and-large-scale-sql-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Jiahui Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Hight quality SQL corpus is essential for intelligent database. For example, Text-to-SQL requires SQL queries and correspond natural language questions as training samples. However, collecting such query corpus remains challenging in practice due to the high cost of manual annotation, which highlights the importance of automatic SQL generation. Despite recent advances, existing generation methods still face limitations in achieving both diversity and cost-effectiveness. Besides, many methods also treat all tables equally during generation, which overlooks schema complexity and leads to under-utilization of structurally rich tables. To address these issues, this paper proposes a multi-agent framework for high-quality and large-scale SQL generation, dubbed SQL-Factory. It decomposes the generation process into three collaborative teams: the Generation Team explores diverse query structures using large language models, the Expansion Team scales promising patterns via lightweight local models, and the Management Team adaptively schedules and evaluates generation based on schema coverage and real-time query quality. This modular framework ensures a balanced trade-off between diversity, scalability, and generation cost. We apply SQL-Factory to four widely used benchmarks and generate over 300,000 executable and broadly distributed SQL queries with less than $200 API cost. Our generated queries achieve higher diversity compared to other methods, and extensive experiments demonstrate that the generated queries significantly improve the model performance in various downstream tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14837",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:19.803248Z"
  },
  {
    "id": "1be942af0cd286e39636bc3788817129",
    "title": "Sailor: Automating Distributed Training over Dynamic, Heterogeneous, and Geo-distributed Clusters",
    "slug": "sailor:-automating-distributed-training-over-dynamic,-heterogeneous,-and-geo-distributed-clusters",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Foteini Strati",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The high GPU demand of ML training makes it hard to allocate large homogeneous clusters of high-end GPUs in a single availability zone. Leveraging heterogeneous GPUs available within and across zones can improve throughput at a reasonable cost. However, training ML models on heterogeneous resources introduces significant challenges, such as stragglers and a large search space of possible job configurations. Current systems lack support for efficiently training models on heterogeneous resources. We present Sailor, a system that automates distributed training over heterogeneous, geo-distributed, and dynamically available resources. Sailor combines an efficient search space exploration algorithm, accurate runtime and memory footprint simulation, and a distributed training framework that supports different types of heterogeneity to optimize training throughput and cost.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17096",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.098023Z"
  },
  {
    "id": "90bc6b6f705d07a73bba88df6453acd4",
    "title": "Parallelizing the Approximate Minimum Degree Ordering Algorithm: Strategies and Evaluation",
    "slug": "parallelizing-the-approximate-minimum-degree-ordering-algorithm:-strategies-and-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Yen-Hsiang Chang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The approximate minimum degree algorithm is widely used before numerical factorization to reduce fill-in for sparse matrices. While considerable attention has been given to the numerical factorization process, less focus has been placed on parallelizing the approximate minimum degree algorithm itself. In this paper, we explore different parallelization strategies, and introduce a novel parallel framework that leverages multiple elimination on distance-2 independent sets. Our evaluation shows that parallelism within individual elimination steps is limited due to low computational workload and significant memory contention. In contrast, our proposed framework overcomes these challenges by parallelizing the work across elimination steps. To the best of our knowledge, our implementation is the first scalable shared memory implementation of the approximate minimum degree algorithm. Experimental results show that we achieve up to an 8.30x speedup using 64 threads over the state-of-the-art sequential implementation in SuiteSparse.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17097",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.098248Z"
  },
  {
    "id": "1d32f43737fb5154f496d7aa85188ef6",
    "title": "Dynamic Approximate Maximum Matching in the Distributed Vertex Partition Model",
    "slug": "dynamic-approximate-maximum-matching-in-the-distributed-vertex-partition-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Peter Robinson",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We initiate the study of approximate maximum matching in the vertex partition model, for graphs subject to dynamic changes. We assume that the $n$ vertices of the graph are partitioned among $k$ players, who execute a distributed algorithm and communicate via message passing. An adaptive adversary may perform dynamic updates to the graph topology by inserting or removing edges between the nodes, and the algorithm needs to respond to these changes by adapting the output of the players, with the goal of maintaining an approximate maximum matching. The main performance metric in this setting is the algorithm's update time, which corresponds to the number of rounds required for updating the solution upon an adversarial change. For the standard setting of single-edge insertions and deletions, we obtain the following results:\nWe give a randomized Las Vegas algorithm with an expected update time of $O( \\frac{\\sqrt{m}}{\\beta k} )$ rounds that maintains a $\\frac{2}{3}$-approximate maximum matching that is also maximal, where $m$ is the number of edges of the graph. We also show that any algorithm has a worst case update time of $\\Omega( \\frac{n}{\\beta k^2\\log n} )$, assuming a link bandwidth of $O(\\beta\\log n)$ bits per round, if it maintains a matching that is maximal and does not have any 3-augmenting paths. For batch-dynamic updates, where the adversary may modify up to $\\ell\\ge 1$ edges at once, we prove the following: There is a randomized algorithm that succeeds with high probability in maintaining a $\\frac{2}{3}$-approximate maximum matching and has a worst case update time of $\\Omega( \\frac{\\ell\\log n}{\\sqrt{\\beta k}} )$ rounds. We show that $\\Omega( \\frac{\\ell}{\\beta k \\log n} )$ poses a lower bound for maintaining a maximal matching without 3-augmenting paths.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17338",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.098455Z"
  },
  {
    "id": "73b5b6eb2d84f9807661646af551facd",
    "title": "Shared Randomness in Locally Checkable Problems: The Role of Computational Assumptions",
    "slug": "shared-randomness-in-locally-checkable-problems:-the-role-of-computational-assumptions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Adar Hadad",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Shared randomness is a valuable resource in distributed computing, but what happens when the shared random string can affect the inputs to the system?\nConsider the class of distributed graph problems where the correctness of solutions can be checked locally, known as Locally Checkable Labelings (LCL). LCL problems have been extensively studied in the LOCAL model, where nodes operate in synchronous rounds and have access only to local information. This has led to intriguing insights regarding the power of private randomness. E.g., for certain round complexity classes, derandomization does not incur an overhead (asymptotically).\nThis work considers a setting where the randomness is public. Recently, an LCL problem for which shared randomness can reduce the round complexity was discovered by Balliu et al. (2024). This result applies to inputs set obliviously of the shared randomness, which may not always be a plausible assumption.\nWe define a model where the inputs can be adversarially chosen, even based on the shared randomness, which we now call preset public coins. We study LCL problems in the preset public coins model, under assumptions regarding the computational power of the adversary that selects the input. We show connections to hardness in the class TFNP. Our results are:\n1. Assuming the existence of a hard-on-average problem in TFNP (which follows from fairly benign cryptographic assumptions), we show an LCL problem that, in the preset public coins model, demonstrates a gap in the round complexity between polynomial-time adversaries and unbounded ones.\n2. If there exists an LCL problem for which the error probability is significantly higher when facing unbounded adversaries, then a hard-on-average problem in TFNP/poly must exist.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17583",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.098652Z"
  },
  {
    "id": "e5b90b03811e6888fa92915ca717bf4e",
    "title": "TSUE: A Two-Stage Data Update Method for an Erasure Coded Cluster File System",
    "slug": "tsue:-a-two-stage-data-update-method-for-an-erasure-coded-cluster-file-system",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Zheng Wei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Compared to replication-based storage systems, erasure-coded storage incurs significantly higher overhead during data updates. To address this issue, various parity logging methods have been pro- posed. Nevertheless, due to the long update path and substantial amount of random I/O involved in erasure code update processes, the resulting long latency and low throughput often fail to meet the requirements of high performance applications. To this end, we propose a two-stage data update method called TSUE. TSUE divides the update process into a synchronous stage that records updates in a data log, and an asynchronous stage that recycles the log in real-time. TSUE effectively reduces update latency by transforming random I/O into sequential I/O, and it significantly reduces recycle overhead by utilizing a three-layer log and the spatio-temporal locality of access patterns. In SSDs cluster, TSUE significantly im- proves update performance, achieving improvements of 7.6X under Ali-Cloud trace, 5X under Ten-Cloud trace, while it also extends the SSD's lifespan by up to 13X through reducing the frequencies of reads/writes and of erase operations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17598",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.098867Z"
  },
  {
    "id": "4e7546bc4e4fc6840df80ef91453bcdb",
    "title": "Cross-region Model Training with Communication-Computation Overlapping and Delay Compensation",
    "slug": "cross-region-model-training-with-communication-computation-overlapping-and-delay-compensation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Ying Zhu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Training large language models (LLMs) requires massive computational resources, often necessitating the aggregation of geographically distributed data centers (\\ie, cross-region training). However, the high communication latency in wide-area networks severely degrades the efficiency of traditional distributed training. While methods like DiLoCo reduce communication frequency, they suffer from blocking synchronization. Streaming DiLoCo alleviates this issue via communication-computation overlapping but introduces update staleness and model inconsistency due to delayed global updates and partial synchronization. These factors impair convergence, especially when aggressive overlap is needed to mask high latency. We propose CoCoDC, a novel distributed training framework with communication-computation overlapping and delay compensation, to explicitly tackle these challenges. Within the CoCoDC framework, we specifically develop a novel Delay Compensation strategy based on Taylor expansion to effectively mitigate the staleness and an Adaptive Transmission strategy that dynamically schedules model fragment synchronization to optimize bandwidth usage and accelerate convergence. Extensive experiments highlight the superior performance of CoCoDC over both DiLoCo and Streaming DiLoCo regarding final accuracy and training speed. Specifically, CoCoDC reduces the training steps needed to reach a comparable perplexity by up to 21.0% compared to Streaming DiLoCo. Our work provides an effective solution for scalable and efficient cross-region LLM training.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17672",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.099074Z"
  },
  {
    "id": "43023b7952993df88720cc062665876e",
    "title": "Optimized Cloud Resource Allocation Using Genetic Algorithms for Energy Efficiency and QoS Assurance",
    "slug": "optimized-cloud-resource-allocation-using-genetic-algorithms-for-energy-efficiency-and-qos-assurance",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Caroline Panggabean",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Cloud computing environments demand dynamic and efficient resource management to ensure optimal performance, reduced energy consumption, and adherence to Service Level Agreements (SLAs). This paper presents a Genetic Algorithm (GA)-based approach for Virtual Machine (VM) placement and consolidation, aiming to minimize power usage while maintaining QoS constraints. The proposed method dynamically adjusts VM allocation based on real-time workload variations, outperforming traditional heuristics such as First Fit Decreasing (FFD) and Best Fit Decreasing (BFD). Experimental results show notable reductions in energy consumption, VM migrations, SLA violation rates, and execution time. A correlation heatmap further illustrates strong relationships among these key performance indicators, confirming the effectiveness of our approach in optimizing cloud resource utilization.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17675",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.099291Z"
  },
  {
    "id": "0c4090b5f361c4e67c7387b423ec5aa2",
    "title": "Developing a Blockchain-Based Secure Digital Contents Distribution System",
    "slug": "developing-a-blockchain-based-secure-digital-contents-distribution-system",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Syed Mohiuddin Qadri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As digital content distribution expands rapidly through online platforms, securing digital media and protecting intellectual property has become increasingly complex. Traditional centralized systems, while widely adopted, suffer from vulnerabilities such as single points of failure and limited traceability of unauthorized access. This paper presents a blockchain-based secure digital content distribution system that integrates Sia, a decentralized storage network, and Skynet, a content delivery network, to enhance content protection and distribution. The proposed system employs a dual-layer architecture: off-chain for user authentication and on-chain for transaction validation using smart contracts and asymmetric encryption. By introducing a license issuance and secret block mechanism, the system ensures content authenticity, privacy, and controlled access. Experimental results demonstrate the feasibility and scalability of the system in securely distributing multimedia files. The proposed platform not only improves content security but also paves the way for future enhancements with decentralized applications and integrated royalty payment mechanisms.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17194",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:20.099489Z"
  },
  {
    "id": "a7d4b3664c2c038482f1091445bd2765",
    "title": "CHASe: Client Heterogeneity-Aware Data Selection for Effective Federated Active Learning",
    "slug": "chase:-client-heterogeneity-aware-data-selection-for-effective-federated-active-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jun Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Active learning (AL) reduces human annotation costs for machine learning systems by strategically selecting the most informative unlabeled data for annotation, but performing it individually may still be insufficient due to restricted data diversity and annotation budget. Federated Active Learning (FAL) addresses this by facilitating collaborative data selection and model training, while preserving the confidentiality of raw data samples. Yet, existing FAL methods fail to account for the heterogeneity of data distribution across clients and the associated fluctuations in global and local model parameters, adversely affecting model accuracy. To overcome these challenges, we propose CHASe (Client Heterogeneity-Aware Data Selection), specifically designed for FAL. CHASe focuses on identifying those unlabeled samples with high epistemic variations (EVs), which notably oscillate around the decision boundaries during training. To achieve both effectiveness and efficiency, \\model{} encompasses techniques for 1) tracking EVs by analyzing inference inconsistencies across training epochs, 2) calibrating decision boundaries of inaccurate models with a new alignment loss, and 3) enhancing data selection efficiency via a data freeze and awaken mechanism with subset sampling. Experiments show that CHASe surpasses various established baselines in terms of effectiveness and efficiency, validated across diverse datasets, model complexities, and heterogeneous federation settings.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17448",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:20.099702Z"
  },
  {
    "id": "c1ca163d2f9b49caec431b78426c9bff",
    "title": "GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework",
    "slug": "granite-:-a-byzantine-resilient-dynamic-gossip-learning-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yacine Belal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Gossip Learning (GL) is a decentralized learning paradigm where users iteratively exchange and aggregate models with a small set of neighboring peers. Recent GL approaches rely on dynamic communication graphs built and maintained using Random Peer Sampling (RPS) protocols. Thanks to graph dynamics, GL can achieve fast convergence even over extremely sparse topologies. However, the robustness of GL over dy- namic graphs to Byzantine (model poisoning) attacks remains unaddressed especially when Byzantine nodes attack the RPS protocol to scale up model poisoning. We address this issue by introducing GRANITE, a framework for robust learning over sparse, dynamic graphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two key components (i) a History-aware Byzantine-resilient Peer Sampling protocol (HaPS), which tracks previously encountered identifiers to reduce adversarial influence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which leverages an estimate of Byzantine presence to set aggregation thresholds with formal guarantees. Empirical results confirm that GRANITE maintains convergence with up to 30% Byzantine nodes, improves learning speed via adaptive filtering of poisoned models and obtains these results in up to 9 times sparser graphs than dictated by current theory.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17471",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:20.099908Z"
  },
  {
    "id": "5070e0388898d88eb1e79d09e34c8352",
    "title": "Communication-Efficient Personalized Distributed Learning with Data and Node Heterogeneity",
    "slug": "communication-efficient-personalized-distributed-learning-with-data-and-node-heterogeneity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhuojun Tian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "To jointly tackle the challenges of data and node heterogeneity in decentralized learning, we propose a distributed strong lottery ticket hypothesis (DSLTH), based on which a communication-efficient personalized learning algorithm is developed. In the proposed method, each local model is represented as the Hadamard product of global real-valued parameters and a personalized binary mask for pruning. The local model is learned by updating and fusing the personalized binary masks while the real-valued parameters are fixed among different agents. To further reduce the complexity of hardware implementation, we incorporate a group sparse regularization term in the loss function, enabling the learned local model to achieve structured sparsity. Then, a binary mask aggregation algorithm is designed by introducing an intermediate aggregation tensor and adding a personalized fine-tuning step in each iteration, which constrains model updates towards the local data distribution. The proposed method effectively leverages the relativity among agents while meeting personalized requirements in heterogeneous node conditions. We also provide a theoretical proof for the DSLTH, establishing it as the foundation of the proposed method. Numerical simulations confirm the validity of the DSLTH and demonstrate the effectiveness of the proposed algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17520",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:20.100116Z"
  },
  {
    "id": "ec318b0dd1ca00933195b48e13cc2591",
    "title": "Aegis: Tethering a Blockchain with Primary-Chain Stake",
    "slug": "aegis:-tethering-a-blockchain-with-primary-chain-stake",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Yogev Bar-On",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Blockchains implement decentralized monetary systems and applications. Recent advancements enable what we call tethering a blockchain to a primary blockchain, securing the tethered chain by nodes that post primary-chain tokens as collateral. The collateral ensures nodes behave as intended, until they withdraw it. Unlike a Proof of Stake blockchain which uses its own token as collateral, using primary-chain tokens shields the tethered chain from the volatility of its own token.\nState-of-the-art tethered blockchains either rely on centralization, or make extreme assumptions: that all communication is synchronous, that operators remain correct even post-withdrawal, or that withdrawals can be indefinitely delayed by tethered-chain failures.\nWe prove that with partial synchrony, there is no solution to the problem. However, under the standard assumptions that communication with the primary chain is synchronous and communication among the tethered chain nodes is partially synchronous, there is a solution. We present a tethered-chain protocol called Aegis. Aegis uses references from its blocks to primary blocks to define committees, checkpoints on the primary chain to perpetuate decisions, and resets to establish new committees when previous ones become obsolete. It ensures safety at all times and rapid progress when latency among Aegis nodes is low.",
    "pdfUrl": "https://arxiv.org/pdf/2406.05904",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.100325Z"
  },
  {
    "id": "add84aa839b3e1eb69df9cc6e03c31be",
    "title": "ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation",
    "slug": "real:-efficient-rlhf-training-of-large-language-models-with-parameter-reallocation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Zhiyu Mei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for empowering large language model (LLM) applications. Compared with the supervised training process of LLMs, the RLHF training process is much more sophisticated, requiring a diverse range of computation workloads with intricate dependencies between multiple LLM instances. Therefore, simply adopting the fixed parallelization strategies from supervised training for LLMs can be insufficient for RLHF and result in low training efficiency. To overcome this limitation, we propose a novel technique named parameter ReaLlocation, which dynamically adapts the parallelization strategies for different workloads during training by redistributing LLM parameters across the training cluster. Building upon this idea, we introduce ReaL, a pioneering system for efficient RLHF training. ReaL introduces the concept of an execution plan, which defines a fine-grained resource allocation and parallelization strategy particularly designed for RLHF training. Based on this concept, ReaL employs a tailored search algorithm with a lightweight run-time estimator to automatically discover an efficient execution plan for an instance of RLHF experiment. Subsequently, the runtime engine deploys the selected plan by effectively parallelizing computations and redistributing parameters. We evaluate ReaL on the LLaMA models with up to 70 billion parameters and 128 GPUs. The experimental results demonstrate that ReaL achieves speedups of up to $3.58\\times$ compared to baseline methods. Furthermore, the execution plans generated by ReaL exhibit an average of $81\\%$ performance improvement over heuristic approaches based on Megatron-LM in the long-context scenario. The source code of ReaL is publicly available at this https URL .",
    "pdfUrl": "https://arxiv.org/pdf/2406.14088",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.100542Z"
  },
  {
    "id": "7a1522414622be7cfbc628f5e72c513f",
    "title": "MEV Capture Through Time-Advantaged Arbitrage",
    "slug": "mev-capture-through-time-advantaged-arbitrage",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Robin Fritsch",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As blockchains begin processing significant economic activity, the ability to include and order transactions inevitably becomes highly valuable, a concept known as Maximal Extractable Value (MEV). This makes effective mechanisms for transaction inclusion and ordering, and thereby the extraction of MEV, a key aspect of blockchain design. Beyond traditional approaches such as ordering in a first-come-first-serve manner or using priority fees, a recent proposal suggests auctioning off a time advantage for transaction inclusion. In this paper, we investigate this time advantage mechanism, focusing specifically on arbitrage opportunities on Automated Market Makers (AMMs), one of the largest sources of MEV today. We analyze the optimal strategy for a time-advantaged arbitrageur and compare the profits generated by various MEV extraction methods. Finally, we explore how AMMs can be adapted in the time advantage setting to capture a portion of the MEV.",
    "pdfUrl": "https://arxiv.org/pdf/2410.10797",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.100740Z"
  },
  {
    "id": "a07cab6ea0bb9ec7a9e0d0e3edaf80c3",
    "title": "EPOCH: Enabling Preemption Operation for Context Saving in Heterogeneous FPGA Systems",
    "slug": "epoch:-enabling-preemption-operation-for-context-saving-in-heterogeneous-fpga-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Arsalan Ali Malik",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "FPGAs are increasingly used in multi-tenant cloud environments to offload compute-intensive tasks from the main CPU. The operating system (OS) plays a vital role in identifying tasks suitable for offloading and coordinating between the CPU and FPGA for seamless task execution. The OS leverages preemption to manage CPU efficiently and balance CPU time; however, preempting tasks running on FPGAs without context loss remains challenging. Despite growing reliance on FPGAs, vendors have yet to deliver a solution that fully preserves and restores task context.\nThis paper presents EPOCH, the first out-of-the-box framework to seamlessly preserve the state of tasks running on multi-tenant cloud FPGAs. EPOCH enables interrupting a tenant's execution at any arbitrary clock cycle, capturing its state, and saving this 'state snapshot' in off-chip memory with fine-grain granularity. Subsequently, when task resumption is required, EPOCH can resume execution from the saved 'state snapshot', eliminating the need to restart the task from scratch. EPOCH automates intricate processes, shields users from complexities, and synchronizes all underlying logic in a common clock domain, mitigating timing violations and ensuring seamless handling of interruptions.\nEPOCH proficiently captures the state of fundamental FPGA elements, such as look-up tables, flip-flops, block--RAMs, and digital signal processing units. On real hardware, ZynQ-XC7Z020 SoC, the proposed solution achieves context save and restore operations per frame in 62.2us and 67.4us, respectively.",
    "pdfUrl": "https://arxiv.org/pdf/2501.16205",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.100937Z"
  },
  {
    "id": "295aa11f54de52f51978448e2e9183e0",
    "title": "Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable Random Walks",
    "slug": "honeybee:-byzantine-tolerant-decentralized-peer-sampling-with-verifiable-random-walks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Yunqi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and table consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\\geq50\\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes.",
    "pdfUrl": "https://arxiv.org/pdf/2402.16201",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:20.101127Z"
  },
  {
    "id": "6fad4474153f437311df4a1110590a3c",
    "title": "THEMIS: Time, Heterogeneity, and Energy Minded Scheduling for Fair Multi-Tenant Use in FPGAs",
    "slug": "themis:-time,-heterogeneity,-and-energy-minded-scheduling-for-fair-multi-tenant-use-in-fpgas",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operating Systems (cs.OS)",
    "author": {
      "name": "Emre Karabulut",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Using correct design metrics and understanding the limitations of the underlying technology is critical to developing effective scheduling algorithms. Unfortunately, existing scheduling techniques used \\emph{incorrect} metrics and had \\emph{unrealistic} assumptions for fair scheduling of multi-tenant FPGAs where each tenant is aimed to share approximately the same number of resources both spatially and temporally.\nThis paper introduces an enhanced fair scheduling algorithm for multi-tenant FPGA use, addressing previous metric and assumption issues, with three specific improvements claimed First, our method ensures spatiotemporal fairness by considering both spatial and temporal aspects, addressing the limitation of prior work that assumed uniform task latency. Second, we incorporate energy considerations into fairness by adjusting scheduling intervals and accounting for energy overhead, thereby balancing energy efficiency with fairness. Third, we acknowledge overlooked aspects of FPGA multi-tenancy, including heterogeneous regions and the constraints on dynamically merging/splitting partially reconfigurable regions. We develop and evaluate our improved fair scheduling algorithm with these three enhancements. Inspired by the Greek goddess of law and personification of justice, we name our fair scheduling solution THEMIS: \\underline{T}ime, \\underline{H}eterogeneity, and \\underline{E}nergy \\underline{Mi}nded \\underline{S}cheduling.\nWe used the Xilinx Zedboard XC7Z020 to quantify our approach's savings. Compared to previous algorithms, our improved scheduling algorithm enhances fairness between 24.2--98.4\\% and allows a trade-off between 55.3$\\times$ in energy vs. 69.3$\\times$ in fairness. The paper thus informs cloud providers about future scheduling optimizations for fairness with related challenges and opportunities.",
    "pdfUrl": "https://arxiv.org/pdf/2404.00507",
    "tags": [
      "Operating Systems (cs.OS)"
    ],
    "createdAt": "2025-04-25T15:49:20.101337Z"
  },
  {
    "id": "c11dcca2b653943ac04708a6709e76f8",
    "title": "DDU-Net: A Domain Decomposition-Based CNN for High-Resolution Image Segmentation on Multiple GPUs",
    "slug": "ddu-net:-a-domain-decomposition-based-cnn-for-high-resolution-image-segmentation-on-multiple-gpus",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Corn Verburg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The segmentation of ultra-high resolution images poses challenges such as loss of spatial information or computational inefficiency. In this work, a novel approach that combines encoder-decoder architectures with domain decomposition strategies to address these challenges is proposed. Specifically, a domain decomposition-based U-Net (DDU-Net) architecture is introduced, which partitions input images into non-overlapping patches that can be processed independently on separate devices. A communication network is added to facilitate inter-patch information exchange to enhance the understanding of spatial context. Experimental validation is performed on a synthetic dataset that is designed to measure the effectiveness of the communication network. Then, the performance is tested on the DeepGlobe land cover classification dataset as a real-world benchmark data set. The results demonstrate that the approach, which includes inter-patch communication for images divided into $16\\times16$ non-overlapping subimages, achieves a $2-3\\,\\%$ higher intersection over union (IoU) score compared to the same network without inter-patch communication. The performance of the network which includes communication is equivalent to that of a baseline U-Net trained on the full image, showing that our model provides an effective solution for segmenting ultra-high-resolution images while preserving spatial context. The code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2407.21266",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:20.101534Z"
  },
  {
    "id": "66750d501bd0f65f7bd287f41e116afa",
    "title": "SPAARC: Spatial Proximity and Association based prefetching for Augmented Reality in edge Cache",
    "slug": "spaarc:-spatial-proximity-and-association-based-prefetching-for-augmented-reality-in-edge-cache",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Emerging Technologies (cs.ET)",
    "author": {
      "name": "Nikhil Sreekumar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Mobile Augmented Reality (MAR) applications face performance challenges due to their high computational demands and need for low-latency responses. Traditional approaches like on-device storage or reactive data fetching from the cloud often result in limited AR experiences or unacceptable lag. Edge caching, which caches AR objects closer to the user, provides a promising solution. However, existing edge caching approaches do not consider AR-specific features such as AR object sizes, user interactions, and physical location. This paper investigates how to further optimize edge caching by employing AR-aware prefetching techniques. We present SPAARC, a Spatial Proximity and Association-based Prefetching policy specifically designed for MAR Caches. SPAARC intelligently prioritizes the caching of virtual objects based on their association with other similar objects and the user's proximity to them. It also considers the recency of associations and uses a lazy fetching strategy to efficiently manage edge resources and maximize Quality of Experience (QoE).\nThrough extensive evaluation using both synthetic and real-world workloads, we demonstrate that SPAARC significantly improves cache hit rates compared to standard caching algorithms, achieving gains ranging from 3% to 40% while reducing the need for on-demand data retrieval from the cloud. Further, we present an adaptive tuning algorithm that automatically tunes SPAARC parameters to achieve optimal performance. Our findings demonstrate the potential of SPAARC to substantially enhance the user experience in MAR applications by ensuring the timely availability of virtual objects.",
    "pdfUrl": "https://arxiv.org/pdf/2502.15192",
    "tags": [
      "Emerging Technologies (cs.ET)"
    ],
    "createdAt": "2025-04-25T15:49:20.101726Z"
  },
  {
    "id": "34322948433d085f33f3e6d2ff8604a2",
    "title": "Metadata Augmentation using NLP, Machine Learning and AI chatbots: A comparison",
    "slug": "metadata-augmentation-using-nlp,-machine-learning-and-ai-chatbots:-a-comparison",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Digital Libraries (cs.DL)",
    "author": {
      "name": "Alfredo Gonzlez-Espinoza",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advances in machine learning and artificial intelligence have provided more alternatives for the implementation of repetitive or monotonous tasks. However, the development of AI tools has not been straightforward, and use case exploration and workflow integration are still ongoing challenges. In this work, we present a detailed qualitative analysis of the performance and user experience of popular commercial AI chatbots when used for document classification with limited data. We report the results for a real-world example of metadata augmentation in academic libraries environment. We compare the results of AI chatbots with other machine learning and natural language processing methods such as XGBoost and BERT-based fine tuning, and share insights from our experience. We found that AI chatbots perform similarly among them while outperforming the machine learning methods we tested, showing their advantage when the method relies on local data for training. We also found that while working with AI chatbots is easier than with code, getting useful results from them still represents a challenge for the user. Furthermore, we encountered alarming conceptual errors in the output of some chatbots, such as not being able to count the number of lines of our inputs and explaining the mistake as ``human error''. Although this is not complete evidence that AI chatbots can be effectively used for metadata classification, we believe that the information provided in this work can be useful to librarians and data curators in developing pathways for the integration and use of AI tools for data curation or metadata augmentation tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17189",
    "tags": [
      "Digital Libraries (cs.DL)"
    ],
    "createdAt": "2025-04-25T15:49:20.381675Z"
  },
  {
    "id": "cacbb7c157ae957fd9d9a890faf96ab5",
    "title": "Beyond authorship: Analyzing contributions in PLOS ONE and the challenges of appropriate attribution",
    "slug": "beyond-authorship:-analyzing-contributions-in-plos-one-and-the-challenges-of-appropriate-attribution",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Digital Libraries (cs.DL)",
    "author": {
      "name": "Abdelghani Maddi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study aims to evaluate the accuracy of authorship attributions in scientific publications, focusing on the fairness and precision of individual contributions within academic works. The study analyzes 81,823 publications from the journal PLOS ONE, covering the period from January 2018 to June 2023. It examines the authorship attributions within these publications to try and determine the prevalence of inappropriate authorship. It also investigates the demographic and professional profiles of affected authors, exploring trends and potential factors contributing to inaccuracies in authorship. Surprisingly, 9.14% of articles feature at least one author with inappropriate authorship, affecting over 14,000 individuals (2.56% of the sample). Inappropriate authorship is more concentrated in Asia, Africa, and specific European countries like Italy. Established researchers with significant publication records and those affiliated with companies or nonprofits show higher instances of potential monetary authorship. Our findings are based on contributions as declared by the authors, which implies a degree of trust in their transparency. However, this reliance on self-reporting may introduce biases or inaccuracies into the dataset. Further research could employ additional verification methods to enhance the reliability of the findings. These findings have significant implications for journal publishers, highlighting the necessity for robust control mechanisms to ensure the integrity of authorship attributions. Moreover, researchers must exercise discernment in determining when to acknowledge a contributor and when to include them in the author list. Addressing these issues is crucial for maintaining the credibility and fairness of academic publications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.06314",
    "tags": [
      "Digital Libraries (cs.DL)"
    ],
    "createdAt": "2025-04-25T15:49:20.381885Z"
  },
  {
    "id": "90bc6b6f705d07a73bba88df6453acd4",
    "title": "Parallelizing the Approximate Minimum Degree Ordering Algorithm: Strategies and Evaluation",
    "slug": "parallelizing-the-approximate-minimum-degree-ordering-algorithm:-strategies-and-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Yen-Hsiang Chang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The approximate minimum degree algorithm is widely used before numerical factorization to reduce fill-in for sparse matrices. While considerable attention has been given to the numerical factorization process, less focus has been placed on parallelizing the approximate minimum degree algorithm itself. In this paper, we explore different parallelization strategies, and introduce a novel parallel framework that leverages multiple elimination on distance-2 independent sets. Our evaluation shows that parallelism within individual elimination steps is limited due to low computational workload and significant memory contention. In contrast, our proposed framework overcomes these challenges by parallelizing the work across elimination steps. To the best of our knowledge, our implementation is the first scalable shared memory implementation of the approximate minimum degree algorithm. Experimental results show that we achieve up to an 8.30x speedup using 64 threads over the state-of-the-art sequential implementation in SuiteSparse.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17097",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.647439Z"
  },
  {
    "id": "9d1916302c6568918e8e2cbeb2cf4371",
    "title": "Vertex evaluation of multiplex graphs using Forman Curvature",
    "slug": "vertex-evaluation-of-multiplex-graphs-using-forman-curvature",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Taiki Yamada",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Identifying vertices that play a central role is a fundamental problem in network analysis. Although traditional centrality measures have been widely used for this purpose, the growing complexity of contemporary networks necessitates more sophisticated indicators. Forman curvature has recently emerged as a promising approach. In this paper, we define Forman curvature for multilayer networks, a class of complex networks characterized by multiple types of connections or layers between nodes, which are increasingly used to model intricate real-world phenomena. We establish the key properties of Forman curvature in the context of multilayer networks and demonstrate its utility for identifying vertices that hold central positions within these networks. Furthermore, we show that Forman curvature can also serve as an effective tool for the structural classification of entire multilayer networks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17286",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:20.647642Z"
  },
  {
    "id": "f5d5d64922ed38f8ec96931a8cbb94f1",
    "title": "Morphisms and BWT-run Sensitivity",
    "slug": "morphisms-and-bwt-run-sensitivity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Formal Languages and Automata Theory (cs.FL)",
    "author": {
      "name": "Gabriele Fici",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study how the application of injective morphisms affects the number $r$ of equal-letter runs in the Burrows-Wheeler Transform (BWT). This parameter has emerged as a key repetitiveness measure in compressed indexing. We focus on the notion of BWT-run sensitivity after application of an injective morphism. For binary alphabets, we characterize the class of morphisms that preserve the number of BWT-runs up to a bounded additive increase, by showing that it coincides with the known class of primitivity-preserving morphisms, which are those that map primitive words to primitive words. We further prove that deciding whether a given binary morphism has bounded BWT-run sensitivity is possible in polynomial time with respect to the total length of the images of the two letters. Additionally, we explore new structural and combinatorial properties of synchronizing and recognizable morphisms. These results establish new connections between BWT-based compressibility, code theory, and symbolic dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17443",
    "tags": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "createdAt": "2025-04-25T15:49:20.647843Z"
  },
  {
    "id": "0fd89000077e3c606fa34434c1c88ed1",
    "title": "Boundedness and Separation in the Graph Covering Number Framework",
    "slug": "boundedness-and-separation-in-the-graph-covering-number-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Miriam Goetze",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "For a graph class $\\mathcal G$ and a graph $H$, the four $\\mathcal G$-covering numbers of $H$, namely global ${\\rm cn}_{g}^{\\mathcal{G}}(H)$, union ${\\rm cn}_{u}^{\\mathcal{G}}(H)$, local ${\\rm cn}_{l}^{\\mathcal{G}}(H)$, and folded ${\\rm cn}_{f}^{\\mathcal{G}}(H)$, each measure in a slightly different way how well $H$ can be covered with graphs from $\\mathcal G$. For every $\\mathcal G$ and $H$ it holds \\[\n{\\rm cn}_{g}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{u}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{l}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{f}^{\\mathcal{G}}(H) \\] and in general each inequality can be arbitrarily far apart. We investigate structural properties of graph classes $\\mathcal G$ and $\\mathcal H$ such that for all graphs $H \\in \\mathcal{H}$, a larger $\\mathcal G$-covering number of $H$ can be bounded in terms of a smaller $\\mathcal G$-covering number of $H$. For example, we prove that if $\\mathcal G$ is hereditary and the chromatic number of graphs in $\\mathcal H$ is bounded, then there exists a function $f$ (called a binding function) such that for all $H \\in \\mathcal{H}$ it holds ${\\rm cn}_{u}^{\\mathcal{G}}(H) \\leq f({\\rm cn}_{g}^{\\mathcal{G}}(H))$.\nFor $\\mathcal G$ we consider graph classes that are component-closed, hereditary, monotone, sparse, or of bounded chromatic number. For $\\mathcal H$ we consider graph classes that are sparse, $M$-minor-free, of bounded chromatic number, or of bounded treewidth. For each combination and every pair of $\\mathcal G$-covering numbers, we either give a binding function $f$ or provide an example of such $\\mathcal{G},\\mathcal{H}$ for which no binding function exists.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17458",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:20.648034Z"
  },
  {
    "id": "8576dfb6a605fe5286dbe502b5e771f6",
    "title": "Identifying Approximate Minimizers under Stochastic Uncertainty",
    "slug": "identifying-approximate-minimizers-under-stochastic-uncertainty",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Hessa Al-Thani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study a fundamental stochastic selection problem involving $n$ independent random variables, each of which can be queried at some cost. Given a tolerance level $\\delta$, the goal is to find a value that is $\\delta$-approximately minimum (or maximum) over all the random variables, at minimum expected cost. A solution to this problem is an adaptive sequence of queries, where the choice of the next query may depend on previously-observed values. Two variants arise, depending on whether the goal is to find a $\\delta$-minimum value or a $\\delta$-minimizer. When all query costs are uniform, we provide a $4$-approximation algorithm for both variants. When query costs are non-uniform, we provide a $5.83$-approximation algorithm for the $\\delta$-minimum value and a $7.47$-approximation for the $\\delta$-minimizer. All our algorithms rely on non-adaptive policies (that perform a fixed sequence of queries), so we also upper bound the corresponding ''adaptivity'' gaps. Our analysis relates the stopping probabilities in the algorithm and optimal policies, where a key step is in proving and using certain stochastic dominance properties.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17019",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.947452Z"
  },
  {
    "id": "6c8691b7d1e2c356abefaa7372853230",
    "title": "Breaking the Sorting Barrier for Directed Single-Source Shortest Paths",
    "slug": "breaking-the-sorting-barrier-for-directed-single-source-shortest-paths",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Ran Duan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We give a deterministic $O(m\\log^{2/3}n)$-time algorithm for single-source shortest paths (SSSP) on directed graphs with real non-negative edge weights in the comparison-addition model. This is the first result to break the $O(m+n\\log n)$ time bound of Dijkstra's algorithm on sparse graphs, showing that Dijkstra's algorithm is not optimal for SSSP.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17033",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.947677Z"
  },
  {
    "id": "b9255f1c8242398629c831d1b1ecffdd",
    "title": "Knapsack on Graphs with Relaxed Neighborhood Constraints",
    "slug": "knapsack-on-graphs-with-relaxed-neighborhood-constraints",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Palash Dey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the knapsack problems with neighborhood constraints that were studied before, the input is a graph $\\mathcal{G}$ on a set $\\mathcal{V}$ of items, each item $v \\in \\mathcal{V}$ has a weight $w_v$ and profit $p_v$, the size $s$ of the knapsack, and the demand $d$. The goal is to compute if there exists a feasible solution whose total weight is at most $s$ and total profit is at most $d$. Here, feasible solutions are all subsets $\\mathcal{S}$ of the items such that, for every item in $\\mathcal{S}$, at least one of its neighbors in $\\mathcal{G}$ is also in $\\mathcal{S}$ for \\hor, and all its neighbors in $\\mathcal{G}$ are also in $\\mathcal{S}$ for \\hand~\\cite{borradaile2012knapsack}. We study a relaxation of the above problems. Specifically, we allow all possible subsets of items to be feasible solutions. However, only those items for which we pick at least one or all of its neighbor (out-neighbor for directed graph) contribute to profit whereas every item picked contribute to the weight; we call the corresponding problems \\sor and \\sand. We show that both \\sor and \\sand are strongly \\NPC even on undirected graphs. Regarding parameterized complexity, we show both \\sor and \\hor are \\WTH parameterized by the size $s$ of the knapsack size. Interestingly, both \\sand and \\hand are \\WOH parameterized by knapsack size, $s$ plus profit demand, $d$ and also parameterized by solution size, $b$. For \\sor and \\hor, we present a randomized color-coding-based pseudo-\\FPT algorithm, parameterized by the solution size $b$, and consequently by the demand $d$. We then consider the treewidth of the input graph as our parameter and design pseudo fixed-parameter tractable (\\FPT) algorithm parameterized by treewidth, $\\text{tw}$ for all variants. Finally, we present an additive $1$ approximation for \\sor when both the weight and profit of every vertex is $1$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17297",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.947878Z"
  },
  {
    "id": "72ce3ae40dba297bf604b6121e14ba07",
    "title": "Simple Universally Optimal Dijkstra",
    "slug": "simple-universally-optimal-dijkstra",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Ivor van der Hoog",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let G be a weighted (directed) graph with n vertices and m edges. Given a source vertex s, Dijkstra's algorithm computes the shortest path lengths from s to all other vertices in O(m + n log n) time. This bound is known to be worst-case optimal via a reduction to sorting. Theoretical computer science has developed numerous fine-grained frameworks for analyzing algorithmic performance beyond standard worst-case analysis, such as instance optimality and output sensitivity. Haeupler et al. [FOCS '24] consider the notion of universal optimality, a refined complexity measure that accounts for both the graph topology and the edge weights. For a fixed graph topology, the universal running time of a weighted graph algorithm is defined as its worst-case running time over all possible edge weightings of G. An algorithm is universally optimal if no other algorithm achieves a better asymptotic universal running time on any particular graph topology. They show that Dijkstra's algorithm can be made universally optimal by replacing the heap with a custom data structure.\nWe revisit their result. We introduce a simple heap property called timestamp optimality, where the cost of popping an element x is logarithmic in the number of elements inserted between pushing and popping x. We show that timestamp optimal heaps are not only easier to define but also easier to implement. Using these timestamps, we provide a significantly simpler proof that Dijkstra's algorithm, with the right kind of heap, is universally optimal.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17327",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.948080Z"
  },
  {
    "id": "85ebf29dfcf6c9465ad67d528a9eb1b0",
    "title": "Edge-weighted Online Stochastic Matching Under Jaillet-Lu LP",
    "slug": "edge-weighted-online-stochastic-matching-under-jaillet-lu-lp",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Shuyi Yan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The online stochastic matching problem was introduced by [FMMM09], together with the $(1-\\frac1e)$-competitive Suggested Matching algorithm. In the most general edge-weighted setting, this ratio has not been improved for more than one decade, until recently [Yan24] beat the $1-\\frac1e$ bound and [QFZW23] further improved the ratio to $0.650$. Both of these works measure the online competitiveness against the offline LP relaxation introduced by [JL14]. This LP has also played an important role in other settings since it is a natural choice for two-choices online algorithms.\nIn this paper, we propose an upper bound of $0.663$ and a lower bound of $0.662$ for edge-weighted online stochastic matching under Jaillet-Lu LP. First, we propose a hard instance and prove that the optimal online algorithm for this instance only has a competitive ratio $<0.663$. Then, we show that a near-optimal algorithm for this instance can be generalized to work on all instances and achieve a competitive ratio $>0.662$. It indicates that more powerful LPs are necessary if we want to further improve the ratio by $0.001$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17392",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.948268Z"
  },
  {
    "id": "26701bf9e10596d6941977e02a0d98ba",
    "title": "The Case for External Graph Sketching",
    "slug": "the-case-for-external-graph-sketching",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Michael A. Bender",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Algorithms in the data stream model use $O(polylog(N))$ space to compute some property of an input of size $N$, and many of these algorithms are implemented and used in practice. However, sketching algorithms in the graph semi-streaming model use $O(V polylog(V))$ space for a $V$-vertex graph, and the fact that implementations of these algorithms are not used in the academic literature or in industrial applications may be because this space requirement is too large for RAM on today's hardware.\nIn this paper we introduce the external semi-streaming model, which addresses the aspects of the semi-streaming model that limit its practical impact. In this model, the input is in the form of a stream and $O(V polylog(V))$ space is available, but most of that space is accessible only via block I/O operations as in the external memory model. The goal in the external semi-streaming model is to simultaneously achieve small space and low I/O cost.\nWe present a general transformation from any vertex-based sketch algorithm to one which has a low sketching cost in the new model. We prove that this automatic transformation is tight or nearly (up to a $O(\\log(V))$ factor) tight via an I/O lower bound for the task of sketching the input stream.\nUsing this transformation and other techniques, we present external semi-streaming algorithms for connectivity, bipartiteness testing, $(1+\\epsilon)$-approximating MST weight, testing k-edge connectivity, $(1+\\epsilon)$-approximating the minimum cut of a graph, computing $\\epsilon$-cut sparsifiers, and approximating the density of the densest subgraph. These algorithms all use $O(V poly(\\log(V), \\epsilon^{-1},k)$ space. For many of these problems, our external semi-streaming algorithms outperform the state of the art algorithms in both the sketching and external-memory models.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17563",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.948492Z"
  },
  {
    "id": "5a45b524c2acd496f53b5e229a3260d7",
    "title": "Linear-Time Multilevel Graph Partitioning via Edge Sparsification",
    "slug": "linear-time-multilevel-graph-partitioning-via-edge-sparsification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Lars Gottesbren",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The current landscape of balanced graph partitioning is divided into high-quality but expensive multilevel algorithms and cheaper approaches with linear running time, such as single-level algorithms and streaming algorithms. We demonstrate how to achieve the best of both worlds with a \\emph{linear time multilevel algorithm}. Multilevel algorithms construct a hierarchy of increasingly smaller graphs by repeatedly contracting clusters of nodes. Our approach preserves their distinct advantage, allowing refinement of the partition over multiple levels with increasing detail. At the same time, we use \\emph{edge sparsification} to guarantee geometric size reduction between the levels and thus linear running time.\nWe provide a proof of the linear running time as well as additional insights into the behavior of multilevel algorithms, showing that graphs with low modularity are most likely to trigger worst-case running time. We evaluate multiple approaches for edge sparsification and integrate our algorithm into the state-of-the-art multilevel partitioner KaMinPar, maintaining its excellent parallel scalability. As demonstrated in detailed experiments, this results in a $1.49\\times$ average speedup (up to $4\\times$ for some instances) with only 1\\% loss in solution quality. Moreover, our algorithm clearly outperforms state-of-the-art single-level and streaming approaches.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17615",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.948696Z"
  },
  {
    "id": "556f644cbd34b87e646dd2faf1feefb3",
    "title": "A general framework for finding diverse solutions via network flow and its applications",
    "slug": "a-general-framework-for-finding-diverse-solutions-via-network-flow-and-its-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Yuni Iwamasa",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we present a general framework for efficiently computing diverse solutions to combinatorial optimization problems. Given a problem instance, the goal is to find $k$ solutions that maximize a specified diversity measure; the sum of pairwise Hamming distances or the size of the union of the $k$ solutions. Our framework applies to problems satisfying two structural properties: (i) All solutions are of equal size and (ii) the family of all solutions can be represented by a surjection from the family of ideals of some finite poset. Under these conditions, we show that the problem of computing $k$ diverse solutions can be reduced to the minimum cost flow problem and the maximum $s$-$t$ flow problem. As applications, we demonstrate that both the unweighted minimum $s$-$t$ cut problem and the stable matching problem satisfy the requirements of our framework. By utilizing the recent advances in network flows algorithms, we improve the previously known time complexities of the diverse problems, which were based on submodular function minimization.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17633",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.948893Z"
  },
  {
    "id": "3b4a52e216b81656c72b3bb1acb020f7",
    "title": "Pushing the frontiers of subexponential FPT time for Feedback Vertex Set",
    "slug": "pushing-the-frontiers-of-subexponential-fpt-time-for-feedback-vertex-set",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Gatan Berthe",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The paper deals with the Feedback Vertex Set problem parameterized by the solution size. Given a graph $G$ and a parameter $k$, one has to decide if there is a set $S$ of at most $k$ vertices such that $G-S$ is acyclic. Assuming the Exponential Time Hypothesis, it is known that FVS cannot be solved in time $2^{o(k)}n^{\\mathcal{O}(1)}$ in general graphs. To overcome this, many recent results considered FVS restricted to particular intersection graph classes and provided such $2^{o(k)}n^{\\mathcal{O}(1)}$ algorithms.\nIn this paper we provide generic conditions on a graph class for the existence of an algorithm solving FVS in subexponential FPT time, i.e. time $2^{k^\\varepsilon} \\mathop{\\rm poly}(n)$, for some $\\varepsilon<1$, where $n$ denotes the number of vertices of the instance and $k$ the parameter. On the one hand this result unifies algorithms that have been proposed over the years for several graph classes such as planar graphs, map graphs, unit-disk graphs, pseudo-disk graphs, and string graphs of bounded edge-degree. On the other hand it extends the tractability horizon of FVS to new classes that are not amenable to previously used techniques, in particular intersection graphs of ``thin'' objects like segment graphs or more generally $s$-string graphs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17708",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.949095Z"
  },
  {
    "id": "7dc04d962601b21ec3b0f5190fb49fca",
    "title": "Online metric TSP",
    "slug": "online-metric-tsp",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Christian Bertram",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the online metric traveling salesperson problem, $n$ points of a metric space arrive one by one and have to be placed (immediately and irrevocably) into empty cells of a size-$n$ array. The goal is to minimize the sum of distances between consecutive points in the array. This problem was introduced by Abrahamsen, Bercea, Beretta, Klausen, and Kozma [ESA'24] as a generalization of the online sorting problem, which was introduced by Aamand, Abrahamsen, Beretta, and Kleist [SODA'23] as a tool in their study of online geometric packing problems.\nOnline metric TSP has been studied for a range of fixed metric spaces. For 1-dimensional Euclidean space, the problem is equivalent to online sorting, where an optimal competitive ratio of $\\Theta(\\sqrt n)$ is known. For $d$-dimensional Euclidean space, the best-known upper bound is $O(2^{d} \\sqrt{dn\\log n})$, leaving a gap to the $\\Omega(\\sqrt n)$ lower bound. Finally, for the uniform metric, where all distances are 0 or 1, the optimal competitive ratio is known to be $\\Theta(\\log n)$.\nWe study the problem for a general metric space, presenting an algorithm with competitive ratio $O(\\sqrt n)$. In particular, we close the gap for $d$-dimensional Euclidean space, completely removing the dependence on dimension. One might hope to simultaneously guarantee competitive ratio $O(\\sqrt n)$ in general and $O(\\log n)$ for the uniform metric, but we show that this is impossible.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17716",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.949289Z"
  },
  {
    "id": "47038765966377fbd72278979048cb11",
    "title": "Realization of Temporally Connected Graphs Based on Degree Sequences",
    "slug": "realization-of-temporally-connected-graphs-based-on-degree-sequences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Arnaud Casteigts",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Given an undirected graph $G$, the problem of deciding whether $G$ admits a simple and proper time-labeling that makes it temporally connected is known to be NP-hard (Gbel et al., 1991). In this article, we relax this problem and ask whether a given degree sequence can be realized as a temporally connected graph. Our main results are a complete characterization of the feasible cases, and a recognition algorithm that runs in $O(n)$ time for graphical degree sequences (realized as simple temporal graphs) and in $O(n+m)$ time for multigraphical degree sequences (realized as non-simple temporal graphs, where the number of time labels on an edge corresponds to the multiplicity of the edge in the multigraph). In fact, these algorithms can be made constructive at essentially no cost. Namely, we give a constructive $O(n+m)$ time algorithm that outputs, for a given (multi)graphical degree sequence $\\mathbf{d}$, a temporally connected graph whose underlying (multi)graph is a realization of $\\mathbf{d}$, if one exists.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17743",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.949477Z"
  },
  {
    "id": "cdf4b528cf4d07b9119bca5ad9759194",
    "title": "Fitting Tree Metrics and Ultrametrics in Data Streams",
    "slug": "fitting-tree-metrics-and-ultrametrics-in-data-streams",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Amir Carmel",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Fitting distances to tree metrics and ultrametrics are two widely used methods in hierarchical clustering, primarily explored within the context of numerical taxonomy. Given a positive distance function $D:\\binom{V}{2}\\rightarrow\\mathbb{R}_{>0}$, the goal is to find a tree (or ultrametric) $T$ including all elements of set $V$ such that the difference between the distances among vertices in $T$ and those specified by $D$ is minimized. In this paper, we initiate the study of ultrametric and tree metric fitting problems in the semi-streaming model, where the distances between pairs of elements from $V$ (with $|V|=n$), defined by the function $D$, can arrive in an arbitrary order. We study these problems under various distance norms:\nFor the $\\ell_0$ objective, we provide a single-pass polynomial-time $\\tilde{O}(n)$-space $O(1)$ approximation algorithm for ultrametrics and prove that no single-pass exact algorithm exists, even with exponential time.\nNext, we show that the algorithm for $\\ell_0$ implies an $O(\\Delta/\\delta)$ approximation for the $\\ell_1$ objective, where $\\Delta$ is the maximum and $\\delta$ is the minimum absolute difference between distances in the input. This bound matches the best-known approximation for the RAM model using a combinatorial algorithm when $\\Delta/\\delta=O(n)$.\nFor the $\\ell_\\infty$ objective, we provide a complete characterization of the ultrametric fitting problem. We present a single-pass polynomial-time $\\tilde{O}(n)$-space 2-approximation algorithm and show that no better than 2-approximation is possible, even with exponential time. We also show that, with an additional pass, it is possible to achieve a polynomial-time exact algorithm for ultrametrics.\nFinally, we extend the results for all these objectives to tree metrics by using only one additional pass through the stream and without asymptotically increasing the approximation factor.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17776",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.949679Z"
  },
  {
    "id": "90bc6b6f705d07a73bba88df6453acd4",
    "title": "Parallelizing the Approximate Minimum Degree Ordering Algorithm: Strategies and Evaluation",
    "slug": "parallelizing-the-approximate-minimum-degree-ordering-algorithm:-strategies-and-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Yen-Hsiang Chang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The approximate minimum degree algorithm is widely used before numerical factorization to reduce fill-in for sparse matrices. While considerable attention has been given to the numerical factorization process, less focus has been placed on parallelizing the approximate minimum degree algorithm itself. In this paper, we explore different parallelization strategies, and introduce a novel parallel framework that leverages multiple elimination on distance-2 independent sets. Our evaluation shows that parallelism within individual elimination steps is limited due to low computational workload and significant memory contention. In contrast, our proposed framework overcomes these challenges by parallelizing the work across elimination steps. To the best of our knowledge, our implementation is the first scalable shared memory implementation of the approximate minimum degree algorithm. Experimental results show that we achieve up to an 8.30x speedup using 64 threads over the state-of-the-art sequential implementation in SuiteSparse.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17097",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.949899Z"
  },
  {
    "id": "1d32f43737fb5154f496d7aa85188ef6",
    "title": "Dynamic Approximate Maximum Matching in the Distributed Vertex Partition Model",
    "slug": "dynamic-approximate-maximum-matching-in-the-distributed-vertex-partition-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Peter Robinson",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We initiate the study of approximate maximum matching in the vertex partition model, for graphs subject to dynamic changes. We assume that the $n$ vertices of the graph are partitioned among $k$ players, who execute a distributed algorithm and communicate via message passing. An adaptive adversary may perform dynamic updates to the graph topology by inserting or removing edges between the nodes, and the algorithm needs to respond to these changes by adapting the output of the players, with the goal of maintaining an approximate maximum matching. The main performance metric in this setting is the algorithm's update time, which corresponds to the number of rounds required for updating the solution upon an adversarial change. For the standard setting of single-edge insertions and deletions, we obtain the following results:\nWe give a randomized Las Vegas algorithm with an expected update time of $O( \\frac{\\sqrt{m}}{\\beta k} )$ rounds that maintains a $\\frac{2}{3}$-approximate maximum matching that is also maximal, where $m$ is the number of edges of the graph. We also show that any algorithm has a worst case update time of $\\Omega( \\frac{n}{\\beta k^2\\log n} )$, assuming a link bandwidth of $O(\\beta\\log n)$ bits per round, if it maintains a matching that is maximal and does not have any 3-augmenting paths. For batch-dynamic updates, where the adversary may modify up to $\\ell\\ge 1$ edges at once, we prove the following: There is a randomized algorithm that succeeds with high probability in maintaining a $\\frac{2}{3}$-approximate maximum matching and has a worst case update time of $\\Omega( \\frac{\\ell\\log n}{\\sqrt{\\beta k}} )$ rounds. We show that $\\Omega( \\frac{\\ell}{\\beta k \\log n} )$ poses a lower bound for maintaining a maximal matching without 3-augmenting paths.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17338",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:20.950101Z"
  },
  {
    "id": "f5d5d64922ed38f8ec96931a8cbb94f1",
    "title": "Morphisms and BWT-run Sensitivity",
    "slug": "morphisms-and-bwt-run-sensitivity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Formal Languages and Automata Theory (cs.FL)",
    "author": {
      "name": "Gabriele Fici",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study how the application of injective morphisms affects the number $r$ of equal-letter runs in the Burrows-Wheeler Transform (BWT). This parameter has emerged as a key repetitiveness measure in compressed indexing. We focus on the notion of BWT-run sensitivity after application of an injective morphism. For binary alphabets, we characterize the class of morphisms that preserve the number of BWT-runs up to a bounded additive increase, by showing that it coincides with the known class of primitivity-preserving morphisms, which are those that map primitive words to primitive words. We further prove that deciding whether a given binary morphism has bounded BWT-run sensitivity is possible in polynomial time with respect to the total length of the images of the two letters. Additionally, we explore new structural and combinatorial properties of synchronizing and recognizable morphisms. These results establish new connections between BWT-based compressibility, code theory, and symbolic dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17443",
    "tags": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "createdAt": "2025-04-25T15:49:20.950303Z"
  },
  {
    "id": "44df0d299849d10f82f506f21779bcf3",
    "title": "Dynamic Membership for Regular Tree Languages",
    "slug": "dynamic-membership-for-regular-tree-languages",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Formal Languages and Automata Theory (cs.FL)",
    "author": {
      "name": "Antoine Amarilli",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the dynamic membership problem for regular tree languages under relabeling updates: we fix an alphabet ${\\Sigma}$ and a regular tree language $L$ over ${\\Sigma}$ (expressed, e.g., as a tree automaton), we are given a tree $T$ with labels in ${\\Sigma}$, and we must maintain the information of whether the tree $T$ belongs to $L$ while handling relabeling updates that change the labels of individual nodes in $T$. (The shape and size of the tree remain the same throughout.)\nOur first contribution is to show that this problem admits an $O(\\log n / \\log \\log n)$ algorithm for any fixed regular tree language, improving over known algorithms that achieve $O(\\log n)$. This generalizes the known $O(\\log n / \\log \\log n)$ upper bound over words, and it matches the lower bound of ${\\Omega}(\\log n / \\log \\log n)$ from dynamic membership to some word languages and from the existential marked ancestor problem.\nOur second contribution is to introduce a class of regular languages, dubbed almost-commutative tree languages, and show that dynamic membership to such languages under relabeling updates can be done in constant time per update. Almost-commutative languages generalize both commutative languages and finite languages, and they are the analogue for trees of the ZG languages enjoying constant-time dynamic membership over words. Our main technical contribution is to show that this class is conditionally optimal when we assume that the alphabet features a neutral letter, i.e., a letter that has no effect on membership to the language. More precisely, we show that any regular tree language with a neutral letter which is not almost-commutative cannot be maintained in constant time under the assumption that prefix-U1 problem from (Amarilli, Jachiet, Paperman, ICALP'21) also does not admit a constant-time algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17536",
    "tags": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "createdAt": "2025-04-25T15:49:20.950520Z"
  },
  {
    "id": "f318d16faf4a0d7a17ee941867aeb675",
    "title": "Algorithms and Hardness for Estimating Statistical Similarity",
    "slug": "algorithms-and-hardness-for-estimating-statistical-similarity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Arnab Bhattacharyya",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the problem of computing statistical similarity between probability distributions. For distributions $P$ and $Q$ over a finite sample space, their statistical similarity is defined as $S_{\\mathrm{stat}}(P, Q) := \\sum_{x} \\min(P(x), Q(x))$. Statistical similarity is a basic measure of similarity between distributions, with several natural interpretations, and captures the Bayes error in prediction and hypothesis testing problems. Recent work has established that, somewhat surprisingly, even for the simple class of product distributions, exactly computing statistical similarity is $\\#\\mathsf{P}$-hard. This motivates the question of designing approximation algorithms for statistical similarity. Our primary contribution is a Fully Polynomial-Time deterministic Approximation Scheme (FPTAS) for estimating statistical similarity between two product distributions. To obtain this result, we introduce a new variant of the Knapsack problem, which we call the Masked Knapsack problem, and design an FPTAS to estimate the number of solutions of a multidimensional version of this problem. This new technical contribution could be of independent interest. Furthermore, we also establish a complementary hardness result. We show that it is $\\mathsf{NP}$-hard to estimate statistical similarity when $P$ and $Q$ are Bayes net distributions of in-degree $2$.",
    "pdfUrl": "https://arxiv.org/pdf/2502.10527",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.950725Z"
  },
  {
    "id": "434f0e44e58193b5f423bf45f8188a4c",
    "title": "Privately Evaluating Untrusted Black-Box Functions",
    "slug": "privately-evaluating-untrusted-black-box-functions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Ephraim Linder",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We provide tools for sharing sensitive data when the data curator does not know in advance what questions an (untrusted) analyst might ask about the data. The analyst can specify a program that they want the curator to run on the dataset. We model the program as a black-box function $f$. We study differentially private algorithms, called privacy wrappers, that, given black-box access to a real-valued function $f$ and a sensitive dataset $x$, output an accurate approximation to $f(x)$. The dataset $x$ is modeled as a finite subset of a possibly infinite set $U$, in which each entry represents data of one individual. A privacy wrapper calls $f$ on the dataset $x$ and on some subsets of $x$ and returns either an approximation to $f(x)$ or a nonresponse symbol $\\perp$. The wrapper may also use additional information (that is, parameters) provided by the analyst, but differential privacy is required for all values of these parameters. Correct setting of these parameters will ensure better accuracy of the wrapper. The bottleneck in the running time of our wrappers is the number of calls to $f$, which we refer to as queries. Our goal is to design wrappers with high accuracy and low query complexity. We introduce a novel setting, the automated sensitivity detection setting, where the analyst supplies the black-box function $f$ and the intended (finite) range of $f$. In the previously considered setting, the claimed sensitivity bound setting, the analyst supplies additional parameters that describe the sensitivity of $f$. We design privacy wrappers for both settings and show that our wrappers are nearly optimal in terms of accuracy, locality (i.e., the depth of the local neighborhood of the dataset $x$ they explore), and query complexity. In the claimed sensitivity bound setting, we provide the first accuracy guarantees that have no dependence on the size of the universe $U$.",
    "pdfUrl": "https://arxiv.org/pdf/2503.19268",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:20.950933Z"
  },
  {
    "id": "295aa11f54de52f51978448e2e9183e0",
    "title": "Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable Random Walks",
    "slug": "honeybee:-byzantine-tolerant-decentralized-peer-sampling-with-verifiable-random-walks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Yunqi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and table consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\\geq50\\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes.",
    "pdfUrl": "https://arxiv.org/pdf/2402.16201",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:20.951121Z"
  },
  {
    "id": "2afd5d1f0b04c7df2c90fc42bab3bde0",
    "title": "Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation",
    "slug": "attainability-of-two-point-testing-rates-for-finite-sample-location-estimation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Spencer Compton",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LeCam's two-point testing method yields perhaps the simplest lower bound for estimating the mean of a distribution: roughly, if it is impossible to well-distinguish a distribution centered at $\\mu$ from the same distribution centered at $\\mu+\\Delta$, then it is impossible to estimate the mean by better than $\\Delta/2$. It is setting-dependent whether or not a nearly matching upper bound is attainable. We study the conditions under which the two-point testing lower bound can be attained for univariate mean estimation; both in the setting of location estimation (where the distribution is known up to translation) and adaptive location estimation (unknown distribution). Roughly, we will say an estimate nearly attains the two-point testing lower bound if it incurs error that is at most polylogarithmically larger than the Hellinger modulus of continuity for $\\tilde{\\Omega}(n)$ samples.\nAdaptive location estimation is particularly interesting as some distributions admit much better guarantees than sub-Gaussian rates (e.g. $\\operatorname{Unif}(\\mu-1,\\mu+1)$ permits error $\\Theta(\\frac{1}{n})$, while the sub-Gaussian rate is $\\Theta(\\frac{1}{\\sqrt{n}})$), yet it is not obvious whether these rates may be adaptively attained by one unified approach. Our main result designs an algorithm that nearly attains the two-point testing rate for mixtures of symmetric, log-concave distributions with a common mean. Moreover, this algorithm runs in near-linear time and is parameter-free. In contrast, we show the two-point testing rate is not nearly attainable even for symmetric, unimodal distributions.\nWe complement this with results for location estimation, showing the two-point testing rate is nearly attainable for unimodal distributions, but unattainable for symmetric distributions.",
    "pdfUrl": "https://arxiv.org/pdf/2502.05730",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:20.951307Z"
  },
  {
    "id": "0ef3337208623c7d73eee9aa3b24d594",
    "title": "Quantum Speedup for Sampling Random Spanning Trees",
    "slug": "quantum-speedup-for-sampling-random-spanning-trees",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Simon Apers",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present a quantum algorithm for sampling random spanning trees from a weighted graph in $\\widetilde{O}(\\sqrt{mn})$ time, where $n$ and $m$ denote the number of vertices and edges, respectively. Our algorithm has sublinear runtime for dense graphs and achieves a quantum speedup over the best-known classical algorithm, which runs in $\\widetilde{O}(m)$ time. The approach carefully combines, on one hand, a classical method based on ``large-step'' random walks for reduced mixing time and, on the other hand, quantum algorithmic techniques, including quantum graph sparsification and a sampling-without-replacement variant of Hamoudi's multiple-state preparation. We also establish a matching lower bound, proving the optimality of our algorithm up to polylogarithmic factors. These results highlight the potential of quantum computing in accelerating fundamental graph sampling problems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15603",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:20.951517Z"
  },
  {
    "id": "fd81f35202fee3b6fd2fd8507ffda2fd",
    "title": "Molecular Communication Channel as a Physical Reservoir Computer",
    "slug": "molecular-communication-channel-as-a-physical-reservoir-computer",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Emerging Technologies (cs.ET)",
    "author": {
      "name": "Mustafa Uzun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Molecular Communication (MC) channels inherently possess significant memory and nonlinear dynamics due to diffusion and receptor kinetics, often posing challenges for reliable data transmission. This work reconceptualizes these intrinsic properties as computational resources by framing a canonical point-to-point MC channel, consisting of ligand diffusion and reversible ligand-receptor binding at a spherical receiver, as a physical reservoir computer (PRC). We utilize the time-varying fraction of bound receptors as the reservoir's internal state, employing time-multiplexing to generate high-dimensional virtual nodes without explicit recurrence. Only a linear readout layer is trained via ridge regression. Through deterministic mean-field modeling and particle-based spatial stochastic simulations, we demonstrate the MC system's capability for complex temporal processing by successfully performing next-step prediction on standard chaotic time-series benchmarks (Mackey-Glass and NARMA10). Performance, quantified by Normalized Root Mean Square Error (NRMSE), exhibits a non-monotonic dependence on key system parameters (receptor kinetic rates, diffusion coefficient, transmitter-receiver distance), revealing optimal operational regimes. These findings validate the potential of using MC channel as effective and low-complexity computational substrate.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17022",
    "tags": [
      "Emerging Technologies (cs.ET)"
    ],
    "createdAt": "2025-04-25T15:49:21.241436Z"
  },
  {
    "id": "37909cbc1c01d772f50ab719ec34a049",
    "title": "Range and Topology Mutation Based Wireless Agility",
    "slug": "range-and-topology-mutation-based-wireless-agility",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Emerging Technologies (cs.ET)",
    "author": {
      "name": "Qi Duan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we present formal foundations for two wireless agility techniques: (1) Random Range Mutation (RNM) that allows for periodic changes of AP coverage range randomly, and (2) Ran- dom Topology Mutation (RTM) that allows for random motion and placement of APs in the wireless infrastructure. The goal of these techniques is to proactively defend against targeted attacks (e.g., DoS and eavesdropping) by forcing the wireless clients to change their AP association randomly. We apply Satisfiability Modulo The- ories (SMT) and Answer Set Programming (ASP) based constraint solving methods that allow for optimizing wireless AP mutation while maintaining service requirements including coverage, secu- rity and energy properties under incomplete information about the adversary strategies. Our evaluation validates the feasibility, scalability, and effectiveness of the formal methods based technical approaches.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17164",
    "tags": [
      "Emerging Technologies (cs.ET)"
    ],
    "createdAt": "2025-04-25T15:49:21.241645Z"
  },
  {
    "id": "474ca382d66989135585c4fa0e4ad8dd",
    "title": "Rethinking PM Crash Consistency in the CXL Era",
    "slug": "rethinking-pm-crash-consistency-in-the-cxl-era",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Emerging Technologies (cs.ET)",
    "author": {
      "name": "Joo Oliveira",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Persistent Memory (PM) introduces new opportunities for designing crash-consistent applications without the traditional storage overheads. However, ensuring crash consistency in PM demands intricate knowledge of CPU, cache, and memory interactions. Hardware and software mechanisms have been proposed to ease this burden, but neither proved sufficient, prompting a variety of bug detection tools.\nWith the sunset of Intel Optane comes the rise of Compute Express Link (CXL) for PM. In this position paper, we discuss the impact of CXL's disaggregated and heterogeneous nature in the development of crash-consistent PM applications, and outline three research directions: hardware primitives, persistency frameworks, and bug detection tools.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17554",
    "tags": [
      "Emerging Technologies (cs.ET)"
    ],
    "createdAt": "2025-04-25T15:49:21.241855Z"
  },
  {
    "id": "65beaf9f86c348786ee7ea82f6d28973",
    "title": "Intrinsic Barriers to Explaining Deep Foundation Models",
    "slug": "intrinsic-barriers-to-explaining-deep-foundation-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Zhen Tan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deep Foundation Models (DFMs) offer unprecedented capabilities but their increasing complexity presents profound challenges to understanding their internal workings-a critical need for ensuring trust, safety, and accountability. As we grapple with explaining these systems, a fundamental question emerges: Are the difficulties we face merely temporary hurdles, awaiting more sophisticated analytical techniques, or do they stem from \\emph{intrinsic barriers} deeply rooted in the nature of these large-scale models themselves? This paper delves into this critical question by examining the fundamental characteristics of DFMs and scrutinizing the limitations encountered by current explainability methods when confronted with this inherent challenge. We probe the feasibility of achieving satisfactory explanations and consider the implications for how we must approach the verification and governance of these powerful technologies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16948",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:21.242051Z"
  },
  {
    "id": "f2356f179b6c78ba0f9aab20fb6c4cbf",
    "title": "A Novel Graph Transformer Framework for Gene Regulatory Network Inference",
    "slug": "a-novel-graph-transformer-framework-for-gene-regulatory-network-inference",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Binon Teji",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The inference of gene regulatory networks (GRNs) is a foundational stride towards deciphering the fundamentals of complex biological systems. Inferring a possible regulatory link between two genes can be formulated as a link prediction problem. Inference of GRNs via gene coexpression profiling data may not always reflect true biological interactions, as its susceptibility to noise and misrepresenting true biological regulatory relationships. Most GRN inference methods face several challenges in the network reconstruction phase. Therefore, it is important to encode gene expression values, leverege the prior knowledge gained from the available inferred network structures and positional informations of the input network nodes towards inferring a better and more confident GRN network reconstruction. In this paper, we explore the integration of multiple inferred networks to enhance the inference of Gene Regulatory Networks (GRNs). Primarily, we employ autoencoder embeddings to capture gene expression patterns directly from raw data, preserving intricate biological signals. Then, we embed the prior knowledge from GRN structures transforming them into a text-like representation using random walks, which are then encoded with a masked language model, BERT, to generate global embeddings for each gene across all networks. Additionally, we embed the positional encodings of the input gene networks to better identify the position of each unique gene within the graph. These embeddings are integrated into graph transformer-based model, termed GT-GRN, for GRN inference. The GT-GRN model effectively utilizes the topological structure of the ground truth network while incorporating the enriched encoded information. Experimental results demonstrate that GT-GRN significantly outperforms existing GRN inference methods, achieving superior accuracy and highlighting the robustness of our approach.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16961",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:21.242272Z"
  },
  {
    "id": "99a0a5aed5fefddfa009e27134845468",
    "title": "Factually: Exploring Wearable Fact-Checking for Augmented Truth Discernment",
    "slug": "factually:-exploring-wearable-fact-checking-for-augmented-truth-discernment",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Chitralekha Gupta",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Wearable devices are transforming human capabilities by seamlessly augmenting cognitive functions. In this position paper, we propose a voice-based, interactive learning companion designed to amplify and extend cognitive abilities through informal learning. Our vision is threefold: (1) to enable users to discover new knowledge on-the-go through contextual interactive quizzes, fostering critical thinking and mindfulness, (2) to proactively detect misinformation, empowering users to critically assess information in real time, and (3) to provide spoken language correction and prompting hints for second language learning and effective communication. As an initial step toward this vision, we present Factually - a proactive, wearable fact-checking system integrated into devices like smartwatches or rings. Factually discreetly alerts users to potential falsehoods via vibrotactile feedback, helping them assess information critically. We demonstrate its utility through three illustrative scenarios, highlighting its potential to extend cognitive abilities for real-time misinformation detection. Early qualitative feedback suggests that Factually can enhance users' fact-checking capabilities, offering both practical and experiential benefits.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17204",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:21.242498Z"
  },
  {
    "id": "764bd430921766674defcd732f03a341",
    "title": "Building Sustainable and Trustworthy Indigenous Knowledge Preservation Ecosystem",
    "slug": "building-sustainable-and-trustworthy-indigenous-knowledge-preservation-ecosystem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Siguo Bi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper focuses on the essential global issue of protecting and transmitting indigenous knowledge. It reveals the challenges in this area and proposes a sustainable supply chain framework for indigenous knowledge. The paper reviews existing technological solutions and identifies technical challenges and gaps. It then introduces cutting-edge technologies to protect and disseminate indigenous knowledge more effectively. The paper also discusses how the proposed framework can address real-world challenges in protecting and transmitting indigenous knowledge, and explores future research applications of the proposed solutions. Finally, it addresses open issues and provides a detailed analysis, offering promising research directions for the protection and transmission of indigenous knowledge worldwide.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17281",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:21.242692Z"
  },
  {
    "id": "5c41330d0bba75b3f42ea6d973fe2344",
    "title": "Learning Isometric Embeddings of Road Networks using Multidimensional Scaling",
    "slug": "learning-isometric-embeddings-of-road-networks-using-multidimensional-scaling",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Juan Carlos Climent Pardo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The lack of generalization in learning-based autonomous driving applications is shown by the narrow range of road scenarios that vehicles can currently cover. A generalizable approach should capture many distinct road structures and topologies, as well as consider traffic participants, and dynamic changes in the environment, so that vehicles can navigate and perform motion planning tasks even in the most difficult situations. Designing suitable feature spaces for neural network-based motion planers that encapsulate all kinds of road scenarios is still an open research challenge. This paper tackles this learning-based generalization challenge and shows how graph representations of road networks can be leveraged by using multidimensional scaling (MDS) techniques in order to obtain such feature spaces. State-of-the-art graph representations and MDS approaches are analyzed for the autonomous driving use case. Finally, the option of embedding graph nodes is discussed in order to perform easier learning procedures and obtain dimensionality reduction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17534",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:21.242875Z"
  },
  {
    "id": "e4860845f7589c31593effe503de8db7",
    "title": "Towards a HIPAA Compliant Agentic AI System in Healthcare",
    "slug": "towards-a-hipaa-compliant-agentic-ai-system-in-healthcare",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multiagent Systems (cs.MA)",
    "author": {
      "name": "Subash Neupane",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Agentic AI systems powered by Large Language Models (LLMs) as their foundational reasoning engine, are transforming clinical workflows such as medical report generation and clinical summarization by autonomously analyzing sensitive healthcare data and executing decisions with minimal human oversight. However, their adoption demands strict compliance with regulatory frameworks such as Health Insurance Portability and Accountability Act (HIPAA), particularly when handling Protected Health Information (PHI). This work-in-progress paper introduces a HIPAA-compliant Agentic AI framework that enforces regulatory compliance through dynamic, context-aware policy enforcement. Our framework integrates three core mechanisms: (1) Attribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid PHI sanitization pipeline combining regex patterns and BERT-based model to minimize leakage, and (3) immutable audit trails for compliance verification.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17669",
    "tags": [
      "Multiagent Systems (cs.MA)"
    ],
    "createdAt": "2025-04-25T15:49:21.243066Z"
  },
  {
    "id": "b1ce5f2b05c98b2bb0f68f6d35ca8cbf",
    "title": "Disaggregated Deep Learning via In-Physics Computing at Radio Frequency",
    "slug": "disaggregated-deep-learning-via-in-physics-computing-at-radio-frequency",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhihui Gao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Modern edge devices, such as cameras, drones, and Internet-of-Things nodes, rely on deep learning to enable a wide range of intelligent applications, including object recognition, environment perception, and autonomous navigation. However, deploying deep learning models directly on the often resource-constrained edge devices demands significant memory footprints and computational power for real-time inference using traditional digital computing architectures. In this paper, we present WISE, a novel computing architecture for wireless edge networks designed to overcome energy constraints in deep learning inference. WISE achieves this goal through two key innovations: disaggregated model access via wireless broadcasting and in-physics computation of general complex-valued matrix-vector multiplications directly at radio frequency. Using a software-defined radio platform with wirelessly broadcast model weights over the air, we demonstrate that WISE achieves 95.7% image classification accuracy with ultra-low operation power of 6.0 fJ/MAC per client, corresponding to a computation efficiency of 165.8 TOPS/W. This approach enables energy-efficient deep learning inference on wirelessly connected edge devices, achieving more than two orders of magnitude improvement in efficiency compared to traditional digital computing.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17752",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:21.243267Z"
  },
  {
    "id": "5aa7f244abeb3a9b36a013f7699095cc",
    "title": "Towards Scalable Multi-Chip Wireless Networks with Near-Field Time Reversal",
    "slug": "towards-scalable-multi-chip-wireless-networks-with-near-field-time-reversal",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Emerging Technologies (cs.ET)",
    "author": {
      "name": "Ama Bandara",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The concept of Wireless Network-on-Chip (WNoC) has emerged as a potential solution to address the escalating communication demands of modern computing systems due to its low-latency, versatility, and reconfigurability. However, for WNoC to fulfill its potential, it is essential to establish multiple high-speed wireless links across chips. Unfortunately, the compact and enclosed nature of computing packages introduces significant challenges in the form of Co-Channel Interference and Inter-Symbol Interference, which not only hinder the deployment of multiple spatial channels but also severely restrict the symbol rate of each individual channel. In this paper, we posit that Time Reversal (TR) could be effective in addressing both impairments in this static scenario thanks to its spatiotemporal focusing capabilities even in the near field. Through comprehensive full-wave simulations and bit error rate analysis in multiple scenarios and at multiple frequency bands, we provide evidence that TR can increase the symbol rate by an order of magnitude, enabling the deployment of multiple concurrent links and achieving aggregate speeds exceeding 100 Gb/s. Finally, we evaluate the impact of reducing the sampling rate of the TR filter on the achievable speeds, paving the way to practical TR-based wireless communications at the chip scale.",
    "pdfUrl": "https://arxiv.org/pdf/2404.17325",
    "tags": [
      "Emerging Technologies (cs.ET)"
    ],
    "createdAt": "2025-04-25T15:49:21.243475Z"
  },
  {
    "id": "66750d501bd0f65f7bd287f41e116afa",
    "title": "SPAARC: Spatial Proximity and Association based prefetching for Augmented Reality in edge Cache",
    "slug": "spaarc:-spatial-proximity-and-association-based-prefetching-for-augmented-reality-in-edge-cache",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Emerging Technologies (cs.ET)",
    "author": {
      "name": "Nikhil Sreekumar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Mobile Augmented Reality (MAR) applications face performance challenges due to their high computational demands and need for low-latency responses. Traditional approaches like on-device storage or reactive data fetching from the cloud often result in limited AR experiences or unacceptable lag. Edge caching, which caches AR objects closer to the user, provides a promising solution. However, existing edge caching approaches do not consider AR-specific features such as AR object sizes, user interactions, and physical location. This paper investigates how to further optimize edge caching by employing AR-aware prefetching techniques. We present SPAARC, a Spatial Proximity and Association-based Prefetching policy specifically designed for MAR Caches. SPAARC intelligently prioritizes the caching of virtual objects based on their association with other similar objects and the user's proximity to them. It also considers the recency of associations and uses a lazy fetching strategy to efficiently manage edge resources and maximize Quality of Experience (QoE).\nThrough extensive evaluation using both synthetic and real-world workloads, we demonstrate that SPAARC significantly improves cache hit rates compared to standard caching algorithms, achieving gains ranging from 3% to 40% while reducing the need for on-demand data retrieval from the cloud. Further, we present an adaptive tuning algorithm that automatically tunes SPAARC parameters to achieve optimal performance. Our findings demonstrate the potential of SPAARC to substantially enhance the user experience in MAR applications by ensuring the timely availability of virtual objects.",
    "pdfUrl": "https://arxiv.org/pdf/2502.15192",
    "tags": [
      "Emerging Technologies (cs.ET)"
    ],
    "createdAt": "2025-04-25T15:49:21.243664Z"
  },
  {
    "id": "de53d16aee5458045aeb095c0f1a9617",
    "title": "HyDra: SOT-CAM Based Vector Symbolic Macro for Hyperdimensional Computing",
    "slug": "hydra:-sot-cam-based-vector-symbolic-macro-for-hyperdimensional-computing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Emerging Technologies (cs.ET)",
    "author": {
      "name": "Md Mizanur Rahaman Nayan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Hyperdimensional computing (HDC) is a brain-inspired paradigm valued for its noise robustness, parallelism, energy efficiency, and low computational overhead. Hardware accelerators are being explored to further enhance its performance, but current solutions are often limited by application specificity and the latency of encoding and similarity search. This paper presents a generalized, reconfigurable on-chip training and inference architecture for HDC, utilizing spin-orbit-torque magnetic (SOT-MRAM) content-addressable memory (CAM). The proposed SOT-CAM array integrates storage and computation, enabling in-memory execution of key HDC operations: binding (bitwise multiplication), permutation (bit rotation), and efficient similarity search. To mitigate interconnect parasitic effect in similarity search, a four-stage voltage scaling scheme has been proposed to ensure accurate Hamming distance representation. Additionally, a novel bit drop method replaces bit rotation during read operations, and an HDC-specific adder reduces energy and area by 1.51x and 1.43x, respectively. Benchmarked at 7nm, the architecture achieves energy reductions of 21.5x, 552.74x, 1.45x, and 282.57x for addition, permutation, multiplication, and search operations, respectively, compared to CMOS-based HDC. Against state-of-the-art HD accelerators, it achieves a 2.27x lower energy consumption and outperforms CPU and eGPU implementations by 2702x and 23161x, respectively, with less than 3% drop in accuracy",
    "pdfUrl": "https://arxiv.org/pdf/2504.14020",
    "tags": [
      "Emerging Technologies (cs.ET)"
    ],
    "createdAt": "2025-04-25T15:49:21.243859Z"
  },
  {
    "id": "f77f5c6a952e58b8e9294634af9b8c57",
    "title": "Count2Multiply: Reliable In-Memory High-Radix Counting",
    "slug": "count2multiply:-reliable-in-memory-high-radix-counting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Joo Paulo Cardoso de Lima",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Computing-in-memory (CIM) has been demonstrated across various memory technologies, ranging from memristive crossbars performing analog dot-product computations to large-scale digital bitwise operations in commodity DRAM and other proposed non-volative memory technologies. However, current CIM solutions face latency and reliability challenges. CIM fidelity lags considerably behind access fidelity. Furthermore, bulk-bitwise CIM, although highly parallelized, requires long latency for operations like multiplication and addition, due to their bit-serial computation. This paper presents Count2Multiply, a technology-agnostic digital CIM approach to perform multiplication, addition and other operations using high-radix, massively parallel counting enabled by CIM bulk-bitwise logic operations. Designed to meet fault tolerance requirements, Count2Multiply integrates traditional row-wise error correction codes, such as Hamming and BCH, to address the high error rates in existing CIM designs. We demonstrate Count2Multiply with a detailed application to CIM in conventional DRAM due to its ubiquity and high endurance. However, we note that the Count2Multiply architecture is compatible with other functionally complete CIM proposals. Compared to the state-of-the-art in-DRAM CIM method, Count2Multiply achieves up to 10x speedup, 8x higher GOPS/Watt, and 9.5x higher GOPS/area, while outperforming GPU for vector-matrix multiplications.",
    "pdfUrl": "https://arxiv.org/pdf/2409.10136",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:21.244065Z"
  },
  {
    "id": "746c83d2e7d10dcc3f6a05f74b9289d6",
    "title": "Evaluating DAO Sustainability and Longevity Through On-Chain Governance Metrics",
    "slug": "evaluating-dao-sustainability-and-longevity-through-on-chain-governance-metrics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Silvio Meneguzzo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Decentralised Autonomous Organisations (DAOs) automate governance and resource allocation through smart contracts, aiming to shift decision-making to distributed token holders. However, many DAOs face sustainability challenges linked to limited user participation, concentrated voting power, and technical design constraints. This paper addresses these issues by identifying research gaps in DAO evaluation and introducing a framework of Key Performance Indicators (KPIs) that capture governance efficiency, financial robustness, decentralisation, and community engagement. We apply the framework to a custom-built dataset of real-world DAOs constructed from on-chain data and analysed using non-parametric methods. The results reveal recurring governance patterns, including low participation rates and high proposer concentration, which may undermine long-term viability. The proposed KPIs offer a replicable, data-driven method for assessing DAO governance structures and identifying potential areas for improvement. These findings support a multidimensional approach to evaluating decentralised systems and provide practical tools for researchers and practitioners working to improve the resilience and effectiveness of DAO-based governance models.",
    "pdfUrl": "https://arxiv.org/pdf/2504.11341",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:21.244256Z"
  },
  {
    "id": "99db0cf3a841ac7b771768b2c9f23021",
    "title": "Approximate Problems for Finite Transducers",
    "slug": "approximate-problems-for-finite-transducers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Formal Languages and Automata Theory (cs.FL)",
    "author": {
      "name": "Emmanuel Filiot",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Finite (word) state transducers extend finite state automata by defining a binary relation over finite words, called rational relation. If the rational relation is the graph of a function, this function is said to be rational. The class of sequential functions is a strict subclass of rational functions, defined as the functions recognised by input-deterministic finite state transducers. The class membership problems between those classes are known to be decidable. We consider approximate versions of these problems and show they are decidable as well. This includes the approximate functionality problem, which asks whether given a rational relation (by a transducer), is it close to a rational function, and the approximate determinisation problem, which asks whether a given rational function is close to a sequential function. We prove decidability results for several classical distances, including Hamming and Levenshtein edit distance. Finally, we investigate the approximate uniformisation problem, which asks, given a rational relation $R$, whether there exists a sequential function that is close to some function uniformising $R$. As for its exact version, we prove that this problem is undecidable.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17299",
    "tags": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "createdAt": "2025-04-25T15:49:21.527333Z"
  },
  {
    "id": "f5d5d64922ed38f8ec96931a8cbb94f1",
    "title": "Morphisms and BWT-run Sensitivity",
    "slug": "morphisms-and-bwt-run-sensitivity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Formal Languages and Automata Theory (cs.FL)",
    "author": {
      "name": "Gabriele Fici",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study how the application of injective morphisms affects the number $r$ of equal-letter runs in the Burrows-Wheeler Transform (BWT). This parameter has emerged as a key repetitiveness measure in compressed indexing. We focus on the notion of BWT-run sensitivity after application of an injective morphism. For binary alphabets, we characterize the class of morphisms that preserve the number of BWT-runs up to a bounded additive increase, by showing that it coincides with the known class of primitivity-preserving morphisms, which are those that map primitive words to primitive words. We further prove that deciding whether a given binary morphism has bounded BWT-run sensitivity is possible in polynomial time with respect to the total length of the images of the two letters. Additionally, we explore new structural and combinatorial properties of synchronizing and recognizable morphisms. These results establish new connections between BWT-based compressibility, code theory, and symbolic dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17443",
    "tags": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "createdAt": "2025-04-25T15:49:21.527551Z"
  },
  {
    "id": "44df0d299849d10f82f506f21779bcf3",
    "title": "Dynamic Membership for Regular Tree Languages",
    "slug": "dynamic-membership-for-regular-tree-languages",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Formal Languages and Automata Theory (cs.FL)",
    "author": {
      "name": "Antoine Amarilli",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the dynamic membership problem for regular tree languages under relabeling updates: we fix an alphabet ${\\Sigma}$ and a regular tree language $L$ over ${\\Sigma}$ (expressed, e.g., as a tree automaton), we are given a tree $T$ with labels in ${\\Sigma}$, and we must maintain the information of whether the tree $T$ belongs to $L$ while handling relabeling updates that change the labels of individual nodes in $T$. (The shape and size of the tree remain the same throughout.)\nOur first contribution is to show that this problem admits an $O(\\log n / \\log \\log n)$ algorithm for any fixed regular tree language, improving over known algorithms that achieve $O(\\log n)$. This generalizes the known $O(\\log n / \\log \\log n)$ upper bound over words, and it matches the lower bound of ${\\Omega}(\\log n / \\log \\log n)$ from dynamic membership to some word languages and from the existential marked ancestor problem.\nOur second contribution is to introduce a class of regular languages, dubbed almost-commutative tree languages, and show that dynamic membership to such languages under relabeling updates can be done in constant time per update. Almost-commutative languages generalize both commutative languages and finite languages, and they are the analogue for trees of the ZG languages enjoying constant-time dynamic membership over words. Our main technical contribution is to show that this class is conditionally optimal when we assume that the alphabet features a neutral letter, i.e., a letter that has no effect on membership to the language. More precisely, we show that any regular tree language with a neutral letter which is not almost-commutative cannot be maintained in constant time under the assumption that prefix-U1 problem from (Amarilli, Jachiet, Paperman, ICALP'21) also does not admit a constant-time algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17536",
    "tags": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "createdAt": "2025-04-25T15:49:21.527757Z"
  },
  {
    "id": "18faca217e2011e26bc95c2c4c24662c",
    "title": "Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification",
    "slug": "neural-theorem-proving:-generating-and-structuring-proofs-for-formal-verification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Balaji Rao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Formally verifying properties of software code has been a highly desirable task, especially with the emergence of LLM-generated code. In the same vein, they provide an interesting avenue for the exploration of formal verification and mechanistic interpretability. Since the introduction of code-specific models, despite their successes in generating code in Lean4 and Isabelle, the task of generalized theorem proving still remains far from being fully solved and will be a benchmark for reasoning capability in LLMs. In this work, we introduce a framework that generates whole proofs in a formal language to be used within systems that utilize the power of built-in tactics and off-the-shelf automated theorem provers. Our framework includes 3 components: generating natural language statements of the code to be verified, an LLM that generates formal proofs for the given statement, and a module employing heuristics for building the final proof. To train the LLM, we employ a 2-stage fine-tuning process, where we first use SFT-based training to enable the model to generate syntactically correct Isabelle code and then RL-based training that encourages the model to generate proofs verified by a theorem prover. We validate our framework using the miniF2F-test benchmark and the Isabelle proof assistant and design a use case to verify the correctness of the AWS S3 bucket access policy code. We also curate a dataset based on the FVEL\\textsubscript{\\textnormal{ER}} dataset for future training tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17017",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:21.527984Z"
  },
  {
    "id": "642a50e82c4b00ec4d09e0a65caf12fb",
    "title": "A New Graph Grammar Formalism for Robust Syntactic Pattern Recognition",
    "slug": "a-new-graph-grammar-formalism-for-robust-syntactic-pattern-recognition",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Formal Languages and Automata Theory (cs.FL)",
    "author": {
      "name": "Peter Fletcher",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "I introduce a formalism for representing the syntax of recursively structured graph-like patterns. It does not use production rules, like a conventional graph grammar, but represents the syntactic structure in a more direct and declarative way. The grammar and the pattern are both represented as networks, and parsing is seen as the construction of a homomorphism from the pattern to the grammar. The grammars can represent iterative, hierarchical and nested recursive structure in more than one dimension.\nThis supports a highly parallel style of parsing, in which all aspects of pattern recognition (feature detection, segmentation, parsing, filling in missing symbols, top-down and bottom-up inference) are integrated into a single process, to exploit the synergy between them.\nThe emphasis of this paper is on underlying theoretical issues, but I also give some example runs to illustrate the error-tolerant parsing of complex recursively structured patterns of 50-1000 symbols, involving variability in geometric relationships, blurry and indistinct symbols, overlapping symbols, cluttered images, and erased patches.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15975",
    "tags": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "createdAt": "2025-04-25T15:49:21.528176Z"
  },
  {
    "id": "c01cdcbbcfc5045c4a807e9f5ba4dc98",
    "title": "Automatic Generation of Safety-compliant Linear Temporal Logic via Large Language Model: A Self-supervised Framework",
    "slug": "automatic-generation-of-safety-compliant-linear-temporal-logic-via-large-language-model:-a-self-supervised-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic in Computer Science (cs.LO)",
    "author": {
      "name": "Junle Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Converting high-level tasks described by natural language into formal specifications like Linear Temporal Logic (LTL) is a key step towards providing formal safety guarantees over cyber-physical systems (CPS). While the compliance of the formal specifications themselves against the safety restrictions imposed on CPS is crucial for ensuring safety, most existing works only focus on translation consistency between natural languages and formal specifications. In this paper, we introduce AutoSafeLTL, a self-supervised framework that utilizes large language models (LLMs) to automate the generation of LTL specifications complying with a set of safety restrictions while preserving their logical consistency and semantic accuracy. As a key insight, our framework integrates Language Inclusion check with an automated counterexample-guided modification mechanism to ensure the safety-compliance of the resulting LTL specifications. In particular, we develop 1) an LLM-as-an-Aligner, which performs atomic proposition matching between generated LTL specifications and safety restrictions to enforce semantic alignment; and 2) an LLM-as-a-Critic, which automates LTL specification refinement by interpreting counterexamples derived from Language Inclusion checks. Experimental results demonstrate that our architecture effectively guarantees safety-compliance for the generated LTL specifications, achieving a 0% violation rate against imposed safety restrictions. This shows the potential of our work in synergizing AI and formal verification techniques, enhancing safety-aware specification generation and automatic verification for both AI and critical CPS applications.",
    "pdfUrl": "https://arxiv.org/pdf/2503.15840",
    "tags": [
      "Logic in Computer Science (cs.LO)"
    ],
    "createdAt": "2025-04-25T15:49:21.528367Z"
  },
  {
    "id": "f54a318e725c81549ca1bfeda9fb589f",
    "title": "A Recursive Block Pillar Structure in the Kolakoski Sequence K(1,3)",
    "slug": "a-recursive-block-pillar-structure-in-the-kolakoski-sequence-k(1,3)",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "William Cook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Kolakoski sequence K(1,3) over {1, 3} is known to be structured, unlike K(1,2), with symbol frequency d approx. 0.397 linked to the Pisot number alpha (real root of x^3 - 2x^2 - 1 = 0). We reveal an explicit nested recursion defining block sequences B(n) and pillar sequences P(n) via B(n+1) = B(n) P(n) B(n) and P(n+1) = G(R(P(n)), 3), where G generates runs from vector R(P(n)). We prove B(n) are prefixes of K(1,3) converging to it, and B(n+1) = G(R(B(n)), 1), directly reflecting the Kolakoski self-encoding property. We derive recurrences for lengths |B(n)|, |P(n)| and symbol counts, confirming growth governed by alpha (limit |B(n+1)|/|B(n)| = alpha as n -> infinity). If block/pillar densities converge, they must equal d. This constructive framework provides an alternative perspective on K(1,3)'s regularity, consistent with known results from substitution dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13433",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:21.528566Z"
  },
  {
    "id": "ea67458f049d3b3ab7ed934bc649ffed",
    "title": "Detection, Classification and Prevalence of Self-Admitted Aging Debt",
    "slug": "detection,-classification-and-prevalence-of-self-admitted-aging-debt",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Murali Sridharan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Context: Previous research on software aging is limited with focus on dynamic runtime indicators like memory and performance, often neglecting evolutionary indicators like source code comments and narrowly examining legacy issues within the TD context. Objective: We introduce the concept of Aging Debt (AD), representing the increased maintenance efforts and costs needed to keep software updated. We study AD through Self-Admitted Aging Debt (SAAD) observed in source code comments left by software developers. Method: We employ a mixed-methods approach, combining qualitative and quantitative analyses to detect and measure AD in software. This includes framing SAAD patterns from the source code comments after analysing the source code context, then utilizing the SAAD patterns to detect SAAD comments. In the process, we develop a taxonomy for SAAD that reflects the temporal aging of software and its associated debt. Then we utilize the taxonomy to quantify the different types of AD prevalent in OSS repositories. Results: Our proposed taxonomy categorizes temporal software aging into Active and Dormant types. Our extensive analysis of over 9,000+ Open Source Software (OSS) repositories reveals that more than 21% repositories exhibit signs of SAAD as observed from our gold standard SAAD dataset. Notably, Dormant AD emerges as the predominant category, highlighting a critical but often overlooked aspect of software maintenance. Conclusion: As software volume grows annually, so do evolutionary aging and maintenance challenges; our proposed taxonomy can aid researchers in detailed software aging studies and help practitioners develop improved and proactive maintenance strategies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17428",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:21.754153Z"
  },
  {
    "id": "3cb0ad0ed8807999977727088f97967a",
    "title": "ePBR: Extended PBR Materials in Image Synthesis",
    "slug": "epbr:-extended-pbr-materials-in-image-synthesis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Graphics (cs.GR)",
    "author": {
      "name": "Yu Guo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Realistic indoor or outdoor image synthesis is a core challenge in computer vision and graphics. The learning-based approach is easy to use but lacks physical consistency, while traditional Physically Based Rendering (PBR) offers high realism but is computationally expensive. Intrinsic image representation offers a well-balanced trade-off, decomposing images into fundamental components (intrinsic channels) such as geometry, materials, and illumination for controllable synthesis. However, existing PBR materials struggle with complex surface models, particularly high-specular and transparent surfaces. In this work, we extend intrinsic image representations to incorporate both reflection and transmission properties, enabling the synthesis of transparent materials such as glass and windows. We propose an explicit intrinsic compositing framework that provides deterministic, interpretable image synthesis. With the Extended PBR (ePBR) Materials, we can effectively edit the materials with precise controls.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17062",
    "tags": [
      "Graphics (cs.GR)"
    ],
    "createdAt": "2025-04-25T15:49:21.981735Z"
  },
  {
    "id": "c45af5afebb92e9b61369588339a8007",
    "title": "Bolt: Clothing Virtual Characters at Scale",
    "slug": "bolt:-clothing-virtual-characters-at-scale",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Graphics (cs.GR)",
    "author": {
      "name": "Jonathan Leaf",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Clothing virtual characters is a time-consuming and often manual process. Outfits can be composed of multiple garments, and each garment must be fitted to the unique shape of a character. Since characters can vary widely in size and shape, fitting outfits to many characters is a combinatorially large problem. We present Bolt, a system designed to take outfits originally authored on a source body and fit them to new body shapes via a three stage transfer, drape, and rig process. First, our new garment transfer method transforms each garment's 3D mesh positions to the new character, then optimizes the garment's 2D sewing pattern while maintaining key features of the original seams and boundaries. Second, our system simulates the transferred garments to progressively drape and untangle each garment in the outfit. Finally, the garments are rigged to the new character. This entire process is automatic, making it feasible to clothe characters at scale with no human intervention. Clothed characters are then ready for immediate use in applications such as gaming, animation, synthetic generation, and more.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17614",
    "tags": [
      "Graphics (cs.GR)"
    ],
    "createdAt": "2025-04-25T15:49:21.981994Z"
  },
  {
    "id": "b53723b0cd3055d810272f384041da44",
    "title": "CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos",
    "slug": "casualhdrsplat:-robust-high-dynamic-range-3d-gaussian-splatting-from-casually-captured-videos",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Graphics (cs.GR)",
    "author": {
      "name": "Shucheng Gong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, photo-realistic novel view synthesis from multi-view images, such as neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered widespread attention due to their superior performance. However, most works rely on low dynamic range (LDR) images, which limits the capturing of richer scene details. Some prior works have focused on high dynamic range (HDR) scene reconstruction, typically require capturing of multi-view sharp images with different exposure times at fixed camera positions during exposure times, which is time-consuming and challenging in practice. For a more flexible data acquisition, we propose a one-stage method: \\textbf{CasualHDRSplat} to easily and robustly reconstruct the 3D HDR scene from casually captured videos with auto-exposure enabled, even in the presence of severe motion blur and varying unknown exposure time. \\textbf{CasualHDRSplat} contains a unified differentiable physical imaging model which first applies continuous-time trajectory constraint to imaging process so that we can jointly optimize exposure time, camera response function (CRF), camera poses, and sharp 3D HDR scene. Extensive experiments demonstrate that our approach outperforms existing methods in terms of robustness and rendering quality. Our source code will be available at this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17728",
    "tags": [
      "Graphics (cs.GR)"
    ],
    "createdAt": "2025-04-25T15:49:21.982263Z"
  },
  {
    "id": "f54cafd087c13266da2cd8ebcca65557",
    "title": "ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization",
    "slug": "arf-plus:-controlling-perceptual-factors-in-artistic-radiance-fields-for-3d-scene-stylization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Wenzhao Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The radiance fields style transfer is an emerging field that has recently gained popularity as a means of 3D scene stylization, thanks to the outstanding performance of neural radiance fields in 3D reconstruction and view synthesis. We highlight a research gap in radiance fields style transfer, the lack of sufficient perceptual controllability, motivated by the existing concept in the 2D image style transfer. In this paper, we present ARF-Plus, a 3D neural style transfer framework offering manageable control over perceptual factors, to systematically explore the perceptual controllability in 3D scene stylization. Four distinct types of controls - color preservation control, (style pattern) scale control, spatial (selective stylization area) control, and depth enhancement control - are proposed and integrated into this framework. Results from real-world datasets, both quantitative and qualitative, show that the four types of controls in our ARF-Plus framework successfully accomplish their corresponding perceptual controls when stylizing 3D scenes. These techniques work well for individual style inputs as well as for the simultaneous application of multiple styles within a scene. This unlocks a realm of limitless possibilities, allowing customized modifications of stylization effects and flexible merging of the strengths of different styles, ultimately enabling the creation of novel and eye-catching stylistic effects on 3D scenes.",
    "pdfUrl": "https://arxiv.org/pdf/2308.12452",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:21.982510Z"
  },
  {
    "id": "673e7953462a127698e8c5399a5c3855",
    "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference",
    "slug": "peer-aware-cost-estimation-in-nonlinear-general-sum-dynamic-games-for-mutual-learning-and-intent-inference",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Seyed Yousef Soltanian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Human-robot interactions can be modeled as incomplete-information general-sum dynamic games since the objective functions of both agents are not explicitly known to each other. However, solving for equilibrium policies for such games presents a major challenge, especially if the games involve nonlinear underlying dynamics. To simplify the problem, existing work often assumes that one agent is an expert with complete information about its peer, which can lead to biased estimates and failures in coordination. To address this challenge, we propose a nonlinear peer-aware cost estimation (N-PACE) algorithm for general-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ) approximation of the nonlinear general-sum game, each agent explicitly models the learning dynamics of its peer agent while inferring their objective functions, leading to unbiased fast learning in inferring the unknown objective function of the peer agent, which is critical for task completion and safety assurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent communication} in such multi-agent systems by explicitly modeling the peer's learning dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17129",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:22.176107Z"
  },
  {
    "id": "85ebf29dfcf6c9465ad67d528a9eb1b0",
    "title": "Edge-weighted Online Stochastic Matching Under Jaillet-Lu LP",
    "slug": "edge-weighted-online-stochastic-matching-under-jaillet-lu-lp",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Data Structures and Algorithms (cs.DS)",
    "author": {
      "name": "Shuyi Yan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The online stochastic matching problem was introduced by [FMMM09], together with the $(1-\\frac1e)$-competitive Suggested Matching algorithm. In the most general edge-weighted setting, this ratio has not been improved for more than one decade, until recently [Yan24] beat the $1-\\frac1e$ bound and [QFZW23] further improved the ratio to $0.650$. Both of these works measure the online competitiveness against the offline LP relaxation introduced by [JL14]. This LP has also played an important role in other settings since it is a natural choice for two-choices online algorithms.\nIn this paper, we propose an upper bound of $0.663$ and a lower bound of $0.662$ for edge-weighted online stochastic matching under Jaillet-Lu LP. First, we propose a hard instance and prove that the optimal online algorithm for this instance only has a competitive ratio $<0.663$. Then, we show that a near-optimal algorithm for this instance can be generalized to work on all instances and achieve a competitive ratio $>0.662$. It indicates that more powerful LPs are necessary if we want to further improve the ratio by $0.001$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17392",
    "tags": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "createdAt": "2025-04-25T15:49:22.176304Z"
  },
  {
    "id": "3e21669760fa2aaa5c1daa5f959ea9e3",
    "title": "The Incentive Guarantees Behind Nash Welfare in Divisible Resources Allocation",
    "slug": "the-incentive-guarantees-behind-nash-welfare-in-divisible-resources-allocation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Science and Game Theory (cs.GT)",
    "author": {
      "name": "Xiaohui Bei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the problem of allocating divisible resources among $n$ agents, hopefully in a fair and efficient manner. With the presence of strategic agents, additional incentive guarantees are also necessary, and the problem of designing fair and efficient mechanisms becomes much less tractable. While there are flourishing positive results against strategic agents for homogeneous divisible items, very few of them are known to hold in cake cutting.\nWe show that the Maximum Nash Welfare (MNW) mechanism, which provides desirable fairness and efficiency guarantees and achieves an incentive ratio of $2$ for homogeneous divisible items, also has an incentive ratio of $2$ in cake cutting. Remarkably, this result holds even without the free disposal assumption, which is hard to get rid of in the design of truthful cake cutting mechanisms.\nMoreover, we show that, for cake cutting, the Partial Allocation (PA) mechanism proposed by Cole et al. (EC'13), which is truthful and $1/e$-MNW for homogeneous divisible items, has an incentive ratio between $[e^{1 / e}, e]$ and when randomization is allowed, can be turned to be truthful in expectation. Given two alternatives for a trade-off between incentive ratio and Nash welfare provided by the MNW and PA mechanisms, we establish an interpolation between them for both cake cutting and homogeneous divisible items.\nFinally, we study the optimal incentive ratio achievable by envy-free cake cutting mechanisms. We first give an envy-free mechanism for two agents with an incentive ratio of $4 / 3$. Then, we show that any envy-free cake cutting mechanism with the connected pieces constraint has an incentive ratio of $\\Theta(n)$.",
    "pdfUrl": "https://arxiv.org/pdf/2308.08903",
    "tags": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "createdAt": "2025-04-25T15:49:22.176523Z"
  },
  {
    "id": "b587b6667aeda0ed2224900f3ab79ca7",
    "title": "The Role of Prescreening in Auctions with Predictions",
    "slug": "the-role-of-prescreening-in-auctions-with-predictions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Science and Game Theory (cs.GT)",
    "author": {
      "name": "Yanwei Sun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Auctioneers often use closed auctions to create scarcity and prestige, aiming to intensify competition among a select group of high-status bidders. Advances in machine learning and AI make this strategy increasingly viable, enabling cost-effective identification of capable participants. In this paper, we develop a theoretical model to assess whether such practice can be justified from an economic perspective. We consider a setting in which bidders have i.i.d. private valuations, and the auction designer observes a noisy predictor of each bidder's valuation, which is assumed to be fully informative with some probability. Based on this noisy predictor, the designer determines how many bidders to admit -- a process we refer to as prescreening. We show that an auction with prescreening is equivalent to a standard auction (i.e., without prescreening) in which bidder valuations are correlated. Notably, the standard notion of affiliation commonly assumed in the auction literature does not generally hold in this equivalent formulation. We characterize conditions for the existence of symmetric and strictly monotone equilibrium strategies across three classical auction formats: all-pay, first-price, and second-price auctions. Our results demonstrate that prescreening with noisy predictors can significantly enhance revenue in all-pay auctions; in fact, with a perfect predictor, admitting only two bidders is optimal. By contrast, in both first-price and second-price auctions, admitting all bidders remains revenue-maximizing.",
    "pdfUrl": "https://arxiv.org/pdf/2502.12117",
    "tags": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "createdAt": "2025-04-25T15:49:22.176725Z"
  },
  {
    "id": "e382f8de2e18dea0b25dd4772db1dbc8",
    "title": "Linear Functions to the Extended Reals",
    "slug": "linear-functions-to-the-extended-reals",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Bo Waggoner",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper investigates functions from $\\mathbb{R}^d$ to $\\mathbb{R} \\cup \\{\\pm \\infty\\}$ that satisfy axioms of linearity wherever allowed by extended-value arithmetic. They have a nontrivial structure defined inductively on $d$, and unlike finite linear functions, they require $\\Omega(d^2)$ parameters to uniquely identify. In particular they can capture vertical tangent planes to epigraphs: a function (never $-\\infty$) is convex if and only if it has an extended-valued subgradient at every point in its effective domain, if and only if it is the supremum of a family of \"affine extended\" functions. These results are applied to the well-known characterization of proper scoring rules, for the finite-dimensional case: it is carefully and rigorously extended here to a more constructive form. In particular it is investigated when proper scoring rules can be constructed from a given convex function.",
    "pdfUrl": "https://arxiv.org/pdf/2102.09552",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:22.176918Z"
  },
  {
    "id": "55889b23d4d73040fad3db792908f04b",
    "title": "LLM impact on BLV programming",
    "slug": "llm-impact-on-blv-programming",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Prashant Chandrasekar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) are rapidly becoming integral to a wide range of tools, tasks, and problem-solving processes, especially in software development. Originally designed for natural language processing tasks such as text generation, LLMs are increasingly being used to assist both professionals and students in writing code. This growing reliance on LLM-based tools is reshaping programming workflows and task execution. In this study, we explore the impact of these technologies on blind and low-vision (BLV) developers. Our review of existing literature indicates that while LLMs help mitigate some of the challenges faced by BLV programmers, they also introduce new forms of inaccessibility. We conducted an evaluation of five popular LLM-powered integrated development environments (IDEs), assessing their performance across a comprehensive set of programming tasks. Our findings highlight several unsupported scenarios, instances of incorrect model output, and notable limitations in interaction support for specific tasks. Through observing BLV developers as they engaged in coding activities, we uncovered key interaction barriers that go beyond model accuracy or code generation quality. This paper outlines the challenges and corresponding opportunities for improving accessibility in the context of generative AI-assisted programming. Addressing these issues can meaningfully enhance the programming experience for BLV developers. As the generative AI revolution continues to unfold, it must also address the unique burdens faced by this community.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17018",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.484781Z"
  },
  {
    "id": "d7d5634bcdf519fe365f557dafad6142",
    "title": "What Makes for a Good Saliency Map? Comparing Strategies for Evaluating Saliency Maps in Explainable AI (XAI)",
    "slug": "what-makes-for-a-good-saliency-map?-comparing-strategies-for-evaluating-saliency-maps-in-explainable-ai-(xai)",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Felix Kares",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Saliency maps are a popular approach for explaining classifications of (convolutional) neural networks. However, it remains an open question as to how best to evaluate salience maps, with three families of evaluation methods commonly being used: subjective user measures, objective user measures, and mathematical metrics. We examine three of the most popular saliency map approaches (viz., LIME, Grad-CAM, and Guided Backpropagation) in a between subject study (N=166) across these families of evaluation methods. We test 1) for subjective measures, if the maps differ with respect to user trust and satisfaction; 2) for objective measures, if the maps increase users' abilities and thus understanding of a model; 3) for mathematical metrics, which map achieves the best ratings across metrics; and 4) whether the mathematical metrics can be associated with objective user measures. To our knowledge, our study is the first to compare several salience maps across all these evaluation methods$-$with the finding that they do not agree in their assessment (i.e., there was no difference concerning trust and satisfaction, Grad-CAM improved users' abilities best, and Guided Backpropagation had the most favorable mathematical metrics). Additionally, we show that some mathematical metrics were associated with user understanding, although this relationship was often counterintuitive. We discuss these findings in light of general debates concerning the complementary use of user studies and mathematical metrics in the evaluation of explainable AI (XAI) approaches.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17023",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.485005Z"
  },
  {
    "id": "a9f3df8a662a571053104d12a3ecdf62",
    "title": "Psychological Effect of AI driven marketing tools for beauty/facial feature enhancement",
    "slug": "psychological-effect-of-ai-driven-marketing-tools-for-beauty/facial-feature-enhancement",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Ayushi Agrawal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "AI-powered facial assessment tools are reshaping how individuals evaluate appearance and internalize social judgments. This study examines the psychological impact of such tools on self-objectification, self-esteem, and emotional responses, with attention to gender differences. Two samples used distinct versions of a facial analysis tool: one overtly critical (N=75; M=22.9 years), and another more neutral (N=51; M=19.9 years). Participants completed validated self-objectification and self-esteem scales and custom items measuring emotion, digital/physical appearance enhancement (DAE, PAEE), and perceived social emotion (PSE). Results revealed consistent links between high self-objectification, low self-esteem, and increased appearance enhancement behaviors across both versions. Despite softer framing, the newer tool still evoked negative emotional responses (U=1466.5, p=0.013), indicating implicit feedback may reinforce appearance-related insecurities. Gender differences emerged in DAE (p=0.025) and PSE (p<0.001), with females more prone to digital enhancement and less likely to perceive emotional impact in others. These findings reveal how AI tools may unintentionally reinforce and amplify existing social biases and underscore the critical need for responsible AI design and development. Future research will investigate how human ideologies embedded in the training data of such tools shape their evaluative outputs, and how these, in turn, influence user attitudes and decisions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17055",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.485223Z"
  },
  {
    "id": "e4d01cdf33fabe11eef2df4fd10147af",
    "title": "DashGuide: Authoring Interactive Dashboard Tours for Guiding Dashboard Users",
    "slug": "dashguide:-authoring-interactive-dashboard-tours-for-guiding-dashboard-users",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Naimul Hoque",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dashboard guidance helps dashboard users better navigate interactive features, understand the underlying data, and assess insights they can potentially extract from dashboards. However, authoring dashboard guidance is a time consuming task, and embedding guidance into dashboards for effective delivery is difficult to realize. In this work, we contribute DashGuide, a framework and system to support the creation of interactive dashboard guidance with minimal authoring input. Given a dashboard and a communication goal, DashGuide captures a sequence of author-performed interactions to generate guidance materials delivered as playable step-by-step overlays, a.k.a., dashboard tours. Authors can further edit and refine individual tour steps while receiving generative assistance. We also contribute findings from a formative assessment with 9 dashboard creators, which helped inform the design of DashGuide; and findings from an evaluation of DashGuide with 12 dashboard creators, suggesting it provides an improved authoring experience that balances efficiency, expressiveness, and creative freedom.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17150",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.485412Z"
  },
  {
    "id": "fb0232e1c3d77bf1301817e1975e5b82",
    "title": "Improving Human-Autonomous Vehicle Interaction in Complex Systems",
    "slug": "improving-human-autonomous-vehicle-interaction-in-complex-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Robert Kaufman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Unresolved questions about how autonomous vehicles (AVs) should meet the informational needs of riders hinder real-world adoption. Complicating our ability to satisfy rider needs is that different people, goals, and driving contexts have different criteria for what constitutes interaction success. Unfortunately, most human-AV research and design today treats all people and situations uniformly. It is crucial to understand how an AV should communicate to meet rider needs, and how communications should change when the human-AV complex system changes. I argue that understanding the relationships between different aspects of the human-AV system can help us build improved and adaptable AV communications. I support this argument using three empirical studies. First, I identify optimal communication strategies that enhance driving performance, confidence, and trust for learning in extreme driving environments. Findings highlight the need for task-sensitive, modality-appropriate communications tuned to learner cognitive limits and goals. Next, I highlight the consequences of deploying faulty communication systems and demonstrate the need for context-sensitive communications. Third, I use machine learning (ML) to illuminate personal factors predicting trust in AVs, emphasizing the importance of tailoring designs to individual traits and concerns. Together, this dissertation supports the necessity of transparent, adaptable, and personalized AV systems that cater to individual needs, goals, and contextual demands. By considering the complex system within which human-AV interactions occur, we can deliver valuable insights for designers, researchers, and policymakers. This dissertation also provides a concrete domain to study theories of human-machine joint action and situational awareness, and can be used to guide future human-AI interaction research. [shortened for arxiv]",
    "pdfUrl": "https://arxiv.org/pdf/2504.17170",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.485611Z"
  },
  {
    "id": "eae6050008ff42409d19c3b140963ae2",
    "title": "Augmenting Captions with Emotional Cues: An AR Interface for Real-Time Accessible Communication",
    "slug": "augmenting-captions-with-emotional-cues:-an-ar-interface-for-real-time-accessible-communication",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Sunday David Ubur",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces an augmented reality (AR) captioning framework designed to support Deaf and Hard of Hearing (DHH) learners in STEM classrooms by integrating non-verbal emotional cues into live transcriptions. Unlike conventional captioning systems that offer only plain text, our system fuses real-time speech recognition with affective and visual signal interpretation, including facial movements, gestures, and vocal tone, to produce emotionally enriched captions. These enhanced captions are rendered in an AR interface developed with Unity and provide contextual annotations such as speaker tone markers (e.g., \"concerned\") and gesture indicators (e.g., \"nods\"). The system leverages live camera and microphone input, processed through AI models to detect multimodal cues. Findings from preliminary evaluations suggest that this AR-based captioning approach significantly enhances comprehension and reduces cognitive effort compared to standard captions. Our work emphasizes the potential of immersive environments for inclusive, emotion-aware educational accessibility.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17171",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.485796Z"
  },
  {
    "id": "7afb6be0eef05252dffd6fde14cda4db",
    "title": "Lessons from Deploying Learning-based CSI Localization on a Large-Scale ISAC Platform",
    "slug": "lessons-from-deploying-learning-based-csi-localization-on-a-large-scale-isac-platform",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Tianyu Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In recent years, Channel State Information (CSI), recognized for its fine-grained spatial characteristics, has attracted increasing attention in WiFi-based indoor localization. However, despite its potential, CSI-based approaches have yet to achieve the same level of deployment scale and commercialization as those based on Received Signal Strength Indicator (RSSI). A key limitation lies in the fact that most existing CSI-based systems are developed and evaluated in controlled, small-scale environments, limiting their generalizability. To bridge this gap, we explore the deployment of a large-scale CSI-based localization system involving over 400 Access Points (APs) in a real-world building under the Integrated Sensing and Communication (ISAC) paradigm. We highlight two critical yet often overlooked factors: the underutilization of unlabeled data and the inherent heterogeneity of CSI measurements. To address these challenges, we propose a novel CSI-based learning framework for WiFi localization, tailored for large-scale ISAC deployments on the server side. Specifically, we employ a novel graph-based structure to model heterogeneous CSI data and reduce redundancy. We further design a pretext pretraining task that incorporates spatial and temporal priors to effectively leverage large-scale unlabeled CSI data. Complementarily, we introduce a confidence-aware fine-tuning strategy to enhance the robustness of localization results. In a leave-one-smartphone-out experiment spanning five floors and 25, 600 m2, we achieve a median localization error of 2.17 meters and a floor accuracy of 99.49%. This performance corresponds to an 18.7% reduction in mean absolute error (MAE) compared to the best-performing baseline.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17173",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.486009Z"
  },
  {
    "id": "99a0a5aed5fefddfa009e27134845468",
    "title": "Factually: Exploring Wearable Fact-Checking for Augmented Truth Discernment",
    "slug": "factually:-exploring-wearable-fact-checking-for-augmented-truth-discernment",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Chitralekha Gupta",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Wearable devices are transforming human capabilities by seamlessly augmenting cognitive functions. In this position paper, we propose a voice-based, interactive learning companion designed to amplify and extend cognitive abilities through informal learning. Our vision is threefold: (1) to enable users to discover new knowledge on-the-go through contextual interactive quizzes, fostering critical thinking and mindfulness, (2) to proactively detect misinformation, empowering users to critically assess information in real time, and (3) to provide spoken language correction and prompting hints for second language learning and effective communication. As an initial step toward this vision, we present Factually - a proactive, wearable fact-checking system integrated into devices like smartwatches or rings. Factually discreetly alerts users to potential falsehoods via vibrotactile feedback, helping them assess information critically. We demonstrate its utility through three illustrative scenarios, highlighting its potential to extend cognitive abilities for real-time misinformation detection. Early qualitative feedback suggests that Factually can enhance users' fact-checking capabilities, offering both practical and experiential benefits.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17204",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.486235Z"
  },
  {
    "id": "8868fd8cd439e935c2fcb50a6a91d905",
    "title": "MV-Crafter: An Intelligent System for Music-guided Video Generation",
    "slug": "mv-crafter:-an-intelligent-system-for-music-guided-video-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Chuer Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Music videos, as a prevalent form of multimedia entertainment, deliver engaging audio-visual experiences to audiences and have gained immense popularity among singers and fans. Creators can express their interpretations of music naturally through visual elements. However, the creation process of music video demands proficiency in script design, video shooting, and music-video synchronization, posing significant challenges for non-professionals. Previous work has designed automated music video generation frameworks. However, they suffer from complexity in input and poor output quality. In response, we present MV-Crafter, a system capable of producing high-quality music videos with synchronized music-video rhythm and style. Our approach involves three technical modules that simulate the human creation process: the script generation module, video generation module, and music-video synchronization module. MV-Crafter leverages a large language model to generate scripts considering the musical semantics. To address the challenge of synchronizing short video clips with music of varying lengths, we propose a dynamic beat matching algorithm and visual envelope-induced warping method to ensure precise, monotonic music-video synchronization. Besides, we design a user-friendly interface to simplify the creation process with intuitive editing features. Extensive experiments have demonstrated that MV-Crafter provides an effective solution for improving the quality of generated music videos.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17267",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.486443Z"
  },
  {
    "id": "82da5feb8c99f5638f413d4e728b4b7a",
    "title": "Exploring Context-aware and LLM-driven Locomotion for Immersive Virtual Reality",
    "slug": "exploring-context-aware-and-llm-driven-locomotion-for-immersive-virtual-reality",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Sleyman zdel",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Locomotion plays a crucial role in shaping the user experience within virtual reality environments. In particular, hands-free locomotion offers a valuable alternative by supporting accessibility and freeing users from reliance on handheld controllers. To this end, traditional speech-based methods often depend on rigid command sets, limiting the naturalness and flexibility of interaction. In this study, we propose a novel locomotion technique powered by large language models (LLMs), which allows users to navigate virtual environments using natural language with contextual awareness. We evaluate three locomotion methods: controller-based teleportation, voice-based steering, and our language model-driven approach. Our evaluation measures include eye-tracking data analysis, including explainable machine learning through SHAP analysis as well as standardized questionnaires for usability, presence, cybersickness, and cognitive load to examine user attention and engagement. Our findings indicate that the LLM-driven locomotion possesses comparable usability, presence, and cybersickness scores to established methods like teleportation, demonstrating its novel potential as a comfortable, natural language-based, hands-free alternative. In addition, it enhances user attention within the virtual environment, suggesting greater engagement. Complementary to these findings, SHAP analysis revealed that fixation, saccade, and pupil-related features vary across techniques, indicating distinct patterns of visual attention and cognitive processing. Overall, we state that our method can facilitate hands-free locomotion in virtual spaces, especially in supporting accessibility.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17331",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.486647Z"
  },
  {
    "id": "2c15d327cee2aa57f6c0d01e5b953c35",
    "title": "DataScout: Automatic Data Fact Retrieval for Statement Augmentation with an LLM-Based Agent",
    "slug": "datascout:-automatic-data-fact-retrieval-for-statement-augmentation-with-an-llm-based-agent",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Chuer Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A data story typically integrates data facts from multiple perspectives and stances to construct a comprehensive and objective narrative. However, retrieving these facts demands time for data search and challenges the creator's analytical skills. In this work, we introduce DataScout, an interactive system that automatically performs reasoning and stance-based data facts retrieval to augment the user's statement. Particularly, DataScout leverages an LLM-based agent to construct a retrieval tree, enabling collaborative control of its expansion between users and the agent. The interface visualizes the retrieval tree as a mind map that eases users to intuitively steer the retrieval direction and effectively engage in reasoning and analysis. We evaluate the proposed system through case studies and in-depth expert interviews. Our evaluation demonstrates that DataScout can effectively retrieve multifaceted data facts from different stances, helping users verify their statements and enhance the credibility of their stories.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17334",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.486849Z"
  },
  {
    "id": "ec35044951c13221c47982f6f4d0c1e8",
    "title": "The Riemannian Means Field Classifier for EEG-Based BCI Data",
    "slug": "the-riemannian-means-field-classifier-for-eeg-based-bci-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Anton Andreev",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A substantial amount of research has demonstrated the robustness and accuracy of the Riemannian minimum distance to mean (MDM) classifier for all kinds of EEG-based brain--computer interfaces (BCIs). This classifier is simple, fully deterministic, robust to noise, computationally efficient, and prone to transfer learning. Its training is very simple, requiring just the computation of a geometric mean of a symmetric positive-definite (SPD) matrix per class. We propose an improvement of the MDM involving a number of power means of SPD matrices instead of the sole geometric mean. By the analysis of 20 public databases, 10 for the motor-imagery BCI paradigm and 10 for the P300 BCI paradigm, comprising 587 individuals in total, we show that the proposed classifier clearly outperforms the MDM, approaching the state-of-the art in terms of performance while retaining the simplicity and the deterministic behavior. In order to promote reproducible research, our code will be released as open source.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17352",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.487045Z"
  },
  {
    "id": "f59a73ac5f7a1c1cf8533819a23c1814",
    "title": "The Malicious Technical Ecosystem: Exposing Limitations in Technical Governance of AI-Generated Non-Consensual Intimate Images of Adults",
    "slug": "the-malicious-technical-ecosystem:-exposing-limitations-in-technical-governance-of-ai-generated-non-consensual-intimate-images-of-adults",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Michelle L. Ding",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we adopt a survivor-centered approach to locate and dissect the role of sociotechnical AI governance in preventing AI-Generated Non-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as \"deep fake pornography.\" We identify a \"malicious technical ecosystem\" or \"MTE,\" comprising of open-source face-swapping models and nearly 200 \"nudifying\" software programs that allow non-technical users to create AIG-NCII within minutes. Then, using the National Institute of Standards and Technology (NIST) AI 100-4 report as a reflection of current synthetic content governance methods, we show how the current landscape of practices fails to effectively regulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining these gaps.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17663",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.487243Z"
  },
  {
    "id": "70f37e125d011dfc1631df211b2d8b3c",
    "title": "INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models",
    "slug": "insight:-bridging-the-student-teacher-gap-in-times-of-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Jarne Thys",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rise of AI, especially Large Language Models, presents challenges and opportunities to integrate such technology into the classroom. AI has the potential to revolutionize education by helping teaching staff with various tasks, such as personalizing their teaching methods, but it also raises concerns, for example, about the degradation of student-teacher interactions and user privacy. This paper introduces INSIGHT, a proof of concept to combine various AI tools to assist teaching staff and students in the process of solving exercises. INSIGHT has a modular design that allows it to be integrated into various higher education courses. We analyze students' questions to an LLM by extracting keywords, which we use to dynamically build an FAQ from students' questions and provide new insights for the teaching staff to use for more personalized face-to-face support. Future work could build upon INSIGHT by using the collected data to provide adaptive learning and adjust content based on student progress and learning styles to offer a more interactive and inclusive learning experience.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17677",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.487443Z"
  },
  {
    "id": "b32b61cd864e3d166fb4a3d8eec3b38a",
    "title": "'The Boring and the Tedious': Invisible Labour in India's Gig-Economy",
    "slug": "'the-boring-and-the-tedious':-invisible-labour-in-india's-gig-economy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Pratyay Suvarnapathaki",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "India's gig-based food delivery platforms, such as Swiggy and Zomato, provide crucial income to marginalised communities but also entrench workers in cycles of invisible labour. Through 14 semi-structured interviews, we analyse waiting time and repetitive UI itneractions as key burdens that contribute to 'digital discomfort' for gig based food delivery agents. We find that workers employ creative strategies to navigate algorithmic management, yet remain constrained by platform-side 'gamification' and system opacity. We propose worker-centered GUI automation as a potential intervention to reduce friction while preserving agency. In conclusion, this position paper argues for rethinking HCI approaches in the Global South to prioritise worker autonomy over efficiency-driven design optimisations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17697",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.487643Z"
  },
  {
    "id": "78e49d226e9b07e0e607eff9344d66fe",
    "title": "LUIDA: Large-scale Unified Infrastructure for Digital Assessments based on Commercial Metaverse Platform",
    "slug": "luida:-large-scale-unified-infrastructure-for-digital-assessments-based-on-commercial-metaverse-platform",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Yong-Hao Hu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Online experiments using metaverse platforms have gained significant traction in Human-Computer Interaction and Virtual Reality (VR) research. However, current research workflows are highly fragmented, as researchers must use separate tools for system implementation, participant recruitment, experiment execution, and data collection, reducing consistency and increasing workload. We present LUIDA (Large-scale Unified Infrastructure for Digital Assessments), a metaverse-based framework that integrates these fragmented processes. LUIDA automatically allocates interconnected virtual environments for parallel experiment execution and provides implementation templates adaptable to various VR research domains, requiring minimal metaverse development expertise. Our evaluation included two studies using a prototype built on Cluster, the commercial metaverse platform. First, VR researchers using LUIDA to develop and run experiments reported high usability scores (SUS: 73.75) and moderate workload (NASA-TLX: 24.11) for overall usage, with interviews confirming streamlined workflows compared to traditional laboratory experiments. Second, we conducted three replicated experiments with public Cluster users, each recruiting approximately 200 participants within one week. These experiments produced results that closely matched the original studies, validating the experimental integrity of LUIDA across research domains. After technical refinements, we plan to release LUIDA as an open platform, providing a standardized protocol to improve research efficiency and experimental reproducibility in VR studies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17705",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.487847Z"
  },
  {
    "id": "ba9807226073304704ee0d66835f4e71",
    "title": "Cybernetic Governance in a Coliving House",
    "slug": "cybernetic-governance-in-a-coliving-house",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Daniel Kronovet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We report an 18-month field experiment in distributed digital institutions: a nine-bedroom Los Angeles coliving house that runs without managers, while sustaining 98% occupancy and below-market rents.\nDrawing on Elinor Ostrom's commons theory, we outline design principles and three digital mechanisms that form the institutional core: 1) A continuous-auction chore scheduler turns regenerative labor into a time-indexed points market; residents meet a 100-point monthly obligation by claiming tasks whose value rises linearly with neglect. 2) A pairwise-preference layer lets participants asynchronously reprioritize tasks, translating meta-governance into low-cognition spot inputs. 3) A symbolic \"hearts\" ledger tracks norm compliance through automated enforcement, lightweight challenges, and peer-awarded karma. Together, these mechanisms operationalize cybernetic principles--human sensing, machine bookkeeping, real-time feedback--while minimizing dependence on privileged roles.\nOur exploratory data (567 chore claims, 255 heart events, and 551 group purchases) show that such tooling can sustain reliable commons governance without continuous leadership, offering a transferable design palette for online communities, coliving houses, and other digitally mediated collectives.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17113",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:22.488060Z"
  },
  {
    "id": "2ab7b769012e85eadb0baca57870a4b4",
    "title": "AI for Accessible Education: Personalized Audio-Based Learning for Blind Students",
    "slug": "ai-for-accessible-education:-personalized-audio-based-learning-for-blind-students",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Crystal Yang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Blind and visually impaired (BVI) students face significant challenges in traditional educational settings. While screen readers and braille materials offer some accessibility, they often lack interactivity and real-time adaptability to individual learning needs. This paper presents Audemy, an AI-powered audio-based learning platform designed to provide personalized, accessible, and engaging educational experiences for BVI students. Audemy uses adaptive learning techniques to customize content based on student accuracy, pacing preferences, and engagement patterns. The platform has been iteratively developed with input from over 20 educators specializing in accessibility and currently serves over 2,000 BVI students. Educator insights show key considerations for accessible AI, including the importance of engagement, intuitive design, compatibility with existing assistive technologies, and the role of positive reinforcement in maintaining student motivation. Beyond accessibility, this paper explores the ethical implications of AI in education, emphasizing data privacy, security, and transparency. Audemy demonstrates how AI can empower BVI students with personalized and equitable learning opportunities, advancing the broader goal of inclusive education.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17117",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:22.488261Z"
  },
  {
    "id": "2efd20b5ae31c39f557e6a1b042e9d55",
    "title": "Crisp: Cognitive Restructuring of Negative Thoughts through Multi-turn Supportive Dialogues",
    "slug": "crisp:-cognitive-restructuring-of-negative-thoughts-through-multi-turn-supportive-dialogues",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jinfeng Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Cognitive Restructuring (CR) is a psychotherapeutic process aimed at identifying and restructuring an individual's negative thoughts, arising from mental health challenges, into more helpful and positive ones via multi-turn dialogues. Clinician shortage and stigma urge the development of human-LLM interactive psychotherapy for CR. Yet, existing efforts implement CR via simple text rewriting, fixed-pattern dialogues, or a one-shot CR workflow, failing to align with the psychotherapeutic process for effective CR. To address this gap, we propose CRDial, a novel framework for CR, which creates multi-turn dialogues with specifically designed identification and restructuring stages of negative thoughts, integrates sentence-level supportive conversation strategies, and adopts a multi-channel loop mechanism to enable iterative CR. With CRDial, we distill Crisp, a large-scale and high-quality bilingual dialogue dataset, from LLM. We then train Crispers, Crisp-based conversational LLMs for CR, at 7B and 14B scales. Extensive human studies show the superiority of Crispers in pointwise, pairwise, and intervention evaluations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17238",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:22.488489Z"
  },
  {
    "id": "149def33290ceda331ad6be297a8ddcd",
    "title": "Towards User-Centred Design of AI-Assisted Decision-Making in Law Enforcement",
    "slug": "towards-user-centred-design-of-ai-assisted-decision-making-in-law-enforcement",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Vesna Nowack",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Artificial Intelligence (AI) has become an important part of our everyday lives, yet user requirements for designing AI-assisted systems in law enforcement remain unclear. To address this gap, we conducted qualitative research on decision-making within a law enforcement agency. Our study aimed to identify limitations of existing practices, explore user requirements and understand the responsibilities that humans expect to undertake in these systems.\nParticipants in our study highlighted the need for a system capable of processing and analysing large volumes of data efficiently to help in crime detection and prevention. Additionally, the system should satisfy requirements for scalability, accuracy, justification, trustworthiness and adaptability to be adopted in this domain. Participants also emphasised the importance of having end users review the input data that might be challenging for AI to interpret, and validate the generated output to ensure the system's accuracy. To keep up with the evolving nature of the law enforcement domain, end users need to help the system adapt to the changes in criminal behaviour and government guidance, and technical experts need to regularly oversee and monitor the system. Furthermore, user-friendly human interaction with the system is essential for its adoption and some of the participants confirmed they would be happy to be in the loop and provide necessary feedback that the system can learn from. Finally, we argue that it is very unlikely that the system will ever achieve full automation due to the dynamic and complex nature of the law enforcement domain.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17393",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:22.488715Z"
  },
  {
    "id": "96eab251cc8e6c345d091e273a18c575",
    "title": "WiReSens Toolkit: An Open-source Platform towards Accessible Wireless Tactile Sensing",
    "slug": "wiresens-toolkit:-an-open-source-platform-towards-accessible-wireless-tactile-sensing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Devin Murphy",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Past research has widely explored the design and fabrication of resistive matrix-based tactile sensors as a means of creating touch-sensitive devices. However, developing portable, adaptive, and long-lasting tactile sensing systems that incorporate these sensors remains challenging for individuals having limited prior experience with them. To address this, we developed the WiReSens Toolkit, an open-source platform for accessible wireless tactile sensing. Central to our approach is adaptive hardware for interfacing with resistive sensors and a web-based GUI that mediates access to complex functionalities for developing scalable tactile sensing systems, including 1) multi-device programming and wireless visualization across three distinct communication protocols 2) autocalibration methods for adaptive sensitivity and 3) intermittent data transmission for low-power operation. We validated the toolkit's usability through a user study with 11 novice participants, who, on average, successfully configured a tactile sensor with over 95\\% accuracy in under five minutes, calibrated sensors 10x faster than baseline methods, and demonstrated enhanced tactile data sense-making.",
    "pdfUrl": "https://arxiv.org/pdf/2412.00247",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.488920Z"
  },
  {
    "id": "66afd424d86d1bd70e6a486dfd000208",
    "title": "Should Benevolent Deception be Allowed in EHMI? A Mechanism Explanation Based on Game Theory",
    "slug": "should-benevolent-deception-be-allowed-in-ehmi?-a-mechanism-explanation-based-on-game-theory",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Linkun Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The application of external human-machine interface (EHMI) on autonomous vehicles (AVs) facilitates information exchange. Existing research fails to consider the impact of the sequence of actions, as well as the effects of EHMI applications and deception, raising the question of whether benevolent, well-intentioned deception should be permitted (i.e., misleading statements that are intended to benefit both parties). We established a game theory based EHMI information disclosure framework for AVs in this study. In considering benevolent deception, this framework divided the decision-making process into three stages, respectively encompassing three key questions: whether to disclose, when to disclose, and what type of intention information to disclose. The results show that theoretical advantages of deception exist in certain cases when AV expects to maximize the safety of the interaction. In 40 out of 484 cases (8.3%), safety can be enhanced through successful deception. Those successful deceptions fall into two categories: 1) In 28 of these cases, the straight-going AV expected the left-turning HV to yield, while HV exhibited lower speed and higher acceleration; 2) In 12 of these cases, AV expected HV to proceed first, while HV exhibited higher speed and lower acceleration. We also conducted a VR-based driving simulation experiment, and the results confirmed our conclusion. Additionally, we found that when participants had low trust in the EHMI, its use negatively impacted interaction efficiency instead. This study aims to analyze the mechanisms of EHMI information disclosure and contribute to the ongoing discourse on the ethical framework governing autonomous driving systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14539",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.489111Z"
  },
  {
    "id": "9514a23c78984fcc30221358154507c1",
    "title": "Subthreshold Jitter in VR Can Induce Visual Discomfort",
    "slug": "subthreshold-jitter-in-vr-can-induce-visual-discomfort",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Samuel J. Levulis",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Visual-vestibular conflicts (VVCs) are a primary contributor to visually induced motion sickness (VIMS) in head-mounted displays (HMDs). However, virtual reality (VR) comfort studies often rely on exposing seated or standing users to experiences with high intensity visual motion (such as roller coasters). These drastic VVCs tend to induce pronounced VIMS symptoms that can be reliably detected across individuals using common survey measures. The conclusions from studies using these extreme motion-based conflicts may not accurately generalize to naturalistic use cases in VR where efforts are made to minimize, rather than maximize, VIMS symptoms. In this work, we show that a subthreshold visual-vestibular conflict can induce measurable discomfort during naturalistic, long duration use. We first present a psychophysical study, conducted outside of an HMD, to rigorously identify the perceptual thresholds for sinusoidal noise in render pose (i.e., jitter) resulting in erroneous 3D motion of rendered content. We next introduce subthreshold levels of jitter to a Meta Quest 3 VR HMD and demonstrate that this can induce visual discomfort in participants playing the commercially-available game Cubism across a three-session, repeated-measures study. Importantly, we did not identify statistically significant comfort differences between control and jitter conditions with traditional pre- and post-test comparison of Simulator Sickness Questionnaire (SSQ) scores. Significant differences were only identified using the Motion Illness Symptoms Classification (MISC) survey administered every 10 minutes across each 90 minute session. This highlights the benefits of incorporating time-resolved data points and suggests that lightweight, more frequent surveys may be important tools for measuring visual discomfort in more ecologically-valid scenarios.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16295",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.489321Z"
  },
  {
    "id": "7617028c3cd59488139d3f7c1b67a529",
    "title": "Shifts in Doctors' Eye Movements Between Real and AI-Generated Medical Images",
    "slug": "shifts-in-doctors'-eye-movements-between-real-and-ai-generated-medical-images",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "David C Wong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Eye-tracking analysis plays a vital role in medical imaging, providing key insights into how radiologists visually interpret and diagnose clinical cases. In this work, we first analyze radiologists' attention and agreement by measuring the distribution of various eye-movement patterns, including saccades direction, amplitude, and their joint distribution. These metrics help uncover patterns in attention allocation and diagnostic strategies. Furthermore, we investigate whether and how doctors' gaze behavior shifts when viewing authentic (Real) versus deep-learning-generated (Fake) images. To achieve this, we examine fixation bias maps, focusing on first, last, short, and longest fixations independently, along with detailed saccades patterns, to quantify differences in gaze distribution and visual saliency between authentic and synthetic images.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15007",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:22.489822Z"
  },
  {
    "id": "0cf97f934ae545715975e33014a241bd",
    "title": "Dynamic Superblock Pruning for Fast Learned Sparse Retrieval",
    "slug": "dynamic-superblock-pruning-for-fast-learned-sparse-retrieval",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Parker Carlson",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper proposes superblock pruning (SP) during top-k online document retrieval for learned sparse representations. SP structures the sparse index as a set of superblocks on a sequence of document blocks and conducts a superblock-level selection to decide if some superblocks can be pruned before visiting their child blocks. SP generalizes the previous flat block or cluster-based pruning, allowing the early detection of groups of documents that cannot or are less likely to appear in the final top-k list. SP can accelerate sparse retrieval in a rank-safe or approximate manner under a high-relevance competitiveness constraint. Our experiments show that the proposed scheme significantly outperforms state-of-the-art baselines on MS MARCO passages on a single-threaded CPU.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17045",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:22.777368Z"
  },
  {
    "id": "4f301b6db085a7789acef2d05b7cd863",
    "title": "You Are What You Bought: Generating Customer Personas for E-commerce Applications",
    "slug": "you-are-what-you-bought:-generating-customer-personas-for-e-commerce-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Yimin Shi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In e-commerce, user representations are essential for various applications. Existing methods often use deep learning techniques to convert customer behaviors into implicit embeddings. However, these embeddings are difficult to understand and integrate with external knowledge, limiting the effectiveness of applications such as customer segmentation, search navigation, and product recommendations. To address this, our paper introduces the concept of the customer persona. Condensed from a customer's numerous purchasing histories, a customer persona provides a multi-faceted and human-readable characterization of specific purchase behaviors and preferences, such as Busy Parents or Bargain Hunters.\nThis work then focuses on representing each customer by multiple personas from a predefined set, achieving readable and informative explicit user representations. To this end, we propose an effective and efficient solution GPLR. To ensure effectiveness, GPLR leverages pre-trained LLMs to infer personas for customers. To reduce overhead, GPLR applies LLM-based labeling to only a fraction of users and utilizes a random walk technique to predict personas for the remaining customers. We further propose RevAff, which provides an absolute error $\\epsilon$ guarantee while improving the time complexity of the exact solution by a factor of at least $O(\\frac{\\epsilon\\cdot|E|N}{|E|+N\\log N})$, where $N$ represents the number of customers and products, and $E$ represents the interactions between them. We evaluate the performance of our persona-based representation in terms of accuracy and robustness for recommendation and customer segmentation tasks using three real-world e-commerce datasets. Most notably, we find that integrating customer persona representations improves the state-of-the-art graph convolution-based recommendation model by up to 12% in terms of NDCG@K and F1-Score@K.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17304",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:22.777609Z"
  },
  {
    "id": "7d48352e3817323599f4774d24a9ec07",
    "title": "Beyond Whole Dialogue Modeling: Contextual Disentanglement for Conversational Recommendation",
    "slug": "beyond-whole-dialogue-modeling:-contextual-disentanglement-for-conversational-recommendation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Guojia An",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Conversational recommender systems aim to provide personalized recommendations by analyzing and utilizing contextual information related to dialogue. However, existing methods typically model the dialogue context as a whole, neglecting the inherent complexity and entanglement within the dialogue. Specifically, a dialogue comprises both focus information and background information, which mutually influence each other. Current methods tend to model these two types of information mixedly, leading to misinterpretation of users' actual needs, thereby lowering the accuracy of recommendations. To address this issue, this paper proposes a novel model to introduce contextual disentanglement for improving conversational recommender systems, named DisenCRS. The proposed model DisenCRS employs a dual disentanglement framework, including self-supervised contrastive disentanglement and counterfactual inference disentanglement, to effectively distinguish focus information and background information from the dialogue context under unsupervised conditions. Moreover, we design an adaptive prompt learning module to automatically select the most suitable prompt based on the specific dialogue context, fully leveraging the power of large language models. Experimental results on two widely used public datasets demonstrate that DisenCRS significantly outperforms existing conversational recommendation models, achieving superior performance on both item recommendation and response generation tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17427",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:22.777832Z"
  },
  {
    "id": "3af81b54bc86f50b15a617acfa81c1ce",
    "title": "Adaptive Orchestration of Modular Generative Information Access Systems",
    "slug": "adaptive-orchestration-of-modular-generative-information-access-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Mohanna Hoveyda",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Advancements in large language models (LLMs) have driven the emergence of complex new systems to provide access to information, that we will collectively refer to as modular generative information access (GenIA) systems. They integrate a broad and evolving range of specialized components, including LLMs, retrieval models, and a heterogeneous set of sources and tools. While modularity offers flexibility, it also raises critical challenges: How can we systematically characterize the space of possible modules and their interactions? How can we automate and optimize interactions among these heterogeneous components? And, how do we enable this modular system to dynamically adapt to varying user query requirements and evolving module capabilities? In this perspective paper, we argue that the architecture of future modular generative information access systems will not just assemble powerful components, but enable a self-organizing system through real-time adaptive orchestration -- where components' interactions are dynamically configured for each user input, maximizing information relevance while minimizing computational overhead. We give provisional answers to the questions raised above with a roadmap that depicts the key principles and methods for designing such an adaptive modular system. We identify pressing challenges, and propose avenues for addressing them in the years ahead. This perspective urges the IR community to rethink modular system designs for developing adaptive, self-optimizing, and future-ready architectures that evolve alongside their rapidly advancing underlying technologies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17454",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:22.778046Z"
  },
  {
    "id": "1f031aa4d34fdab8655e788b4fd2c568",
    "title": "Replication and Exploration of Generative Retrieval over Dynamic Corpora",
    "slug": "replication-and-exploration-of-generative-retrieval-over-dynamic-corpora",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Zhen Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Generative retrieval (GR) has emerged as a promising paradigm in information retrieval (IR). However, most existing GR models are developed and evaluated using a static document collection, and their performance in dynamic corpora where document collections evolve continuously is rarely studied. In this paper, we first reproduce and systematically evaluate various representative GR approaches over dynamic corpora. Through extensive experiments, we reveal that existing GR models with \\textit{text-based} docids show superior generalization to unseen documents. We observe that the more fine-grained the docid design in the GR model, the better its performance over dynamic corpora, surpassing BM25 and even being comparable to dense retrieval methods. While GR models with \\textit{numeric-based} docids show high efficiency, their performance drops significantly over dynamic corpora. Furthermore, our experiments find that the underperformance of numeric-based docids is partly due to their excessive tendency toward the initial document set, which likely results from overfitting on the training set. We then conduct an in-depth analysis of the best-performing GR methods. We identify three critical advantages of text-based docids in dynamic corpora: (i) Semantic alignment with language models' pretrained knowledge, (ii) Fine-grained docid design, and (iii) High lexical diversity. Building on these insights, we finally propose a novel multi-docid design that leverages both the efficiency of numeric-based docids and the effectiveness of text-based docids, achieving improved performance in dynamic corpus without requiring additional retraining. Our work offers empirical evidence for advancing GR methods over dynamic corpora and paves the way for developing more generalized yet efficient GR models in real-world search engines.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17519",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:22.778272Z"
  },
  {
    "id": "5c698c6ade3ab5aba115f02ed3560804",
    "title": "IRA: Adaptive Interest-aware Representation and Alignment for Personalized Multi-interest Retrieval",
    "slug": "ira:-adaptive-interest-aware-representation-and-alignment-for-personalized-multi-interest-retrieval",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Youngjune Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Online community platforms require dynamic personalized retrieval and recommendation that can continuously adapt to evolving user interests and new documents. However, optimizing models to handle such changes in real-time remains a major challenge in large-scale industrial settings. To address this, we propose the Interest-aware Representation and Alignment (IRA) framework, an efficient and scalable approach that dynamically adapts to new interactions through a cumulative structure. IRA leverages two key mechanisms: (1) Interest Units that capture diverse user interests as contextual texts, while reinforcing or fading over time through cumulative updates, and (2) a retrieval process that measures the relevance between Interest Units and documents based solely on semantic relationships, eliminating dependence on click signals to mitigate temporal biases. By integrating cumulative Interest Unit updates with the retrieval process, IRA continuously adapts to evolving user preferences, ensuring robust and fine-grained personalization without being constrained by past training distributions. We validate the effectiveness of IRA through extensive experiments on real-world datasets, including its deployment in the Home Section of NAVER's CAFE, South Korea's leading community platform.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17529",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:22.778489Z"
  },
  {
    "id": "25dcc34317640429a53ae3c7a6251a28",
    "title": "Quadratic Interest Network for Multimodal Click-Through Rate Prediction",
    "slug": "quadratic-interest-network-for-multimodal-click-through-rate-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Honghao Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Multimodal click-through rate (CTR) prediction is a key technique in industrial recommender systems. It leverages heterogeneous modalities such as text, images, and behavioral logs to capture high-order feature interactions between users and items, thereby enhancing the system's understanding of user interests and its ability to predict click behavior. The primary challenge in this field lies in effectively utilizing the rich semantic information from multiple modalities while satisfying the low-latency requirements of online inference in real-world applications. To foster progress in this area, the Multimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshop formulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding: this task aims to explore multimodal information extraction and item representation learning methods that enhance recommendation tasks; and (2) Task 2 of Multimodal CTR Prediction: this task aims to explore what multimodal recommendation model can effectively leverage multimodal embedding features and achieve better performance. In this paper, we propose a novel model for Task 2, named Quadratic Interest Network (QIN) for Multimodal CTR Prediction. Specifically, QIN employs adaptive sparse target attention to extract multimodal user behavior features, and leverages Quadratic Neural Networks to capture high-order feature interactions. As a result, QIN achieved an AUC of 0.9798 on the leaderboard and ranked second in the competition. The model code, training logs, hyperparameter configurations, and checkpoints are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17699",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:22.778699Z"
  },
  {
    "id": "2ab6de565c395cb683f697990ebb391b",
    "title": "Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?",
    "slug": "does-knowledge-distillation-matter-for-large-language-model-based-bundle-generation?",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Kaidong Feng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LLMs are increasingly explored for bundle generation, thanks to their reasoning capabilities and knowledge. However, deploying large-scale LLMs introduces significant efficiency challenges, primarily high computational costs during fine-tuning and inference due to their massive parameterization. Knowledge distillation (KD) offers a promising solution, transferring expertise from large teacher models to compact student models. This study systematically investigates knowledge distillation approaches for bundle generation, aiming to minimize computational demands while preserving performance. We explore three critical research questions: (1) how does the format of KD impact bundle generation performance? (2) to what extent does the quantity of distilled knowledge influence performance? and (3) how do different ways of utilizing the distilled knowledge affect performance? We propose a comprehensive KD framework that (i) progressively extracts knowledge (patterns, rules, deep thoughts); (ii) captures varying quantities of distilled knowledge through different strategies; and (iii) exploits complementary LLM adaptation techniques (in-context learning, supervised fine-tuning, combination) to leverage distilled knowledge in small student models for domain-specific adaptation and enhanced efficiency. Extensive experiments provide valuable insights into how knowledge format, quantity, and utilization methodologies collectively shape LLM-based bundle generation performance, exhibiting KD's significant potential for more efficient yet effective LLM-based bundle generation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17220",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:22.778901Z"
  },
  {
    "id": "2c15d327cee2aa57f6c0d01e5b953c35",
    "title": "DataScout: Automatic Data Fact Retrieval for Statement Augmentation with an LLM-Based Agent",
    "slug": "datascout:-automatic-data-fact-retrieval-for-statement-augmentation-with-an-llm-based-agent",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Chuer Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A data story typically integrates data facts from multiple perspectives and stances to construct a comprehensive and objective narrative. However, retrieving these facts demands time for data search and challenges the creator's analytical skills. In this work, we introduce DataScout, an interactive system that automatically performs reasoning and stance-based data facts retrieval to augment the user's statement. Particularly, DataScout leverages an LLM-based agent to construct a retrieval tree, enabling collaborative control of its expansion between users and the agent. The interface visualizes the retrieval tree as a mind map that eases users to intuitively steer the retrieval direction and effectively engage in reasoning and analysis. We evaluate the proposed system through case studies and in-depth expert interviews. Our evaluation demonstrates that DataScout can effectively retrieve multifaceted data facts from different stances, helping users verify their statements and enhance the credibility of their stories.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17334",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:22.779140Z"
  },
  {
    "id": "07861829a6c8df77eff0316c75735fbc",
    "title": "DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition",
    "slug": "drc:-enhancing-personalized-image-generation-via-disentangled-representation-composition",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yiyan Xu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Personalized image generation has emerged as a promising direction in multimodal content creation. It aims to synthesize images tailored to individual style preferences (e.g., color schemes, character appearances, layout) and semantic intentions (e.g., emotion, action, scene contexts) by leveraging user-interacted history images and multimodal instructions. Despite notable progress, existing methods -- whether based on diffusion models, large language models, or Large Multimodal Models (LMMs) -- struggle to accurately capture and fuse user style preferences and semantic intentions. In particular, the state-of-the-art LMM-based method suffers from the entanglement of visual features, leading to Guidance Collapse, where the generated images fail to preserve user-preferred styles or reflect the specified semantics.\nTo address these limitations, we introduce DRC, a novel personalized image generation framework that enhances LMMs through Disentangled Representation Composition. DRC explicitly extracts user style preferences and semantic intentions from history images and the reference image, respectively, to form user-specific latent instructions that guide image generation within LMMs. Specifically, it involves two critical learning stages: 1) Disentanglement learning, which employs a dual-tower disentangler to explicitly separate style and semantic features, optimized via a reconstruction-driven paradigm with difficulty-aware importance sampling; and 2) Personalized modeling, which applies semantic-preserving augmentations to effectively adapt the disentangled representations for robust personalized generation. Extensive experiments on two benchmarks demonstrate that DRC shows competitive performance while effectively mitigating the guidance collapse issue, underscoring the importance of disentangled representation learning for controllable and effective personalized image generation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17349",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:22.779363Z"
  },
  {
    "id": "8e60d7b4c054c53ea70891d463198dde",
    "title": "A Comprehensive Survey of Knowledge-Based Vision Question Answering Systems: The Lifecycle of Knowledge in Visual Reasoning Task",
    "slug": "a-comprehensive-survey-of-knowledge-based-vision-question-answering-systems:-the-lifecycle-of-knowledge-in-visual-reasoning-task",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Jiaqi Deng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Knowledge-based Vision Question Answering (KB-VQA) extends general Vision Question Answering (VQA) by not only requiring the understanding of visual and textual inputs but also extensive range of knowledge, enabling significant advancements across various real-world applications. KB-VQA introduces unique challenges, including the alignment of heterogeneous information from diverse modalities and sources, the retrieval of relevant knowledge from noisy or large-scale repositories, and the execution of complex reasoning to infer answers from the combined context. With the advancement of Large Language Models (LLMs), KB-VQA systems have also undergone a notable transformation, where LLMs serve as powerful knowledge repositories, retrieval-augmented generators and strong reasoners. Despite substantial progress, no comprehensive survey currently exists that systematically organizes and reviews the existing KB-VQA methods. This survey aims to fill this gap by establishing a structured taxonomy of KB-VQA approaches, and categorizing the systems into main stages: knowledge representation, knowledge retrieval, and knowledge reasoning. By exploring various knowledge integration techniques and identifying persistent challenges, this work also outlines promising future research directions, providing a foundation for advancing KB-VQA models and their applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17547",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:22.779566Z"
  },
  {
    "id": "74caa3b4855b4751132e9f0fcc8c7662",
    "title": "Synergizing RAG and Reasoning: A Systematic Review",
    "slug": "synergizing-rag-and-reasoning:-a-systematic-review",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Yunfan Gao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent breakthroughs in large language models (LLMs), particularly in reasoning capabilities, have propelled Retrieval-Augmented Generation (RAG) to unprecedented levels. By synergizing retrieval mechanisms with advanced reasoning, LLMs can now tackle increasingly complex problems. This paper presents a systematic review of the collaborative interplay between RAG and reasoning, clearly defining \"reasoning\" within the RAG context. It construct a comprehensive taxonomy encompassing multi-dimensional collaborative objectives, representative paradigms, and technical implementations, and analyze the bidirectional synergy methods. Additionally, we critically evaluate current limitations in RAG assessment, including the absence of intermediate supervision for multi-step reasoning and practical challenges related to cost-risk trade-offs. To bridge theory and practice, we provide practical guidelines tailored to diverse real-world applications. Finally, we identify promising research directions, such as graph-based knowledge integration, hybrid model collaboration, and RL-driven optimization. Overall, this work presents a theoretical framework and practical foundation to advance RAG systems in academia and industry, fostering the next generation of RAG solutions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15909",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:22.779779Z"
  },
  {
    "id": "e71d71f02fcfb5980be89c74cfde3af6",
    "title": "Lab-AI: Using Retrieval Augmentation to Enhance Language Models for Personalized Lab Test Interpretation in Clinical Medicine",
    "slug": "lab-ai:-using-retrieval-augmentation-to-enhance-language-models-for-personalized-lab-test-interpretation-in-clinical-medicine",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Xiaoyu Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate interpretation of lab results is crucial in clinical medicine, yet most patient portals use universal normal ranges, ignoring conditional factors like age and gender. This study introduces Lab-AI, an interactive system that offers personalized normal ranges using retrieval-augmented generation (RAG) from credible health sources. Lab-AI has two modules: factor retrieval and normal range retrieval. We tested these on 122 lab tests: 40 with conditional factors and 82 without. For tests with factors, normal ranges depend on patient-specific information. Our results show GPT-4-turbo with RAG achieved a 0.948 F1 score for factor retrieval and 0.995 accuracy for normal range retrieval. GPT-4-turbo with RAG outperformed the best non-RAG system by 33.5% in factor retrieval and showed 132% and 100% improvements in question-level and lab-level performance, respectively, for normal range retrieval. These findings highlight Lab-AI's potential to enhance patient understanding of lab results.",
    "pdfUrl": "https://arxiv.org/pdf/2409.18986",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:22.779988Z"
  },
  {
    "id": "a68b5f0a73064ddc97030bac1ebec31c",
    "title": "jina-clip-v2: Multilingual Multimodal Embeddings for Text and Images",
    "slug": "jina-clip-v2:-multilingual-multimodal-embeddings-for-text-and-images",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Andreas Koukounas",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Contrastive Language-Image Pretraining (CLIP) has been widely used for crossmodal information retrieval and multimodal understanding tasks. However, CLIP models are mainly optimized for crossmodal vision-language tasks and underperform in single-mode text tasks. Moreover, these models are often trained on English datasets and therefore lack multilingual understanding. Additionally, from a visual understanding perspective, previous CLIP-based models exhibit insufficient understanding of visually rich documents. In this work, we propose jina-clip-v2, a contrastive vision-language model trained on text pairs, triplets and image-text pairs via a multi-task and multi-stage contrastive learning paradigm in order to support both text-only and crossmodal tasks. We employ a multilingual text encoder and expand the training dataset to include multilingual texts from 29 non-English languages, including Hindi, Chinese, German, French, and others, as well as images of visually rich documents. We evaluate the model's performance and show that jina-clip-v2 achieves notable improvements over state-of-the-art CLIP-based models in zero-shot text-only retrieval, semantic textual similarity, and crossmodal retrieval tasks in both English and multilingual settings. jina-clip-v2 also provides for flexibility in embedding dimensionality, enabling users to select the granularity of the representations. jina-clip-v2 is publicly available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2412.08802",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:22.780212Z"
  },
  {
    "id": "ad06b2a15be8b70a3836715610a919db",
    "title": "PSCon: Product Search Through Conversations",
    "slug": "pscon:-product-search-through-conversations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jie Zou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Conversational Product Search ( CPS ) systems interact with users via natural language to offer personalized and context-aware product lists. However, most existing research on CPS is limited to simulated conversations, due to the lack of a real CPS dataset driven by human-like language. Moreover, existing conversational datasets for e-commerce are constructed for a particular market or a particular language and thus can not support cross-market and multi-lingual usage. In this paper, we propose a CPS data collection protocol and create a new CPS dataset, called PSCon, which assists product search through conversations with human-like language. The dataset is collected by a coached human-human data collection protocol and is available for dual markets and two languages. By formulating the task of CPS, the dataset allows for comprehensive and in-depth research on six subtasks: user intent detection, keyword extraction, system action prediction, question selection, item ranking, and response generation. Moreover, we present a concise analysis of the dataset and propose a benchmark model on the proposed CPS dataset. Our proposed dataset and model will be helpful for facilitating future research on CPS.",
    "pdfUrl": "https://arxiv.org/pdf/2502.13881",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:22.780428Z"
  },
  {
    "id": "f8c77fcd00b23ebd282ff343a55d74f1",
    "title": "A Coding-Enhanced Jamming Approach for Secure Semantic Communication over Wiretap Channels",
    "slug": "a-coding-enhanced-jamming-approach-for-secure-semantic-communication-over-wiretap-channels",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Weixuan Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As semantic communication (SemCom) gains increasing attention as a novel communication paradigm, ensuring the security of transmitted semantic information over open wireless channels becomes crucial. Existing secure SemCom solutions often lack explicit control over security. To address this, we propose a coding-enhanced jamming approach for secure SemCom over wiretap channels. This approach integrates deep joint source and channel coding (DeepJSCC) with neural network-based digital modulation, enabling controlled jamming through two-layer superposition coding. The outer constellation sequence encodes the source image, while the inner constellation sequence, derived from a secret image, acts as the jamming signal. By minimizing the mutual information between the outer and inner constellation sequences, the jamming effect is enhanced. The jamming signal is superposed on the outer constellation sequence, preventing the eavesdropper from recovering the source image. The power allocation coefficient (PAC) in the superposition coding can be adjusted to control system security. Experiments show that our approach matches existing methods in security while significantly improving reconstruction performance across varying channel signal-to-noise ratios (SNRs) and compression ratios.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16960",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.077761Z"
  },
  {
    "id": "ff63d15f2d54f0c03143bcfe3b4c3557",
    "title": "Relationship between Hlder Divergence and Functional Density Power Divergence: Intersection and Generalization",
    "slug": "relationship-between-hlder-divergence-and-functional-density-power-divergence:-intersection-and-generalization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Masahiro Kobayashi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this study, we discuss the relationship between two families of density-power-based divergences with functional degrees of freedom -- the Hlder divergence and the functional density power divergence (FDPD) -- based on their intersection and generalization. These divergence families include the density power divergence and the $\\gamma$-divergence as special cases. First, we prove that the intersection of the Hlder divergence and the FDPD is limited to a general divergence family introduced by Jones et al. (Biometrika, 2001). Subsequently, motivated by the fact that Hlder's inequality is used in the proofs of nonnegativity for both the Hlder divergence and the FDPD, we define a generalized divergence family, referred to as the $\\xi$-Hlder divergence. The nonnegativity of the $\\xi$-Hlder divergence is established through a combination of the inequalities used to prove the nonnegativity of the Hlder divergence and the FDPD. Furthermore, we derive an inequality between the composite scoring rules corresponding to different FDPDs based on the $\\xi$-Hlder divergence. Finally, we prove that imposing the mathematical structure of the Hlder score on a composite scoring rule results in the $\\xi$-Hlder divergence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17008",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.077970Z"
  },
  {
    "id": "21aa4775b86dbfd8c071027aea3fe59c",
    "title": "Rate-Distortion-Perception Theory for the Quadratic Wasserstein Space",
    "slug": "rate-distortion-perception-theory-for-the-quadratic-wasserstein-space",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Xiqiang Qu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish a single-letter characterization of the fundamental distortion-rate-perception tradeoff with limited common randomness under the squared error distortion measure and the squared Wasserstein-2 perception measure. Moreover, it is shown that this single-letter characterization can be explicitly evaluated for the Gaussian source. Various notions of universal representation are also clarified.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17236",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.078170Z"
  },
  {
    "id": "3a01db7984dea0e153110045becfdbfc",
    "title": "Service Rate Regions of MDS Codes & Fractional Matchings in Quasi-uniform Hypergraphs",
    "slug": "service-rate-regions-of-mds-codes-&-fractional-matchings-in-quasi-uniform-hypergraphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Hoang Ly",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The service rate region (SRR) has emerged as a critical performance metric for distributed systems that store data redundantly. It measures the system's ability to serve multiple users concurrently. Mathematically, the SRR is a polytope in R^k where each dimension corresponds to the service request rate of one of the k data objects. This paper focuses on systems employing a class of Maximum Distance Separable (MDS) codes. For each code in the class, we characterize the k axes intercept points of its SRR, and the smallest standard simplex that includes the SRR. We use these results to show that the SRR grows with the increasing number of systematic columns in the generator matrices. We establish a graph-theoretic framework associating this SRR problem with fractional matchings in quasi-uniform hypergraphs. Identifying the SRR polytope is equivalent to determining a particular image of the fractional-matching polytope. We introduce a notion of Greedy Matching and show that it is sufficient to focus on these matchings to characterize the SRR rather than the entire matching polytope. With these tools, we determine the SRR of a large subset of the considered class of codes. Our results generalize previous characterizations of systematic and non-systematic MDS-coded systems, offering a unified framework for analyzing service rate regions of codes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17244",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.078363Z"
  },
  {
    "id": "eef167e4f57a9dbaae65e7d1714ddae0",
    "title": "Error Exponents for DNA Storage Codes with a Variable Number of Reads",
    "slug": "error-exponents-for-dna-storage-codes-with-a-variable-number-of-reads",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yan Hao Ling",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we study error exponents for a concatataned coding based class of DNA storage codes in which the number of reads performed can be variable. That is, the decoder can sequentially perform reads and choose whether to output the final decision or take more reads, and we are interested in minimizing the average number of reads performed rather than a fixed pre-specified value. We show that this flexibility leads to a considerable reduction in the error probability compared to a fixed number of reads, not only in terms of constants in the error exponent but also in the scaling laws. This is shown via an achievability result for a suitably-designed protocol, and in certain parameter regimes we additionally establish a matching converse that holds for all protocols within a broader concatenated coding based class.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17337",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.078558Z"
  },
  {
    "id": "bf9d6eea488a3170041476743f20680a",
    "title": "Subcode Ensemble Decoding of Polar Codes",
    "slug": "subcode-ensemble-decoding-of-polar-codes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Henning Lulei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the short block length regime, pre-transformed polar codes together with successive cancellation list (SCL) decoding possess excellent error correction capabilities. However, in practice, the list size is limited due to the suboptimal scaling of the required area in hardware implementations. Automorphism ensemble decoding (AED) can improve performance for a fixed list size by running multiple parallel SCL decodings on permuted received words, yielding a list of estimates from which the final estimate is selected. Yet, AED is limited to appropriately designed polar codes. Subcode ensemble decoding (ScED) was recently proposed for low-density parity-check codes and does not impose such design constraints. It uses multiple decodings in different subcodes, ensuring that the selected subcodes jointly cover the original code. We extend ScED to polar codes by expressing polar subcodes through suitable pre-transformations (PTs). To this end, we describe a framework classifying pre-transformations for pre-transformed polar codes based on their role in encoding and decoding. Within this framework, we propose a new type of PT enabling ScED for polar codes, analyze its properties, and discuss how to construct an efficient ensemble.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17511",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.078766Z"
  },
  {
    "id": "ee1bb852438cf978aec272c7a44ee5b6",
    "title": "Secure Network Function Computation for Linear Functions, Part II: Target-Function Security",
    "slug": "secure-network-function-computation-for-linear-functions,-part-ii:-target-function-security",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yang Bai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this Part II of a two-part paper, we put forward secure network function computation, where in a directed acyclic network, a sink node is required to compute a target function of which the inputs are generated as source messages at multiple source nodes, while a wiretapper, who can access any one but not more than one wiretap set in a given collection of wiretap sets, is not allowed to obtain any information about a security function of the source messages. In Part I of the two-part paper, we have investigated securely computing linear functions with the wiretapper who can eavesdrop any edge subset up to a certain size r, referred to as the security level, where the security function is the identity function. The notion of this security is called source security. In the current paper, we consider another interesting model which is the same as the above one except that the security function is identical to the target function, i.e., we need to protect the information on the target function from being leaked to the wiretapper. The notion of this security is called target-function security. We first prove a non-trivial upper bound on the secure computing capacity, which is applicable to arbitrary network topologies and arbitrary security levels. In particular, when the security level r is equal to 0, the upper bound reduces to the computing capacity without security consideration. Further, from an algebraic point of view, we prove two equivalent conditions for target-function security and source security for the existence of the corresponding linear function-computing secure network codes. With them, for any linear function over a given finite field, we develop a code construction of linear secure network codes for target-function security and thus obtain a lower bound on the secure computing capacity; and also generalize the code construction developed in Part I for source security.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17514",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.079121Z"
  },
  {
    "id": "c35026bcdb9b28e432dbd48734d42909",
    "title": "MacWilliams Theory over Zk and nu-functions over Lattices",
    "slug": "macwilliams-theory-over-zk-and-nu-functions-over-lattices",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Zhiyong Zheng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Continuing previous works on MacWilliams theory over codes and lattices, a generalization of the MacWilliams theory over $\\mathbb{Z}_k$ for $m$ codes is established, and the complete weight enumerator MacWilliams identity also holds for codes over the finitely generated rings $\\mathbb{Z}_k[\\xi]$. In the context of lattices, the analogy of the MacWilliams identity associated with nu-function was conjectured by Sol in 1995, and we present a new formula for nu-function over the lattices associated with a ternary code, which is rather different from the original conjecture. Furthermore, we provide many counterexamples to show that the Sol conjecture never holds in the general case, except for the lattices associated with a binary code.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17589",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.079392Z"
  },
  {
    "id": "e2fac3b8d105bf5b0ed7a0c2cdc46096",
    "title": "Integrated Sensing and Communications for Unsourced Random Access: A Spectrum Sharing Compressive Sensing Approach",
    "slug": "integrated-sensing-and-communications-for-unsourced-random-access:-a-spectrum-sharing-compressive-sensing-approach",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Zhentian Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper addresses the unsourced/uncoordinated random access problem in an integrated sensing and communications (ISAC) system, with a focus on uplink multiple access code design. Recent theoretical advancements highlight that an ISAC system will be overwhelmed by the increasing number of active devices, driven by the growth of massive machine-type communication (mMTC). To meet the demands of future mMTC network, fundamental solutions are required that ensure robust capacity while maintaining favorable energy and spectral efficiency. One promising approach to support emerging massive connectivity is the development of systems based on the unsourced ISAC (UNISAC) framework. This paper proposes a spectrum-sharing compressive sensing-based UNISAC (SSCS-UNISAC) and offers insights into the practical design of UNISAC multiple access codes. In this framework, both communication signals (data transmission) and sensing signals (e.g., radar echoes) overlap within finite channel uses and are transmitted via the proposed UNISAC protocol. The proposed decoder exhibits robust performance, providing 20-30 dB capacity gains compared to conventional protocols such as TDMA and ALOHA. Numerical results validate the promising performance of the proposed scheme.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17629",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.079596Z"
  },
  {
    "id": "b30ead38b35b4c32c709e0b41813f34a",
    "title": "Sparsity-Exploiting Channel Estimation For Unsourced Random Access With Fluid Antenna",
    "slug": "sparsity-exploiting-channel-estimation-for-unsourced-random-access-with-fluid-antenna",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Keru Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This work explores the channel estimation (CE) problem in uplink transmission for unsourced random access (URA) with a fluid antenna receiver. The additional spatial diversity in a fluid antenna system (FAS) addresses the needs of URA design in multiple-input and multiple-output (MIMO) systems. We present two CE strategies based on the activation of different FAS ports, namely alternate ports and partial ports CE. Both strategies facilitate the estimation of channel coefficients and angles of arrival (AoAs). Additionally, we discuss how to refine channel estimation by leveraging the sparsity of finite scatterers. Specifically, the proposed partial ports CE strategy is implemented using a regularized estimator, and we optimize the estimator's parameter to achieve the desired AoA precision and refinement. Extensive numerical results demonstrate the feasibility of the proposed strategies, and a comparison with a conventional receiver using half-wavelength antennas highlights the promising future of integrating URA and FAS.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17634",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.079803Z"
  },
  {
    "id": "61dcd45c8304750fbf68362fdbbb1495",
    "title": "DTECM: Digital Twin Enabled Channel Measurement and Modeling in Terahertz Urban Macrocell",
    "slug": "dtecm:-digital-twin-enabled-channel-measurement-and-modeling-in-terahertz-urban-macrocell",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yuanbo Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, in the THz UMa, extensive channel measurements are conducted and an accurate channel model is developed by combining ray-tracing, computer vision (CV), and statistical methods. Specifically, substantial channel measurement campaigns with distances up to 410~m are conducted at 220~GHz, with nanosecond-level absolute time synchronization. Based on the measurement results, the propagation phenomena are analyzed in detail and the channel characteristics are calculated and statistically modeled. Furthermore, a digital twin enabled channel model (DTECM) is proposed, which generates THz channel responses in a hybrid manner. Specifically, the dominant paths are generated deterministically by using the ray-tracing technique and CV methods. Apart from the path gains determined by ray-tracing, the additional foliage loss is accurately modeled based on foliage information extracted from panoramic pictures. To maintain a low computational complexity for the DTECM, non-dominant paths are then generated statistically. Numeric results reveal that compared to the traditional statistical channel models, the DTECM reduces the path loss modeling error from 14~dB to 4~dB, showing its great superiority. Furthermore, a preliminary link performance evaluation using the DTECM indicates that THz UMa is feasible, though requiring high antenna gains and coverage extension techniques to achieve high spectral efficiencies and wide coverage.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17673",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.080009Z"
  },
  {
    "id": "cda84ffc834a46dd30383d2b06d0a6a3",
    "title": "Path Integral Methods for Synthesizing and Preventing Stealthy Attacks in Nonlinear Cyber-Physical Systems",
    "slug": "path-integral-methods-for-synthesizing-and-preventing-stealthy-attacks-in-nonlinear-cyber-physical-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Apurva Patil",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper studies the synthesis and mitigation of stealthy attacks in nonlinear cyber-physical systems (CPS). To quantify stealthiness, we employ the Kullback-Leibler (KL) divergence, a measure rooted in hypothesis testing and detection theory, which captures the trade-off between an attacker's desire to remain stealthy and her goal of degrading system performance. First, we synthesize the worst-case stealthy attack in nonlinear CPS using the path integral approach. Second, we consider how a controller can mitigate the impact of such stealthy attacks by formulating a minimax KL control problem, yielding a zero-sum game between the attacker and the controller. Again, we leverage a path integral-based solution that computes saddle-point policies for both players through Monte Carlo simulations. We validate our approach using unicycle navigation and cruise control problems, demonstrating how an attacker can covertly drive the system into unsafe regions, and how the controller can adapt her policy to combat the worst-case attacks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17118",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:23.080209Z"
  },
  {
    "id": "1f9ebbb86ef1e33f04f57e352ddacb2a",
    "title": "P$_\\ell$-Kyber: Packing $\\ell$ Plaintexts and Lattice Coding for Kyber",
    "slug": "p$_\\ell$-kyber:-packing-$\\ell$-plaintexts-and-lattice-coding-for-kyber",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Shuiyin Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, we propose a joint design of encoding and encryption processes for KEMs like Kyber, without assuming the independence of the decoding noise entries. Our design features two techniques: ciphertext packing and lattice packing. First, we extend the Peikert-Vaikuntanathan-Waters (PVW) method to the Kyber: $\\ell$ plaintexts are packed into a single ciphertext. This scheme is referred to as P$_\\ell$-Kyber. We prove that the P$_\\ell$-Kyber is IND-CCA secure under the M-LWE hardness assumption. We show that the decryption decoding noise entries across the $\\ell$ plaintexts (also known as layers) are mutually independent. Second, we propose a cross-layer lattice encoding scheme for the P$_\\ell$-Kyber, where every $\\ell$ cross-layer information symbols are encoded to a lattice point. This way we obtain a \\emph{coded} P$_\\ell$-Kyber, where the decoding noise entries for each lattice point are mutually independent. Therefore, the decryption failure rate (DFR) analysis does not require the assumption of independence among the decryption decoding noise entries. Both DFR and communication cost (CER) are greatly decreased thanks to ciphertext packing and lattice packing. Finally, we demonstrate that with $\\ell=24$ and Leech lattice encoder, the proposed coded P$_\\ell$-KYBER1024 achieves DFR $<2^{-281}$ and CER $ = 4.6$, i.e., a decrease of CER by $90\\%$ compared to KYBER1024.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17185",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:23.080403Z"
  },
  {
    "id": "997c769ca5664fc178fb75196e12bc56",
    "title": "Quantum-Enhanced Change Detection and Joint Communication-Detection",
    "slug": "quantum-enhanced-change-detection-and-joint-communication-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Zihao Gong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Quick detection of transmittance changes in optical channel is crucial for secure communication. We demonstrate that pre-shared entanglement using two-mode squeezed vacuum states significantly reduces detection latency compared to classical and entanglement-augmented coherent-state probes. The change detection latency is inversely proportional to the quantum relative entropy (QRE), which goes to infinity in the absence of thermal noise, suggesting idealized instantaneous detection. However, in realistic scenarios, we show that QRE scales logarithmically with the inverse of the thermal noise mean photon number. We propose a receiver that achieves this scaling and quantify its performance gains over existing methods. Additionally, we explore the fundamental trade-off between communication capacity and change detection latency, highlighting how pre-shared entanglement enhances both.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17237",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.080616Z"
  },
  {
    "id": "6a2e639759a35dd90c4596d572ba6d49",
    "title": "Coding for Computation: Efficient Compression of Neural Networks for Reconfigurable Hardware",
    "slug": "coding-for-computation:-efficient-compression-of-neural-networks-for-reconfigurable-hardware",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hans Rosenberger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As state of the art neural networks (NNs) continue to grow in size, their resource-efficient implementation becomes ever more important. In this paper, we introduce a compression scheme that reduces the number of computations required for NN inference on reconfigurable hardware such as FPGAs. This is achieved by combining pruning via regularized training, weight sharing and linear computation coding (LCC). Contrary to common NN compression techniques, where the objective is to reduce the memory used for storing the weights of the NNs, our approach is optimized to reduce the number of additions required for inference in a hardware-friendly manner. The proposed scheme achieves competitive performance for simple multilayer perceptrons, as well as for large scale deep NNs such as ResNet-34.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17403",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.080822Z"
  },
  {
    "id": "563113a1e9a36deb603f7461d6ef5e52",
    "title": "UNILoc: Unified Localization Combining Model-Based Geometry and Unsupervised Learning",
    "slug": "uniloc:-unified-localization-combining-model-based-geometry-and-unsupervised-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Signal Processing (eess.SP)",
    "author": {
      "name": "Yuhao Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate mobile device localization is critical for emerging 5G/6G applications such as autonomous vehicles and augmented reality. In this paper, we propose a unified localization method that integrates model-based and machine learning (ML)-based methods to reap their respective advantages by exploiting available map information. In order to avoid supervised learning, we generate training labels automatically via optimal transport (OT) by fusing geometric estimates with building layouts. Ray-tracing based simulations are carried out to demonstrate that the proposed method significantly improves positioning accuracy for both line-of-sight (LoS) users (compared to ML-based methods) and non-line-of-sight (NLoS) users (compared to model-based methods). Remarkably, the unified method is able to achieve competitive overall performance with the fully-supervised fingerprinting, while eliminating the need for cumbersome labeled data measurement and collection.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17676",
    "tags": [
      "Signal Processing (eess.SP)"
    ],
    "createdAt": "2025-04-25T15:49:23.081071Z"
  },
  {
    "id": "e484eff1a9c72a5e96075af419aebda1",
    "title": "Quantum Error Correction with Girth-16 Non-Binary LDPC Codes via Affine Permutation Construction",
    "slug": "quantum-error-correction-with-girth-16-non-binary-ldpc-codes-via-affine-permutation-construction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Kenta Kasai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a method for constructing quantum error-correcting codes based on non-binary low-density parity-check codes with girth 16. In conventional constructions using circulant permutation matrices, the girth is upper-bounded by 12, which limits the suppression of harmful short cycles. Our construction employs affine permutation matrices and a randomized sequential selection procedure designed to eliminate short cycles, which are known to limit decoding performance.\nJoint belief propagation decoding is applied over depolarizing channels. Numerical experiments confirm that the proposed codes reduce the number of low-weight codewords in $C_X \\setminus C_Z^\\perp$ and $C_Z \\setminus C_X^\\perp$, and thus have the potential to suppress error floors. In addition, we obtain a significantly improved upper bound on the minimum distance, which we conjecture to be tight.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17790",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.081259Z"
  },
  {
    "id": "ca4cf1b11fc9dfd9c4556565d16b3ab0",
    "title": "QoS-based Beamforming and Compression Design for Cooperative Cellular Networks via Lagrangian Duality",
    "slug": "qos-based-beamforming-and-compression-design-for-cooperative-cellular-networks-via-lagrangian-duality",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Xilai Fan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper considers the quality-of-service (QoS)-based joint beamforming and compression design problem in the downlink cooperative cellular network, where multiple relay-like base stations (BSs), connected to the central processor via rate-limited fronthaul links, cooperatively transmit messages to the users. The problem of interest is formulated as the minimization of the total transmit power of the BSs, subject to all users' signal-to-interference-plus-noise ratio (SINR) constraints and all BSs' fronthaul rate constraints. In this paper, we first show that there is no duality gap between the considered joint optimization problem and its Lagrangian dual by showing the tightness of its semidefinite relaxation (SDR). Then, we propose an efficient algorithm based on the above duality result for solving the considered problem. The proposed algorithm judiciously exploits the special structure of an enhanced Karush-Kuhn-Tucker (KKT) conditions of the considered problem and finds the solution that satisfies the enhanced KKT conditions via two fixed point iterations. Two key features of the proposed algorithm are: (1) it is able to detect whether the considered problem is feasible or not and find its globally optimal solution when it is feasible; (2) it is highly efficient because both of the fixed point iterations in the proposed algorithm are linearly convergent and evaluating the functions in the fixed point iterations are computationally cheap. Numerical results show the global optimality and efficiency of the proposed algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2306.13962",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.081462Z"
  },
  {
    "id": "7b1787bbba88dad7ca44ab0c98e3404c",
    "title": "Revisit the Arimoto-Blahut algorithm: New Analysis with Approximation",
    "slug": "revisit-the-arimoto-blahut-algorithm:-new-analysis-with-approximation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Michail Fasoulakis",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "By the seminal paper of Claude Shannon \\cite{Shannon48}, the computation of the capacity of a discrete memoryless channel has been considered as one of the most important and fundamental problems in Information Theory. Nearly 50 years ago, Arimoto and Blahut independently proposed identical algorithms to solve this problem in their seminal papers \\cite{Arimoto1972AnAF, Blahut1972ComputationOC}. The Arimoto-Blahut algorithm was proven to converge to the capacity of the channel as $t \\to \\infty$ with the convergence rate upper bounded by $O\\left(\\log(m)/t\\right)$, where $m$ is the size of the input distribution, and being inverse exponential when there is a unique solution in the interior of the input probability simplex \\cite{Arimoto1972AnAF}. Recently it was proved, in \\cite{Nakagawa2020AnalysisOT}, that the convergence rate is at worst inverse linear $O(1/t)$ in some specific cases.\nIn this paper, we revisit this fundamental algorithm looking at the rate of convergence to the capacity and the time complexity, given $m,n$, where $n$ is size of the output of the channel, focusing on the approximation of the capacity. We prove that the rate of convergence to an $\\varepsilon$-optimal solution, for any sufficiently small constant $\\varepsilon > 0$, is inverse exponential $O\\left(\\log(m)/c^t\\right)$, for a constant $c > 1$ and $O\\left(\\log \\left(\\log (m)/\\varepsilon\\right)\\right)$ at most iterations, implying $O\\left(m n\\log \\left(\\log (m)/\\varepsilon\\right)\\right)$ total complexity of the algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2407.06013",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.081652Z"
  },
  {
    "id": "19076c3e1454701902a8562288b3446d",
    "title": "Capacity of Hierarchical Secure Coded Gradient Aggregation with Straggling Communication Links",
    "slug": "capacity-of-hierarchical-secure-coded-gradient-aggregation-with-straggling-communication-links",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Qinyi Lu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The growing privacy concerns in distributed learning have led to the widespread adoption of secure aggregation techniques in distributed machine learning systems, such as federated learning. Motivated by a coded gradient aggregation problem in a user-helper-master hierarchical network setting with straggling communication links, we formulate a new secure hierarchical coded gradient aggregation problem. In our setting, \\( K \\) users communicate with the master through an intermediate layer of \\( N \\) helpers, who can communicate with each other. With a resiliency threshold of \\( N_r \\) for straggling communication links, and at most \\( T \\) colluding helpers and any number of colluding users, the master aims to recover the sum of all users' gradients while remaining unaware of any individual gradient that exceeds the expected sum. In addition, helpers cannot infer more about users' gradients than what is already known by the colluding users. We propose an achievable scheme where users' upload messages are based on a globally known Vandermonde matrix, and helper communication is facilitated using an extended Vandermonde matrix with special structural properties. A matching converse bound is also derived, establishing the optimal result for this hierarchical coded gradient aggregation problem.",
    "pdfUrl": "https://arxiv.org/pdf/2412.11496",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.081848Z"
  },
  {
    "id": "e5d264b49b96b448f2b3b98315d73ef8",
    "title": "On Achievable Rates Over Noisy Nanopore Channels",
    "slug": "on-achievable-rates-over-noisy-nanopore-channels",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "V. Arvind Rameshwar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we consider a recent channel model of a nanopore sequencer proposed by McBain, Viterbo, and Saunderson (2024), termed the noisy nanopore channel (NNC). In essence, an NNC is a duplication channel with structured, Markov inputs, that is corrupted by memoryless noise. We first discuss a (tight) lower bound on the capacity of the NNC in the absence of random noise. Next, we present lower and upper bounds on the channel capacity of general noisy nanopore channels. We then consider two interesting regimes of operation of an NNC: first, where the memory of the input process is large and the random noise introduces erasures, and second, where the rate of measurements of the electric current (also called the sampling rate) is high. For these regimes, we show that it is possible to achieve information rates close to the noise-free capacity, using low-complexity encoding and decoding schemes. In particular, our decoder for the regime of high sampling rates makes use of a change-point detection procedure -- a subroutine of immediate relevance for practitioners.",
    "pdfUrl": "https://arxiv.org/pdf/2501.02917",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.082040Z"
  },
  {
    "id": "ab0bc8aacfcd4f0282d95a1723a92046",
    "title": "Proofs for Folklore Theorems on the Radon-Nikodym Derivative",
    "slug": "proofs-for-folklore-theorems-on-the-radon-nikodym-derivative",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yaiza Bermudez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, rigorous statements and formal proofs are presented for both foundational and advanced folklore theorems on the Radon-Nikodym derivative. The cases of conditional and marginal probability measures are carefully considered, which leads to an identity involving the sum of mutual and lautum information suggesting a new interpretation for such a sum.",
    "pdfUrl": "https://arxiv.org/pdf/2501.18374",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.082246Z"
  },
  {
    "id": "4a6ee53af0ec6159715db2f605a3c355",
    "title": "Function-Correcting Codes for Locally Bounded Functions",
    "slug": "function-correcting-codes-for-locally-bounded-functions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Charul Rajput",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we introduce a class of functions that assume only a limited number $\\lambda$ of values within a given Hamming $\\rho$-ball and call them locally $(\\rho, \\lambda)$-bounded functions. We develop function-correcting codes (FCCs) for these functions and propose an upper bound on the redundancy of FCCs. The bound is based on the minimum length of an error-correcting code with a given number of codewords and a minimum distance. Furthermore, we provide a sufficient optimality condition for FCCs when $\\lambda =4$. We also demonstrate that any function can be represented as a locally $(\\rho, \\lambda)$-bounded function, illustrating this with a representation of Hamming weight distribution functions. Furthermore, we present another construction of function-correcting codes for Hamming weight distribution functions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.07804",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.082446Z"
  },
  {
    "id": "da6f10832b9d7dede024e0345e4866f7",
    "title": "Passive Channel Charting: Locating Passive Targets using Wi-Fi Channel State Information",
    "slug": "passive-channel-charting:-locating-passive-targets-using-wi-fi-channel-state-information",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Florian Euchner",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose passive channel charting, an extension of channel charting to passive target localization. As in conventional channel charting, we follow a dimensionality reduction approach to reconstruct a physically interpretable map of target positions from similarities in high-dimensional channel state information. We show that algorithms and neural network architectures developed in the context of channel charting with active mobile transmitters can be straightforwardly applied to the passive case, where we assume a scenario with static transmitters and receivers and a mobile target. We evaluate our method on a channel state information dataset collected indoors with a distributed setup of ESPARGOS Wi-Fi sensing antenna arrays. This scenario can be interpreted as either a multi-static or passive radar system. We demonstrate that passive channel charting outperforms a baseline based on classical triangulation in terms of localization accuracy. We discuss our results and highlight some unsolved issues related to the proposed concept.",
    "pdfUrl": "https://arxiv.org/pdf/2504.09924",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.082687Z"
  },
  {
    "id": "7ae3d874b9548121c1da8d36057a314b",
    "title": "Exponentially Consistent Nonparametric Linkage-Based Clustering of Data Sequences",
    "slug": "exponentially-consistent-nonparametric-linkage-based-clustering-of-data-sequences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Bhupender Singh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we consider nonparametric clustering of $M$ independent and identically distributed (i.i.d.) data sequences generated from {\\em unknown} distributions. The distributions of the $M$ data sequences belong to $K$ underlying distribution clusters. Existing results on exponentially consistent nonparametric clustering algorithms, like single linkage-based (SLINK) clustering and $k$-medoids distribution clustering, assume that the maximum intra-cluster distance ($d_L$) is smaller than the minimum inter-cluster distance ($d_H$). First, in the fixed sample size (FSS) setting, we show that exponential consistency can be achieved for SLINK clustering under a less strict assumption, $d_I < d_H$, where $d_I$ is the maximum distance between any two sub-clusters of a cluster that partition the cluster. Note that $d_I < d_L$ in general. Thus, our results show that SLINK is exponentially consistent for a larger class of problems than previously known. In our simulations, we also identify examples where $k$-medoids clustering is unable to find the true clusters, but SLINK is exponentially consistent. Then, we propose a sequential clustering algorithm, named SLINK-SEQ, based on SLINK and prove that it is also exponentially consistent. Simulation results show that the SLINK-SEQ algorithm requires fewer expected number of samples than the FSS SLINK algorithm for the same probability of error.",
    "pdfUrl": "https://arxiv.org/pdf/2411.13922",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.082880Z"
  },
  {
    "id": "14e6add221fb65478fcb949b1238950f",
    "title": "ROMA: ROtary and Movable Antenna",
    "slug": "roma:-rotary-and-movable-antenna",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Signal Processing (eess.SP)",
    "author": {
      "name": "Jiayi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rotary and movable antenna (ROMA) architecture represents a next-generation multi-antenna technology that enables flexible adjustment of antenna position and array rotation angles of the transceiver. In this letter, we propose a ROMA-aided multi-user MIMO communication system to fully enhance the efficiency and reliability of system transmissions. By deploying ROMA panels at both the transmitter and receiver sides, and jointly optimizing the three-dimensional (3D) rotation angles of each ROMA panel and the relative positions of antenna elements based on the spatial distribution of users and channel state information (CSI), we can achieve the objective of maximizing the average spectral efficiency (SE). Subsequently, we conduct a detailed analysis of the average SE performance of the system under the consideration of maximum ratio (MR) precoding. Due to the non-convexity of the optimization problem in the ROMA multi-user MIMO system, we propose an efficient solution based on an alternating optimization (AO) algorithm. Finally, simulation results demonstrate that the AO-based ROMA architecture can significantly improve the average SE. Furthermore, the performance improvement becomes more pronounced as the size of the movable region and the transmission power increase.",
    "pdfUrl": "https://arxiv.org/pdf/2501.13403",
    "tags": [
      "Signal Processing (eess.SP)"
    ],
    "createdAt": "2025-04-25T15:49:23.083089Z"
  },
  {
    "id": "f2356f179b6c78ba0f9aab20fb6c4cbf",
    "title": "A Novel Graph Transformer Framework for Gene Regulatory Network Inference",
    "slug": "a-novel-graph-transformer-framework-for-gene-regulatory-network-inference",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Binon Teji",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The inference of gene regulatory networks (GRNs) is a foundational stride towards deciphering the fundamentals of complex biological systems. Inferring a possible regulatory link between two genes can be formulated as a link prediction problem. Inference of GRNs via gene coexpression profiling data may not always reflect true biological interactions, as its susceptibility to noise and misrepresenting true biological regulatory relationships. Most GRN inference methods face several challenges in the network reconstruction phase. Therefore, it is important to encode gene expression values, leverege the prior knowledge gained from the available inferred network structures and positional informations of the input network nodes towards inferring a better and more confident GRN network reconstruction. In this paper, we explore the integration of multiple inferred networks to enhance the inference of Gene Regulatory Networks (GRNs). Primarily, we employ autoencoder embeddings to capture gene expression patterns directly from raw data, preserving intricate biological signals. Then, we embed the prior knowledge from GRN structures transforming them into a text-like representation using random walks, which are then encoded with a masked language model, BERT, to generate global embeddings for each gene across all networks. Additionally, we embed the positional encodings of the input gene networks to better identify the position of each unique gene within the graph. These embeddings are integrated into graph transformer-based model, termed GT-GRN, for GRN inference. The GT-GRN model effectively utilizes the topological structure of the ground truth network while incorporating the enriched encoded information. Experimental results demonstrate that GT-GRN significantly outperforms existing GRN inference methods, achieving superior accuracy and highlighting the robustness of our approach.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16961",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.764020Z"
  },
  {
    "id": "fb58946142bea1dd00572fe698eba1c0",
    "title": "Backslash: Rate Constrained Optimized Training of Large Language Models",
    "slug": "backslash:-rate-constrained-optimized-training-of-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jun Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid advancement of large-language models (LLMs) has driven extensive research into parameter compression after training has been completed, yet compression during the training phase remains largely unexplored. In this work, we introduce Rate-Constrained Training (Backslash), a novel training-time compression approach based on rate-distortion optimization (RDO). Backslash enables a flexible trade-off between model accuracy and complexity, significantly reducing parameter redundancy while preserving performance. Experiments in various architectures and tasks demonstrate that Backslash can reduce memory usage by 60\\% - 90\\% without accuracy loss and provides significant compression gain compared to compression after training. Moreover, Backslash proves to be highly versatile: it enhances generalization with small Lagrange multipliers, improves model robustness to pruning (maintaining accuracy even at 80\\% pruning rates), and enables network simplification for accelerated inference on edge devices.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16968",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.764241Z"
  },
  {
    "id": "8ed8dbce715f3771e302ef29949f0297",
    "title": "STFM: A Spatio-Temporal Information Fusion Model Based on Phase Space Reconstruction for Sea Surface Temperature Prediction",
    "slug": "stfm:-a-spatio-temporal-information-fusion-model-based-on-phase-space-reconstruction-for-sea-surface-temperature-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yin Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The sea surface temperature (SST), a key environmental parameter, is crucial to optimizing production planning, making its accurate prediction a vital research topic. However, the inherent nonlinearity of the marine dynamic system presents significant challenges. Current forecasting methods mainly include physics-based numerical simulations and data-driven machine learning approaches. The former, while describing SST evolution through differential equations, suffers from high computational complexity and limited applicability, whereas the latter, despite its computational benefits, requires large datasets and faces interpretability challenges. This study presents a prediction framework based solely on data-driven techniques. Using phase space reconstruction, we construct initial-delay attractor pairs with a mathematical homeomorphism and design a Spatio-Temporal Fusion Mapping (STFM) to uncover their intrinsic connections. Unlike conventional models, our method captures SST dynamics efficiently through phase space reconstruction and achieves high prediction accuracy with minimal training data in comparative tests",
    "pdfUrl": "https://arxiv.org/pdf/2504.16970",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.764454Z"
  },
  {
    "id": "415c6f34ca176b6fa352fc8e703e9311",
    "title": "Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications",
    "slug": "unsupervised-time-series-signal-analysis-with-autoencoders-and-vision-transformers:-a-review-of-architectures-and-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hossein Ahmadi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid growth of unlabeled time-series data in domains such as wireless communications, radar, biomedical engineering, and the Internet of Things (IoT) has driven advancements in unsupervised learning. This review synthesizes recent progress in applying autoencoders and vision transformers for unsupervised signal analysis, focusing on their architectures, applications, and emerging trends. We explore how these models enable feature extraction, anomaly detection, and classification across diverse signal types, including electrocardiograms, radar waveforms, and IoT sensor data. The review highlights the strengths of hybrid architectures and self-supervised learning, while identifying challenges in interpretability, scalability, and domain generalization. By bridging methodological innovations and practical applications, this work offers a roadmap for developing robust, adaptive models for signal intelligence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16972",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.764659Z"
  },
  {
    "id": "6449bb5910cada0e61a5a0bd7d86218c",
    "title": "Safety Pretraining: Toward the Next Generation of Safe AI",
    "slug": "safety-pretraining:-toward-the-next-generation-of-safe-ai",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Pratyush Maini",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As large language models (LLMs) are increasingly deployed in high-stakes settings, the risk of generating harmful or toxic content remains a central challenge. Post-hoc alignment methods are brittle: once unsafe patterns are learned during pretraining, they are hard to remove. We present a data-centric pretraining framework that builds safety into the model from the start. Our contributions include: (i) a safety classifier trained on 10,000 GPT-4 labeled examples, used to filter 600B tokens; (ii) the largest synthetic safety dataset to date (100B tokens) generated via recontextualization of harmful web data; (iii) RefuseWeb and Moral Education datasets that convert harmful prompts into refusal dialogues and web-style educational material; (iv) Harmfulness-Tag annotations injected during pretraining to flag unsafe content and steer away inference from harmful generations; and (v) safety evaluations measuring base model behavior before instruction tuning. Our safety-pretrained models reduce attack success rates from 38.8% to 8.4% with no performance degradation on standard LLM safety benchmarks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16980",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.764878Z"
  },
  {
    "id": "f34b4af627a687b8fda97668585ea4e1",
    "title": "(Im)possibility of Automated Hallucination Detection in Large Language Models",
    "slug": "(im)possibility-of-automated-hallucination-detection-in-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Amin Karbasi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Is automated hallucination detection possible? In this work, we introduce a theoretical framework to analyze the feasibility of automatically detecting hallucinations produced by large language models (LLMs). Inspired by the classical Gold-Angluin framework for language identification and its recent adaptation to language generation by Kleinberg and Mullainathan, we investigate whether an algorithm, trained on examples drawn from an unknown target language $K$ (selected from a countable collection) and given access to an LLM, can reliably determine whether the LLM's outputs are correct or constitute hallucinations.\nFirst, we establish an equivalence between hallucination detection and the classical task of language identification. We prove that any hallucination detection method can be converted into a language identification method, and conversely, algorithms solving language identification can be adapted for hallucination detection. Given the inherent difficulty of language identification, this implies that hallucination detection is fundamentally impossible for most language collections if the detector is trained using only correct examples from the target language.\nSecond, we show that the use of expert-labeled feedback, i.e., training the detector with both positive examples (correct statements) and negative examples (explicitly labeled incorrect statements), dramatically changes this conclusion. Under this enriched training regime, automated hallucination detection becomes possible for all countable language collections.\nThese results highlight the essential role of expert-labeled examples in training hallucination detectors and provide theoretical support for feedback-based methods, such as reinforcement learning with human feedback (RLHF), which have proven critical for reliable LLM deployment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17004",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.765086Z"
  },
  {
    "id": "d2089c436cf6e5606772789c00d6c969",
    "title": "Democracy of AI Numerical Weather Models: An Example of Global Forecasting with FourCastNetv2 Made by a University Research Lab Using GPU",
    "slug": "democracy-of-ai-numerical-weather-models:-an-example-of-global-forecasting-with-fourcastnetv2-made-by-a-university-research-lab-using-gpu",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Iman Khadir",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper demonstrates the feasibility of democratizing AI-driven global weather forecasting models among university research groups by leveraging Graphics Processing Units (GPUs) and freely available AI models, such as NVIDIA's FourCastNetv2. FourCastNetv2 is an NVIDIA's advanced neural network for weather prediction and is trained on a 73-channel subset of the European Centre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset at single levels and different pressure levels. Although the training specifications for FourCastNetv2 are not released to the public, the training documentation of the model's first generation, FourCastNet, is available to all users. The training had 64 A100 GPUs and took 16 hours to complete. Although NVIDIA's models offer significant reductions in both time and cost compared to traditional Numerical Weather Prediction (NWP), reproducing published forecasting results presents ongoing challenges for resource-constrained university research groups with limited GPU availability. We demonstrate both (i) leveraging FourCastNetv2 to create predictions through the designated application programming interface (API) and (ii) utilizing NVIDIA hardware to train the original FourCastNet model. Further, this paper demonstrates the capabilities and limitations of NVIDIA A100's for resource-limited research groups in universities. We also explore data management, training efficiency, and model validation, highlighting the advantages and challenges of using limited high-performance computing resources. Consequently, this paper and its corresponding GitHub materials may serve as an initial guide for other university research groups and courses related to machine learning, climate science, and data science to develop research and education programs on AI weather forecasting, and hence help democratize the AI NWP in the digital economy.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17028",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.765314Z"
  },
  {
    "id": "ba582911e2deae514a316b6de3e0f7eb",
    "title": "Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation",
    "slug": "statistical-guarantees-in-synthetic-data-through-conformal-adversarial-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Rahul Vishwakarma",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The generation of high-quality synthetic data presents significant challenges in machine learning research, particularly regarding statistical fidelity and uncertainty quantification. Existing generative models produce compelling synthetic samples but lack rigorous statistical guarantees about their relation to the underlying data distribution, limiting their applicability in critical domains requiring robust error bounds. We address this fundamental limitation by presenting a novel framework that incorporates conformal prediction methodologies into Generative Adversarial Networks (GANs). By integrating multiple conformal prediction paradigms including Inductive Conformal Prediction (ICP), Mondrian Conformal Prediction, Cross-Conformal Prediction, and Venn-Abers Predictors, we establish distribution-free uncertainty quantification in generated samples. This approach, termed Conformalized GAN (cGAN), demonstrates enhanced calibration properties while maintaining the generative power of traditional GANs, producing synthetic data with provable statistical guarantees. We provide rigorous mathematical proofs establishing finite-sample validity guarantees and asymptotic efficiency properties, enabling the reliable application of synthetic data in high-stakes domains including healthcare, finance, and autonomous systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17058",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.765508Z"
  },
  {
    "id": "6cb9d8fa62014bc0deab24bb205291ac",
    "title": "Antenna Near-Field Reconstruction from Far-Field Data Using Convolutional Neural Networks",
    "slug": "antenna-near-field-reconstruction-from-far-field-data-using-convolutional-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Sahar Bagherkhani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Electromagnetic field reconstruction is crucial in many applications, including antenna diagnostics, electromagnetic interference analysis, and system modeling. This paper presents a deep learning-based approach for Far-Field to Near-Field (FF-NF) transformation using Convolutional Neural Networks (CNNs). The goal is to reconstruct near-field distributions from the far-field data of an antenna without relying on explicit analytical transformations. The CNNs are trained on paired far-field and near-field data and evaluated using mean squared error (MSE). The best model achieves a training error of 0.0199 and a test error of 0.3898. Moreover, visual comparisons between the predicted and true near-field distributions demonstrate the model's effectiveness in capturing complex electromagnetic field behavior, highlighting the potential of deep learning in electromagnetic field reconstruction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17065",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.765708Z"
  },
  {
    "id": "26a0fa6d2730d30b7780ca8b2bb4dbf2",
    "title": "Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching",
    "slug": "whence-is-a-model-fair?-fixing-fairness-bugs-via-propensity-score-matching",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Kewen Peng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Fairness-aware learning aims to mitigate discrimination against specific protected social groups (e.g., those categorized by gender, ethnicity, age) while minimizing predictive performance loss. Despite efforts to improve fairness in machine learning, prior studies have shown that many models remain unfair when measured against various fairness metrics. In this paper, we examine whether the way training and testing data are sampled affects the reliability of reported fairness metrics. Since training and test sets are often randomly sampled from the same population, bias present in the training data may still exist in the test data, potentially skewing fairness assessments. To address this, we propose FairMatch, a post-processing method that applies propensity score matching to evaluate and mitigate bias. FairMatch identifies control and treatment pairs with similar propensity scores in the test set and adjusts decision thresholds for different subgroups accordingly. For samples that cannot be matched, we perform probabilistic calibration using fairness-aware loss functions. Experimental results demonstrate that our approach can (a) precisely locate subsets of the test data where the model is unbiased, and (b) significantly reduce bias on the remaining data. Overall, propensity score matching offers a principled way to improve both fairness evaluation and mitigation, without sacrificing predictive performance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17066",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.765923Z"
  },
  {
    "id": "b677db092c270b24ab994a12c25924ca",
    "title": "In-Context Learning can distort the relationship between sequence likelihoods and biological fitness",
    "slug": "in-context-learning-can-distort-the-relationship-between-sequence-likelihoods-and-biological-fitness",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Pranav Kantroo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Language models have emerged as powerful predictors of the viability of biological sequences. During training these models learn the rules of the grammar obeyed by sequences of amino acids or nucleotides. Once trained, these models can take a sequence as input and produce a likelihood score as an output; a higher likelihood implies adherence to the learned grammar and correlates with experimental fitness measurements. Here we show that in-context learning can distort the relationship between fitness and likelihood scores of sequences. This phenomenon most prominently manifests as anomalously high likelihood scores for sequences that contain repeated motifs. We use protein language models with different architectures trained on the masked language modeling objective for our experiments, and find transformer-based models to be particularly vulnerable to this effect. This behavior is mediated by a look-up operation where the model seeks the identity of the masked position by using the other copy of the repeated motif as a reference. This retrieval behavior can override the model's learned priors. This phenomenon persists for imperfectly repeated sequences, and extends to other kinds of biologically relevant features such as reversed complement motifs in RNA sequences that fold into hairpin structures.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17068",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.766119Z"
  },
  {
    "id": "085a9972f200f0832fa0ee3475763c9d",
    "title": "Sparse Phased Array Optimization Using Deep Learning",
    "slug": "sparse-phased-array-optimization-using-deep-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "David Lu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Antenna arrays are widely used in wireless communication, radar systems, radio astronomy, and military defense to enhance signal strength, directivity, and interference suppression. We introduce a deep learning-based optimization approach that enhances the design of sparse phased arrays by reducing grating lobes. This approach begins by generating sparse array configurations to address the non-convex challenges and extensive degrees of freedom inherent in array design. We use neural networks to approximate the non-convex cost function that estimates the energy ratio between the main and side lobes. This differentiable approximation facilitates cost function minimization through gradient descent, optimizing the antenna elements' coordinates and leading to an improved layout. Additionally, we incorporate a tailored penalty mechanism that includes various physical and design constraints into the optimization process, enhancing its robustness and practical applicability. We demonstrate the effectiveness of our method by applying it to the ten array configurations with the lowest initial costs, achieving further cost reductions ranging from 411% to 643%, with an impressive average improvement of 552%. By significantly reducing side lobe levels in antenna arrays, this breakthrough paves the way for ultra-precise beamforming, enhanced interference mitigation, and next-generation wireless and radar systems with unprecedented efficiency and clarity.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17073",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.766336Z"
  },
  {
    "id": "2094aac975e534599e46384ea2d93ae0",
    "title": "Conditional Diffusion-Based Retrieval of Atmospheric CO2 from Earth Observing Spectroscopy",
    "slug": "conditional-diffusion-based-retrieval-of-atmospheric-co2-from-earth-observing-spectroscopy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "William R. Keely",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Satellite-based estimates of greenhouse gas (GHG) properties from observations of reflected solar spectra are integral for understanding and monitoring complex terrestrial systems and their impact on the carbon cycle due to their near global coverage. Known as retrieval, making GHG concentration estimations from these observations is a non-linear Bayesian inverse problem, which is operationally solved using a computationally expensive algorithm called Optimal Estimation (OE), providing a Gaussian approximation to a non-Gaussian posterior. This leads to issues in solver algorithm convergence, and to unrealistically confident uncertainty estimates for the retrieved quantities. Upcoming satellite missions will provide orders of magnitude more data than the current constellation of GHG observers. Development of fast and accurate retrieval algorithms with robust uncertainty quantification is critical. Doing so stands to provide substantial climate impact of moving towards the goal of near continuous real-time global monitoring of carbon sources and sinks which is essential for policy making. To achieve this goal, we propose a diffusion-based approach to flexibly retrieve a Gaussian or non-Gaussian posterior, for NASA's Orbiting Carbon Observatory-2 spectrometer, while providing a substantial computational speed-up over the current operational state-of-the-art.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17074",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.766571Z"
  },
  {
    "id": "db36795c07fcdfde02208bc65b2f5979",
    "title": "A Novel Hybrid Approach Using an Attention-Based Transformer + GRU Model for Predicting Cryptocurrency Prices",
    "slug": "a-novel-hybrid-approach-using-an-attention-based-transformer-+-gru-model-for-predicting-cryptocurrency-prices",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Esam Mahdi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this article, we introduce a novel deep learning hybrid model that integrates attention Transformer and Gated Recurrent Unit (GRU) architectures to improve the accuracy of cryptocurrency price predictions. By combining the Transformer's strength in capturing long-range patterns with the GRU's ability to model short-term and sequential trends, the hybrid model provides a well-rounded approach to time series forecasting. We apply the model to predict the daily closing prices of Bitcoin and Ethereum based on historical data that include past prices, trading volumes, and the Fear and Greed index. We evaluate the performance of our proposed model by comparing it with four other machine learning models: two are non-sequential feedforward models: Radial Basis Function Network (RBFN) and General Regression Neural Network (GRNN), and two are bidirectional sequential memory-based models: Bidirectional Long-Short-Term Memory (BiLSTM) and Bidirectional Gated Recurrent Unit (BiGRU). The performance of the model is assessed using several metrics, including Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE), along with statistical validation through the nonparametric Friedman test followed by a post hoc Wilcoxon signed rank test. The results demonstrate that our hybrid model consistently achieves superior accuracy, highlighting its effectiveness for financial prediction tasks. These findings provide valuable insights for improving real-time decision making in cryptocurrency markets and support the growing use of hybrid deep learning models in financial analytics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17079",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.766769Z"
  },
  {
    "id": "ee6e84100f3d520c07bde78af2d5e456",
    "title": "GeoRDF2Vec Learning Location-Aware Entity Representations in Knowledge Graphs",
    "slug": "geordf2vec-learning-location-aware-entity-representations-in-knowledge-graphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Martin Boeckling",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many knowledge graphs contain a substantial number of spatial entities, such as cities, buildings, and natural landmarks. For many of these entities, exact geometries are stored within the knowledge graphs. However, most existing approaches for learning entity representations do not take these geometries into account. In this paper, we introduce a variant of RDF2Vec that incorporates geometric information to learn location-aware embeddings of entities. Our approach expands different nodes by flooding the graph from geographic nodes, ensuring that each reachable node is considered. Based on the resulting flooded graph, we apply a modified version of RDF2Vec that biases graph walks using spatial weights. Through evaluations on multiple benchmark datasets, we demonstrate that our approach outperforms both non-location-aware RDF2Vec and GeoTransE.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17099",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.766974Z"
  },
  {
    "id": "795bc9ce26d62f973cb76432e22160e9",
    "title": "Discovering the Precursors of Traffic Breakdowns Using Spatiotemporal Graph Attribution Networks",
    "slug": "discovering-the-precursors-of-traffic-breakdowns-using-spatiotemporal-graph-attribution-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhaobin Mo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Understanding and predicting the precursors of traffic breakdowns is critical for improving road safety and traffic flow management. This paper presents a novel approach combining spatiotemporal graph neural networks (ST-GNNs) with Shapley values to identify and interpret traffic breakdown precursors. By extending Shapley explanation methods to a spatiotemporal setting, our proposed method bridges the gap between black-box neural network predictions and interpretable causes. We demonstrate the method on the Interstate-24 data, and identify that road topology and abrupt braking are major factors that lead to traffic breakdowns.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17109",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.767182Z"
  },
  {
    "id": "157cc36badab4eb5d1b7636edfb1811f",
    "title": "Scalable Permutation-Aware Modeling for Temporal Set Prediction",
    "slug": "scalable-permutation-aware-modeling-for-temporal-set-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ashish Ranjan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Temporal set prediction involves forecasting the elements that will appear in the next set, given a sequence of prior sets, each containing a variable number of elements. Existing methods often rely on intricate architectures with substantial computational overhead, which hampers their scalability. In this work, we introduce a novel and scalable framework that leverages permutation-equivariant and permutation-invariant transformations to efficiently model set dynamics. Our approach significantly reduces both training and inference time while maintaining competitive performance. Extensive experiments on multiple public benchmarks show that our method achieves results on par with or superior to state-of-the-art models across several evaluation metrics. These results underscore the effectiveness of our model in enabling efficient and scalable temporal set prediction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17140",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.767381Z"
  },
  {
    "id": "f7e6ee346e69e11dec819132edc3d22d",
    "title": "OUI Need to Talk About Weight Decay: A New Perspective on Overfitting Detection",
    "slug": "oui-need-to-talk-about-weight-decay:-a-new-perspective-on-overfitting-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Alberto Fernndez-Hernndez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce the Overfitting-Underfitting Indicator (OUI), a novel tool for monitoring the training dynamics of Deep Neural Networks (DNNs) and identifying optimal regularization hyperparameters. Specifically, we validate that OUI can effectively guide the selection of the Weight Decay (WD) hyperparameter by indicating whether a model is overfitting or underfitting during training without requiring validation data. Through experiments on DenseNet-BC-100 with CIFAR- 100, EfficientNet-B0 with TinyImageNet and ResNet-34 with ImageNet-1K, we show that maintaining OUI within a prescribed interval correlates strongly with improved generalization and validation scores. Notably, OUI converges significantly faster than traditional metrics such as loss or accuracy, enabling practitioners to identify optimal WD (hyperparameter) values within the early stages of training. By leveraging OUI as a reliable indicator, we can determine early in training whether the chosen WD value leads the model to underfit the training data, overfit, or strike a well-balanced trade-off that maximizes validation scores. This enables more precise WD tuning for optimal performance on the tested datasets and DNNs. All code for reproducing these experiments is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17160",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.767592Z"
  },
  {
    "id": "93dc71f599820bb3c76e8c5c5ded44f9",
    "title": "A Double-Norm Aggregated Tensor Latent Factorization Model for Temporal-Aware Traffic Speed Imputation",
    "slug": "a-double-norm-aggregated-tensor-latent-factorization-model-for-temporal-aware-traffic-speed-imputation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jiawen Hou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In intelligent transportation systems (ITS), traffic management departments rely on sensors, cameras, and GPS devices to collect real-time traffic data. Traffic speed data is often incomplete due to sensor failures, data transmission delays, or occlusions, resulting in missing speed data in certain road segments. Currently, tensor decomposition based methods are extensively utilized, they mostly rely on the $L_2$-norm to construct their learning objectives, which leads to reduced robustness in the algorithms. To address this, we propose Temporal-Aware Traffic Speed Imputation (TATSI), which combines the $L_2$-norm and smooth $L_1$ (${SL}_1$)-norm in its loss function, thereby achieving both high accuracy and robust performance in imputing missing time-varying traffic speed data. TATSI adopts a single latent factor-dependent, nonnegative, and multiplicative update (SLF-NMU) approach, which serves as an efficient solver for performing nonnegative latent factor analysis (LFA) on a tensor. Empirical studies on three real-world time-varying traffic speed datasets demonstrate that, compared with state-of-the-art traffic speed predictors, TATSI more precisely captures temporal patterns, thereby yielding the most accurate imputations for missing traffic speed data.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17196",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.767790Z"
  },
  {
    "id": "42a2b858f6c3949365352c6e601241a5",
    "title": "Synthetic Power Flow Data Generation Using Physics-Informed Denoising Diffusion Probabilistic Models",
    "slug": "synthetic-power-flow-data-generation-using-physics-informed-denoising-diffusion-probabilistic-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Junfei Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many data-driven modules in smart grid rely on access to high-quality power flow data; however, real-world data are often limited due to privacy and operational constraints. This paper presents a physics-informed generative framework based on Denoising Diffusion Probabilistic Models (DDPMs) for synthesizing feasible power flow data. By incorporating auxiliary training and physics-informed loss functions, the proposed method ensures that the generated data exhibit both statistical fidelity and adherence to power system feasibility. We evaluate the approach on the IEEE 14-bus and 30-bus benchmark systems, demonstrating its ability to capture key distributional properties and generalize to out-of-distribution scenarios. Comparative results show that the proposed model outperforms three baseline models in terms of feasibility, diversity, and accuracy of statistical features. This work highlights the potential of integrating generative modelling into data-driven power system applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17210",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.767997Z"
  },
  {
    "id": "3832b9b58a81c253d518510694906ffa",
    "title": "Enhancing Variational Autoencoders with Smooth Robust Latent Encoding",
    "slug": "enhancing-variational-autoencoders-with-smooth-robust-latent-encoding",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hyomin Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Variational Autoencoders (VAEs) have played a key role in scaling up diffusion-based generative models, as in Stable Diffusion, yet questions regarding their robustness remain largely underexplored. Although adversarial training has been an established technique for enhancing robustness in predictive models, it has been overlooked for generative models due to concerns about potential fidelity degradation by the nature of trade-offs between performance and robustness. In this work, we challenge this presumption, introducing Smooth Robust Latent VAE (SRL-VAE), a novel adversarial training framework that boosts both generation quality and robustness. In contrast to conventional adversarial training, which focuses on robustness only, our approach smooths the latent space via adversarial perturbations, promoting more generalizable representations while regularizing with originality representation to sustain original fidelity. Applied as a post-training step on pre-trained VAEs, SRL-VAE improves image robustness and fidelity with minimal computational overhead. Experiments show that SRL-VAE improves both generation quality, in image reconstruction and text-guided image editing, and robustness, against Nightshade attacks and image editing attacks. These results establish a new paradigm, showing that adversarial training, once thought to be detrimental to generative models, can instead enhance both fidelity and robustness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17219",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.768226Z"
  },
  {
    "id": "810e32412d7900838f3388a8594f10c2",
    "title": "Multi-Modal Traffic Analysis: Integrating Time-Series Forecasting, Accident Prediction, and Image Classification",
    "slug": "multi-modal-traffic-analysis:-integrating-time-series-forecasting,-accident-prediction,-and-image-classification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Nivedita M",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study proposes an integrated machine learning framework for advanced traffic analysis, combining time-series forecasting, classification, and computer vision techniques. The system utilizes an ARIMA(2,0,1) model for traffic prediction (MAE: 2.1), an XGBoost classifier for accident severity classification (100% accuracy on balanced data), and a Convolutional Neural Network (CNN) for traffic image classification (92% accuracy). Tested on diverse datasets, the framework outperforms baseline models and identifies key factors influencing accident severity, including weather and road infrastructure. Its modular design supports deployment in smart city systems for real-time monitoring, accident prevention, and resource optimization, contributing to the evolution of intelligent transportation systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17232",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.768427Z"
  },
  {
    "id": "14a39ac272764c12fb3d997a441b6782",
    "title": "NeuralGrok: Accelerate Grokking by Neural Gradient Transformation",
    "slug": "neuralgrok:-accelerate-grokking-by-neural-gradient-transformation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Xinyu Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Grokking is proposed and widely studied as an intricate phenomenon in which generalization is achieved after a long-lasting period of overfitting. In this work, we propose NeuralGrok, a novel gradient-based approach that learns an optimal gradient transformation to accelerate the generalization of transformers in arithmetic tasks. Specifically, NeuralGrok trains an auxiliary module (e.g., an MLP block) in conjunction with the base model. This module dynamically modulates the influence of individual gradient components based on their contribution to generalization, guided by a bilevel optimization algorithm. Our extensive experiments demonstrate that NeuralGrok significantly accelerates generalization, particularly in challenging arithmetic tasks. We also show that NeuralGrok promotes a more stable training paradigm, constantly reducing the model's complexity, while traditional regularization methods, such as weight decay, can introduce substantial instability and impede generalization. We further investigate the intrinsic model complexity leveraging a novel Absolute Gradient Entropy (AGE) metric, which explains that NeuralGrok effectively facilitates generalization by reducing the model complexity. We offer valuable insights on the grokking phenomenon of Transformer models, which encourages a deeper understanding of the fundamental principles governing generalization ability.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17243",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.768632Z"
  },
  {
    "id": "0b85ed7d5ee66eb6fc8590e240673606",
    "title": "Targeted AMP generation through controlled diffusion with efficient embeddings",
    "slug": "targeted-amp-generation-through-controlled-diffusion-with-efficient-embeddings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Diogo Soares",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deep learning-based antimicrobial peptide (AMP) discovery faces critical challenges such as low experimental hit rates as well as the need for nuanced controllability and efficient modeling of peptide properties. To address these challenges, we introduce OmegAMP, a framework that leverages a diffusion-based generative model with efficient low-dimensional embeddings, precise controllability mechanisms, and novel classifiers with drastically reduced false positive rates for candidate filtering. OmegAMP enables the targeted generation of AMPs with specific physicochemical properties, activity profiles, and species-specific effectiveness. Moreover, it maximizes sample diversity while ensuring faithfulness to the underlying data distribution during generation. We demonstrate that OmegAMP achieves state-of-the-art performance across all stages of the AMP discovery pipeline, significantly advancing the potential of computational frameworks in combating antimicrobial resistance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17247",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.768862Z"
  },
  {
    "id": "2db535dab7f7a4b99959939e62fb4c44",
    "title": "Group Downsampling with Equivariant Anti-aliasing",
    "slug": "group-downsampling-with-equivariant-anti-aliasing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Md Ashiqur Rahman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Downsampling layers are crucial building blocks in CNN architectures, which help to increase the receptive field for learning high-level features and reduce the amount of memory/computation in the model. In this work, we study the generalization of the uniform downsampling layer for group equivariant architectures, e.g., G-CNNs. That is, we aim to downsample signals (feature maps) on general finite groups with anti-aliasing. This involves the following: (a) Given a finite group and a downsampling rate, we present an algorithm to form a suitable choice of subgroup. (b) Given a group and a subgroup, we study the notion of bandlimited-ness and propose how to perform anti-aliasing. Notably, our method generalizes the notion of downsampling based on classical sampling theory. When the signal is on a cyclic group, i.e., periodic, our method recovers the standard downsampling of an ideal low-pass filter followed by a subsampling operation. Finally, we conducted experiments on image classification tasks demonstrating that the proposed downsampling operation improves accuracy, better preserves equivariance, and reduces model size when incorporated into G-equivariant networks",
    "pdfUrl": "https://arxiv.org/pdf/2504.17258",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.769237Z"
  },
  {
    "id": "294fccd88d27dc116f07d9f4301c75fd",
    "title": "Symbolic Representation for Any-to-Any Generative Tasks",
    "slug": "symbolic-representation-for-any-to-any-generative-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jiaqi Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a symbolic generative task description language and a corresponding inference engine capable of representing arbitrary multimodal tasks as structured symbolic flows. Unlike conventional generative models that rely on large-scale training and implicit neural representations to learn cross-modal mappings, often at high computational cost and with limited flexibility, our framework introduces an explicit symbolic representation comprising three core primitives: functions, parameters, and topological logic. Leveraging a pre-trained language model, our inference engine maps natural language instructions directly to symbolic workflows in a training-free manner. Our framework successfully performs over 12 diverse multimodal generative tasks, demonstrating strong performance and flexibility without the need for task-specific tuning. Experiments show that our method not only matches or outperforms existing state-of-the-art unified models in content quality, but also offers greater efficiency, editability, and interruptibility. We believe that symbolic task representations provide a cost-effective and extensible foundation for advancing the capabilities of generative AI.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17261",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.769634Z"
  },
  {
    "id": "6ba5e6b1adc5410bf58bf806e4186a15",
    "title": "Signal Recovery from Random Dot-Product Graphs Under Local Differential Privacy",
    "slug": "signal-recovery-from-random-dot-product-graphs-under-local-differential-privacy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Siddharth Vishwanath",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider the problem of recovering latent information from graphs under $\\varepsilon$-edge local differential privacy where the presence of relationships/edges between two users/vertices remains confidential, even from the data curator. For the class of generalized random dot-product graphs, we show that a standard local differential privacy mechanism induces a specific geometric distortion in the latent positions. Leveraging this insight, we show that consistent recovery of the latent positions is achievable by appropriately adjusting the statistical inference procedure for the privatized graph. Furthermore, we prove that our procedure is nearly minimax-optimal under local edge differential privacy constraints. Lastly, we show that this framework allows for consistent recovery of geometric and topological information underlying the latent positions, as encoded in their persistence diagrams. Our results extend previous work from the private community detection literature to a substantially richer class of models and inferential tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17274",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.769932Z"
  },
  {
    "id": "b7747bf30c389d33be552382ff1713d5",
    "title": "HeRB: Heterophily-Resolved Structure Balancer for Graph Neural Networks",
    "slug": "herb:-heterophily-resolved-structure-balancer-for-graph-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ke-Jia Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent research has witnessed the remarkable progress of Graph Neural Networks (GNNs) in the realm of graph data representation. However, GNNs still encounter the challenge of structural imbalance. Prior solutions to this problem did not take graph heterophily into account, namely that connected nodes process distinct labels or features, thus resulting in a deficiency in effectiveness. Upon verifying the impact of heterophily on solving the structural imbalance problem, we propose to rectify the heterophily first and then transfer homophilic knowledge. To the end, we devise a method named HeRB (Heterophily-Resolved Structure Balancer) for GNNs. HeRB consists of two innovative components: 1) A heterophily-lessening augmentation module which serves to reduce inter-class edges and increase intra-class edges; 2) A homophilic knowledge transfer mechanism to convey homophilic information from head nodes to tail nodes. Experimental results demonstrate that HeRB achieves superior performance on two homophilic and six heterophilic benchmark datasets, and the ablation studies further validate the efficacy of two proposed components.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17276",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.770164Z"
  },
  {
    "id": "dae2c56ed68376f5b70d5c1ab2fa2680",
    "title": "ExOSITO: Explainable Off-Policy Learning with Side Information for Intensive Care Unit Blood Test Orders",
    "slug": "exosito:-explainable-off-policy-learning-with-side-information-for-intensive-care-unit-blood-test-orders",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zongliang Ji",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Ordering a minimal subset of lab tests for patients in the intensive care unit (ICU) can be challenging. Care teams must balance between ensuring the availability of the right information and reducing the clinical burden and costs associated with each lab test order. Most in-patient settings experience frequent over-ordering of lab tests, but are now aiming to reduce this burden on both hospital resources and the environment. This paper develops a novel method that combines off-policy learning with privileged information to identify the optimal set of ICU lab tests to order. Our approach, EXplainable Off-policy learning with Side Information for ICU blood Test Orders (ExOSITO) creates an interpretable assistive tool for clinicians to order lab tests by considering both the observed and predicted future status of each patient. We pose this problem as a causal bandit trained using offline data and a reward function derived from clinically-approved rules; we introduce a novel learning framework that integrates clinical knowledge with observational data to bridge the gap between the optimal and logging policies. The learned policy function provides interpretable clinical information and reduces costs without omitting any vital lab orders, outperforming both a physician's policy and prior approaches to this practical problem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17277",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.770374Z"
  },
  {
    "id": "64c1fc4d4ea0ea077766f9f183efc86a",
    "title": "The Ultimate Cookbook for Invisible Poison: Crafting Subtle Clean-Label Text Backdoors with Style Attributes",
    "slug": "the-ultimate-cookbook-for-invisible-poison:-crafting-subtle-clean-label-text-backdoors-with-style-attributes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Wencong You",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Backdoor attacks on text classifiers can cause them to predict a predefined label when a particular \"trigger\" is present. Prior attacks often rely on triggers that are ungrammatical or otherwise unusual, leading to conspicuous attacks. As a result, human annotators, who play a critical role in curating training data in practice, can easily detect and filter out these unnatural texts during manual inspection, reducing the risk of such attacks. We argue that a key criterion for a successful attack is for text with and without triggers to be indistinguishable to humans. However, prior work neither directly nor comprehensively evaluated attack subtlety and invisibility with human involvement. We bridge the gap by conducting thorough human evaluations to assess attack subtlety. We also propose \\emph{AttrBkd}, consisting of three recipes for crafting subtle yet effective trigger attributes, such as extracting fine-grained attributes from existing baseline backdoor attacks. Our human evaluations find that AttrBkd with these baseline-derived attributes is often more effective (higher attack success rate) and more subtle (fewer instances detected by humans) than the original baseline backdoor attacks, demonstrating that backdoor attacks can bypass detection by being inconspicuous and appearing natural even upon close inspection, while still remaining effective. Our human annotation also provides information not captured by automated metrics used in prior work, and demonstrates the misalignment of these metrics with human judgment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17300",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.770574Z"
  },
  {
    "id": "0fc29cc5e5b77442d695038ab86180ce",
    "title": "Machine learning-based condition monitoring of powertrains in modern electric drives",
    "slug": "machine-learning-based-condition-monitoring-of-powertrains-in-modern-electric-drives",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Dinan Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The recent technological advances in digitalization have revolutionized the industrial sector. Leveraging data analytics has now enabled the collection of deep insights into the performance and, as a result, the optimization of assets. Industrial drives, for example, already accumulate all the necessary information to control electric machines. These signals include but are not limited to currents, frequency, and temperature. Integrating machine learning (ML) models responsible for predicting the evolution of those directly collected or implicitly derived parameters enhances the smartness of industrial systems even further. In this article, data already residing in most modern electric drives has been used to develop a data-driven thermal model of a power module. A test bench has been designed and used specifically for training and validating the thermal digital twin undergoing various static and dynamic operating profiles. Different approaches, from traditional linear models to deep neural networks, have been implemented to emanate the best ML model for estimating the case temperature of a power module. Several evaluation metrics were then used to assess the investigated methods' performance and implementation in industrial embedded systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17305",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.770780Z"
  },
  {
    "id": "939e40318bd4d436f29eb7d08ea54038",
    "title": "Class-Conditional Distribution Balancing for Group Robust Classification",
    "slug": "class-conditional-distribution-balancing-for-group-robust-classification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Miaoyun Zhao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Spurious correlations that lead models to correct predictions for the wrong reasons pose a critical challenge for robust real-world generalization. Existing research attributes this issue to group imbalance and addresses it by maximizing group-balanced or worst-group accuracy, which heavily relies on expensive bias annotations. A compromise approach involves predicting bias information using extensively pretrained foundation models, which requires large-scale data and becomes impractical for resource-limited rare domains. To address these challenges, we offer a novel perspective by reframing the spurious correlations as imbalances or mismatches in class-conditional distributions, and propose a simple yet effective robust learning method that eliminates the need for both bias annotations and predictions. With the goal of reducing the mutual information between spurious factors and label information, our method leverages a sample reweighting strategy to achieve class-conditional distribution balancing, which automatically highlights minority groups and classes, effectively dismantling spurious correlations and producing a debiased data distribution for classification. Extensive experiments and analysis demonstrate that our approach consistently delivers state-of-the-art performance, rivaling methods that rely on bias supervision.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17314",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.770978Z"
  },
  {
    "id": "ad3ff3e7b756d22318bde23e81f37fb7",
    "title": "Collaborative Multi-Agent Reinforcement Learning for Automated Feature Transformation with Graph-Driven Path Optimization",
    "slug": "collaborative-multi-agent-reinforcement-learning-for-automated-feature-transformation-with-graph-driven-path-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Xiaohan Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Feature transformation methods aim to find an optimal mathematical feature-feature crossing process that generates high-value features and improves the performance of downstream machine learning tasks. Existing frameworks, though designed to mitigate manual costs, often treat feature transformations as isolated operations, ignoring dynamic dependencies between transformation steps. To address the limitations, we propose TCTO, a collaborative multi-agent reinforcement learning framework that automates feature engineering through graph-driven path optimization. The framework's core innovation lies in an evolving interaction graph that models features as nodes and transformations as edges. Through graph pruning and backtracking, it dynamically eliminates low-impact edges, reduces redundant operations, and enhances exploration stability. This graph also provides full traceability to empower TCTO to reuse high-utility subgraphs from historical transformations. To demonstrate the efficacy and adaptability of our approach, we conduct comprehensive experiments and case studies, which show superior performance across a range of datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17355",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.771215Z"
  },
  {
    "id": "4b062aeaf3284edc6fd343b3518eec96",
    "title": "Doubly Adaptive Social Learning",
    "slug": "doubly-adaptive-social-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Marco Carpentiero",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In social learning, a network of agents assigns probability scores (beliefs) to some hypotheses of interest, which rule the generation of local streaming data observed by each agent. Belief formation takes place by means of an iterative two-step procedure where: i) the agents update locally their beliefs by using some likelihood model; and ii) the updated beliefs are combined with the beliefs of the neighboring agents, using a pooling rule. This procedure can fail to perform well in the presence of dynamic drifts, leading the agents to incorrect decision making. Here, we focus on the fully online setting where both the true hypothesis and the likelihood models can change over time. We propose the doubly adaptive social learning ($\\text{A}^2\\text{SL}$) strategy, which infuses social learning with the necessary adaptation capabilities. This goal is achieved by exploiting two adaptation stages: i) a stochastic gradient descent update to learn and track the drifts in the decision model; ii) and an adaptive belief update to track the true hypothesis changing over time. These stages are controlled by two adaptation parameters that govern the evolution of the error probability for each agent. We show that all agents learn consistently for sufficiently small adaptation parameters, in the sense that they ultimately place all their belief mass on the true hypothesis. In particular, the probability of choosing the wrong hypothesis converges to values on the order of the adaptation parameters. The theoretical analysis is illustrated both on synthetic data and by applying the $\\text{A}^2\\text{SL}$ strategy to a social learning problem in the online setting using real data.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17370",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.771421Z"
  },
  {
    "id": "6a2e639759a35dd90c4596d572ba6d49",
    "title": "Coding for Computation: Efficient Compression of Neural Networks for Reconfigurable Hardware",
    "slug": "coding-for-computation:-efficient-compression-of-neural-networks-for-reconfigurable-hardware",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hans Rosenberger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As state of the art neural networks (NNs) continue to grow in size, their resource-efficient implementation becomes ever more important. In this paper, we introduce a compression scheme that reduces the number of computations required for NN inference on reconfigurable hardware such as FPGAs. This is achieved by combining pruning via regularized training, weight sharing and linear computation coding (LCC). Contrary to common NN compression techniques, where the objective is to reduce the memory used for storing the weights of the NNs, our approach is optimized to reduce the number of additions required for inference in a hardware-friendly manner. The proposed scheme achieves competitive performance for simple multilayer perceptrons, as well as for large scale deep NNs such as ResNet-34.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17403",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.771652Z"
  },
  {
    "id": "cd5de82eb543cdfa5384db4c0fb72684",
    "title": "Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks",
    "slug": "towards-harnessing-the-collaborative-power-of-large-and-small-models-for-domain-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yang Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large language models (LLMs) have demonstrated remarkable capabilities, but they require vast amounts of data and computational resources. In contrast, smaller models (SMs), while less powerful, can be more efficient and tailored to specific domains. In this position paper, we argue that taking a collaborative approach, where large and small models work synergistically, can accelerate the adaptation of LLMs to private domains and unlock new potential in AI. We explore various strategies for model collaboration and identify potential challenges and opportunities. Building upon this, we advocate for industry-driven research that prioritizes multi-objective benchmarks on real-world private datasets and applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17421",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.771886Z"
  },
  {
    "id": "a7d4b3664c2c038482f1091445bd2765",
    "title": "CHASe: Client Heterogeneity-Aware Data Selection for Effective Federated Active Learning",
    "slug": "chase:-client-heterogeneity-aware-data-selection-for-effective-federated-active-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jun Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Active learning (AL) reduces human annotation costs for machine learning systems by strategically selecting the most informative unlabeled data for annotation, but performing it individually may still be insufficient due to restricted data diversity and annotation budget. Federated Active Learning (FAL) addresses this by facilitating collaborative data selection and model training, while preserving the confidentiality of raw data samples. Yet, existing FAL methods fail to account for the heterogeneity of data distribution across clients and the associated fluctuations in global and local model parameters, adversely affecting model accuracy. To overcome these challenges, we propose CHASe (Client Heterogeneity-Aware Data Selection), specifically designed for FAL. CHASe focuses on identifying those unlabeled samples with high epistemic variations (EVs), which notably oscillate around the decision boundaries during training. To achieve both effectiveness and efficiency, \\model{} encompasses techniques for 1) tracking EVs by analyzing inference inconsistencies across training epochs, 2) calibrating decision boundaries of inaccurate models with a new alignment loss, and 3) enhancing data selection efficiency via a data freeze and awaken mechanism with subset sampling. Experiments show that CHASe surpasses various established baselines in terms of effectiveness and efficiency, validated across diverse datasets, model complexities, and heterogeneous federation settings.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17448",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.772102Z"
  },
  {
    "id": "e343f1498347f73eb0cd13537fff7472",
    "title": "HMI: Hierarchical Knowledge Management for Efficient Multi-Tenant Inference in Pretrained Language Models",
    "slug": "hmi:-hierarchical-knowledge-management-for-efficient-multi-tenant-inference-in-pretrained-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jun Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The significant computational demands of pretrained language models (PLMs), which often require dedicated hardware, present a substantial challenge in serving them efficiently, especially in multi-tenant environments. To address this, we introduce HMI, a Hierarchical knowledge management-based Multi-tenant Inference system, designed to manage tenants with distinct PLMs resource-efficiently. Our approach is three-fold: Firstly, we categorize PLM knowledge into general, domain-specific, and task-specific. Leveraging insights on knowledge acquisition across different model layers, we construct hierarchical PLMs (hPLMs) by extracting and storing knowledge at different levels, significantly reducing GPU memory usage per tenant. Secondly, we establish hierarchical knowledge management for hPLMs generated by various tenants in HMI. We manage domain-specific knowledge with acceptable storage increases by constructing and updating domain-specific knowledge trees based on frequency. We manage task-specific knowledge within limited GPU memory through parameter swapping. Finally, we propose system optimizations to enhance resource utilization and inference throughput. These include fine-grained pipelining via hierarchical knowledge prefetching to overlap CPU and I/O operations with GPU computations, and optimizing parallel implementations with batched matrix multiplications. Our experimental results demonstrate that the proposed HMI can efficiently serve up to 10,000 hPLMs (hBERTs and hGPTs) on a single GPU, with only a negligible compromise in accuracy.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17449",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.772330Z"
  },
  {
    "id": "287fe1045a9783e4fbd0cf14ad5e6800",
    "title": "Evaluating Time Series Models for Urban Wastewater Management: Predictive Performance, Model Complexity and Resilience",
    "slug": "evaluating-time-series-models-for-urban-wastewater-management:-predictive-performance,-model-complexity-and-resilience",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Vipin Singh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Climate change increases the frequency of extreme rainfall, placing a significant strain on urban infrastructures, especially Combined Sewer Systems (CSS). Overflows from overburdened CSS release untreated wastewater into surface waters, posing environmental and public health risks. Although traditional physics-based models are effective, they are costly to maintain and difficult to adapt to evolving system dynamics. Machine Learning (ML) approaches offer cost-efficient alternatives with greater adaptability. To systematically assess the potential of ML for modeling urban infrastructure systems, we propose a protocol for evaluating Neural Network architectures for CSS time series forecasting with respect to predictive performance, model complexity, and robustness to perturbations. In addition, we assess model performance on peak events and critical fluctuations, as these are the key regimes for urban wastewater management. To investigate the feasibility of lightweight models suitable for IoT deployment, we compare global models, which have access to all information, with local models, which rely solely on nearby sensor readings. Additionally, to explore the security risks posed by network outages or adversarial attacks on urban infrastructure, we introduce error models that assess the resilience of models. Our results demonstrate that while global models achieve higher predictive performance, local models provide sufficient resilience in decentralized scenarios, ensuring robust modeling of urban infrastructure. Furthermore, models with longer native forecast horizons exhibit greater robustness to data perturbations. These findings contribute to the development of interpretable and reliable ML solutions for sustainable urban wastewater management. The implementation is available in our GitHub repository.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17461",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.772540Z"
  },
  {
    "id": "c1ca163d2f9b49caec431b78426c9bff",
    "title": "GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework",
    "slug": "granite-:-a-byzantine-resilient-dynamic-gossip-learning-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yacine Belal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Gossip Learning (GL) is a decentralized learning paradigm where users iteratively exchange and aggregate models with a small set of neighboring peers. Recent GL approaches rely on dynamic communication graphs built and maintained using Random Peer Sampling (RPS) protocols. Thanks to graph dynamics, GL can achieve fast convergence even over extremely sparse topologies. However, the robustness of GL over dy- namic graphs to Byzantine (model poisoning) attacks remains unaddressed especially when Byzantine nodes attack the RPS protocol to scale up model poisoning. We address this issue by introducing GRANITE, a framework for robust learning over sparse, dynamic graphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two key components (i) a History-aware Byzantine-resilient Peer Sampling protocol (HaPS), which tracks previously encountered identifiers to reduce adversarial influence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which leverages an estimate of Byzantine presence to set aggregation thresholds with formal guarantees. Empirical results confirm that GRANITE maintains convergence with up to 30% Byzantine nodes, improves learning speed via adaptive filtering of poisoned models and obtains these results in up to 9 times sparser graphs than dictated by current theory.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17471",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.772741Z"
  },
  {
    "id": "9d150ffdcd7b1919497080745bad98c6",
    "title": "Plasticine: Accelerating Research in Plasticity-Motivated Deep Reinforcement Learning",
    "slug": "plasticine:-accelerating-research-in-plasticity-motivated-deep-reinforcement-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Mingqi Yuan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Developing lifelong learning agents is crucial for artificial general intelligence. However, deep reinforcement learning (RL) systems often suffer from plasticity loss, where neural networks gradually lose their ability to adapt during training. Despite its significance, this field lacks unified benchmarks and evaluation protocols. We introduce Plasticine, the first open-source framework for benchmarking plasticity optimization in deep RL. Plasticine provides single-file implementations of over 13 mitigation methods, 10 evaluation metrics, and learning scenarios with increasing non-stationarity levels from standard to open-ended environments. This framework enables researchers to systematically quantify plasticity loss, evaluate mitigation strategies, and analyze plasticity dynamics across different contexts. Our documentation, examples, and source code are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17490",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.772975Z"
  },
  {
    "id": "1c1d78293a73d8e054a5772478be901d",
    "title": "Prototype-enhanced prediction in graph neural networks for climate applications",
    "slug": "prototype-enhanced-prediction-in-graph-neural-networks-for-climate-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Nawid Keshtmand",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Data-driven emulators are increasingly being used to learn and emulate physics-based simulations, reducing computational expense and run time. Here, we present a structured way to improve the quality of these high-dimensional emulated outputs, through the use of prototypes: an approximation of the emulator's output passed as an input, which informs the model and leads to better predictions. We demonstrate our approach to emulate atmospheric dispersion, key for greenhouse gas emissions monitoring, by comparing a baseline model to models trained using prototypes as an additional input. The prototype models achieve better performance, even with few prototypes and even if they are chosen at random, but we show that choosing the prototypes through data-driven methods (k-means) can lead to almost 10\\% increased performance in some metrics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17492",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.773190Z"
  },
  {
    "id": "7c282a4b228de505b66331d407f17535",
    "title": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design",
    "slug": "goal-oriented-time-series-forecasting:-foundation-framework-design",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Luca-Andrei Fechete",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Traditional time-series forecasting often focuses only on minimizing prediction errors, ignoring the specific requirements of real-world applications that employ them. This paper presents a new training methodology, which allows a forecasting model to dynamically adjust its focus based on the importance of forecast ranges specified by the end application. Unlike previous methods that fix these ranges beforehand, our training approach breaks down predictions over the entire signal range into smaller segments, which are then dynamically weighted and combined to produce accurate forecasts. We tested our method on standard datasets, including a new dataset from wireless communication, and found that not only it improves prediction accuracy but also improves the performance of end application employing the forecasting model. This research provides a basis for creating forecasting systems that better connect prediction and decision-making in various practical applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17493",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.773414Z"
  },
  {
    "id": "af1f43cada66e22dabff0ab8aea9acd8",
    "title": "Combining GCN Structural Learning with LLM Chemical Knowledge for or Enhanced Virtual Screening",
    "slug": "combining-gcn-structural-learning-with-llm-chemical-knowledge-for-or-enhanced-virtual-screening",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Radia Berreziga",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Virtual screening plays a critical role in modern drug discovery by enabling the identification of promising candidate molecules for experimental validation. Traditional machine learning methods such as support vector machines (SVM) and XGBoost rely on predefined molecular representations, often leading to information loss and potential bias. In contrast, deep learning approaches-particularly Graph Convolutional Networks (GCNs)-offer a more expressive and unbiased alternative by operating directly on molecular graphs. Meanwhile, Large Language Models (LLMs) have recently demonstrated state-of-the-art performance in drug design, thanks to their capacity to capture complex chemical patterns from large-scale data via attention mechanisms.\nIn this paper, we propose a hybrid architecture that integrates GCNs with LLM-derived embeddings to combine localized structural learning with global chemical knowledge. The LLM embeddings can be precomputed and stored in a molecular feature library, removing the need to rerun the LLM during training or inference and thus maintaining computational efficiency. We found that concatenating the LLM embeddings after each GCN layer-rather than only at the final layer-significantly improves performance, enabling deeper integration of global context throughout the network. The resulting model achieves superior results, with an F1-score of (88.8%), outperforming standalone GCN (87.9%), XGBoost (85.5%), and SVM (85.4%) baselines.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17497",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.773614Z"
  },
  {
    "id": "45337fb21815bebff925a830ef945b7b",
    "title": "Tailored minimal reservoir computing: on the bidirectional connection between nonlinearities in the reservoir and in data",
    "slug": "tailored-minimal-reservoir-computing:-on-the-bidirectional-connection-between-nonlinearities-in-the-reservoir-and-in-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Davide Prosperino",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study how the degree of nonlinearity in the input data affects the optimal design of reservoir computers, focusing on how closely the model's nonlinearity should align with that of the data. By reducing minimal RCs to a single tunable nonlinearity parameter, we explore how the predictive performance varies with the degree of nonlinearity in the reservoir. To provide controlled testbeds, we generalize to the fractional Halvorsen system, a novel chaotic system with fractional exponents. Our experiments reveal that the prediction performance is maximized when the reservoir's nonlinearity matches the nonlinearity present in the data. In cases where multiple nonlinearities are present in the data, we find that the correlation dimension of the predicted signal is reconstructed correctly when the smallest nonlinearity is matched. We use this observation to propose a method for estimating the minimal nonlinearity in unknown time series by sweeping the reservoir exponent and identifying the transition to a successful reconstruction. Applying this method to both synthetic and real-world datasets, including financial time series, we demonstrate its practical viability. Finally, we transfer these insights to classical RC by augmenting traditional architectures with fractional, generalized reservoir states. This yields performance gains, particularly in resource-constrained scenarios such as physical reservoirs, where increasing reservoir size is impractical or economically unviable. Our work provides a principled route toward tailoring RCs to the intrinsic complexity of the systems they aim to model.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17503",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.773822Z"
  },
  {
    "id": "5070e0388898d88eb1e79d09e34c8352",
    "title": "Communication-Efficient Personalized Distributed Learning with Data and Node Heterogeneity",
    "slug": "communication-efficient-personalized-distributed-learning-with-data-and-node-heterogeneity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhuojun Tian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "To jointly tackle the challenges of data and node heterogeneity in decentralized learning, we propose a distributed strong lottery ticket hypothesis (DSLTH), based on which a communication-efficient personalized learning algorithm is developed. In the proposed method, each local model is represented as the Hadamard product of global real-valued parameters and a personalized binary mask for pruning. The local model is learned by updating and fusing the personalized binary masks while the real-valued parameters are fixed among different agents. To further reduce the complexity of hardware implementation, we incorporate a group sparse regularization term in the loss function, enabling the learned local model to achieve structured sparsity. Then, a binary mask aggregation algorithm is designed by introducing an intermediate aggregation tensor and adding a personalized fine-tuning step in each iteration, which constrains model updates towards the local data distribution. The proposed method effectively leverages the relativity among agents while meeting personalized requirements in heterogeneous node conditions. We also provide a theoretical proof for the DSLTH, establishing it as the foundation of the proposed method. Numerical simulations confirm the validity of the DSLTH and demonstrate the effectiveness of the proposed algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17520",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.774028Z"
  },
  {
    "id": "7d8f74a715b9137c94db0da59c1e5f2c",
    "title": "Cooperative Task Offloading through Asynchronous Deep Reinforcement Learning in Mobile Edge Computing for Future Networks",
    "slug": "cooperative-task-offloading-through-asynchronous-deep-reinforcement-learning-in-mobile-edge-computing-for-future-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yuelin Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Future networks (including 6G) are poised to accelerate the realisation of Internet of Everything. However, it will result in a high demand for computing resources to support new services. Mobile Edge Computing (MEC) is a promising solution, enabling to offload computation-intensive tasks to nearby edge servers from the end-user devices, thereby reducing latency and energy consumption. However, relying solely on a single MEC server for task offloading can lead to uneven resource utilisation and suboptimal performance in complex scenarios. Additionally, traditional task offloading strategies specialise in centralised policy decisions, which unavoidably entail extreme transmission latency and reach computational bottleneck. To fill the gaps, we propose a latency and energy efficient Cooperative Task Offloading framework with Transformer-driven Prediction (CTO-TP), leveraging asynchronous multi-agent deep reinforcement learning to address these challenges. This approach fosters edge-edge cooperation and decreases the synchronous waiting time by performing asynchronous training, optimising task offloading, and resource allocation across distributed networks. The performance evaluation demonstrates that the proposed CTO-TP algorithm reduces up to 80% overall system latency and 87% energy consumption compared to the baseline schemes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17526",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.774238Z"
  },
  {
    "id": "c878159597f2fa1e6ef92b149ff66411",
    "title": "TACO: Tackling Over-correction in Federated Learning with Tailored Adaptive Correction",
    "slug": "taco:-tackling-over-correction-in-federated-learning-with-tailored-adaptive-correction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Weijie Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Non-independent and identically distributed (Non-IID) data across edge clients have long posed significant challenges to federated learning (FL) training in edge computing environments. Prior works have proposed various methods to mitigate this statistical heterogeneity. While these works can achieve good theoretical performance, in this work we provide the first investigation into a hidden over-correction phenomenon brought by the uniform model correction coefficients across clients adopted by existing methods. Such over-correction could degrade model performance and even cause failures in model convergence. To address this, we propose TACO, a novel algorithm that addresses the non-IID nature of clients' data by implementing fine-grained, client-specific gradient correction and model aggregation, steering local models towards a more accurate global optimum. Moreover, we verify that leading FL algorithms generally have better model accuracy in terms of communication rounds rather than wall-clock time, resulting from their extra computation overhead imposed on clients. To enhance the training efficiency, TACO deploys a lightweight model correction and tailored aggregation approach that requires minimum computation overhead and no extra information beyond the synchronized model parameters. To validate TACO's effectiveness, we present the first FL convergence analysis that reveals the root cause of over-correction. Extensive experiments across various datasets confirm TACO's superior and stable performance in practice.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17528",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.774459Z"
  },
  {
    "id": "5c41330d0bba75b3f42ea6d973fe2344",
    "title": "Learning Isometric Embeddings of Road Networks using Multidimensional Scaling",
    "slug": "learning-isometric-embeddings-of-road-networks-using-multidimensional-scaling",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Juan Carlos Climent Pardo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The lack of generalization in learning-based autonomous driving applications is shown by the narrow range of road scenarios that vehicles can currently cover. A generalizable approach should capture many distinct road structures and topologies, as well as consider traffic participants, and dynamic changes in the environment, so that vehicles can navigate and perform motion planning tasks even in the most difficult situations. Designing suitable feature spaces for neural network-based motion planers that encapsulate all kinds of road scenarios is still an open research challenge. This paper tackles this learning-based generalization challenge and shows how graph representations of road networks can be leveraged by using multidimensional scaling (MDS) techniques in order to obtain such feature spaces. State-of-the-art graph representations and MDS approaches are analyzed for the autonomous driving use case. Finally, the option of embedding graph nodes is discussed in order to perform easier learning procedures and obtain dimensionality reduction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17534",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.774649Z"
  },
  {
    "id": "0c7d06a1e47481b57db445b08d101b33",
    "title": "Beyond Cox Models: Assessing the Performance of Machine-Learning Methods in Non-Proportional Hazards and Non-Linear Survival Analysis",
    "slug": "beyond-cox-models:-assessing-the-performance-of-machine-learning-methods-in-non-proportional-hazards-and-non-linear-survival-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ivan Rossi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Survival analysis often relies on Cox models, assuming both linearity and proportional hazards (PH). This study evaluates machine and deep learning methods that relax these constraints, comparing their performance with penalized Cox models on a benchmark of three synthetic and three real datasets. In total, eight different models were tested, including six non-linear models of which four were also non-PH. Although Cox regression often yielded satisfactory performance, we showed the conditions under which machine and deep learning models can perform better. Indeed, the performance of these methods has often been underestimated due to the improper use of Harrell's concordance index (C-index) instead of more appropriate scores such as Antolini's concordance index, which generalizes C-index in cases where the PH assumption does not hold. In addition, since occasionally high C-index models happen to be badly calibrated, combining Antolini's C-index with Brier's score is useful to assess the overall performance of a survival method. Results on our benchmark data showed that survival prediction should be approached by testing different methods to select the most appropriate one according to sample size, non-linearity and non-PH conditions. To allow an easy reproducibility of these tests on our benchmark data, code and documentation are freely available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17568",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.774860Z"
  },
  {
    "id": "4a2942b63b71486e774480b3d76ea75b",
    "title": "TileLang: A Composable Tiled Programming Model for AI Systems",
    "slug": "tilelang:-a-composable-tiled-programming-model-for-ai-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Lei Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Modern AI workloads rely heavily on optimized computing kernels for both training and inference. These AI kernels follow well-defined data-flow patterns, such as moving tiles between DRAM and SRAM and performing a sequence of computations on those tiles. However, writing high-performance kernels remains complex despite the clarity of these patterns. Achieving peak performance requires careful, hardware-centric optimizations to fully leverage modern accelerators. While domain-specific compilers attempt to reduce the burden of writing high-performance kernels, they often struggle with usability and expressiveness gaps. In this paper, we present TileLang, a generalized tiled programming model for more efficient AI Kernel programming. TileLang decouples scheduling space (thread binding, layout, tensorize and pipeline) from dataflow, and encapsulated them as a set of customization annotations and primitives. This approach allows users to focus on the kernel's data-flow itself, while leaving most other optimizations to compilers. We conduct comprehensive experiments on commonly-used devices, across numerous experiments, our evaluation shows that TileLang can achieve state-of-the-art performance in key kernels, demonstrating that its unified block-and-thread paradigm and transparent scheduling capabilities deliver both the power and flexibility demanded by modern AI system development.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17577",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.775093Z"
  },
  {
    "id": "77e8ca97d3099e42cee85ef12f6763d3",
    "title": "Advancing CMA-ES with Learning-Based Cooperative Coevolution for Scalable Optimization",
    "slug": "advancing-cma-es-with-learning-based-cooperative-coevolution-for-scalable-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hongshu Guo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent research in Cooperative Coevolution~(CC) have achieved promising progress in solving large-scale global optimization problems. However, existing CC paradigms have a primary limitation in that they require deep expertise for selecting or designing effective variable decomposition strategies. Inspired by advancements in Meta-Black-Box Optimization, this paper introduces LCC, a pioneering learning-based cooperative coevolution framework that dynamically schedules decomposition strategies during optimization processes. The decomposition strategy selector is parameterized through a neural network, which processes a meticulously crafted set of optimization status features to determine the optimal strategy for each optimization step. The network is trained via the Proximal Policy Optimization method in a reinforcement learning manner across a collection of representative problems, aiming to maximize the expected optimization performance. Extensive experimental results demonstrate that LCC not only offers certain advantages over state-of-the-art baselines in terms of optimization effectiveness and resource consumption, but it also exhibits promising transferability towards unseen problems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17578",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.775304Z"
  },
  {
    "id": "c2456f359db0347f4e6dfd7608bf42bd",
    "title": "Interpretable non-linear dimensionality reduction using gaussian weighted linear transformation",
    "slug": "interpretable-non-linear-dimensionality-reduction-using-gaussian-weighted-linear-transformation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Erik Bergh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dimensionality reduction techniques are fundamental for analyzing and visualizing high-dimensional data. With established methods like t-SNE and PCA presenting a trade-off between representational power and interpretability. This paper introduces a novel approach that bridges this gap by combining the interpretability of linear methods with the expressiveness of non-linear transformations. The proposed algorithm constructs a non-linear mapping between high-dimensional and low-dimensional spaces through a combination of linear transformations, each weighted by Gaussian functions. This architecture enables complex non-linear transformations while preserving the interpretability advantages of linear methods, as each transformation can be analyzed independently. The resulting model provides both powerful dimensionality reduction and transparent insights into the transformed space. Techniques for interpreting the learned transformations are presented, including methods for identifying suppressed dimensions and how space is expanded and contracted. These tools enable practitioners to understand how the algorithm preserves and modifies geometric relationships during dimensionality reduction. To ensure the practical utility of this algorithm, the creation of user-friendly software packages is emphasized, facilitating its adoption in both academia and industry.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17601",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.775504Z"
  },
  {
    "id": "c584f7d19bfe46f3e40875de9a3e99d5",
    "title": "TarDiff: Target-Oriented Diffusion Guidance for Synthetic Electronic Health Record Time Series Generation",
    "slug": "tardiff:-target-oriented-diffusion-guidance-for-synthetic-electronic-health-record-time-series-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Bowen Deng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Synthetic Electronic Health Record (EHR) time-series generation is crucial for advancing clinical machine learning models, as it helps address data scarcity by providing more training data. However, most existing approaches focus primarily on replicating statistical distributions and temporal dependencies of real-world data. We argue that fidelity to observed data alone does not guarantee better model performance, as common patterns may dominate, limiting the representation of rare but important conditions. This highlights the need for generate synthetic samples to improve performance of specific clinical models to fulfill their target outcomes. To address this, we propose TarDiff, a novel target-oriented diffusion framework that integrates task-specific influence guidance into the synthetic data generation process. Unlike conventional approaches that mimic training data distributions, TarDiff optimizes synthetic samples by quantifying their expected contribution to improving downstream model performance through influence functions. Specifically, we measure the reduction in task-specific loss induced by synthetic samples and embed this influence gradient into the reverse diffusion process, thereby steering the generation towards utility-optimized data. Evaluated on six publicly available EHR datasets, TarDiff achieves state-of-the-art performance, outperforming existing methods by up to 20.4% in AUPRC and 18.4% in AUROC. Our results demonstrate that TarDiff not only preserves temporal fidelity but also enhances downstream model performance, offering a robust solution to data scarcity and class imbalance in healthcare analytics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17613",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.775711Z"
  },
  {
    "id": "be015d14f19ed9f82fe0932801fc2362",
    "title": "Decentralized Time Series Classification with ROCKET Features",
    "slug": "decentralized-time-series-classification-with-rocket-features",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Bruno Casella",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Time series classification (TSC) is a critical task with applications in various domains, including healthcare, finance, and industrial monitoring. Due to privacy concerns and data regulations, Federated Learning has emerged as a promising approach for learning from distributed time series data without centralizing raw information. However, most FL solutions rely on a client-server architecture, which introduces robustness and confidentiality risks related to the distinguished role of the server, which is a single point of failure and can observe knowledge extracted from clients. To address these challenges, we propose DROCKS, a fully decentralized FL framework for TSC that leverages ROCKET (RandOm Convolutional KErnel Transform) features. In DROCKS, the global model is trained by sequentially traversing a structured path across federation nodes, where each node refines the model and selects the most effective local kernels before passing them to the successor. Extensive experiments on the UCR archive demonstrate that DROCKS outperforms state-of-the-art client-server FL approaches while being more resilient to node failures and malicious attacks. Our code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17617",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.775922Z"
  },
  {
    "id": "8050e94f36f06c6541c7e0fa37ac4557",
    "title": "The effects of Hessian eigenvalue spectral density type on the applicability of Hessian analysis to generalization capability assessment of neural networks",
    "slug": "the-effects-of-hessian-eigenvalue-spectral-density-type-on-the-applicability-of-hessian-analysis-to-generalization-capability-assessment-of-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Nikita Gabdullin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Hessians of neural network (NN) contain essential information about the curvature of NN loss landscapes which can be used to estimate NN generalization capabilities. We have previously proposed generalization criteria that rely on the observation that Hessian eigenvalue spectral density (HESD) behaves similarly for a wide class of NNs. This paper further studies their applicability by investigating factors that can result in different types of HESD. We conduct a wide range of experiments showing that HESD mainly has positive eigenvalues (MP-HESD) for NN training and fine-tuning with various optimizers on different datasets with different preprocessing and augmentation procedures. We also show that mainly negative HESD (MN-HESD) is a consequence of external gradient manipulation, indicating that the previously proposed Hessian analysis methodology cannot be applied in such cases. We also propose criteria and corresponding conditions to determine HESD type and estimate NN generalization potential. These HESD types and previously proposed generalization criteria are combined into a unified HESD analysis methodology. Finally, we discuss how HESD changes during training, and show the occurrence of quasi-singular (QS) HESD and its influence on the proposed methodology and on the conventional assumptions about the relation between Hessian eigenvalues and NN loss landscape curvature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17618",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.776113Z"
  },
  {
    "id": "50ea81f47d17c12bcd660a242374743c",
    "title": "PTCL: Pseudo-Label Temporal Curriculum Learning for Label-Limited Dynamic Graph",
    "slug": "ptcl:-pseudo-label-temporal-curriculum-learning-for-label-limited-dynamic-graph",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Shengtao Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dynamic node classification is critical for modeling evolving systems like financial transactions and academic collaborations. In such systems, dynamically capturing node information changes is critical for dynamic node classification, which usually requires all labels at every timestamp. However, it is difficult to collect all dynamic labels in real-world scenarios due to high annotation costs and label uncertainty (e.g., ambiguous or delayed labels in fraud detection). In contrast, final timestamp labels are easier to obtain as they rely on complete temporal patterns and are usually maintained as a unique label for each user in many open platforms, without tracking the history data. To bridge this gap, we propose PTCL(Pseudo-label Temporal Curriculum Learning), a pioneering method addressing label-limited dynamic node classification where only final labels are available. PTCL introduces: (1) a temporal decoupling architecture separating the backbone (learning time-aware representations) and decoder (strictly aligned with final labels), which generate pseudo-labels, and (2) a Temporal Curriculum Learning strategy that prioritizes pseudo-labels closer to the final timestamp by assigning them higher weights using an exponentially decaying function. We contribute a new academic dataset (CoOAG), capturing long-range research interest in dynamic graph. Experiments across real-world scenarios demonstrate PTCL's consistent superiority over other methods adapted to this task. Beyond methodology, we propose a unified framework FLiD (Framework for Label-Limited Dynamic Node Classification), consisting of a complete preparation workflow, training pipeline, and evaluation standards, and supporting various models and datasets. The code can be found at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17641",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.776328Z"
  },
  {
    "id": "2635971a1de91b76163a038a7737c2ac",
    "title": "Aerial Image Classification in Scarce and Unconstrained Environments via Conformal Prediction",
    "slug": "aerial-image-classification-in-scarce-and-unconstrained-environments-via-conformal-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Farhad Pourkamali-Anaraki",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper presents a comprehensive empirical analysis of conformal prediction methods on a challenging aerial image dataset featuring diverse events in unconstrained environments. Conformal prediction is a powerful post-hoc technique that takes the output of any classifier and transforms it into a set of likely labels, providing a statistical guarantee on the coverage of the true label. Unlike evaluations on standard benchmarks, our study addresses the complexities of data-scarce and highly variable real-world settings. We investigate the effectiveness of leveraging pretrained models (MobileNet, DenseNet, and ResNet), fine-tuned with limited labeled data, to generate informative prediction sets. To further evaluate the impact of calibration, we consider two parallel pipelines (with and without temperature scaling) and assess performance using two key metrics: empirical coverage and average prediction set size. This setup allows us to systematically examine how calibration choices influence the trade-off between reliability and efficiency. Our findings demonstrate that even with relatively small labeled samples and simple nonconformity scores, conformal prediction can yield valuable uncertainty estimates for complex tasks. Moreover, our analysis reveals that while temperature scaling is often employed for calibration, it does not consistently lead to smaller prediction sets, underscoring the importance of careful consideration in its application. Furthermore, our results highlight the significant potential of model compression techniques within the conformal prediction pipeline for deployment in resource-constrained environments. Based on our observations, we advocate for future research to delve into the impact of noisy or ambiguous labels on conformal prediction performance and to explore effective model reduction strategies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17655",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.776522Z"
  },
  {
    "id": "703e5bdfbc5a9b906ccb04fc7bb75555",
    "title": "Effortless, Simulation-Efficient Bayesian Inference using Tabular Foundation Models",
    "slug": "effortless,-simulation-efficient-bayesian-inference-using-tabular-foundation-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Julius Vetter",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Simulation-based inference (SBI) offers a flexible and general approach to performing Bayesian inference: In SBI, a neural network is trained on synthetic data simulated from a model and used to rapidly infer posterior distributions for observed data. A key goal for SBI is to achieve accurate inference with as few simulations as possible, especially for expensive simulators. In this work, we address this challenge by repurposing recent probabilistic foundation models for tabular data: We show how tabular foundation models -- specifically TabPFN -- can be used as pre-trained autoregressive conditional density estimators for SBI. We propose Neural Posterior Estimation with Prior-data Fitted Networks (NPE-PF) and show that it is competitive with current SBI approaches in terms of accuracy for both benchmark tasks and two complex scientific inverse problems. Crucially, it often substantially outperforms them in terms of simulation efficiency, sometimes requiring orders of magnitude fewer simulations. NPE-PF eliminates the need for inference network selection, training, and hyperparameter tuning. We also show that it exhibits superior robustness to model misspecification and can be scaled to simulation budgets that exceed the context size limit of TabPFN. NPE-PF provides a new direction for SBI, where training-free, general-purpose inference models offer efficient, easy-to-use, and flexible solutions for a wide range of stochastic inverse problems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17660",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.776717Z"
  },
  {
    "id": "654c886ea4802e98834d2964f5ed5810",
    "title": "On Multivariate Financial Time Series Classification",
    "slug": "on-multivariate-financial-time-series-classification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Grgory Bournassenko",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This article investigates the use of Machine Learning and Deep Learning models in multivariate time series analysis within financial markets. It compares small and big data approaches, focusing on their distinct challenges and the benefits of scaling. Traditional methods such as SVMs are contrasted with modern architectures like ConvTimeNet. The results show the importance of using and understanding Big Data in depth in the analysis and prediction of financial time series.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17664",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.776904Z"
  },
  {
    "id": "b82347b232de122fc17469cca1512e4a",
    "title": "Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence",
    "slug": "federated-learning:-a-survey-on-privacy-preserving-collaborative-intelligence",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Edward Collins",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Federated Learning (FL) has emerged as a transformative paradigm in the field of distributed machine learning, enabling multiple clients such as mobile devices, edge nodes, or organizations to collaboratively train a shared global model without the need to centralize sensitive data. This decentralized approach addresses growing concerns around data privacy, security, and regulatory compliance, making it particularly attractive in domains such as healthcare, finance, and smart IoT systems. This survey provides a concise yet comprehensive overview of Federated Learning, beginning with its core architecture and communication protocol. We discuss the standard FL lifecycle, including local training, model aggregation, and global updates. A particular emphasis is placed on key technical challenges such as handling non-IID (non-independent and identically distributed) data, mitigating system and hardware heterogeneity, reducing communication overhead, and ensuring privacy through mechanisms like differential privacy and secure aggregation. Furthermore, we examine emerging trends in FL research, including personalized FL, cross-device versus cross-silo settings, and integration with other paradigms such as reinforcement learning and quantum computing. We also highlight real-world applications and summarize benchmark datasets and evaluation metrics commonly used in FL research. Finally, we outline open research problems and future directions to guide the development of scalable, efficient, and trustworthy FL systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17703",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.777111Z"
  },
  {
    "id": "66079ca9bd0c0d8d30b09ab85114012c",
    "title": "Fault Diagnosis in New Wind Turbines using Knowledge from Existing Turbines by Generative Domain Adaptation",
    "slug": "fault-diagnosis-in-new-wind-turbines-using-knowledge-from-existing-turbines-by-generative-domain-adaptation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Stefan Jonas",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Intelligent condition monitoring of wind turbines is essential for reducing downtimes. Machine learning models trained on wind turbine operation data are commonly used to detect anomalies and, eventually, operation faults. However, data-driven normal behavior models (NBMs) require a substantial amount of training data, as NBMs trained with scarce data may result in unreliable fault diagnosis. To overcome this limitation, we present a novel generative deep learning approach to make SCADA samples from one wind turbine lacking training data resemble SCADA data from wind turbines with representative training data. Through CycleGAN-based domain mapping, our method enables the application of an NBM trained on an existing wind turbine to one with severely limited data. We demonstrate our approach on field data mapping SCADA samples across 7 substantially different WTs. Our findings show significantly improved fault diagnosis in wind turbines with scarce data. Our method achieves the most similar anomaly scores to an NBM trained with abundant data, outperforming NBMs trained on scarce training data with improvements of +10.3% in F1-score when 1 month of training data is available and +16.8% when 2 weeks are available. The domain mapping approach outperforms conventional fine-tuning at all considered degrees of data scarcity, ranging from 1 to 8 weeks of training data. The proposed technique enables earlier and more reliable fault diagnosis in newly installed wind farms, demonstrating a novel and promising research direction to improve anomaly detection when faced with training data scarcity.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17709",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.777307Z"
  },
  {
    "id": "182c3cbcc707fe2798ce9e787fc69389",
    "title": "Early Detection of Multidrug Resistance Using Multivariate Time Series Analysis and Interpretable Patient-Similarity Representations",
    "slug": "early-detection-of-multidrug-resistance-using-multivariate-time-series-analysis-and-interpretable-patient-similarity-representations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "scar Escudero-Arnanz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Background and Objectives: Multidrug Resistance (MDR) is a critical global health issue, causing increased hospital stays, healthcare costs, and mortality. This study proposes an interpretable Machine Learning (ML) framework for MDR prediction, aiming for both accurate inference and enhanced explainability.\nMethods: Patients are modeled as Multivariate Time Series (MTS), capturing clinical progression and patient-to-patient interactions. Similarity among patients is quantified using MTS-based methods: descriptive statistics, Dynamic Time Warping, and Time Cluster Kernel. These similarity measures serve as inputs for MDR classification via Logistic Regression, Random Forest, and Support Vector Machines, with dimensionality reduction and kernel transformations improving model performance. For explainability, patient similarity networks are constructed from these metrics. Spectral clustering and t-SNE are applied to identify MDR-related subgroups and visualize high-risk clusters, enabling insight into clinically relevant patterns.\nResults: The framework was validated on ICU Electronic Health Records from the University Hospital of Fuenlabrada, achieving an AUC of 81%. It outperforms baseline ML and deep learning models by leveraging graph-based patient similarity. The approach identifies key risk factors -- prolonged antibiotic use, invasive procedures, co-infections, and extended ICU stays -- and reveals clinically meaningful clusters. Code and results are available at \\this https URL.\nConclusions: Patient similarity representations combined with graph-based analysis provide accurate MDR prediction and interpretable insights. This method supports early detection, risk factor identification, and patient stratification, highlighting the potential of explainable ML in critical care.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17717",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.777515Z"
  },
  {
    "id": "dc9a31365368682e8f2c2609ae63dd10",
    "title": "Conformal Segmentation in Industrial Surface Defect Detection with Statistical Guarantees",
    "slug": "conformal-segmentation-in-industrial-surface-defect-detection-with-statistical-guarantees",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Cheng Shen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In industrial settings, surface defects on steel can significantly compromise its service life and elevate potential safety risks. Traditional defect detection methods predominantly rely on manual inspection, which suffers from low efficiency and high costs. Although automated defect detection approaches based on Convolutional Neural Networks(e.g., Mask R-CNN) have advanced rapidly, their reliability remains challenged due to data annotation uncertainties during deep model training and overfitting issues. These limitations may lead to detection deviations when processing the given new test samples, rendering automated detection processes unreliable. To address this challenge, we first evaluate the detection model's practical performance through calibration data that satisfies the independent and identically distributed (i.i.d) condition with test data. Specifically, we define a loss function for each calibration sample to quantify detection error rates, such as the complement of recall rate and false discovery rate. Subsequently, we derive a statistically rigorous threshold based on a user-defined risk level to identify high-probability defective pixels in test images, thereby constructing prediction sets (e.g., defect regions). This methodology ensures that the expected error rate (mean error rate) on the test set remains strictly bounced by the predefined risk level. Additionally, we observe a negative correlation between the average prediction set size and the risk level on the test set, establishing a statistically rigorous metric for assessing detection model uncertainty. Furthermore, our study demonstrates robust and efficient control over the expected test set error rate across varying calibration-to-test partitioning ratios, validating the method's adaptability and operational effectiveness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17721",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.777730Z"
  },
  {
    "id": "03f07b0080c39dc0497c592d6abcc2da",
    "title": "Towards Robust LLMs: an Adversarial Robustness Measurement Framework",
    "slug": "towards-robust-llms:-an-adversarial-robustness-measurement-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Natan Levy",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rise of Large Language Models (LLMs) has revolutionized artificial intelligence, yet these models remain vulnerable to adversarial perturbations, undermining their reliability in high-stakes applications. While adversarial robustness in vision-based neural networks has been extensively studied, LLM robustness remains under-explored. We adapt the Robustness Measurement and Assessment (RoMA) framework to quantify LLM resilience against adversarial inputs without requiring access to model parameters. By comparing RoMA's estimates to those of formal verification methods, we demonstrate its accuracy with minimal error margins while maintaining computational efficiency. Our empirical evaluation reveals that robustness varies significantly not only between different models but also across categories within the same task and between various types of perturbations. This non-uniformity underscores the need for task-specific robustness evaluations, enabling practitioners to compare and select models based on application-specific robustness requirements. Our work provides a systematic methodology to assess LLM robustness, advancing the development of more reliable language models for real-world deployment.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17723",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.777937Z"
  },
  {
    "id": "fc235515fad086f831459d9b1b67b074",
    "title": "Interpretable Early Detection of Parkinson's Disease through Speech Analysis",
    "slug": "interpretable-early-detection-of-parkinson's-disease-through-speech-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Lorenzo Simone",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Parkinson's disease is a progressive neurodegenerative disorder affecting motor and non-motor functions, with speech impairments among its earliest symptoms. Speech impairments offer a valuable diagnostic opportunity, with machine learning advances providing promising tools for timely detection. In this research, we propose a deep learning approach for early Parkinson's disease detection from speech recordings, which also highlights the vocal segments driving predictions to enhance interpretability. This approach seeks to associate predictive speech patterns with articulatory features, providing a basis for interpreting underlying neuromuscular impairments. We evaluated our approach using the Italian Parkinson's Voice and Speech Database, containing 831 audio recordings from 65 participants, including both healthy individuals and patients. Our approach showed competitive classification performance compared to state-of-the-art methods, while providing enhanced interpretability by identifying key speech features influencing predictions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17739",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.778138Z"
  },
  {
    "id": "c6ac894f3f3b5723a79922d27add689b",
    "title": "Embedding Empirical Distributions for Computing Optimal Transport Maps",
    "slug": "embedding-empirical-distributions-for-computing-optimal-transport-maps",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Mingchen Jiang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Distributional data have become increasingly prominent in modern signal processing, highlighting the necessity of computing optimal transport (OT) maps across multiple probability distributions. Nevertheless, recent studies on neural OT methods predominantly focused on the efficient computation of a single map between two distributions. To address this challenge, we introduce a novel approach to learning transport maps for new empirical distributions. Specifically, we employ the transformer architecture to produce embeddings from distributional data of varying length; these embeddings are then fed into a hypernetwork to generate neural OT maps. Various numerical experiments were conducted to validate the embeddings and the generated OT maps. The model implementation and the code are provided on this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17740",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.778360Z"
  },
  {
    "id": "6a4a5bed7c4ebb46b3bf0f368aadc07e",
    "title": "MSGCN: Multiplex Spatial Graph Convolution Network for Interlayer Link Weight Prediction",
    "slug": "msgcn:-multiplex-spatial-graph-convolution-network-for-interlayer-link-weight-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Steven E. Wilson",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Graph Neural Networks (GNNs) have been widely used for various learning tasks, ranging from node classification to link prediction. They have demonstrated excellent performance in multiple domains involving graph-structured data. However, an important category of learning tasks, namely link weight prediction, has received less emphasis due to its increased complexity compared to binary link classification. Link weight prediction becomes even more challenging when considering multilayer networks, where nodes can be interconnected across multiple layers. To address these challenges, we propose a new method named Multiplex Spatial Graph Convolution Network (MSGCN), which spatially embeds information across multiple layers to predict interlayer link weights. The MSGCN model generalizes spatial graph convolution to multiplex networks and captures the geometric structure of nodes across multiple layers. Extensive experiments using data with known interlayer link information show that the MSGCN model has robust, accurate, and generalizable link weight prediction performance across a wide variety of multiplex network structures.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17749",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.778549Z"
  },
  {
    "id": "b1ce5f2b05c98b2bb0f68f6d35ca8cbf",
    "title": "Disaggregated Deep Learning via In-Physics Computing at Radio Frequency",
    "slug": "disaggregated-deep-learning-via-in-physics-computing-at-radio-frequency",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhihui Gao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Modern edge devices, such as cameras, drones, and Internet-of-Things nodes, rely on deep learning to enable a wide range of intelligent applications, including object recognition, environment perception, and autonomous navigation. However, deploying deep learning models directly on the often resource-constrained edge devices demands significant memory footprints and computational power for real-time inference using traditional digital computing architectures. In this paper, we present WISE, a novel computing architecture for wireless edge networks designed to overcome energy constraints in deep learning inference. WISE achieves this goal through two key innovations: disaggregated model access via wireless broadcasting and in-physics computation of general complex-valued matrix-vector multiplications directly at radio frequency. Using a software-defined radio platform with wirelessly broadcast model weights over the air, we demonstrate that WISE achieves 95.7% image classification accuracy with ultra-low operation power of 6.0 fJ/MAC per client, corresponding to a computation efficiency of 165.8 TOPS/W. This approach enables energy-efficient deep learning inference on wirelessly connected edge devices, achieving more than two orders of magnitude improvement in efficiency compared to traditional digital computing.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17752",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.778757Z"
  },
  {
    "id": "ef88ba76d8ec60a881cfb8dfbcaff510",
    "title": "Replay to Remember: Retaining Domain Knowledge in Streaming Language Models",
    "slug": "replay-to-remember:-retaining-domain-knowledge-in-streaming-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Sneh Pillai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Continual learning in large language models (LLMs) typically encounters the critical challenge of catastrophic forgetting, where previously acquired knowledge deteriorates upon exposure to new data. While techniques like replay buffers and parameter-efficient tuning (e.g., Low-Rank Adaptation or LoRA) have been proposed, few studies investigate real-time domain adaptation under strict computational and data-stream constraints. In this paper, we demonstrate a lightweight method combining LoRA and a minimal replay mechanism in a realistic streaming setting across three diverse knowledge domains: medical question answering, genetics, and law. Using perplexity, semantic similarity, and GPT-based human-like evaluation metrics, we quantify the model's adaptation, forgetting, and recovery over time. Our experiments reveal that while catastrophic forgetting naturally occurs, even minimal replay significantly stabilizes and partially restores domain-specific knowledge. This study contributes practical insights for deploying adaptable LLMs in resource-constrained, real-world scenarios.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17780",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.778948Z"
  },
  {
    "id": "f2ddee4efb5fb45741e13c5e78f4fc6c",
    "title": "Mathematical Modeling of Protein Structures: A Cohomology-Based Approach to the Flagellar Motor",
    "slug": "mathematical-modeling-of-protein-structures:-a-cohomology-based-approach-to-the-flagellar-motor",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Biomolecules (q-bio.BM)",
    "author": {
      "name": "Zakaria Lamine",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study presents a novel mathematical model derived from cohomology, leveraging the KEEL-proven theorem that establishes cohomology as tautological, generated by boundary classes of curves with fixed dual graphs. Simplicial complexes are constructed using skew-commutative graded algebra, and the structure theorem is applied to connect distinct homologies, enabling precise interpretations of the resulting geometric forms. The proposed model is utilized for protein structure analysis and prediction, with a specific application to the Flagellar Motor structure. This approach offers new insights into the geometric and algebraic foundations of biological macromolecular modeling, highlighting its potential for advancement in structural biology.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16941",
    "tags": [
      "Biomolecules (q-bio.BM)"
    ],
    "createdAt": "2025-04-25T15:49:23.779144Z"
  },
  {
    "id": "572f459531805e66c3f6dc8b1f53e311",
    "title": "Flexibility of German gas-fired generation: evidence from clustering empirical operation",
    "slug": "flexibility-of-german-gas-fired-generation:-evidence-from-clustering-empirical-operation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Chiara Fusar Bassini",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A key input to energy models are assumptions about the flexibility of power generation units, i.e., how quickly and often they can start up. These assumptions are usually calibrated on the technical characteristics of the units, such as installed capacity or technology type. However, even if power generation units technically can dispatch flexibly, service obligations and market incentives may constrain their operation. Here, we cluster over 60% of German national gas generation (generation units of 100 MWp or above) based on their empirical flexibility. We process the hourly dispatch of sample units between 2019 and 2023 using a novel deep learning approach, that transforms time series into easy-to-cluster representations. We identify two clusters of peaker units and two clusters of non-peaker units, whose different empirical flexibility is quantified by cluster-level ramp rates. Non-peaker units, around half of the sample, are empirically less flexible than peakers, and make up for more than 83% of sample must-run generation. Regulatory changes addressing the low market responsiveness of non-peakers are needed to unlock their flexibility.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16943",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:23.779351Z"
  },
  {
    "id": "22f61945dfe22c39ab7aec9d7a61bb28",
    "title": "Bidirectional Mamba for Single-Cell Data: Efficient Context Learning with Biological Fidelity",
    "slug": "bidirectional-mamba-for-single-cell-data:-efficient-context-learning-with-biological-fidelity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Cong Qi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of cellular heterogeneity, but its complexity, which is marked by high dimensionality, sparsity, and batch effects, which poses major computational challenges. Transformer-based models have made significant advances in this domain but are often limited by their quadratic complexity and suboptimal handling of long-range dependencies. In this work, we introduce GeneMamba, a scalable and efficient foundation model for single-cell transcriptomics built on state space modeling. Leveraging the Bi-Mamba architecture, GeneMamba captures bidirectional gene context with linear-time complexity, offering substantial computational gains over transformer baselines. The model is pretrained on nearly 30 million cells and incorporates biologically informed objectives, including pathway-aware contrastive loss and rank-based gene encoding. We evaluate GeneMamba across diverse tasks, including multi-batch integration, cell type annotation, and gene-gene correlation, demonstrating strong performance, interpretability, and robustness. These results position GeneMamba as a practical and powerful alternative to transformer-based methods, advancing the development of biologically grounded, scalable tools for large-scale single-cell data analysis.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16956",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.779556Z"
  },
  {
    "id": "7c0979c0f9f2667bf4c420dc85f7b835",
    "title": "Engineering the Law-Machine Learning Translation Problem: Developing Legally Aligned Models",
    "slug": "engineering-the-law-machine-learning-translation-problem:-developing-legally-aligned-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Mathias Hanson",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Organizations developing machine learning-based (ML) technologies face the complex challenge of achieving high predictive performance while respecting the law. This intersection between ML and the law creates new complexities. As ML model behavior is inferred from training data, legal obligations cannot be operationalized in source code directly. Rather, legal obligations require \"indirect\" operationalization. However, choosing context-appropriate operationalizations presents two compounding challenges: (1) laws often permit multiple valid operationalizations for a given legal obligation-each with varying degrees of legal adequacy; and, (2) each operationalization creates unpredictable trade-offs among the different legal obligations and with predictive performance. Evaluating these trade-offs requires metrics (or heuristics), which are in turn difficult to validate against legal obligations. Current methodologies fail to fully address these interwoven challenges as they either focus on legal compliance for traditional software or on ML model development without adequately considering legal complexities. In response, we introduce a five-stage interdisciplinary framework that integrates legal and ML-technical analysis during ML model development. This framework facilitates designing ML models in a legally aligned way and identifying high-performing models that are legally justifiable. Legal reasoning guides choices for operationalizations and evaluation metrics, while ML experts ensure technical feasibility, performance optimization and an accurate interpretation of metric values. This framework bridges the gap between more conceptual analysis of law and ML models' need for deterministic specifications. We illustrate its application using a case study in the context of anti-money laundering.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16969",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:23.779771Z"
  },
  {
    "id": "e52c6575d55fa526ffab0b0235110f69",
    "title": "A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs",
    "slug": "a-systematic-approach-to-design-real-world-human-in-the-loop-deep-reinforcement-learning:-salient-features,-challenges-and-trade-offs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Jalal Arabneydi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "With the growing popularity of deep reinforcement learning (DRL), human-in-the-loop (HITL) approach has the potential to revolutionize the way we approach decision-making problems and create new opportunities for human-AI collaboration. In this article, we introduce a novel multi-layered hierarchical HITL DRL algorithm that comprises three types of learning: self learning, imitation learning and transfer learning. In addition, we consider three forms of human inputs: reward, action and demonstration. Furthermore, we discuss main challenges, trade-offs and advantages of HITL in solving complex problems and how human information can be integrated in the AI solution systematically. To verify our technical results, we present a real-world unmanned aerial vehicles (UAV) problem wherein a number of enemy drones attack a restricted area. The objective is to design a scalable HITL DRL algorithm for ally drones to neutralize the enemy drones before they reach the area. To this end, we first implement our solution using an award-winning open-source HITL software called Cogment. We then demonstrate several interesting results such as (a) HITL leads to faster training and higher performance, (b) advice acts as a guiding direction for gradient methods and lowers variance, and (c) the amount of advice should neither be too large nor too small to avoid over-training and under-training. Finally, we illustrate the role of human-AI cooperation in solving two real-world complex scenarios, i.e., overloaded and decoy attacks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17006",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:23.780013Z"
  },
  {
    "id": "18faca217e2011e26bc95c2c4c24662c",
    "title": "Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification",
    "slug": "neural-theorem-proving:-generating-and-structuring-proofs-for-formal-verification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Balaji Rao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Formally verifying properties of software code has been a highly desirable task, especially with the emergence of LLM-generated code. In the same vein, they provide an interesting avenue for the exploration of formal verification and mechanistic interpretability. Since the introduction of code-specific models, despite their successes in generating code in Lean4 and Isabelle, the task of generalized theorem proving still remains far from being fully solved and will be a benchmark for reasoning capability in LLMs. In this work, we introduce a framework that generates whole proofs in a formal language to be used within systems that utilize the power of built-in tactics and off-the-shelf automated theorem provers. Our framework includes 3 components: generating natural language statements of the code to be verified, an LLM that generates formal proofs for the given statement, and a module employing heuristics for building the final proof. To train the LLM, we employ a 2-stage fine-tuning process, where we first use SFT-based training to enable the model to generate syntactically correct Isabelle code and then RL-based training that encourages the model to generate proofs verified by a theorem prover. We validate our framework using the miniF2F-test benchmark and the Isabelle proof assistant and design a use case to verify the correctness of the AWS S3 bucket access policy code. We also curate a dataset based on the FVEL\\textsubscript{\\textnormal{ER}} dataset for future training tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17017",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:23.780227Z"
  },
  {
    "id": "29a8d316ab8f2f403b7ce237fdf4d62f",
    "title": "Approaches to Responsible Governance of GenAI in Organizations",
    "slug": "approaches-to-responsible-governance-of-genai-in-organizations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Dhari Gandhi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid evolution of Generative AI (GenAI) has introduced unprecedented opportunities while presenting complex challenges around ethics, accountability, and societal impact. This paper draws on a literature review, established governance frameworks, and industry roundtable discussions to identify core principles for integrating responsible GenAI governance into diverse organizational structures. Our objective is to provide actionable recommendations for a balanced, risk-based governance approach that enables both innovation and oversight. Findings emphasize the need for adaptable risk assessment tools, continuous monitoring practices, and cross-sector collaboration to establish trustworthy GenAI. These insights provide a structured foundation and Responsible GenAI Guide (ResAI) for organizations to align GenAI initiatives with ethical, legal, and operational best practices.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17044",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:23.780424Z"
  },
  {
    "id": "23de29e9d7f1f92636b07ac31a866ce1",
    "title": "Neural Contraction Metrics with Formal Guarantees for Discrete-Time Nonlinear Dynamical Systems",
    "slug": "neural-contraction-metrics-with-formal-guarantees-for-discrete-time-nonlinear-dynamical-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Haoyu Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Contraction metrics are crucial in control theory because they provide a powerful framework for analyzing stability, robustness, and convergence of various dynamical systems. However, identifying these metrics for complex nonlinear systems remains an open challenge due to the lack of scalable and effective tools. This paper explores the approach of learning verifiable contraction metrics parametrized as neural networks (NNs) for discrete-time nonlinear dynamical systems. While prior works on formal verification of contraction metrics for general nonlinear systems have focused on convex optimization methods (e.g. linear matrix inequalities, etc) under the assumption of continuously differentiable dynamics, the growing prevalence of NN-based controllers, often utilizing ReLU activations, introduces challenges due to the non-smooth nature of the resulting closed-loop dynamics. To bridge this gap, we establish a new sufficient condition for establishing formal neural contraction metrics for general discrete-time nonlinear systems assuming only the continuity of the dynamics. We show that from a computational perspective, our sufficient condition can be efficiently verified using the state-of-the-art neural network verifier $\\alpha,\\!\\beta$-CROWN, which scales up non-convex neural network verification via novel integration of symbolic linear bound propagation and branch-and-bound. Built upon our analysis tool, we further develop a learning method for synthesizing neural contraction metrics from sampled data. Finally, our approach is validated through the successful synthesis and verification of NN contraction metrics for various nonlinear examples.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17102",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:23.780626Z"
  },
  {
    "id": "40711ba97c4025a7f41de20ddb1fd368",
    "title": "Physics-informed features in supervised machine learning",
    "slug": "physics-informed-features-in-supervised-machine-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Margherita Lampani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Supervised machine learning involves approximating an unknown functional relationship from a limited dataset of features and corresponding labels. The classical approach to feature-based machine learning typically relies on applying linear regression to standardized features, without considering their physical meaning. This may limit model explainability, particularly in scientific applications. This study proposes a physics-informed approach to feature-based machine learning that constructs non-linear feature maps informed by physical laws and dimensional analysis. These maps enhance model interpretability and, when physical laws are unknown, allow for the identification of relevant mechanisms through feature ranking. The method aims to improve both predictive performance in regression tasks and classification skill scores by integrating domain knowledge into the learning process, while also enabling the potential discovery of new physical equations within the context of explainable machine learning.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17112",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.780835Z"
  },
  {
    "id": "05a766afb9699939ca5396288a4ccede",
    "title": "PACE: A Framework for Learning and Control in Linear Incomplete-Information Differential Games",
    "slug": "pace:-a-framework-for-learning-and-control-in-linear-incomplete-information-differential-games",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Seyed Yousef Soltanian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we address the problem of a two-player linear quadratic differential game with incomplete information, a scenario commonly encountered in multi-agent control, human-robot interaction (HRI), and approximation methods for solving general-sum differential games. While solutions to such linear differential games are typically obtained through coupled Riccati equations, the complexity increases when agents have incomplete information, particularly when neither is aware of the other's cost function. To tackle this challenge, we propose a model-based Peer-Aware Cost Estimation (PACE) framework for learning the cost parameters of the other agent. In PACE, each agent treats its peer as a learning agent rather than a stationary optimal agent, models their learning dynamics, and leverages this dynamic to infer the cost function parameters of the other agent. This approach enables agents to infer each other's objective function in real time based solely on their previous state observations and dynamically adapt their control policies. Furthermore, we provide a theoretical guarantee for the convergence of parameter estimation and the stability of system states in PACE. Additionally, in our numerical studies, we demonstrate how modeling the learning dynamics of the other agent benefits PACE, compared to approaches that approximate the other agent as having complete information, particularly in terms of stability and convergence speed.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17128",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:23.781038Z"
  },
  {
    "id": "d7b5ca4be6e8abdd9e61dcf7e06fae48",
    "title": "Reinforcement learning framework for the mechanical design of microelectronic components under multiphysics constraints",
    "slug": "reinforcement-learning-framework-for-the-mechanical-design-of-microelectronic-components-under-multiphysics-constraints",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Physics (physics.comp-ph)",
    "author": {
      "name": "Siddharth Nair",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study focuses on the development of reinforcement learning based techniques for the design of microelectronic components under multiphysics constraints. While traditional design approaches based on global optimization approaches are effective when dealing with a small number of design parameters, as the complexity of the solution space and of the constraints increases different techniques are needed. This is an important reason that makes the design and optimization of microelectronic components (characterized by large solution space and multiphysics constraints) very challenging for traditional methods. By taking as prototypical elements an application-specific integrated circuit (ASIC) and a heterogeneously integrated (HI) interposer, we develop and numerically test an optimization framework based on reinforcement learning (RL). More specifically, we consider the optimization of the bonded interconnect geometry for an ASIC chip as well as the placement of components on a HI interposer while satisfying thermoelastic and design constraints. This placement problem is particularly interesting because it features a high-dimensional solution space.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17142",
    "tags": [
      "Computational Physics (physics.comp-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.781248Z"
  },
  {
    "id": "46f6a1dd4ecf90d822870149689da225",
    "title": "Causal rule ensemble approach for multi-arm data",
    "slug": "causal-rule-ensemble-approach-for-multi-arm-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Ke Wan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Heterogeneous treatment effect (HTE) estimation is critical in medical research. It provides insights into how treatment effects vary among individuals, which can provide statistical evidence for precision medicine. While most existing methods focus on binary treatment situations, real-world applications often involve multiple interventions. However, current HTE estimation methods are primarily designed for binary comparisons and often rely on black-box models, which limit their applicability and interpretability in multi-arm settings. To address these challenges, we propose an interpretable machine learning framework for HTE estimation in multi-arm trials. Our method employs a rule-based ensemble approach consisting of rule generation, rule ensemble, and HTE estimation, ensuring both predictive accuracy and interpretability. Through extensive simulation studies and real data applications, the performance of our method was evaluated against state-of-the-art multi-arm HTE estimation approaches. The results indicate that our approach achieved lower bias and higher estimation accuracy compared with those of existing methods. Furthermore, the interpretability of our framework allows clearer insights into how covariates influence treatment effects, facilitating clinical decision making. By bridging the gap between accuracy and interpretability, our study contributes a valuable tool for multi-arm HTE estimation, supporting precision medicine.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17166",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.781449Z"
  },
  {
    "id": "7afb6be0eef05252dffd6fde14cda4db",
    "title": "Lessons from Deploying Learning-based CSI Localization on a Large-Scale ISAC Platform",
    "slug": "lessons-from-deploying-learning-based-csi-localization-on-a-large-scale-isac-platform",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Tianyu Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In recent years, Channel State Information (CSI), recognized for its fine-grained spatial characteristics, has attracted increasing attention in WiFi-based indoor localization. However, despite its potential, CSI-based approaches have yet to achieve the same level of deployment scale and commercialization as those based on Received Signal Strength Indicator (RSSI). A key limitation lies in the fact that most existing CSI-based systems are developed and evaluated in controlled, small-scale environments, limiting their generalizability. To bridge this gap, we explore the deployment of a large-scale CSI-based localization system involving over 400 Access Points (APs) in a real-world building under the Integrated Sensing and Communication (ISAC) paradigm. We highlight two critical yet often overlooked factors: the underutilization of unlabeled data and the inherent heterogeneity of CSI measurements. To address these challenges, we propose a novel CSI-based learning framework for WiFi localization, tailored for large-scale ISAC deployments on the server side. Specifically, we employ a novel graph-based structure to model heterogeneous CSI data and reduce redundancy. We further design a pretext pretraining task that incorporates spatial and temporal priors to effectively leverage large-scale unlabeled CSI data. Complementarily, we introduce a confidence-aware fine-tuning strategy to enhance the robustness of localization results. In a leave-one-smartphone-out experiment spanning five floors and 25, 600 m2, we achieve a median localization error of 2.17 meters and a floor accuracy of 99.49%. This performance corresponds to an 18.7% reduction in mean absolute error (MAE) compared to the best-performing baseline.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17173",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:23.781660Z"
  },
  {
    "id": "aeaca6ea02995bef665200c219058100",
    "title": "A Genealogy of Multi-Sensor Foundation Models in Remote Sensing",
    "slug": "a-genealogy-of-multi-sensor-foundation-models-in-remote-sensing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Kevin Lane",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Foundation models have garnered increasing attention for representation learning in remote sensing, primarily adopting approaches that have demonstrated success in computer vision with minimal domain-specific modification. However, the development and application of foundation models in this field are still burgeoning, as there are a variety of competing approaches that each come with significant benefits and drawbacks. This paper examines these approaches along with their roots in the computer vision field in order to characterize potential advantages and pitfalls while outlining future directions to further improve remote sensing-specific foundation models. We discuss the quality of the learned representations and methods to alleviate the need for massive compute resources. We place emphasis on the multi-sensor aspect of Earth observations, and the extent to which existing approaches leverage multiple sensors in training foundation models in relation to multi-modal foundation models. Finally, we identify opportunities for further harnessing the vast amounts of unlabeled, seasonal, and multi-sensor remote sensing observations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17177",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.781861Z"
  },
  {
    "id": "10536ca35011acc43f303910cb696ecc",
    "title": "AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models",
    "slug": "authentication:-identifying-rare-failure-modes-in-autonomous-vehicle-perception-systems-using-adversarially-guided-diffusion-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Mohammad Zarei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autonomous Vehicles (AVs) rely on artificial intelligence (AI) to accurately detect objects and interpret their surroundings. However, even when trained using millions of miles of real-world data, AVs are often unable to detect rare failure modes (RFMs). The problem of RFMs is commonly referred to as the \"long-tail challenge\", due to the distribution of data including many instances that are very rarely seen. In this paper, we present a novel approach that utilizes advanced generative and explainable AI techniques to aid in understanding RFMs. Our methods can be used to enhance the robustness and reliability of AVs when combined with both downstream model training and testing. We extract segmentation masks for objects of interest (e.g., cars) and invert them to create environmental masks. These masks, combined with carefully crafted text prompts, are fed into a custom diffusion model. We leverage the Stable Diffusion inpainting model guided by adversarial noise optimization to generate images containing diverse environments designed to evade object detection models and expose vulnerabilities in AI systems. Finally, we produce natural language descriptions of the generated RFMs that can guide developers and policymakers to improve the safety and reliability of AV systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17179",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:23.782069Z"
  },
  {
    "id": "91f12f4732b76b37384600a3c1c11195",
    "title": "High-Fidelity And Complex Test Data Generation For Real-World SQL Code Generation Services",
    "slug": "high-fidelity-and-complex-test-data-generation-for-real-world-sql-code-generation-services",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Shivasankari Kannan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The demand for high-fidelity test data is paramount in industrial settings where access to production data is largely restricted. Traditional data generation methods often fall short, struggling with low-fidelity and the ability to model complex data structures and semantic relationships that are critical for testing complex SQL code generation services like Natural Language to SQL (NL2SQL). In this paper, we address the critical need for generating syntactically correct and semantically ``meaningful'' mock data for complex schema that includes columns with nested structures that we frequently encounter in Google SQL code generation workloads. We highlight the limitations of existing approaches used in production, particularly their inability to handle large and complex schema, as well as the lack of semantically coherent test data that lead to limited test coverage. We demonstrate that by leveraging Large Language Models (LLMs) and incorporating strategic pre- and post-processing steps, we can generate realistic high-fidelity test data that adheres to complex structural constraints and maintains semantic integrity to the test targets (SQL queries/functions). This approach supports comprehensive testing of complex SQL queries involving joins, aggregations, and even deeply nested subqueries, ensuring robust evaluation of SQL code generation services, like NL2SQL and SQL Code Assistant services. Our results demonstrate the practical utility of an out-of-the-box LLM (\\textit{gemini}) based test data generation for industrial SQL code generation services where generating realistic test data is essential due to the frequent unavailability of production datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17203",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:23.782269Z"
  },
  {
    "id": "21aa4775b86dbfd8c071027aea3fe59c",
    "title": "Rate-Distortion-Perception Theory for the Quadratic Wasserstein Space",
    "slug": "rate-distortion-perception-theory-for-the-quadratic-wasserstein-space",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Xiqiang Qu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish a single-letter characterization of the fundamental distortion-rate-perception tradeoff with limited common randomness under the squared error distortion measure and the squared Wasserstein-2 perception measure. Moreover, it is shown that this single-letter characterization can be explicitly evaluated for the Gaussian source. Various notions of universal representation are also clarified.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17236",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:23.782463Z"
  },
  {
    "id": "5cf3bc24d3d92b24ce7cc8fc07f9d7a4",
    "title": "Low-Resource Neural Machine Translation Using Recurrent Neural Networks and Transfer Learning: A Case Study on English-to-Igbo",
    "slug": "low-resource-neural-machine-translation-using-recurrent-neural-networks-and-transfer-learning:-a-case-study-on-english-to-igbo",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Ocheme Anthony Ekle",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this study, we develop Neural Machine Translation (NMT) and Transformer-based transfer learning models for English-to-Igbo translation - a low-resource African language spoken by over 40 million people across Nigeria and West Africa. Our models are trained on a curated and benchmarked dataset compiled from Bible corpora, local news, Wikipedia articles, and Common Crawl, all verified by native language experts. We leverage Recurrent Neural Network (RNN) architectures, including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), enhanced with attention mechanisms to improve translation accuracy. To further enhance performance, we apply transfer learning using MarianNMT pre-trained models within the SimpleTransformers framework. Our RNN-based system achieves competitive results, closely matching existing English-Igbo benchmarks. With transfer learning, we observe a performance gain of +4.83 BLEU points, reaching an estimated translation accuracy of 70%. These findings highlight the effectiveness of combining RNNs with transfer learning to address the performance gap in low-resource language translation tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17252",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.782662Z"
  },
  {
    "id": "35058105fc7c67715b013c026491a870",
    "title": "Dargana: fine-tuning EarthPT for dynamic tree canopy mapping from space",
    "slug": "dargana:-fine-tuning-earthpt-for-dynamic-tree-canopy-mapping-from-space",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geophysics (physics.geo-ph)",
    "author": {
      "name": "Michael J. Smith",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present Dargana, a fine-tuned variant of the EarthPT time-series foundation model that achieves specialisation using <3% of its pre-training data volume and 5% of its pre-training compute. Dargana is fine-tuned to generate regularly updated classification of tree canopy cover at 10m resolution, distinguishing conifer and broadleaved tree types. Using Cornwall, UK, as a test case, the model achieves a pixel-level ROC-AUC of 0.98 and a PR-AUC of 0.83 on unseen satellite imagery. Dargana can identify fine structures like hedgerows and coppice below the training sample limit, and can track temporal changes to canopy cover such as new woodland establishment. Our results demonstrate how pre-trained Large Observation Models like EarthPT can be specialised for granular, dynamic land cover monitoring from space, providing a valuable, scalable tool for natural capital management and conservation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17321",
    "tags": [
      "Geophysics (physics.geo-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.782876Z"
  },
  {
    "id": "2018193a37b5125a1227214a27c26d18",
    "title": "Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning",
    "slug": "comprehend,-divide,-and-conquer:-feature-subspace-exploration-via-multi-agent-hierarchical-reinforcement-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Weiliang Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Feature selection aims to preprocess the target dataset, find an optimal and most streamlined feature subset, and enhance the downstream machine learning task. Among filter, wrapper, and embedded-based approaches, the reinforcement learning (RL)-based subspace exploration strategy provides a novel objective optimization-directed perspective and promising performance. Nevertheless, even with improved performance, current reinforcement learning approaches face challenges similar to conventional methods when dealing with complex datasets. These challenges stem from the inefficient paradigm of using one agent per feature and the inherent complexities present in the datasets. This observation motivates us to investigate and address the above issue and propose a novel approach, namely HRLFS. Our methodology initially employs a Large Language Model (LLM)-based hybrid state extractor to capture each feature's mathematical and semantic characteristics. Based on this information, features are clustered, facilitating the construction of hierarchical agents for each cluster and sub-cluster. Extensive experiments demonstrate the efficiency, scalability, and robustness of our approach. Compared to contemporary or the one-feature-one-agent RL-based approaches, HRLFS improves the downstream ML performance with iterative feature subspace exploration while accelerating total run time by reducing the number of agents involved.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17356",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:23.783098Z"
  },
  {
    "id": "e5da52204c72263ba922f161142cf103",
    "title": "On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration",
    "slug": "on-device-qwen2.5:-efficient-llm-inference-with-model-compression-and-hardware-acceleration",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Maoyang Xiang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Transformer-based Large Language Models (LLMs) have significantly advanced AI capabilities but pose considerable challenges for deployment on edge devices due to high computational demands, memory bandwidth constraints, and energy consumption. This paper addresses these challenges by presenting an efficient framework for deploying the Qwen2.5-0.5B model on the Xilinx Kria KV260 edge platform, a heterogeneous system integrating an ARM Cortex-A53 CPU with reconfigurable FPGA logic. Leveraging Activation-aware Weight Quantization (AWQ) with FPGA-accelerated execution pipelines, the proposed approach enhances both model compression rate and system throughput. Additionally, we propose a hybrid execution strategy that intelligently offloads compute-intensive operations to the FPGA while utilizing the CPU for lighter tasks, effectively balancing the computational workload and maximizing overall performance. Our framework achieves a model compression rate of 55.08% compared to the original model and produces output at a rate of 5.1 tokens per second, outperforming the baseline performance of 2.8 tokens per second.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17376",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:23.783290Z"
  },
  {
    "id": "45c155d03b4f275855354edbfd32ef2e",
    "title": "HydroStartML: A combined machine learning and physics-based approach to reduce hydrological model spin-up time",
    "slug": "hydrostartml:-a-combined-machine-learning-and-physics-based-approach-to-reduce-hydrological-model-spin-up-time",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geophysics (physics.geo-ph)",
    "author": {
      "name": "Louisa Pawusch",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Finding the initial depth-to-water table (DTWT) configuration of a catchment is a critical challenge when simulating the hydrological cycle with integrated models, significantly impacting simulation outcomes. Traditionally, this involves iterative spin-up computations, where the model runs under constant atmospheric settings until steady-state is achieved. These so-called model spin-ups are computationally expensive, often requiring many years of simulated time, particularly when the initial DTWT configuration is far from steady state.\nTo accelerate the model spin-up process we developed HydroStartML, a machine learning emulator trained on steady-state DTWT configurations across the contiguous United States. HydroStartML predicts, based on available data like conductivity and surface slopes, a DTWT configuration of the respective watershed, which can be used as an initial DTWT.\nOur results show that initializing spin-up computations with HydroStartML predictions leads to faster convergence than with other initial configurations like spatially constant DTWTs. The emulator accurately predicts configurations close to steady state, even for terrain configurations not seen in training, and allows especially significant reductions in computational spin-up effort in regions with deep DTWTs. This work opens the door for hybrid approaches that blend machine learning and traditional simulation, enhancing predictive accuracy and efficiency in hydrology for improving water resource management and understanding complex environmental interactions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17420",
    "tags": [
      "Geophysics (physics.geo-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.783496Z"
  },
  {
    "id": "5c698c6ade3ab5aba115f02ed3560804",
    "title": "IRA: Adaptive Interest-aware Representation and Alignment for Personalized Multi-interest Retrieval",
    "slug": "ira:-adaptive-interest-aware-representation-and-alignment-for-personalized-multi-interest-retrieval",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Retrieval (cs.IR)",
    "author": {
      "name": "Youngjune Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Online community platforms require dynamic personalized retrieval and recommendation that can continuously adapt to evolving user interests and new documents. However, optimizing models to handle such changes in real-time remains a major challenge in large-scale industrial settings. To address this, we propose the Interest-aware Representation and Alignment (IRA) framework, an efficient and scalable approach that dynamically adapts to new interactions through a cumulative structure. IRA leverages two key mechanisms: (1) Interest Units that capture diverse user interests as contextual texts, while reinforcing or fading over time through cumulative updates, and (2) a retrieval process that measures the relevance between Interest Units and documents based solely on semantic relationships, eliminating dependence on click signals to mitigate temporal biases. By integrating cumulative Interest Unit updates with the retrieval process, IRA continuously adapts to evolving user preferences, ensuring robust and fine-grained personalization without being constrained by past training distributions. We validate the effectiveness of IRA through extensive experiments on real-world datasets, including its deployment in the Home Section of NAVER's CAFE, South Korea's leading community platform.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17529",
    "tags": [
      "Information Retrieval (cs.IR)"
    ],
    "createdAt": "2025-04-25T15:49:23.783718Z"
  },
  {
    "id": "d3b342d0e4b04e4528452d4b81a1bade",
    "title": "An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm",
    "slug": "an-explainable-nature-inspired-framework-for-monkeypox-diagnosis:-xception-features-combined-with-ngboost-and-african-vultures-optimization-algorithm",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Ahmadreza Shateri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The recent global spread of monkeypox, particularly in regions where it has not historically been prevalent, has raised significant public health concerns. Early and accurate diagnosis is critical for effective disease management and control. In response, this study proposes a novel deep learning-based framework for the automated detection of monkeypox from skin lesion images, leveraging the power of transfer learning, dimensionality reduction, and advanced machine learning techniques. We utilize the newly developed Monkeypox Skin Lesion Dataset (MSLD), which includes images of monkeypox, chickenpox, and measles, to train and evaluate our models. The proposed framework employs the Xception architecture for deep feature extraction, followed by Principal Component Analysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting (NGBoost) algorithm for classification. To optimize the model's performance and generalization, we introduce the African Vultures Optimization Algorithm (AVOA) for hyperparameter tuning, ensuring efficient exploration of the parameter space. Our results demonstrate that the proposed AVOA-NGBoost model achieves state-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72% and an AUC of 97.47%. Additionally, we enhance model interpretability using Grad-CAM and LIME techniques, providing insights into the decision-making process and highlighting key features influencing classification. This framework offers a highly precise and efficient diagnostic tool, potentially aiding healthcare providers in early detection and diagnosis, particularly in resource-constrained environments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17540",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.783917Z"
  },
  {
    "id": "131c13e123a77849efc155fd345a0120",
    "title": "An introduction to R package `mvs`",
    "slug": "an-introduction-to-r-package-`mvs`",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation (stat.CO)",
    "author": {
      "name": "Wouter van Loon",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In biomedical science, a set of objects or persons can often be described by multiple distinct sets of features obtained from different data sources or modalities (called \"multi-view data\"). Classical machine learning methods ignore the multi-view structure of such data, limiting model interpretability and performance. The R package `mvs` provides methods that were designed specifically for dealing with multi-view data, based on the multi-view stacking (MVS) framework. MVS is a form of supervised (machine) learning used to train multi-view classification or prediction models. MVS works by training a learning algorithm on each view separately, estimating the predictive power of each view-specific model through cross-validation, and then using another learning algorithm to assign weights to the view-specific models based on their estimated predictions. MVS is a form of ensemble learning, dividing the large multi-view learning problem into smaller sub-problems. Most of these sub-problems can be solved in parallel, making it computationally attractive. Additionally, the number of features of the sub-problems is greatly reduced compared with the full multi-view learning problem. This makes MVS especially useful when the total number of features is larger than the number of observations (i.e., high-dimensional data). MVS can still be applied even if the sub-problems are themselves high-dimensional by adding suitable penalty terms to the learning algorithms. Furthermore, MVS can be used to automatically select the views which are most important for prediction. The R package `mvs` makes fitting MVS models, including such penalty terms, easily and openly accessible. `mvs` allows for the fitting of stacked models with any number of levels, with different penalty terms, different outcome distributions, and provides several options for missing data handling.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17546",
    "tags": [
      "Computation (stat.CO)"
    ],
    "createdAt": "2025-04-25T15:49:23.784111Z"
  },
  {
    "id": "16cb6ab95ba1eac9ff847e170091ac03",
    "title": "Quantum Autoencoder for Multivariate Time Series Anomaly Detection",
    "slug": "quantum-autoencoder-for-multivariate-time-series-anomaly-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Kilian Tscharke",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Anomaly Detection (AD) defines the task of identifying observations or events that deviate from typical - or normal - patterns, a critical capability in IT security for recognizing incidents such as system misconfigurations, malware infections, or cyberattacks. In enterprise environments like SAP HANA Cloud systems, this task often involves monitoring high-dimensional, multivariate time series (MTS) derived from telemetry and log data. With the advent of quantum machine learning offering efficient calculations in high-dimensional latent spaces, many avenues open for dealing with such complex data. One approach is the Quantum Autoencoder (QAE), an emerging and promising method with potential for application in both data compression and AD. However, prior applications of QAEs to time series AD have been restricted to univariate data, limiting their relevance for real-world enterprise systems. In this work, we introduce a novel QAE-based framework designed specifically for MTS AD towards enterprise scale. We theoretically develop and experimentally validate the architecture, demonstrating that our QAE achieves performance competitive with neural-network-based autoencoders while requiring fewer trainable parameters. We evaluate our model on datasets that closely reflect SAP system telemetry and show that the proposed QAE is a viable and efficient alternative for semisupervised AD in real-world enterprise settings.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17548",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.784328Z"
  },
  {
    "id": "a41d05d2abd98b833f8e7937c430a95d",
    "title": "When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars",
    "slug": "when-does-metadata-conditioning-(not)-work-for-language-model-pre-training?-a-study-with-context-free-grammars",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Rei Higuchi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The ability to acquire latent semantics is one of the key properties that determines the performance of language models. One convenient approach to invoke this ability is to prepend metadata (e.g. URLs, domains, and styles) at the beginning of texts in the pre-training data, making it easier for the model to access latent semantics before observing the entire text. Previous studies have reported that this technique actually improves the performance of trained models in downstream tasks; however, this improvement has been observed only in specific downstream tasks, without consistent enhancement in average next-token prediction loss. To understand this phenomenon, we closely investigate how prepending metadata during pre-training affects model performance by examining its behavior using artificial data. Interestingly, we found that this approach produces both positive and negative effects on the downstream tasks. We demonstrate that the effectiveness of the approach depends on whether latent semantics can be inferred from the downstream task's prompt. Specifically, through investigations using data generated by probabilistic context-free grammars, we show that training with metadata helps improve model's performance when the given context is long enough to infer the latent semantics. In contrast, the technique negatively impacts performance when the context lacks the necessary information to make an accurate posterior inference.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17562",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.784623Z"
  },
  {
    "id": "e0817b455b3a038f89105ecfe0e98618",
    "title": "L3: DIMM-PIM Integrated Architecture and Coordination for Scalable Long-Context LLM Inference",
    "slug": "l3:-dimm-pim-integrated-architecture-and-coordination-for-scalable-long-context-llm-inference",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Qingyuan Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) increasingly require processing long text sequences, but GPU memory limitations force difficult trade-offs between memory capacity and bandwidth. While HBM-based acceleration offers high bandwidth, its capacity remains constrained. Offloading data to host-side DIMMs improves capacity but introduces costly data swapping overhead. We identify that the critical memory bottleneck lies in the decoding phase of multi-head attention (MHA) exclusively, which demands substantial capacity for storing KV caches and high bandwidth for attention computation. Our key insight reveals this operation uniquely aligns with modern DIMM-based processing-in-memory (PIM) architectures, which offers scalability of both capacity and bandwidth.\nBased on this observation and insight, we propose L3, a hardware-software co-designed system integrating DIMM-PIM and GPU devices. L3 introduces three innovations: First, hardware redesigns resolve data layout mismatches and computational element mismatches in DIMM-PIM, enhancing LLM inference utilization. Second, communication optimization enables hiding the data transfer overhead with the computation. Third, an adaptive scheduler coordinates GPU-DIMM-PIM operations to maximize parallelism between devices. Evaluations using real-world traces show L3 achieves up to 6.1$\\times$ speedup over state-of-the-art HBM-PIM solutions while significantly improving batch sizes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17584",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:23.785045Z"
  },
  {
    "id": "d929cf19e79bd8ea829761f1d10bd063",
    "title": "A Machine Learning Approach for Denoising and Upsampling HRTFs",
    "slug": "a-machine-learning-approach-for-denoising-and-upsampling-hrtfs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Sound (cs.SD)",
    "author": {
      "name": "Xuyi Hu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The demand for realistic virtual immersive audio continues to grow, with Head-Related Transfer Functions (HRTFs) playing a key role. HRTFs capture how sound reaches our ears, reflecting unique anatomical features and enhancing spatial perception. It has been shown that personalized HRTFs improve localization accuracy, but their measurement remains time-consuming and requires a noise-free environment. Although machine learning has been shown to reduce the required measurement points and, thus, the measurement time, a controlled environment is still necessary. This paper proposes a method to address this constraint by presenting a novel technique that can upsample sparse, noisy HRTF measurements. The proposed approach combines an HRTF Denoisy U-Net for denoising and an Autoencoding Generative Adversarial Network (AE-GAN) for upsampling from three measurement points. The proposed method achieves a log-spectral distortion (LSD) error of 5.41 dB and a cosine similarity loss of 0.0070, demonstrating the method's effectiveness in HRTF upsampling.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17586",
    "tags": [
      "Sound (cs.SD)"
    ],
    "createdAt": "2025-04-25T15:49:23.785272Z"
  },
  {
    "id": "1763e3a3385903b65600beec5dae9d1f",
    "title": "Likelihood-Free Variational Autoencoders",
    "slug": "likelihood-free-variational-autoencoders",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Chen Xu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Variational Autoencoders (VAEs) typically rely on a probabilistic decoder with a predefined likelihood, most commonly an isotropic Gaussian, to model the data conditional on latent variables. While convenient for optimization, this choice often leads to likelihood misspecification, resulting in blurry reconstructions and poor data fidelity, especially for high-dimensional data such as images. In this work, we propose \\textit{EnVAE}, a novel likelihood-free generative framework that has a deterministic decoder and employs the energy score -- a proper scoring rule -- to build the reconstruction loss. This enables likelihood-free inference without requiring explicit parametric density functions. To address the computational inefficiency of the energy score, we introduce a fast variant, \\textit{FEnVAE}, based on the local smoothness of the decoder and the sharpness of the posterior distribution of latent variables. This yields an efficient single-sample training objective that integrates seamlessly into existing VAE pipelines with minimal overhead. Empirical results on standard benchmarks demonstrate that \\textit{EnVAE} achieves superior reconstruction and generation quality compared to likelihood-based baselines. Our framework offers a general, scalable, and statistically principled alternative for flexible and nonparametric distribution learning in generative modeling.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17622",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.785488Z"
  },
  {
    "id": "7432993161f809e0b80c6d48673dcaea",
    "title": "polyGen: A Learning Framework for Atomic-level Polymer Structure Generation",
    "slug": "polygen:-a-learning-framework-for-atomic-level-polymer-structure-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Engineering, Finance, and Science (cs.CE)",
    "author": {
      "name": "Ayush Jain",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Synthetic polymeric materials underpin fundamental technologies in the energy, electronics, consumer goods, and medical sectors, yet their development still suffers from prolonged design timelines. Although polymer informatics tools have supported speedup, polymer simulation protocols continue to face significant challenges: on-demand generation of realistic 3D atomic structures that respect the conformational diversity of polymer structures. Generative algorithms for 3D structures of inorganic crystals, bio-polymers, and small molecules exist, but have not addressed synthetic polymers. In this work, we introduce polyGen, the first latent diffusion model designed specifically to generate realistic polymer structures from minimal inputs such as the repeat unit chemistry alone, leveraging a molecular encoding that captures polymer connectivity throughout the architecture. Due to a scarce dataset of only 3855 DFT-optimized polymer structures, we augment our training with DFT-optimized molecular structures, showing improvement in joint learning between similar chemical structures. We also establish structure matching criteria to benchmark our approach on this novel problem. polyGen effectively generates diverse conformations of both linear chains and complex branched structures, though its performance decreases when handling repeat units with a high atom count. Given these initial results, polyGen represents a paradigm shift in atomic-level structure generation for polymer science-the first proof-of-concept for predicting realistic atomic-level polymer conformations while accounting for their intrinsic structural flexibility.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17656",
    "tags": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "createdAt": "2025-04-25T15:49:23.785689Z"
  },
  {
    "id": "f59a73ac5f7a1c1cf8533819a23c1814",
    "title": "The Malicious Technical Ecosystem: Exposing Limitations in Technical Governance of AI-Generated Non-Consensual Intimate Images of Adults",
    "slug": "the-malicious-technical-ecosystem:-exposing-limitations-in-technical-governance-of-ai-generated-non-consensual-intimate-images-of-adults",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Michelle L. Ding",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we adopt a survivor-centered approach to locate and dissect the role of sociotechnical AI governance in preventing AI-Generated Non-Consensual Intimate Images (AIG-NCII) of adults, colloquially known as \"deep fake pornography.\" We identify a \"malicious technical ecosystem\" or \"MTE,\" comprising of open-source face-swapping models and nearly 200 \"nudifying\" software programs that allow non-technical users to create AIG-NCII within minutes. Then, using the National Institute of Standards and Technology (NIST) AI 100-4 report as a reflection of current synthetic content governance methods, we show how the current landscape of practices fails to effectively regulate the MTE for adult AIG-NCII, as well as flawed assumptions explaining these gaps.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17663",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:23.785885Z"
  },
  {
    "id": "e4946c543be26d06ee1041396e7cb55b",
    "title": "Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction",
    "slug": "data-driven-calibration-of-prediction-sets-in-large-vision-language-models-based-on-inductive-conformal-prediction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yuanchang Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study addresses the critical challenge of hallucination mitigation in Large Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks through a Split Conformal Prediction (SCP) framework. While LVLMs excel in multi-modal reasoning, their outputs often exhibit hallucinated content with high confidence, posing risks in safety-critical applications. We propose a model-agnostic uncertainty quantification method that integrates dynamic threshold calibration and cross-modal consistency verification. By partitioning data into calibration and test sets, the framework computes nonconformity scores to construct prediction sets with statistical guarantees under user-defined risk levels ($\\alpha$). Key innovations include: (1) rigorous control of \\textbf{marginal coverage} to ensure empirical error rates remain strictly below $\\alpha$; (2) dynamic adjustment of prediction set sizes inversely with $\\alpha$, filtering low-confidence outputs; (3) elimination of prior distribution assumptions and retraining requirements. Evaluations on benchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces theoretical guarantees across all $\\alpha$ values. The framework achieves stable performance across varying calibration-to-test split ratios, underscoring its robustness for real-world deployment in healthcare, autonomous systems, and other safety-sensitive domains. This work bridges the gap between theoretical reliability and practical applicability in multi-modal AI systems, offering a scalable solution for hallucination detection and uncertainty-aware decision-making.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17671",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.786075Z"
  },
  {
    "id": "5fcf8cf38f6df5814fb6948802f1cc7d",
    "title": "Energy Considerations of Large Language Model Inference and Efficiency Optimizations",
    "slug": "energy-considerations-of-large-language-model-inference-and-efficiency-optimizations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jared Fernandez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As large language models (LLMs) scale in size and adoption, their computational and environmental costs continue to rise. Prior benchmarking efforts have primarily focused on latency reduction in idealized settings, often overlooking the diverse real-world inference workloads that shape energy use. In this work, we systematically analyze the energy implications of common inference efficiency optimizations across diverse Natural Language Processing (NLP) and generative Artificial Intelligence (AI) workloads, including conversational AI and code generation. We introduce a modeling approach that approximates real-world LLM workflows through a binning strategy for input-output token distributions and batch size variations. Our empirical analysis spans software frameworks, decoding strategies, GPU architectures, online and offline serving settings, and model parallelism configurations. We show that the effectiveness of inference optimizations is highly sensitive to workload geometry, software stack, and hardware accelerators, demonstrating that naive energy estimates based on FLOPs or theoretical GPU utilization significantly underestimate real-world energy consumption. Our findings reveal that the proper application of relevant inference efficiency optimizations can reduce total energy use by up to 73% from unoptimized baselines. These insights provide a foundation for sustainable LLM deployment and inform energy-efficient design strategies for future AI infrastructure.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17674",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.786302Z"
  },
  {
    "id": "9550b620555ec14ea9351596d5049853",
    "title": "On the Generalization of Adversarially Trained Quantum Classifiers",
    "slug": "on-the-generalization-of-adversarially-trained-quantum-classifiers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Petros Georgiou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Quantum classifiers are vulnerable to adversarial attacks that manipulate their input classical or quantum data. A promising countermeasure is adversarial training, where quantum classifiers are trained by using an attack-aware, adversarial loss function. This work establishes novel bounds on the generalization error of adversarially trained quantum classifiers when tested in the presence of perturbation-constrained adversaries. The bounds quantify the excess generalization error incurred to ensure robustness to adversarial attacks as scaling with the training sample size $m$ as $1/\\sqrt{m}$, while yielding insights into the impact of the quantum embedding. For quantum binary classifiers employing \\textit{rotation embedding}, we find that, in the presence of adversarial attacks on classical inputs $\\mathbf{x}$, the increase in sample complexity due to adversarial training over conventional training vanishes in the limit of high dimensional inputs $\\mathbf{x}$. In contrast, when the adversary can directly attack the quantum state $\\rho(\\mathbf{x})$ encoding the input $\\mathbf{x}$, the excess generalization error depends on the choice of embedding only through its Hilbert space dimension. The results are also extended to multi-class classifiers. We validate our theoretical findings with numerical experiments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17690",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.786505Z"
  },
  {
    "id": "b2fa132e3ef37209c0fd07c20959782e",
    "title": "Plasma State Monitoring and Disruption Characterization using Multimodal VAEs",
    "slug": "plasma-state-monitoring-and-disruption-characterization-using-multimodal-vaes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Plasma Physics (physics.plasm-ph)",
    "author": {
      "name": "Yoeri Poels",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "When a plasma disrupts in a tokamak, significant heat and electromagnetic loads are deposited onto the surrounding device components. These forces scale with plasma current and magnetic field strength, making disruptions one of the key challenges for future devices. Unfortunately, disruptions are not fully understood, with many different underlying causes that are difficult to anticipate. Data-driven models have shown success in predicting them, but they only provide limited interpretability. On the other hand, large-scale statistical analyses have been a great asset to understanding disruptive patterns. In this paper, we leverage data-driven methods to find an interpretable representation of the plasma state for disruption characterization. Specifically, we use a latent variable model to represent diagnostic measurements as a low-dimensional, latent representation. We build upon the Variational Autoencoder (VAE) framework, and extend it for (1) continuous projections of plasma trajectories; (2) a multimodal structure to separate operating regimes; and (3) separation with respect to disruptive regimes. Subsequently, we can identify continuous indicators for the disruption rate and the disruptivity based on statistical properties of measurement data. The proposed method is demonstrated using a dataset of approximately 1600 TCV discharges, selecting for flat-top disruptions or regular terminations. We evaluate the method with respect to (1) the identified disruption risk and its correlation with other plasma properties; (2) the ability to distinguish different types of disruptions; and (3) downstream analyses. For the latter, we conduct a demonstrative study on identifying parameters connected to disruptions using counterfactual-like analysis. Overall, the method can adequately identify distinct operating regimes characterized by varying proximity to disruptions in an interpretable manner.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17710",
    "tags": [
      "Plasma Physics (physics.plasm-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.786726Z"
  },
  {
    "id": "871a6de891456134067e53b831c29851",
    "title": "Evaluating Uncertainty in Deep Gaussian Processes",
    "slug": "evaluating-uncertainty-in-deep-gaussian-processes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Matthijs van der Lende",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reliable uncertainty estimates are crucial in modern machine learning. Deep Gaussian Processes (DGPs) and Deep Sigma Point Processes (DSPPs) extend GPs hierarchically, offering promising methods for uncertainty quantification grounded in Bayesian principles. However, their empirical calibration and robustness under distribution shift relative to baselines like Deep Ensembles remain understudied. This work evaluates these models on regression (CASP dataset) and classification (ESR dataset) tasks, assessing predictive performance (MAE, Accu- racy), calibration using Negative Log-Likelihood (NLL) and Expected Calibration Error (ECE), alongside robustness under various synthetic feature-level distribution shifts. Results indicate DSPPs provide strong in-distribution calibration leveraging their sigma point approximations. However, compared to Deep Ensembles, which demonstrated superior robustness in both per- formance and calibration under the tested shifts, the GP-based methods showed vulnerabilities, exhibiting particular sensitivity in the observed metrics. Our findings underscore ensembles as a robust baseline, suggesting that while deep GP methods offer good in-distribution calibration, their practical robustness under distribution shift requires careful evaluation. To facilitate reproducibility, we make our code available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17719",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.786930Z"
  },
  {
    "id": "b7fa5d587e20d2112f4471cf18b9b463",
    "title": "EgoCHARM: Resource-Efficient Hierarchical Activity Recognition using an Egocentric IMU Sensor",
    "slug": "egocharm:-resource-efficient-hierarchical-activity-recognition-using-an-egocentric-imu-sensor",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Akhil Padmanabha",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Human activity recognition (HAR) on smartglasses has various use cases, including health/fitness tracking and input for context-aware AI assistants. However, current approaches for egocentric activity recognition suffer from low performance or are resource-intensive. In this work, we introduce a resource (memory, compute, power, sample) efficient machine learning algorithm, EgoCHARM, for recognizing both high level and low level activities using a single egocentric (head-mounted) Inertial Measurement Unit (IMU). Our hierarchical algorithm employs a semi-supervised learning strategy, requiring primarily high level activity labels for training, to learn generalizable low level motion embeddings that can be effectively utilized for low level activity recognition. We evaluate our method on 9 high level and 3 low level activities achieving 0.826 and 0.855 F1 scores on high level and low level activity recognition respectively, with just 63k high level and 22k low level model parameters, allowing the low level encoder to be deployed directly on current IMU chips with compute. Lastly, we present results and insights from a sensitivity analysis and highlight the opportunities and limitations of activity recognition using egocentric IMUs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17735",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.787145Z"
  },
  {
    "id": "b22776cce68c7fd26f62997f1ebc0751",
    "title": "The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs",
    "slug": "the-sparse-frontier:-sparse-attention-trade-offs-in-transformer-llms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Piotr Nawrot",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Sparse attention offers a promising strategy to extend long-context capabilities in Transformer LLMs, yet its viability, its efficiency-accuracy trade-offs, and systematic scaling studies remain unexplored. To address this gap, we perform a careful comparison of training-free sparse attention methods at varying model scales, sequence lengths, and sparsity levels on a diverse collection of long-sequence tasks-including novel ones that rely on natural language while remaining controllable and easy to evaluate. Based on our experiments, we report a series of key findings: 1) an isoFLOPS analysis reveals that for very long sequences, larger and highly sparse models are preferable to smaller and dense ones. 2) The level of sparsity attainable while statistically guaranteeing accuracy preservation is higher during decoding than prefilling, and correlates with model size in the former. 3) There is no clear strategy that performs best across tasks and phases, with different units of sparsification or budget adaptivity needed for different scenarios. Even moderate sparsity levels often result in significant performance degradation on at least one task, highlighting that sparse attention is not a universal solution. 4) We introduce and validate novel scaling laws specifically tailored for sparse attention, providing evidence that our findings are likely to hold true beyond our range of experiments. Through these insights, we demonstrate that sparse attention is a key tool to enhance the capabilities of Transformer LLMs for processing longer sequences, but requires careful evaluation of trade-offs for performance-sensitive applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17768",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.787353Z"
  },
  {
    "id": "92105dc5bd3557801fdb82e6e2d2ae41",
    "title": "Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control",
    "slug": "integrating-learning-based-manipulation-and-physics-based-locomotion-for-whole-body-badminton-robot-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Haochen Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Learning-based methods, such as imitation learning (IL) and reinforcement learning (RL), can produce excel control policies over challenging agile robot tasks, such as sports robot. However, no existing work has harmonized learning-based policy with model-based methods to reduce training complexity and ensure the safety and stability for agile badminton robot control. In this paper, we introduce \\ourmethod, a novel hybrid control system for agile badminton robots. Specifically, we propose a model-based strategy for chassis locomotion which provides a base for arm policy. We introduce a physics-informed ``IL+RL'' training framework for learning-based arm policy. In this train framework, a model-based strategy with privileged information is used to guide arm policy training during both IL and RL phases. In addition, we train the critic model during IL phase to alleviate the performance drop issue when transitioning from IL to RL. We present results on our self-engineered badminton robot, achieving 94.5% success rate against the serving machine and 90.7% success rate against human players. Our system can be easily generalized to other agile mobile manipulation tasks such as agile catching and table tennis. Our project website: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17771",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:23.787584Z"
  },
  {
    "id": "962d11fe76c014b731b98d25163d1baa",
    "title": "Unleashing the Power of Natural Audio Featuring Multiple Sound Sources",
    "slug": "unleashing-the-power-of-natural-audio-featuring-multiple-sound-sources",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Sound (cs.SD)",
    "author": {
      "name": "Xize Cheng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Universal sound separation aims to extract clean audio tracks corresponding to distinct events from mixed audio, which is critical for artificial auditory perception. However, current methods heavily rely on artificially mixed audio for training, which limits their ability to generalize to naturally mixed audio collected in real-world environments. To overcome this limitation, we propose ClearSep, an innovative framework that employs a data engine to decompose complex naturally mixed audio into multiple independent tracks, thereby allowing effective sound separation in real-world scenarios. We introduce two remix-based evaluation metrics to quantitatively assess separation quality and use these metrics as thresholds to iteratively apply the data engine alongside model training, progressively optimizing separation performance. In addition, we propose a series of training strategies tailored to these separated independent tracks to make the best use of them. Extensive experiments demonstrate that ClearSep achieves state-of-the-art performance across multiple sound separation tasks, highlighting its potential for advancing sound separation in natural audio scenarios. For more examples and detailed results, please visit our demo page at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17782",
    "tags": [
      "Sound (cs.SD)"
    ],
    "createdAt": "2025-04-25T15:49:23.787803Z"
  },
  {
    "id": "0db85ee03dfdfee9fa648f0a59be8c10",
    "title": "Predictive and prescriptive analytics for multi-site modelling of frail and elderly patient services",
    "slug": "predictive-and-prescriptive-analytics-for-multi-site-modelling-of-frail-and-elderly-patient-services",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Elizabeth Williams",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many economies are challenged by the effects of an ageing population, particularly in sectors where resource capacity planning is critical, such as healthcare. This research addresses the operational challenges of bed and staffing capacity planning in hospital wards by using predictive and prescriptive analytical methods, both individually and in tandem. We applied these methodologies to a study of 165,000 patients across a network of 11 hospitals in the UK. Predictive modelling, specifically Classification and Regression Trees, forecasts patient length of stay based on clinical and demographic data. On the prescriptive side, deterministic and two-stage stochastic optimisation models determine optimal bed and staff planning strategies to minimise costs. Linking the predictive models with the prescriptive optimisation models, generates demand forecasts that inform the optimisation process, providing accurate and practical solutions. The results demonstrate that this integrated approach captures real-world variations in patient LOS and offers a 7% cost saving compared to average-based planning. This approach helps healthcare managers make robust decisions by incorporating patient-specific characteristics, improving capacity allocation, and mitigating risks associated with demand variability. Consequently, this combined methodology can be broadly extended across various sectors facing similar challenges, showcasing the versatility and effectiveness of integrating predictive and prescriptive analytics.",
    "pdfUrl": "https://arxiv.org/pdf/2311.07283",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.788008Z"
  },
  {
    "id": "5be04c9b5aaa0e38422a6c43370e2f22",
    "title": "MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations",
    "slug": "muvo:-a-multimodal-generative-world-model-for-autonomous-driving-with-geometric-representations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Daniel Bogdoll",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "World models for autonomous driving have the potential to dramatically improve the reasoning capabilities of today's systems. However, most works focus on camera data, with only a few that leverage lidar data or combine both to better represent autonomous vehicle sensor setups. In addition, raw sensor predictions are less actionable than 3D occupancy predictions, but there are no works examining the effects of combining both multimodal sensor data and 3D occupancy prediction. In this work, we perform a set of experiments with a MUltimodal World Model with Geometric VOxel representations (MUVO) to evaluate different sensor fusion strategies to better understand the effects on sensor data prediction. We also analyze potential weaknesses of current sensor fusion approaches and examine the benefits of additionally predicting 3D occupancy.",
    "pdfUrl": "https://arxiv.org/pdf/2311.11762",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.788222Z"
  },
  {
    "id": "c561b9c0a76b9bb1d9d9a1650c38df48",
    "title": "Learning by Doing: An Online Causal Reinforcement Learning Framework with Causal-Aware Policy",
    "slug": "learning-by-doing:-an-online-causal-reinforcement-learning-framework-with-causal-aware-policy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ruichu Cai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As a key component to intuitive cognition and reasoning solutions in human intelligence, causal knowledge provides great potential for reinforcement learning (RL) agents' interpretability towards decision-making by helping reduce the searching space. However, there is still a considerable gap in discovering and incorporating causality into RL, which hinders the rapid development of causal RL. In this paper, we consider explicitly modeling the generation process of states with the causal graphical model, based on which we augment the policy. We formulate the causal structure updating into the RL interaction process with active intervention learning of the environment. To optimize the derived objective, we propose a framework with theoretical performance guarantees that alternates between two steps: using interventions for causal structure learning during exploration and using the learned causal structure for policy guidance during exploitation. Due to the lack of public benchmarks that allow direct intervention in the state space, we design the root cause localization task in our simulated fault alarm environment and then empirically show the effectiveness and robustness of the proposed method against state-of-the-art baselines. Theoretical analysis shows that our performance improvement attributes to the virtuous cycle of causal-guided policy learning and causal structure learning, which aligns with our experimental results. Codes are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2402.04869",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.788452Z"
  },
  {
    "id": "ecf9f47480b4de39e95a39749e236475",
    "title": "Effective Bayesian Causal Inference via Structural Marginalisation and Autoregressive Orders",
    "slug": "effective-bayesian-causal-inference-via-structural-marginalisation-and-autoregressive-orders",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Christian Toth",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The traditional two-stage approach to causal inference first identifies a single causal model (or equivalence class of models), which is then used to answer causal queries. However, this neglects any epistemic model uncertainty. In contrast, Bayesian causal inference does incorporate epistemic uncertainty into query estimates via Bayesian marginalisation (posterior averaging) over all causal models. While principled, this marginalisation over entire causal models, i.e., both causal structures (graphs) and mechanisms, poses a tremendous computational challenge. In this work, we address this challenge by decomposing structure marginalisation into the marginalisation over (i) causal orders and (ii) directed acyclic graphs (DAGs) given an order. We can marginalise the latter in closed form by limiting the number of parents per variable and utilising Gaussian processes to model mechanisms. To marginalise over orders, we use a sampling-based approximation, for which we devise a novel auto-regressive distribution over causal orders (ARCO). Our method outperforms state-of-the-art in structure learning on simulated non-linear additive noise benchmarks, and yields competitive results on real-world data. Furthermore, we can accurately infer interventional distributions and average causal effects.",
    "pdfUrl": "https://arxiv.org/pdf/2402.14781",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.788656Z"
  },
  {
    "id": "70df52f40ca00ff2441a098bbaff259b",
    "title": "PARMESAN: Parameter-Free Memory Search and Transduction for Dense Prediction Tasks",
    "slug": "parmesan:-parameter-free-memory-search-and-transduction-for-dense-prediction-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Philip Matthias Winter",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This work addresses flexibility in deep learning by means of transductive reasoning. For adaptation to new data and tasks, e.g., in continual learning, existing methods typically involve tuning learnable parameters or complete re-training from scratch, rendering such approaches unflexible in practice. We argue that the notion of separating computation from memory by the means of transduction can act as a stepping stone for solving these issues. We therefore propose PARMESAN (parameter-free memory search and transduction), a scalable method which leverages a memory module for solving dense prediction tasks. At inference, hidden representations in memory are being searched to find corresponding patterns. In contrast to other methods that rely on continuous training of learnable parameters, PARMESAN learns via memory consolidation simply by modifying stored contents. Our method is compatible with commonly used architectures and canonically transfers to 1D, 2D, and 3D grid-based data. The capabilities of our approach are demonstrated at the complex task of continual learning. PARMESAN learns by 3-4 orders of magnitude faster than established baselines while being on par in terms of predictive performance, hardware-efficiency, and knowledge retention.",
    "pdfUrl": "https://arxiv.org/pdf/2403.11743",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.788890Z"
  },
  {
    "id": "5844c5d22623af6f31398a5fbfb9c009",
    "title": "T-Explainer: A Model-Agnostic Explainability Framework Based on Gradients",
    "slug": "t-explainer:-a-model-agnostic-explainability-framework-based-on-gradients",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Evandro S. Ortigossa",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The development of machine learning applications has increased significantly in recent years, motivated by the remarkable ability of learning-powered systems to discover and generalize intricate patterns hidden in massive datasets. Modern learning models, while powerful, often exhibit a complexity level that renders them opaque black boxes, lacking transparency and hindering our understanding of their decision-making processes. Opacity challenges the practical application of machine learning, especially in critical domains requiring informed decisions. Explainable Artificial Intelligence (XAI) addresses that challenge, unraveling the complexity of black boxes by providing explanations. Feature attribution/importance XAI stands out for its ability to delineate the significance of input features in predictions. However, most attribution methods have limitations, such as instability, when divergent explanations result from similar or the same instance. This work introduces T-Explainer, a novel additive attribution explainer based on the Taylor expansion that offers desirable properties such as local accuracy and consistency. We demonstrate T-Explainer's effectiveness and stability over multiple runs in quantitative benchmark experiments against well-known attribution methods. Additionally, we provide several tools to evaluate and visualize explanations, turning T-Explainer into a comprehensive XAI framework.",
    "pdfUrl": "https://arxiv.org/pdf/2404.16495",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.789102Z"
  },
  {
    "id": "b5423d6d8a1f397cdc0135d56cbde379",
    "title": "Overcoming Knowledge Barriers: Online Imitation Learning from Visual Observation with Pretrained World Models",
    "slug": "overcoming-knowledge-barriers:-online-imitation-learning-from-visual-observation-with-pretrained-world-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Xingyuan Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Pretraining and finetuning models has become increasingly popular in decision-making. But there are still serious impediments in Imitation Learning from Observation (ILfO) with pretrained models. This study identifies two primary obstacles: the Embodiment Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB). The EKB emerges due to the pretrained models' limitations in handling novel observations, which leads to inaccurate action inference. Conversely, the DKB stems from the reliance on limited demonstration datasets, restricting the model's adaptability across diverse scenarios. We propose separate solutions to overcome each barrier and apply them to Action Inference by Maximising Evidence (AIME), a state-of-the-art algorithm. This new algorithm, AIME-NoB, integrates online interactions and a data-driven regulariser to mitigate the EKB. Additionally, it uses a surrogate reward function to broaden the policy's supported states, addressing the DKB. Our experiments on vision-based control tasks from the DeepMind Control Suite and MetaWorld benchmarks show that AIME-NoB significantly improves sample efficiency and converged performance, presenting a robust framework for overcoming the challenges in ILfO with pretrained models. Code available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2404.18896",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.789307Z"
  },
  {
    "id": "b4594a2812d083830bc20a9394099e07",
    "title": "MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation",
    "slug": "mage:-model-level-graph-neural-networks-explanations-via-motif-based-graph-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhaoning Yu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Graph Neural Networks (GNNs) have shown remarkable success in molecular tasks, yet their interpretability remains challenging. Traditional model-level explanation methods like XGNN and GNNInterpreter often fail to identify valid substructures like rings, leading to questionable interpretability. This limitation stems from XGNN's atom-by-atom approach and GNNInterpreter's reliance on average graph embeddings, which overlook the essential structural elements crucial for molecules. To address these gaps, we introduce an innovative \\textbf{M}otif-b\\textbf{A}sed \\textbf{G}NN \\textbf{E}xplainer (MAGE) that uses motifs as fundamental units for generating explanations. Our approach begins with extracting potential motifs through a motif decomposition technique. Then, we utilize an attention-based learning method to identify class-specific motifs. Finally, we employ a motif-based graph generator for each class to create molecular graph explanations based on these class-specific motifs. This novel method not only incorporates critical substructures into the explanations but also guarantees their validity, yielding results that are human-understandable. Our proposed method's effectiveness is demonstrated through quantitative and qualitative assessments conducted on six real-world molecular datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2405.12519",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.789503Z"
  },
  {
    "id": "6971b37c693e7a0cf7739b2e6e666184",
    "title": "On Minimizing Adversarial Counterfactual Error in Adversarial RL",
    "slug": "on-minimizing-adversarial-counterfactual-error-in-adversarial-rl",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Roman Belaire",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deep Reinforcement Learning (DRL) policies are highly susceptible to adversarial noise in observations, which poses significant risks in safety-critical scenarios. The challenge inherent to adversarial perturbations is that by altering the information observed by the agent, the state becomes only partially observable. Existing approaches address this by either enforcing consistent actions across nearby states or maximizing the worst-case value within adversarially perturbed observations. However, the former suffers from performance degradation when attacks succeed, while the latter tends to be overly conservative, leading to suboptimal performance in benign settings. We hypothesize that these limitations stem from their failing to account for partial observability directly. To this end, we introduce a novel objective called Adversarial Counterfactual Error (ACoE), defined on the beliefs about the true state and balancing value optimization with robustness. To make ACoE scalable in model-free settings, we propose the theoretically-grounded surrogate objective Cumulative-ACoE (C-ACoE). Our empirical evaluations on standard benchmarks (MuJoCo, Atari, and Highway) demonstrate that our method significantly outperforms current state-of-the-art approaches for addressing adversarial RL challenges, offering a promising direction for improving robustness in DRL under adversarial conditions. Our code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2406.04724",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.789708Z"
  },
  {
    "id": "a025d8badf7212fe6105ba6aa0b2d9bd",
    "title": "Diffusion Models Are Real-Time Game Engines",
    "slug": "diffusion-models-are-real-time-game-engines",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Dani Valevski",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present GameNGen, the first game engine powered entirely by a neural model that also enables real-time interaction with a complex environment over long trajectories at high quality. When trained on the classic game DOOM, GameNGen extracts gameplay and uses it to generate a playable environment that can interactively simulate new trajectories. GameNGen runs at 20 frames per second on a single TPU and remains stable over extended multi-minute play sessions. Next frame prediction achieves a PSNR of 29.4, comparable to lossy JPEG compression. Human raters are only slightly better than random chance at distinguishing short clips of the game from clips of the simulation, even after 5 minutes of auto-regressive generation. GameNGen is trained in two phases: (1) an RL-agent learns to play the game and the training sessions are recorded, and (2) a diffusion model is trained to produce the next frame, conditioned on the sequence of past frames and actions. Conditioning augmentations help ensure stable auto-regressive generation over long trajectories, and decoder fine-tuning improves the fidelity of visual details and text.",
    "pdfUrl": "https://arxiv.org/pdf/2408.14837",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.789916Z"
  },
  {
    "id": "f417315e9599a57daae8d0992244bc30",
    "title": "On the Benefits of Memory for Modeling Time-Dependent PDEs",
    "slug": "on-the-benefits-of-memory-for-modeling-time-dependent-pdes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ricardo Buitrago Ruiz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Data-driven techniques have emerged as a promising alternative to traditional numerical methods for solving PDEs. For time-dependent PDEs, many approaches are Markovian -- the evolution of the trained system only depends on the current state, and not the past states. In this work, we investigate the benefits of using memory for modeling time-dependent PDEs: that is, when past states are explicitly used to predict the future. Motivated by the Mori-Zwanzig theory of model reduction, we theoretically exhibit examples of simple (even linear) PDEs, in which a solution that uses memory is arbitrarily better than a Markovian solution. Additionally, we introduce Memory Neural Operator (MemNO), a neural operator architecture that combines recent state space models (specifically, S4) and Fourier Neural Operators (FNOs) to effectively model memory. We empirically demonstrate that when the PDEs are supplied in low resolution or contain observation noise at train and test time, MemNO significantly outperforms the baselines without memory -- with up to 6x reduction in test error. Furthermore, we show that this benefit is particularly pronounced when the PDE solutions have significant high-frequency Fourier modes (e.g., low-viscosity fluid dynamics) and we construct a challenging benchmark dataset consisting of such PDEs.",
    "pdfUrl": "https://arxiv.org/pdf/2409.02313",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.790114Z"
  },
  {
    "id": "5d1c7f6359549070c6f5b7226891b16e",
    "title": "nGPT: Normalized Transformer with Representation Learning on the Hypersphere",
    "slug": "ngpt:-normalized-transformer-with-representation-learning-on-the-hypersphere",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ilya Loshchilov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a novel neural network architecture, the normalized Transformer (nGPT) with representation learning on the hypersphere. In nGPT, all vectors forming the embeddings, MLP, attention matrices and hidden states are unit norm normalized. The input stream of tokens travels on the surface of a hypersphere, with each layer contributing a displacement towards the target output predictions. These displacements are defined by the MLP and attention blocks, whose vector components also reside on the same hypersphere. Experiments show that nGPT learns much faster, reducing the number of training steps required to achieve the same accuracy by a factor of 4 to 20, depending on the sequence length.",
    "pdfUrl": "https://arxiv.org/pdf/2410.01131",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.790326Z"
  },
  {
    "id": "96ae566923927b2406029800a8f9cad3",
    "title": "Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF",
    "slug": "regressing-the-relative-future:-efficient-policy-optimization-for-multi-turn-rlhf",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhaolin Gao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) have achieved remarkable success at tasks like summarization that involve a single turn of interaction. However, they can still struggle with multi-turn tasks like dialogue that require long-term planning. Previous works on multi-turn dialogue extend single-turn reinforcement learning from human feedback (RLHF) methods to the multi-turn setting by treating all prior dialogue turns as a long context. Such approaches suffer from covariate shift: the conversations in the training set have previous turns generated by some reference policy, which means that low training error may not necessarily correspond to good performance when the learner is actually in the conversation loop. In response, we introduce REgressing the RELative FUture (REFUEL), an efficient policy optimization approach designed to address multi-turn RLHF in LLMs. REFUEL employs a single model to estimate $Q$-values and trains on self-generated data, addressing the covariate shift issue. REFUEL frames the multi-turn RLHF problem as a sequence of regression tasks on iteratively collected datasets, enabling ease of implementation. Theoretically, we prove that REFUEL can match the performance of any policy covered by the training set. Empirically, we evaluate our algorithm by using Llama-3.1-70B-it to simulate a user in conversation with our model. REFUEL consistently outperforms state-of-the-art methods such as DPO and REBEL across various settings. Furthermore, despite having only 8 billion parameters, Llama-3-8B-it fine-tuned with REFUEL outperforms Llama-3.1-70B-it on long multi-turn dialogues. Implementation of REFUEL can be found at this https URL, and models trained by REFUEL can be found at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2410.04612",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.790546Z"
  },
  {
    "id": "b67f0a2eada45142b5196a0f46fb8e33",
    "title": "Transfer Learning with Foundational Models for Time Series Forecasting using Low-Rank Adaptations",
    "slug": "transfer-learning-with-foundational-models-for-time-series-forecasting-using-low-rank-adaptations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "M. Germn-Morales",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Foundational Models are an emerging widely used technique of GenAI. These models are distinguished by their scalability and the ease with which they can be adapted through the exploitation of Transfer Learning. The availability of high computational power and large datasets have supported their development, achieving a high generalization capacity due to the enormous and heterogeneous amounts of data used in their initial training. These characteristics contribute to a solid base that can be adapted or adjusted to a wide range of tasks, increasing their applicability. This study proposes the methodology LLIAM, a straightforward adaptation of a kind of FM, Large Language Models, for the Time Series Forecasting task. An adequate time-series prompting schema and Low-Rank Adaptations are used to enhance the knowledge of the model with diverse time series datasets, known as the fine-tuning phase. A study divided in two stages has been performed for evaluating the effectiveness of the proposed methodology. Initially, a comparison was made between the performance of LLIAM and different state-of-the-art DL algorithms, including Recurrent Neural Networks and Temporal Convolutional Networks, as well as a LLM-based method, TimeLLM. Following this, a zero-shot study is presented in order to evaluate the generalization capacity of the proposed methodology with time series datasets from unknown domains not considered in the model training. The outcomes of this investigation demonstrate the efficacy of LLIAM, highlighting that this straightforward and general approach can attain competent results without the necessity for applying complex modifications. This work also encourages the use of available resources (such as these pre-trained models) and efficient fine-tuning techniques to avoid unnecessary and costly training, narrowing the gap between the goals of traditional AI and Green AI.",
    "pdfUrl": "https://arxiv.org/pdf/2410.11539",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.790750Z"
  },
  {
    "id": "e21b3ba91ca69fa3bed8001569de3637",
    "title": "A Simple and Efficient Approach to Batch Bayesian Optimization",
    "slug": "a-simple-and-efficient-approach-to-batch-bayesian-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Dawei Zhan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Extending Bayesian optimization to batch evaluation can enable the designer to make the most use of parallel computing technology. However, most of current batch approaches do not scale well with the batch size. That is, their performances deteriorate dramatically as the batch size increases. To address this issue, we propose a simple and efficient approach to extend Bayesian optimization to large-scale batch evaluation in this work. Different from existing batch approaches, the idea of the new approach is to draw a batch of axis-aligned subspaces of the original problem and select one acquisition point from each subspace. To achieve this, we propose the expected subspace improvement criterion to measure the amount of the improvement that a candidate point can achieve within a certain axis-aligned subspace. By optimizing these expected subspace improvement functions simultaneously, we can get a batch of query points for parallel evaluation. Numerical experiments show that our proposed approach can speedup the convergence significantly when compared with the sequential Bayesian optimization algorithm, and performs very competitively when compared with seven batch Bayesian optimization algorithms. A Matlab implementation of the proposed approach is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2411.16206",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.790951Z"
  },
  {
    "id": "a5b50b139f2dd7ae5c81963d4875721b",
    "title": "Know Unreported Roadway Incidents in Real-time: Early Traffic Anomaly Detection",
    "slug": "know-unreported-roadway-incidents-in-real-time:-early-traffic-anomaly-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Haocheng Duan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This research aims to know traffic anomalies as early as possible. A traffic anomaly refers to a generic incident on the road that influences traffic flow and calls for urgent traffic management measures. `Knowing'' the occurrence of a traffic anomaly is twofold: the ability to detect this anomaly before it is reported anywhere, or it may be such that an anomaly can be predicted before it actually occurs on the road (e.g., non-recurrent traffic breakdown). In either way, the objective is to inform traffic operators of unreported incidents in real time and as early as possible. The key is to stay ahead of the curve. Time is of the essence.\nConventional automatic incident detection (AID) methods often struggle with early detection due to their limited consideration of spatial effects and early-stage characteristics. Therefore, we propose a deep learning framework utilizing prior domain knowledge and model-designing strategies. This allows the model to detect a broader range of anomalies, not only incidents that significantly influence traffic flow but also early characteristics of incidents along with historically unreported anomalies. We specially design the model to target the early-stage detection/prediction of an incident. Additionally, unlike most conventional AID studies, our method is highly scalable and generalizable, as it is fully automated with no manual selection of historical reports required, relies solely on widely available low-cost data, and requires no additional detectors. The experimental results across numerous road segments on different maps demonstrate that our model leads to more effective and early anomaly detection.",
    "pdfUrl": "https://arxiv.org/pdf/2412.10892",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.791157Z"
  },
  {
    "id": "106281aecaed377e8e4e1a9fa78fe3ed",
    "title": "Optimal Rates for Robust Stochastic Convex Optimization",
    "slug": "optimal-rates-for-robust-stochastic-convex-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Changyu Gao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Machine learning algorithms in high-dimensional settings are highly susceptible to the influence of even a small fraction of structured outliers, making robust optimization techniques essential. In particular, within the $\\epsilon$-contamination model, where an adversary can inspect and replace up to an $\\epsilon$-fraction of the samples, a fundamental open problem is determining the optimal rates for robust stochastic convex optimization (SCO) under such contamination. We develop novel algorithms that achieve minimax-optimal excess risk (up to logarithmic factors) under the $\\epsilon$-contamination model. Our approach improves over existing algorithms, which are not only suboptimal but also require stringent assumptions, including Lipschitz continuity and smoothness of individual sample functions. By contrast, our optimal algorithms do not require these stringent assumptions, assuming only population-level smoothness of the loss. Moreover, our algorithms can be adapted to handle the case in which the covariance parameter is unknown, and can be extended to nonsmooth population risks via convolutional smoothing. We complement our algorithmic developments with a tight information-theoretic lower bound for robust SCO.",
    "pdfUrl": "https://arxiv.org/pdf/2412.11003",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.791379Z"
  },
  {
    "id": "d0204ed0bf3a02154a3af1d056225975",
    "title": "Emergent Symbol-like Number Variables in Artificial Neural Networks",
    "slug": "emergent-symbol-like-number-variables-in-artificial-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Satchel Grant",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "What types of numeric representations emerge in neural systems? What would a satisfying answer to this question look like? In this work, we interpret Neural Network (NN) solutions to sequence based counting tasks through a variety of lenses. We seek to understand how well we can understand NNs through the lens of interpretable Symbolic Algorithms (SAs), where SAs are defined by precise, abstract, mutable variables used to perform computations. We use GRUs, LSTMs, and Transformers trained using Next Token Prediction (NTP) on numeric tasks where the solutions to the tasks depend on numeric information only latent in the task structure. We show through multiple causal and theoretical methods that we can interpret NN's raw activity through the lens of simplified SAs when we frame the neural activity in terms of interpretable subspaces rather than individual neurons. Depending on the analysis, however, these interpretations can be graded, existing on a continuum, highlighting the philosophical question of what it means to \"interpret\" neural activity, and motivating us to introduce Alignment Functions to add flexibility to the existing Distributed Alignment Search (DAS) method. Through our specific analyses we show the importance of causal interventions for NN interpretability; we show that recurrent models develop graded, symbol-like number variables within their neural activity; we introduce a generalization of DAS to frame NN activity in terms of linear functions of interpretable variables; and we show that Transformers must use anti-Markovian solutions -- solutions that avoid using cumulative, Markovian hidden states -- in the absence of sufficient attention layers. We use our results to encourage interpreting NNs at the level of neural subspaces through the lens of SAs.",
    "pdfUrl": "https://arxiv.org/pdf/2501.06141",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.791574Z"
  },
  {
    "id": "12952f92c4220ff86eca2aa19c3d8bf0",
    "title": "Model Alignment Search",
    "slug": "model-alignment-search",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Satchel Grant",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "When can we say that two neural systems are the same? The answer to this question is goal-dependent, and it is often addressed through correlative methods such as Representational Similarity Analysis (RSA) and Centered Kernel Alignment (CKA). We find ourselves chiefly interested in the relationship between representations and behavior, asking ourselves how we can isolate specific functional aspects of representational similarity to relate our measures to behavior -- avoiding cause vs. correlation pitfalls in the process. In this work, we introduce Model Alignment Search (MAS), a method for causally exploring distributed representational similarity as it relates to behavior. The method learns invertible linear transformations that find an aligned subspace between two distributed networks' representations where functional information can be isolated and manipulated. We first show that the method can be used to transfer values of specific causal variables -- such as the number of items in a counting task -- between networks with different training seeds and different architectures. We then explore open questions in number cognition by comparing different types of numeric representations in models trained on structurally different tasks, we explore differences between MAS and preexisting functional similarity methods, and lastly, we introduce a counterfactual latent auxiliary loss that helps shape functionally relevant alignments even in cases where we do not have causal access to one of the two models for training.",
    "pdfUrl": "https://arxiv.org/pdf/2501.06164",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.791768Z"
  },
  {
    "id": "8a9ea7b3f5e46b5d435c76ad2ad9562c",
    "title": "Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data",
    "slug": "spatially-delineated-domain-adapted-ai-classification:-an-application-for-oncology-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Majid Farhadloo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Given multi-type point maps from different place-types (e.g., tumor regions), our objective is to develop a classifier trained on the source place-type to accurately distinguish between two classes of the target place-type based on their point arrangements. This problem is societally important for many applications, such as generating clinical hypotheses for designing new immunotherapies for cancer treatment. The challenge lies in the spatial variability, the inherent heterogeneity and variation observed in spatial properties or arrangements across different locations (i.e., place-types). Previous techniques focus on self-supervised tasks to learn domain-invariant features and mitigate domain differences; however, they often neglect the underlying spatial arrangements among data points, leading to significant discrepancies across different place-types. We explore a novel multi-task self-learning framework that targets spatial arrangements, such as spatial mix-up masking and spatial contrastive predictive coding, for spatially-delineated domain-adapted AI classification. Experimental results on real-world datasets (e.g., oncology data) show that the proposed framework provides higher prediction accuracy than baseline methods.",
    "pdfUrl": "https://arxiv.org/pdf/2501.11695",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.791985Z"
  },
  {
    "id": "a4d651fe7d0b21a6c0c84a1ac9ef75b7",
    "title": "GraphRAG under Fire",
    "slug": "graphrag-under-fire",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Jiacheng Liang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "GraphRAG advances retrieval-augmented generation (RAG) by structuring external knowledge as multi-scale knowledge graphs, enabling language models to integrate both broad context and granular details in their generation. While GraphRAG has demonstrated success across domains, its security implications remain largely unexplored. To bridge this gap, this work examines GraphRAG's vulnerability to poisoning attacks, uncovering an intriguing security paradox: compared to conventional RAG, GraphRAG's graph-based indexing and retrieval enhance resilience against simple poisoning attacks; yet, the same features also create new attack surfaces. We present GRAGPoison, a novel attack that exploits shared relations in the underlying knowledge graph to craft poisoning text capable of compromising multiple queries simultaneously. GRAGPoison employs three key strategies: i) relation injection to introduce false knowledge, ii) relation enhancement to amplify poisoning influence, and iii) narrative generation to embed malicious content within coherent text. Empirical evaluation across diverse datasets and models shows that GRAGPoison substantially outperforms existing attacks in terms of effectiveness (up to 98\\% success rate) and scalability (using less than 68\\% poisoning text) on various GraphRAG-based systems. We also explore potential defensive measures and their limitations, identifying promising directions for future research.",
    "pdfUrl": "https://arxiv.org/pdf/2501.14050",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.792287Z"
  },
  {
    "id": "d6c0daab53c1a2f71244f47b85b50acb",
    "title": "Weak-to-Strong Diffusion with Reflection",
    "slug": "weak-to-strong-diffusion-with-reflection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Lichen Bai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The goal of diffusion generative models is to align the learned distribution with the real data distribution through gradient score matching. However, inherent limitations in training data quality, modeling strategies, and architectural design lead to inevitable gap between generated outputs and real data. To reduce this gap, we propose Weak-to-Strong Diffusion (W2SD), a novel framework that utilizes the estimated difference between existing weak and strong models (i.e., weak-to-strong difference) to bridge the gap between an ideal model and a strong model. By employing a reflective operation that alternates between denoising and inversion with weak-to-strong difference, we theoretically understand that W2SD steers latent variables along sampling trajectories toward regions of the real data distribution. W2SD is highly flexible and broadly applicable, enabling diverse improvements through the strategic selection of weak-to-strong model pairs (e.g., DreamShaper vs. SD1.5, good experts vs. bad experts in MoE). Extensive experiments demonstrate that W2SD significantly improves human preference, aesthetic quality, and prompt adherence, achieving SOTA performance across various modalities (e.g., image, video), architectures (e.g., UNet-based, DiT-based, MoE), and benchmarks. For example, Juggernaut-XL with W2SD can improve with the HPSv2 winning rate up to 90% over the original results. Moreover, the performance gains achieved by W2SD markedly outweigh its additional computational overhead, while the cumulative improvements from different weak-to-strong difference further solidify its practical utility and deployability.",
    "pdfUrl": "https://arxiv.org/pdf/2502.00473",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.792487Z"
  },
  {
    "id": "87b5f322f5d1b333bd5c437bd352d5be",
    "title": "Efficient Model Editing with Task Vector Bases: A Theoretical Framework and Scalable Approach",
    "slug": "efficient-model-editing-with-task-vector-bases:-a-theoretical-framework-and-scalable-approach",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Siqi Zeng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Task vectors, which are derived from the difference between pre-trained and fine-tuned model weights, enable flexible task adaptation and model merging through arithmetic operations such as addition and negation. However, existing approaches often rely on heuristics with limited theoretical support, often leading to performance gaps comparing to direct task fine tuning. Meanwhile, although it is easy to manipulate saved task vectors with arithmetic for different purposes, such compositional flexibility demands high memory usage, especially when dealing with a huge number of tasks, limiting scalability. This work addresses these issues with a theoretically grounded framework that explains task vector arithmetic and introduces the task vector bases framework. Building upon existing task arithmetic literature, our method significantly reduces the memory cost for downstream arithmetic with little effort, while achieving competitive performance and maintaining compositional advantage, providing a practical solution for large-scale task arithmetic. The code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2502.01015",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.792708Z"
  },
  {
    "id": "5e6faf58e830c1ac9012616c8121e35d",
    "title": "Nonasymptotic CLT and Error Bounds for Two-Time-Scale Stochastic Approximation",
    "slug": "nonasymptotic-clt-and-error-bounds-for-two-time-scale-stochastic-approximation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Seo Taek Kong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider linear two-time-scale stochastic approximation algorithms driven by martingale noise. Recent applications in machine learning motivate the need to understand finite-time error rates, but conventional stochastic approximation analysis focus on either asymptotic convergence in distribution or finite-time bounds that are far from optimal. Prior work on asymptotic central limit theorems (CLTs) suggest that two-time-scale algorithms may be able to achieve $1/\\sqrt{n}$ error in expectation, with a constant given by the expected norm of the limiting Gaussian vector. However, the best known finite-time rates are much slower. We derive the first non-asymptotic central limit theorem with respect to the Wasserstein-1 distance for two-time-scale stochastic approximation with Polyak-Ruppert averaging. As a corollary, we show that expected error achieved by Polyak-Ruppert averaging decays at rate $1/\\sqrt{n}$, which significantly improves on the rates of convergence in prior works.",
    "pdfUrl": "https://arxiv.org/pdf/2502.09884",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.792918Z"
  },
  {
    "id": "b75665baefbbec71e307ba0bbb30b44b",
    "title": "Data Analysis Prediction over Multiple Unseen Datasets: A Vector Embedding Approach",
    "slug": "data-analysis-prediction-over-multiple-unseen-datasets:-a-vector-embedding-approach",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Andreas Loizou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The massive increase in the data volume and dataset availability for analysts compels researchers to focus on data content and select high-quality datasets to enhance the performance of analytics operators. While selecting the highest quality data for analysis highly increases task accuracy and efficiency, it is still a hard task, especially when the number of available inputs is very large. To address this issue, we propose a novel methodology that infers the outcome of analytics operators by creating a model from datasets similar to the queried one. Dataset similarity is performed via projecting each dataset to a vector embedding representation. The vectorization process is performed using our proposed deep learning model NumTabData2Vec, which takes a whole dataset and projects it into a lower vector embedding representation space. Through experimental evaluation, we compare the prediction performance and the execution time of our framework to another state-of-the-art modelling operator framework, illustrating that our approach predicts analytics outcomes accurately. Furthermore, our vectorization model can project different real-world scenarios to a lower vector embedding representation and distinguish between them.",
    "pdfUrl": "https://arxiv.org/pdf/2502.17060",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.793111Z"
  },
  {
    "id": "a158ca1367967d454e53c7613307f254",
    "title": "Investigating the Relationship Between Debiasing and Artifact Removal using Saliency Maps",
    "slug": "investigating-the-relationship-between-debiasing-and-artifact-removal-using-saliency-maps",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Lukasz Sztukiewicz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The widespread adoption of machine learning systems has raised critical concerns about fairness and bias, making mitigating harmful biases essential for AI development. In this paper, we investigate the relationship between debiasing and removing artifacts in neural networks for computer vision tasks. First, we introduce a set of novel XAI-based metrics that analyze saliency maps to assess shifts in a model's decision-making process. Then, we demonstrate that successful debiasing methods systematically redirect model focus away from protected attributes. Finally, we show that techniques originally developed for artifact removal can be effectively repurposed for improving fairness. These findings provide evidence for the existence of a bidirectional connection between ensuring fairness and removing artifacts corresponding to protected attributes.",
    "pdfUrl": "https://arxiv.org/pdf/2503.00234",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.793313Z"
  },
  {
    "id": "387c3494461a3b353446339a1e9340d5",
    "title": "Keyframe-oriented Vision Token Pruning: Enhancing Efficiency of Large Vision Language Models on Long-Form Video Processing",
    "slug": "keyframe-oriented-vision-token-pruning:-enhancing-efficiency-of-large-vision-language-models-on-long-form-video-processing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yudong Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Vision language models (VLMs) demonstrate strong capabilities in jointly processing visual and textual data. However, they often incur substantial computational overhead due to redundant visual information, particularly in long-form video scenarios. Existing approaches predominantly focus on either vision token pruning, which may overlook spatio-temporal dependencies, or keyframe selection, which identifies informative frames but discards others, thus disrupting contextual continuity. In this work, we propose KVTP (Keyframe-oriented Vision Token Pruning), a novel framework that overcomes the drawbacks of token pruning and keyframe selection. By adaptively assigning pruning rates based on frame relevance to the query, KVTP effectively retains essential contextual information while significantly reducing redundant computation. To thoroughly evaluate the long-form video understanding capacities of VLMs, we curated and reorganized subsets from VideoMME, EgoSchema, and NextQA into a unified benchmark named SparseKV-QA that highlights real-world scenarios with sparse but crucial events. Our experiments with VLMs of various scales show that KVTP can reduce token usage by 80% without compromising spatiotemporal and contextual consistency, significantly cutting computation while maintaining the performance. These results demonstrate our approach's effectiveness in efficient long-video processing, facilitating more scalable VLM deployment.",
    "pdfUrl": "https://arxiv.org/pdf/2503.10742",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.793548Z"
  },
  {
    "id": "076fcff748a3517bf67def545e1606c3",
    "title": "Adaptive Resampling with Bootstrap for Noisy Multi-Objective Optimization Problems",
    "slug": "adaptive-resampling-with-bootstrap-for-noisy-multi-objective-optimization-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Timo Budszuhn",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The challenge of noisy multi-objective optimization lies in the constant trade-off between exploring new decision points and improving the precision of known points through resampling. This decision should take into account both the variability of the objective functions and the current estimate of a point in relation to the Pareto front. Since the amount and distribution of noise are generally unknown, it is desirable for a decision function to be highly adaptive to the properties of the optimization problem. This paper presents a resampling decision function that incorporates the stochastic nature of the optimization problem by using bootstrapping and the probability of dominance. The distribution-free estimation of the probability of dominance is achieved using bootstrap estimates of the means. To make the procedure applicable even with very few observations, we transfer the distribution observed at other decision points. The efficiency of this resampling approach is demonstrated by applying it in the NSGA-II algorithm with a sequential resampling procedure under multiple noise variations.",
    "pdfUrl": "https://arxiv.org/pdf/2503.21495",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.793750Z"
  },
  {
    "id": "6d85aefa62e5488082ac715d54550f72",
    "title": "A Robust Model-Based Approach for Continuous-Time Policy Evaluation with Unknown Lvy Process Dynamics",
    "slug": "a-robust-model-based-approach-for-continuous-time-policy-evaluation-with-unknown-lvy-process-dynamics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Qihao Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper develops a model-based framework for continuous-time policy evaluation (CTPE) in reinforcement learning, incorporating both Brownian and Lvy noise to model stochastic dynamics influenced by rare and extreme events. Our approach formulates the policy evaluation problem as solving a partial integro-differential equation (PIDE) for the value function with unknown coefficients. A key challenge in this setting is accurately recovering the unknown coefficients in the stochastic dynamics, particularly when driven by Lvy processes with heavy tail effects. To address this, we propose a robust numerical approach that effectively handles both unbiased and censored trajectory datasets. This method combines maximum likelihood estimation with an iterative tail correction mechanism, improving the stability and accuracy of coefficient recovery. Additionally, we establish a theoretical bound for the policy evaluation error based on coefficient recovery error. Through numerical experiments, we demonstrate the effectiveness and robustness of our method in recovering heavy-tailed Lvy dynamics and verify the theoretical error analysis in policy evaluation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.01482",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.793958Z"
  },
  {
    "id": "9bf4499be9a2d2ae0c0e56c223a45ce8",
    "title": "Variational Self-Supervised Learning",
    "slug": "variational-self-supervised-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Mehmet Can Yavuz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present Variational Self-Supervised Learning (VSSL), a novel framework that combines variational inference with self-supervised learning to enable efficient, decoder-free representation learning. Unlike traditional VAEs that rely on input reconstruction via a decoder, VSSL symmetrically couples two encoders with Gaussian outputs. A momentum-updated teacher network defines a dynamic, data-dependent prior, while the student encoder produces an approximate posterior from augmented views. The reconstruction term in the ELBO is replaced with a cross-view denoising objective, preserving the analytical tractability of Gaussian KL divergence. We further introduce cosine-based formulations of KL and log-likelihood terms to enhance semantic alignment in high-dimensional latent spaces. Experiments on CIFAR-10, CIFAR-100, and ImageNet-100 show that VSSL achieves competitive or superior performance to leading self-supervised methods, including BYOL and MoCo V3. VSSL offers a scalable, probabilistically grounded approach to learning transferable representations without generative reconstruction, bridging the gap between variational modeling and modern self-supervised techniques.",
    "pdfUrl": "https://arxiv.org/pdf/2504.04318",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.794154Z"
  },
  {
    "id": "a31166f5525d04a81b2dfa3547882d44",
    "title": "Sharpness-Aware Parameter Selection for Machine Unlearning",
    "slug": "sharpness-aware-parameter-selection-for-machine-unlearning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Saber Malekmohammadi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It often happens that some sensitive personal information, such as credit card numbers or passwords, are mistakenly incorporated in the training of machine learning models and need to be removed afterwards. The removal of such information from a trained model is a complex task that needs to partially reverse the training process. There have been various machine unlearning techniques proposed in the literature to address this problem. Most of the proposed methods revolve around removing individual data samples from a trained model. Another less explored direction is when features/labels of a group of data samples need to be reverted. While the existing methods for these tasks do the unlearning task by updating the whole set of model parameters or only the last layer of the model, we show that there are a subset of model parameters that have the largest contribution in the unlearning target features. More precisely, the model parameters with the largest corresponding diagonal value in the Hessian matrix (computed at the learned model parameter) have the most contribution in the unlearning task. By selecting these parameters and updating them during the unlearning stage, we can have the most progress in unlearning. We provide theoretical justifications for the proposed strategy by connecting it to sharpness-aware minimization and robust unlearning. We empirically show the effectiveness of the proposed strategy in improving the efficacy of unlearning with a low computational cost.",
    "pdfUrl": "https://arxiv.org/pdf/2504.06398",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.794348Z"
  },
  {
    "id": "4088c68b7bfb2030c60c0799f8d04212",
    "title": "FedMerge: Federated Personalization via Model Merging",
    "slug": "fedmerge:-federated-personalization-via-model-merging",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Shutong Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "One global model in federated learning (FL) might not be sufficient to serve many clients with non-IID tasks and distributions. While there has been advances in FL to train multiple global models for better personalization, they only provide limited choices to clients so local finetuning is still indispensable. In this paper, we propose a novel ``FedMerge'' approach that can create a personalized model per client by simply merging multiple global models with automatically optimized and customized weights. In FedMerge, a few global models can serve many non-IID clients, even without further local finetuning. We formulate this problem as a joint optimization of global models and the merging weights for each client. Unlike existing FL approaches where the server broadcasts one or multiple global models to all clients, the server only needs to send a customized, merged model to each client. Moreover, instead of periodically interrupting the local training and re-initializing it to a global model, the merged model aligns better with each client's task and data distribution, smoothening the local-global gap between consecutive rounds caused by client drift. We evaluate FedMerge on three different non-IID settings applied to different domains with diverse tasks and data types, in which FedMerge consistently outperforms existing FL approaches, including clustering-based and mixture-of-experts (MoE) based methods.",
    "pdfUrl": "https://arxiv.org/pdf/2504.06768",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.794565Z"
  },
  {
    "id": "23d675c0e57c192d7940da0966c27733",
    "title": "Looking beyond the next token",
    "slug": "looking-beyond-the-next-token",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Abitha Thankaraj",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The structure of causal language model training assumes that each token can be accurately predicted from the previous context. This contrasts with humans' natural writing and reasoning process, where goals are typically known before the exact argument or phrasings. While this mismatch has been well studied in the literature, the working assumption has been that architectural changes are needed to address this mismatch. We argue that rearranging and processing the training data sequences can allow models to more accurately imitate the true data-generating process, and does not require any other changes to the architecture or training infrastructure. We demonstrate that this technique, Trelawney, and the inference algorithms derived from it allow us to improve performance on several key benchmarks that span planning, algorithmic reasoning, and story generation tasks. Finally, our method naturally enables the generation of long-term goals at no additional cost. We investigate how using the model's goal-generation capability can further improve planning and reasoning. Additionally, we believe Trelawney could potentially open doors to new capabilities beyond the current language modeling paradigm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.11336",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.794764Z"
  },
  {
    "id": "41d621a353d4a5c65a552d445437d61c",
    "title": "Teaching Large Language Models to Reason through Learning and Forgetting",
    "slug": "teaching-large-language-models-to-reason-through-learning-and-forgetting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Tianwei Ni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Leveraging inference-time search in large language models has proven effective in further enhancing a trained model's capability to solve complex mathematical and reasoning problems. However, this approach significantly increases computational costs and inference time, as the model must generate and evaluate multiple candidate solutions to identify a viable reasoning path. To address this, we propose an effective approach that integrates search capabilities directly into the model by fine-tuning it using both successful (learning) and failed reasoning paths (forgetting) derived from diverse search methods. While fine-tuning the model with these data might seem straightforward, we identify a critical issue: the model's search capability tends to degrade rapidly if fine-tuning is performed naively. We show that this degradation can be substantially mitigated by employing a smaller learning rate. Extensive experiments on the challenging Game-of-24 and Countdown mathematical reasoning benchmarks show that our approach not only outperforms both standard fine-tuning and inference-time search baselines but also significantly reduces inference time by 180$\\times$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.11364",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.794979Z"
  },
  {
    "id": "72d69fe3d88eea47b0dc16122c698026",
    "title": "Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning",
    "slug": "nemotron-crossthink:-scaling-self-learning-beyond-math-reasoning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Syeda Nahida Akter",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Large Language Models (LLMs) have shown strong reasoning capabilities, particularly when enhanced through Reinforcement Learning (RL). While prior work has successfully applied RL to mathematical reasoning -- where rules and correctness are well-defined -- generalizing these methods to broader reasoning domains remains challenging due to limited data, the lack of verifiable reward structures, and diverse task requirements. In this work, we propose NEMOTRON-CROSSTHINK, a framework that systematically incorporates multi-domain corpora, including both synthetic and real-world question-answer pairs, into RL training to improve generalization across diverse reasoning tasks. NEMOTRON-CROSSTHINK addresses key challenges by (1) incorporating data from varied sources spanning STEM, humanities, social sciences, etc.; (2) applying structured templates (e.g., multiple-choice and open-ended) to control answer-space complexity; (3) filtering for verifiable answers; and (4) optimizing data blending strategies that utilizes data from multiple sources effectively. Our approach enables scalable and verifiable reward modeling beyond mathematics and demonstrates improved accuracies on both math (MATH-500: +30.1%, AMC23:+27.5%) and non-math reasoning benchmarks (MMLU-PRO: +12.8%, GPQA-DIAMOND: +11.3%, AGIEVAL: +15.1%, SUPERGPQA: +3.8%). Moreover, NEMOTRON-CROSSTHINK exhibits significantly improved response efficiency -- using 28% fewer tokens for correct answers -- highlighting more focused and effective reasoning. Through NEMOTRON-CROSSTHINK, we demonstrate that integrating multi-domain, multi-format data in RL leads to more accurate, efficient, and generalizable LLMs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13941",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.795218Z"
  },
  {
    "id": "a95e1217f0878d565f9e1b36ff630823",
    "title": "Reinforcement Learning from Multi-level and Episodic Human Feedback",
    "slug": "reinforcement-learning-from-multi-level-and-episodic-human-feedback",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Muhammad Qasim Elahi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Designing an effective reward function has long been a challenge in reinforcement learning, particularly for complex tasks in unstructured environments. To address this, various learning paradigms have emerged that leverage different forms of human input to specify or refine the reward function. Reinforcement learning from human feedback is a prominent approach that utilizes human comparative feedback, expressed as a preference for one behavior over another, to tackle this problem. In contrast to comparative feedback, we explore multi-level human feedback, which is provided in the form of a score at the end of each episode. This type of feedback offers more coarse but informative signals about the underlying reward function than binary feedback. Additionally, it can handle non-Markovian rewards, as it is based on the evaluation of an entire episode. We propose an algorithm to efficiently learn both the reward function and the optimal policy from this form of feedback. Moreover, we show that the proposed algorithm achieves sublinear regret and demonstrate its empirical effectiveness through extensive simulations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14732",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.795421Z"
  },
  {
    "id": "16e488f1eebe23195806e83aed50ebd3",
    "title": "Clifford Group Equivariant Diffusion Models for 3D Molecular Generation",
    "slug": "clifford-group-equivariant-diffusion-models-for-3d-molecular-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Cong Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper explores leveraging the Clifford algebra's expressive power for $\\E(n)$-equivariant diffusion models. We utilize the geometric products between Clifford multivectors and the rich geometric information encoded in Clifford subspaces in \\emph{Clifford Diffusion Models} (CDMs). We extend the diffusion process beyond just Clifford one-vectors to incorporate all higher-grade multivector subspaces. The data is embedded in grade-$k$ subspaces, allowing us to apply latent diffusion across complete multivectors. This enables CDMs to capture the joint distribution across different subspaces of the algebra, incorporating richer geometric information through higher-order features. We provide empirical results for unconditional molecular generation on the QM9 dataset, showing that CDMs provide a promising avenue for generative modeling.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15773",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.795629Z"
  },
  {
    "id": "432db526f7130d21bbc1132270c19df7",
    "title": "An Effective Gram Matrix Characterizes Generalization in Deep Networks",
    "slug": "an-effective-gram-matrix-characterizes-generalization-in-deep-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Rubing Yang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We derive a differential equation that governs the evolution of the generalization gap when a deep network is trained by gradient descent. This differential equation is controlled by two quantities, a contraction factor that brings together trajectories corresponding to slightly different datasets, and a perturbation factor that accounts for them training on different datasets. We analyze this differential equation to compute an ``effective Gram matrix'' that characterizes the generalization gap after training in terms of the alignment between this Gram matrix and a certain initial ``residual''. Empirical evaluations on image classification datasets indicate that this analysis can predict the test loss accurately. Further, at any point during training, the residual predominantly lies in the subspace of the effective Gram matrix with the smallest eigenvalues. This indicates that the training process is benign, i.e., it does not lead to significant deterioration of the generalization gap (which is zero at initialization). The alignment between the effective Gram matrix and the residual is different for different datasets and architectures. The match/mismatch of the data and the architecture is primarily responsible for good/bad generalization.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16450",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.795826Z"
  },
  {
    "id": "f6ea69251841f1dda38d55e1a822ee8f",
    "title": "Hyper-Transforming Latent Diffusion Models",
    "slug": "hyper-transforming-latent-diffusion-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Ignacio Peis",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a novel generative framework for functions by integrating Implicit Neural Representations (INRs) and Transformer-based hypernetworks into latent variable models. Unlike prior approaches that rely on MLP-based hypernetworks with scalability limitations, our method employs a Transformer-based decoder to generate INR parameters from latent variables, addressing both representation capacity and computational efficiency. Our framework extends latent diffusion models (LDMs) to INR generation by replacing standard decoders with a Transformer-based hypernetwork, which can be trained either from scratch or via hyper-transforming-a strategy that fine-tunes only the decoder while freezing the pre-trained latent space. This enables efficient adaptation of existing generative models to INR-based representations without requiring full retraining.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16580",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.796023Z"
  },
  {
    "id": "08a1158405e605d48311bdb4db8e1399",
    "title": "Simple Graph Contrastive Learning via Fractional-order Neural Diffusion Networks",
    "slug": "simple-graph-contrastive-learning-via-fractional-order-neural-diffusion-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Yanan Zhao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Graph Contrastive Learning (GCL) has recently made progress as an unsupervised graph representation learning paradigm. GCL approaches can be categorized into augmentation-based and augmentation-free methods. The former relies on complex data augmentations, while the latter depends on encoders that can generate distinct views of the same input. Both approaches may require negative samples for training. In this paper, we introduce a novel augmentation-free GCL framework based on graph neural diffusion models. Specifically, we utilize learnable encoders governed by Fractional Differential Equations (FDE). Each FDE is characterized by an order parameter of the differential operator. We demonstrate that varying these parameters allows us to produce learnable encoders that generate diverse views, capturing either local or global information, for contrastive learning. Our model does not require negative samples for training and is applicable to both homophilic and heterophilic datasets. We demonstrate its effectiveness across various datasets, achieving state-of-the-art performance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16748",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.796259Z"
  },
  {
    "id": "ca2b923d531791e83a5370d0e797f8a5",
    "title": "Exploring How LLMs Capture and Represent Domain-Specific Knowledge",
    "slug": "exploring-how-llms-capture-and-represent-domain-specific-knowledge",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Mirian Hipolito Garcia",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study whether Large Language Models (LLMs) inherently capture domain-specific nuances in natural language. Our experiments probe the domain sensitivity of LLMs by examining their ability to distinguish queries from different domains using hidden states generated during the prefill phase. We reveal latent domain-related trajectories that indicate the model's internal recognition of query domains. We also study the robustness of these domain representations to variations in prompt styles and sources. Our approach leverages these representations for model selection, mapping the LLM that best matches the domain trace of the input query (i.e., the model with the highest performance on similar traces). Our findings show that LLMs can differentiate queries for related domains, and that the fine-tuned model is not always the most accurate. Unlike previous work, our interpretations apply to both closed and open-ended generative tasks",
    "pdfUrl": "https://arxiv.org/pdf/2504.16871",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:23.796473Z"
  },
  {
    "id": "57e018162c4a7c446df334cdab1fdd0d",
    "title": "Analysing Multiscale Clusterings with Persistent Homology",
    "slug": "analysing-multiscale-clusterings-with-persistent-homology",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Juni Schindler",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In data clustering, it is often desirable to find not just a single partition into clusters but a sequence of partitions that describes the data at different scales (or levels of coarseness). A natural problem then is to analyse and compare the (not necessarily hierarchical) sequences of partitions that underpin such multiscale descriptions. Here, we use tools from topological data analysis and introduce the Multiscale Clustering Filtration (MCF), a well-defined and stable filtration of abstract simplicial complexes that encodes arbitrary cluster assignments in a sequence of partitions across scales of increasing coarseness. We show that the zero-dimensional persistent homology of the MCF measures the degree of hierarchy of this sequence, and the higher-dimensional persistent homology tracks the emergence and resolution of conflicts between cluster assignments across the sequence of partitions. To broaden the theoretical foundations of the MCF, we provide an equivalent construction via a nerve complex filtration, and we show that, in the hierarchical case, the MCF reduces to a Vietoris-Rips filtration of an ultrametric space. Using synthetic data, we then illustrate how the persistence diagram of the MCF provides a feature map that can serve to characterise and classify multiscale clusterings.",
    "pdfUrl": "https://arxiv.org/pdf/2305.04281",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:23.796667Z"
  },
  {
    "id": "599ef632c4fe79e4a0f0fad8b4d4dee7",
    "title": "Efficient Neural Network Approaches for Conditional Optimal Transport with Applications in Bayesian Inference",
    "slug": "efficient-neural-network-approaches-for-conditional-optimal-transport-with-applications-in-bayesian-inference",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Zheyu Oliver Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present two neural network approaches that approximate the solutions of static and dynamic $\\unicode{x1D450}\\unicode{x1D45C}\\unicode{x1D45B}\\unicode{x1D451}\\unicode{x1D456}\\unicode{x1D461}\\unicode{x1D456}\\unicode{x1D45C}\\unicode{x1D45B}\\unicode{x1D44E}\\unicode{x1D459}\\unicode{x0020}\\unicode{x1D45C}\\unicode{x1D45D}\\unicode{x1D461}\\unicode{x1D456}\\unicode{x1D45A}\\unicode{x1D44E}\\unicode{x1D459}\\unicode{x0020}\\unicode{x1D461}\\unicode{x1D45F}\\unicode{x1D44E}\\unicode{x1D45B}\\unicode{x1D460}\\unicode{x1D45D}\\unicode{x1D45C}\\unicode{x1D45F}\\unicode{x1D461}$ (COT) problems. Both approaches enable conditional sampling and conditional density estimation, which are core tasks in Bayesian inference$\\unicode{x2013}$particularly in the simulation-based ($\\unicode{x201C}$likelihood-free$\\unicode{x201D}$) setting. Our methods represent the target conditional distribution as a transformation of a tractable reference distribution. Obtaining such a transformation, chosen here to be an approximation of the COT map, is computationally challenging even in moderate dimensions. To improve scalability, our numerical algorithms use neural networks to parameterize candidate maps and further exploit the structure of the COT problem. Our static approach approximates the map as the gradient of a partially input-convex neural network. It uses a novel numerical implementation to increase computational efficiency compared to state-of-the-art alternatives. Our dynamic approach approximates the conditional optimal transport via the flow map of a regularized neural ODE; compared to the static approach, it is slower to train but offers more modeling choices and can lead to faster sampling. We demonstrate both algorithms numerically, comparing them with competing state-of-the-art approaches, using benchmark datasets and simulation-based Bayesian inverse problems.",
    "pdfUrl": "https://arxiv.org/pdf/2310.16975",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.796887Z"
  },
  {
    "id": "07bba198f9a664ae1f91166dd065d2c4",
    "title": "Simulating Nighttime Visible Satellite Imagery of Tropical Cyclones Using Conditional Generative Adversarial Networks",
    "slug": "simulating-nighttime-visible-satellite-imagery-of-tropical-cyclones-using-conditional-generative-adversarial-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Atmospheric and Oceanic Physics (physics.ao-ph)",
    "author": {
      "name": "Jinghuai Yao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Visible (VIS) imagery is important for monitoring Tropical Cyclones (TCs) but is unavailable at night. This study presents a Conditional Generative Adversarial Networks (CGAN) model to generate nighttime VIS imagery with significantly enhanced accuracy and spatial resolution. Our method offers three key improvements compared to existing models. First, we replaced the L1 loss in the pix2pix framework with the Structural Similarity Index Measure (SSIM) loss, which significantly reduced image blurriness. Second, we selected multispectral infrared (IR) bands as input based on a thorough examination of their spectral properties, providing essential physical information for accurate simulation. Third, we incorporated the direction parameters of the sun and the satellite, which addressed the dependence of VIS images on sunlight directions and enabled a much larger training set from continuous daytime data. The model was trained and validated using data from the Advanced Himawari Imager (AHI) in the daytime, achieving statistical results of SSIM = 0.923 and Root Mean Square Error (RMSE) = 0.0299, which significantly surpasses existing models. We also performed a cross-satellite nighttime model validation using the Day/Night Band (DNB) of the Visible/Infrared Imager Radiometer Suite (VIIRS), which yields outstanding results compared to existing models. Our model is operationally applied to generate accurate VIS imagery with arbitrary virtual sunlight directions, significantly contributing to the nighttime monitoring of various meteorological phenomena.",
    "pdfUrl": "https://arxiv.org/pdf/2401.11679",
    "tags": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.797091Z"
  },
  {
    "id": "0298596107039ec7b8d990dee004f936",
    "title": "Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An Application for MxIF Oncology Data",
    "slug": "towards-spatially-lucid-ai-classification-in-non-euclidean-space:-an-application-for-mxif-oncology-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Image and Video Processing (eess.IV)",
    "author": {
      "name": "Majid Farhadloo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Given multi-category point sets from different place-types, our goal is to develop a spatially-lucid classifier that can distinguish between two classes based on the arrangements of their points. This problem is important for many applications, such as oncology, for analyzing immune-tumor relationships and designing new immunotherapies. It is challenging due to spatial variability and interpretability needs. Previously proposed techniques require dense training data or have limited ability to handle significant spatial variability within a single place-type. Most importantly, these deep neural network (DNN) approaches are not designed to work in non-Euclidean space, particularly point sets. Existing non-Euclidean DNN methods are limited to one-size-fits-all approaches. We explore a spatial ensemble framework that explicitly uses different training strategies, including weighted-distance learning rate and spatial domain adaptation, on various place-types for spatially-lucid classification. Experimental results on real-world datasets (e.g., MxIF oncology data) show that the proposed framework provides higher prediction accuracy than baseline methods.",
    "pdfUrl": "https://arxiv.org/pdf/2402.14974",
    "tags": [
      "Image and Video Processing (eess.IV)"
    ],
    "createdAt": "2025-04-25T15:49:23.797311Z"
  },
  {
    "id": "4abb2df5bb817a86352f4f9cc40b5eaf",
    "title": "Variation Due to Regularization Tractably Recovers Bayesian Deep Learning",
    "slug": "variation-due-to-regularization-tractably-recovers-bayesian-deep-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "James McInerney",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Uncertainty quantification in deep learning is crucial for safe and reliable decision-making in downstream tasks. Existing methods quantify uncertainty at the last layer or other approximations of the network which may miss some sources of uncertainty in the model. To address this gap, we propose an uncertainty quantification method for large networks based on variation due to regularization. Essentially, predictions that are more (less) sensitive to the regularization of network parameters are less (more, respectively) certain. This principle can be implemented by deterministically tweaking the training loss during the fine-tuning phase and reflects confidence in the output as a function of all layers of the network. We show that regularization variation (RegVar) provides rigorous uncertainty estimates that, in the infinitesimal limit, exactly recover the Laplace approximation in Bayesian deep learning. We demonstrate its success in several deep learning architectures, showing it can scale tractably with the network size while maintaining or improving uncertainty quantification quality. Our experiments across multiple datasets show that RegVar not only identifies uncertain predictions effectively but also provides insights into the stability of learned representations.",
    "pdfUrl": "https://arxiv.org/pdf/2403.10671",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.797514Z"
  },
  {
    "id": "44d56ae073cd2a51570a62bf6c7a3a25",
    "title": "AI in Lung Health: Benchmarking Detection and Diagnostic Models Across Multiple CT Scan Datasets",
    "slug": "ai-in-lung-health:-benchmarking-detection-and-diagnostic-models-across-multiple-ct-scan-datasets",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Fakrul Islam Tushar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Lung cancer remains the leading cause of cancer-related mortality worldwide, and early detection through low-dose computed tomography (LDCT) has shown significant promise in reducing death rates. With the growing integration of artificial intelligence (AI) into medical imaging, the development and evaluation of robust AI models require access to large, well-annotated datasets. In this study, we introduce the utility of Duke Lung Cancer Screening (DLCS) Dataset, the largest open-access LDCT dataset with over 2,000 scans and 3,000 expert-verified nodules. We benchmark deep learning models for both 3D nodule detection and lung cancer classification across internal and external datasets including LUNA16, LUNA25, and NLST-3D+. For detection, we develop two MONAI-based RetinaNet models (DLCSDmD and LUNA16-mD), evaluated using the Competition Performance Metric (CPM). For classification, we compare five models, including state-of-the-art pretrained models (Models Genesis, Med3D), a selfsupervised foundation model (FMCB), a randomly initialized ResNet50, and proposed a novel Strategic Warm-Start++ (SWS++) model. SWS++ uses curated candidate patches to pretrain a classification backbone within the same detection pipeline, enabling task-relevant feature learning. Our models demonstrated strong generalizability, with SWS++ achieving comparable or superior performance to existing foundational models across multiple datasets (AUC: 0.71 to 0.90). All code, models, and data are publicly released to promote reproducibility and collaboration. This work establishes a standardized benchmarking resource for lung cancer AI research, supporting future efforts in model development, validation, and clinical translation.",
    "pdfUrl": "https://arxiv.org/pdf/2405.04605",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.797731Z"
  },
  {
    "id": "ac65bd17f00359ad5353c91ff1cf6d9d",
    "title": "RACH Traffic Prediction in Massive Machine Type Communications",
    "slug": "rach-traffic-prediction-in-massive-machine-type-communications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Hossein Mehri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Traffic pattern prediction has emerged as a promising approach for efficiently managing and mitigating the impacts of event-driven bursty traffic in massive machine-type communication (mMTC) networks. However, achieving accurate predictions of bursty traffic remains a non-trivial task due to the inherent randomness of events, and these challenges intensify within live network environments. Consequently, there is a compelling imperative to design a lightweight and agile framework capable of assimilating continuously collected data from the network and accurately forecasting bursty traffic in mMTC networks. This paper addresses these challenges by presenting a machine learning-based framework tailored for forecasting bursty traffic in multi-channel slotted ALOHA networks. The proposed machine learning network comprises long-term short-term memory (LSTM) and a DenseNet with feed-forward neural network (FFNN) layers, where the residual connections enhance the training ability of the machine learning network in capturing complicated patterns. Furthermore, we develop a new low-complexity online prediction algorithm that updates the states of the LSTM network by leveraging frequently collected data from the mMTC network. Simulation results and complexity analysis demonstrate the superiority of our proposed algorithm in terms of both accuracy and complexity, making it well-suited for time-critical live scenarios. We evaluate the performance of the proposed framework in a network with a single base station and thousands of devices organized into groups with distinct traffic-generating characteristics. Comprehensive evaluations and simulations indicate that our proposed machine learning approach achieves a remarkable $52\\%$ higher accuracy in long-term predictions compared to traditional methods, without imposing additional processing load on the system.",
    "pdfUrl": "https://arxiv.org/pdf/2405.05235",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:23.797930Z"
  },
  {
    "id": "ad4bf695fa4de810bdf2e88737c7fda8",
    "title": "Discrete Cosine Transform Based Decorrelated Attention for Vision Transformers",
    "slug": "discrete-cosine-transform-based-decorrelated-attention-for-vision-transformers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Hongyi Pan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Central to the Transformer architectures' effectiveness is the self-attention mechanism, a function that maps queries, keys, and values into a high-dimensional vector space. However, training the attention weights of queries, keys, and values is non-trivial from a state of random initialization. In this paper, we propose two methods. (i) We first address the initialization problem of Vision Transformers by introducing a simple, yet highly innovative, initialization approach utilizing discrete cosine transform (DCT) coefficients. Our proposed DCT-based \\textit{attention} initialization marks a significant gain compared to traditional initialization strategies; offering a robust foundation for the attention mechanism. Our experiments reveal that the DCT-based initialization enhances the accuracy of Vision Transformers in classification tasks. (ii) We also recognize that since DCT effectively decorrelates image information in the frequency domain, this decorrelation is useful for compression because it allows the quantization step to discard many of the higher-frequency components. Based on this observation, we propose a novel DCT-based compression technique for the attention function of Vision Transformers. Since high-frequency DCT coefficients usually correspond to noise, we truncate the high-frequency DCT components of the input patches. Our DCT-based compression reduces the size of weight matrices for queries, keys, and values. While maintaining the same level of accuracy, our DCT compressed Swin Transformers obtain a considerable decrease in the computational overhead.",
    "pdfUrl": "https://arxiv.org/pdf/2405.13901",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.798132Z"
  },
  {
    "id": "8c7ba59c17df8e9fd736adaa06f1180f",
    "title": "Siren -- Advancing Cybersecurity through Deception and Adaptive Analysis",
    "slug": "siren----advancing-cybersecurity-through-deception-and-adaptive-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Samhruth Ananthanarayanan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Siren represents a pioneering research effort aimed at fortifying cybersecurity through strategic integration of deception, machine learning, and proactive threat analysis. Drawing inspiration from mythical sirens, this project employs sophisticated methods to lure potential threats into controlled environments. The system features a dynamic machine learning model for realtime analysis and classification, ensuring continuous adaptability to emerging cyber threats. The architectural framework includes a link monitoring proxy, a purpose-built machine learning model for dynamic link analysis, and a honeypot enriched with simulated user interactions to intensify threat engagement. Data protection within the honeypot is fortified with probabilistic encryption. Additionally, the incorporation of simulated user activity extends the system's capacity to capture and learn from potential attackers even after user disengagement. Overall, Siren introduces a paradigm shift in cybersecurity, transforming traditional defense mechanisms into proactive systems that actively engage and learn from potential adversaries. The research strives to enhance user protection while yielding valuable insights for ongoing refinement in response to the evolving landscape of cybersecurity threats.",
    "pdfUrl": "https://arxiv.org/pdf/2406.06225",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:23.798339Z"
  },
  {
    "id": "3ae2c8fff5247109dbf768ec57c56aad",
    "title": "RSEND: Retinex-based Squeeze and Excitation Network with Dark Region Detection for Efficient Low Light Image Enhancement",
    "slug": "rsend:-retinex-based-squeeze-and-excitation-network-with-dark-region-detection-for-efficient-low-light-image-enhancement",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Jingcheng Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Images captured under low-light scenarios often suffer from low quality. Previous CNN-based deep learning methods often involve using Retinex theory. Nevertheless, most of them cannot perform well in more complicated datasets like LOL-v2 while consuming too much computational resources. Besides, some of these methods require sophisticated training at different stages, making the procedure even more time-consuming and tedious. In this paper, we propose a more accurate, concise, and one-stage Retinex theory based framework, RSEND. RSEND first divides the low-light image into the illumination map and reflectance map, then captures the important details in the illumination map and performs light enhancement. After this step, it refines the enhanced gray-scale image and does element-wise matrix multiplication with the reflectance map. By denoising the output it has from the previous step, it obtains the final result. In all the steps, RSEND utilizes Squeeze and Excitation network to better capture the details. Comprehensive quantitative and qualitative experiments show that our Efficient Retinex model significantly outperforms other CNN-based models, achieving a PSNR improvement ranging from 0.44 dB to 4.2 dB in different datasets and even outperforms transformer-based models in the LOL-v2-real dataset.",
    "pdfUrl": "https://arxiv.org/pdf/2406.09656",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.798539Z"
  },
  {
    "id": "add84aa839b3e1eb69df9cc6e03c31be",
    "title": "ReaL: Efficient RLHF Training of Large Language Models with Parameter Reallocation",
    "slug": "real:-efficient-rlhf-training-of-large-language-models-with-parameter-reallocation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Distributed, Parallel, and Cluster Computing (cs.DC)",
    "author": {
      "name": "Zhiyu Mei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for empowering large language model (LLM) applications. Compared with the supervised training process of LLMs, the RLHF training process is much more sophisticated, requiring a diverse range of computation workloads with intricate dependencies between multiple LLM instances. Therefore, simply adopting the fixed parallelization strategies from supervised training for LLMs can be insufficient for RLHF and result in low training efficiency. To overcome this limitation, we propose a novel technique named parameter ReaLlocation, which dynamically adapts the parallelization strategies for different workloads during training by redistributing LLM parameters across the training cluster. Building upon this idea, we introduce ReaL, a pioneering system for efficient RLHF training. ReaL introduces the concept of an execution plan, which defines a fine-grained resource allocation and parallelization strategy particularly designed for RLHF training. Based on this concept, ReaL employs a tailored search algorithm with a lightweight run-time estimator to automatically discover an efficient execution plan for an instance of RLHF experiment. Subsequently, the runtime engine deploys the selected plan by effectively parallelizing computations and redistributing parameters. We evaluate ReaL on the LLaMA models with up to 70 billion parameters and 128 GPUs. The experimental results demonstrate that ReaL achieves speedups of up to $3.58\\times$ compared to baseline methods. Furthermore, the execution plans generated by ReaL exhibit an average of $81\\%$ performance improvement over heuristic approaches based on Megatron-LM in the long-context scenario. The source code of ReaL is publicly available at this https URL .",
    "pdfUrl": "https://arxiv.org/pdf/2406.14088",
    "tags": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "createdAt": "2025-04-25T15:49:23.798768Z"
  },
  {
    "id": "877a212471b3e2419cdbf4f905b8ec16",
    "title": "Synthetic Lyrics Detection Across Languages and Genres",
    "slug": "synthetic-lyrics-detection-across-languages-and-genres",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yanis Labrak",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In recent years, the use of large language models (LLMs) to generate music content, particularly lyrics, has gained in popularity. These advances provide valuable tools for artists and enhance their creative processes, but they also raise concerns about copyright violations, consumer satisfaction, and content spamming. Previous research has explored content detection in various domains. However, no work has focused on the text modality, lyrics, in music. To address this gap, we curated a diverse dataset of real and synthetic lyrics from multiple languages, music genres, and artists. The generation pipeline was validated using both humans and automated methods. We performed a thorough evaluation of existing synthetic text detection approaches on lyrics, a previously unexplored data type. We also investigated methods to adapt the best-performing features to lyrics through unsupervised domain adaptation. Following both music and industrial constraints, we examined how well these approaches generalize across languages, scale with data availability, handle multilingual language content, and perform on novel genres in few-shot settings. Our findings show promising results that could inform policy decisions around AI-generated music and enhance transparency for users.",
    "pdfUrl": "https://arxiv.org/pdf/2406.15231",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.798980Z"
  },
  {
    "id": "c11dcca2b653943ac04708a6709e76f8",
    "title": "DDU-Net: A Domain Decomposition-Based CNN for High-Resolution Image Segmentation on Multiple GPUs",
    "slug": "ddu-net:-a-domain-decomposition-based-cnn-for-high-resolution-image-segmentation-on-multiple-gpus",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Corn Verburg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The segmentation of ultra-high resolution images poses challenges such as loss of spatial information or computational inefficiency. In this work, a novel approach that combines encoder-decoder architectures with domain decomposition strategies to address these challenges is proposed. Specifically, a domain decomposition-based U-Net (DDU-Net) architecture is introduced, which partitions input images into non-overlapping patches that can be processed independently on separate devices. A communication network is added to facilitate inter-patch information exchange to enhance the understanding of spatial context. Experimental validation is performed on a synthetic dataset that is designed to measure the effectiveness of the communication network. Then, the performance is tested on the DeepGlobe land cover classification dataset as a real-world benchmark data set. The results demonstrate that the approach, which includes inter-patch communication for images divided into $16\\times16$ non-overlapping subimages, achieves a $2-3\\,\\%$ higher intersection over union (IoU) score compared to the same network without inter-patch communication. The performance of the network which includes communication is equivalent to that of a baseline U-Net trained on the full image, showing that our model provides an effective solution for segmenting ultra-high-resolution images while preserving spatial context. The code is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2407.21266",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.799184Z"
  },
  {
    "id": "6b8e20bd14523f4f325924626b0972ee",
    "title": "Set2Seq Transformer: Temporal and Positional-Aware Set Representations for Sequential Multiple-Instance Learning",
    "slug": "set2seq-transformer:-temporal-and-positional-aware-set-representations-for-sequential-multiple-instance-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Athanasios Efthymiou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Sequential multiple-instance learning involves learning representations of sets distributed across discrete timesteps. In many real-world applications, modeling both the internal structure of sets and their temporal relationships across time is essential for capturing complex underlying patterns. However, existing methods either focus on learning set representations at a static level, ignoring temporal dynamics, or treat sequences as ordered lists of individual elements, lacking explicit mechanisms to represent sets. In this work, we propose Set2Seq Transformer, a novel architecture that jointly models permutation-invariant set structure and temporal dependencies by learning temporal and positional-aware representations of sets within a sequence in an end-to-end multimodal manner. We evaluate our Set2Seq Transformer on two tasks that require modeling both set structure alongside temporal and positional patterns, but differ significantly in domain, modality, and objective. First, we consider a fine-art analysis task, modeling artists' oeuvres for predicting artistic success using a novel dataset, WikiArt-Seq2Rank. Second, we utilize our Set2Seq Transformer for a short-term wildfire danger forecasting task. Through extensive experimentation, we show that our Set2Seq Transformer significantly improves over traditional static multiple-instance learning methods by effectively learning permutation-invariant set, temporal, and positional-aware representations across diverse domains, modalities, and tasks. We will release both the dataset and model implementations on GitHub.",
    "pdfUrl": "https://arxiv.org/pdf/2408.03404",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.799387Z"
  },
  {
    "id": "31c70603f8536068b24bd3488fd5e8e2",
    "title": "A causal viewpoint on prediction model performance under changes in case-mix: discrimination and calibration respond differently for prognosis and diagnosis predictions",
    "slug": "a-causal-viewpoint-on-prediction-model-performance-under-changes-in-case-mix:-discrimination-and-calibration-respond-differently-for-prognosis-and-diagnosis-predictions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Methodology (stat.ME)",
    "author": {
      "name": "Wouter A.C. van Amsterdam",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Prediction models need reliable predictive performance as they inform clinical decisions, aiding in diagnosis, prognosis, and treatment planning. The predictive performance of these models is typically assessed through discrimination and calibration. Changes in the distribution of the data impact model performance and there may be important changes between a model's current application and when and where its performance was last evaluated. In health-care, a typical change is a shift in case-mix. For example, for cardiovascular risk management, a general practitioner sees a different mix of patients than a specialist in a tertiary hospital.\nThis work introduces a novel framework that differentiates the effects of case-mix shifts on discrimination and calibration based on the causal direction of the prediction task. When prediction is in the causal direction (often the case for prognosis predictions), calibration remains stable under case-mix shifts, while discrimination does not. Conversely, when predicting in the anti-causal direction (often with diagnosis predictions), discrimination remains stable, but calibration does not.\nA simulation study and empirical validation using cardiovascular disease prediction models demonstrate the implications of this framework. The causal case-mix framework provides insights for developing, evaluating and deploying prediction models across different clinical settings, emphasizing the importance of understanding the causal structure of the prediction task.",
    "pdfUrl": "https://arxiv.org/pdf/2409.01444",
    "tags": [
      "Methodology (stat.ME)"
    ],
    "createdAt": "2025-04-25T15:49:23.799575Z"
  },
  {
    "id": "f31b3587adee2aa087652b80e7f6a0d3",
    "title": "LaMsS: When Large Language Models Meet Self-Skepticism",
    "slug": "lamss:-when-large-language-models-meet-self-skepticism",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yetao Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Hallucination is a major challenge for large language models (LLMs), preventing their further application in some fields. The skeptical thinking of humankind could be useful for LLMs to self-cognition, self-reflection and alleviate their hallucinations. Inspired by this consideration, we propose a novel approach called LaMsS, which combines the semantic understanding capability of LLMs with self-skepticism. By introducing a series of skepticism tokens and augmenting them into the vocabulary, we conduct both pertaining and finetuning, which allow the LLM to decode each normal token followed by a skeptical token, representing different skepticism levels. By calculating the response skepticism given a query, one can define a new self-aware LLM which is only willing to answer with relative lower skepticism level than the threshold. By examining the accuracy, AUC and AP of willingly answering questions, we demonstrate that LaMsS achieves better performance than baselines on both multi-choice questions and open-domain question-answering benchmarks, and can generalize to multi-task and out-of-domain settings. Our study sheds some lights on the self-skepticism modeling on further artificial intelligence. Project code and model checkpoints can be found in this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2409.06601",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.799792Z"
  },
  {
    "id": "1fd8c98555a408ce08247a4ce35fa9ad",
    "title": "On the Generalizability of Foundation Models for Crop Type Mapping",
    "slug": "on-the-generalizability-of-foundation-models-for-crop-type-mapping",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yi-Chia Chang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Foundation models pre-trained using self-supervised learning have shown powerful transfer learning capabilities on various downstream tasks, including language understanding, text generation, and image recognition. The Earth observation (EO) field has produced several foundation models pre-trained directly on multispectral satellite imagery for applications like precision agriculture, wildfire and drought monitoring, and natural disaster response. However, few studies have investigated the ability of these models to generalize to new geographic locations, and potential concerns of geospatial bias -- models trained on data-rich developed nations not transferring well to data-scarce developing nations -- remain. We investigate the ability of popular EO foundation models to transfer to new geographic regions in the agricultural domain, where differences in farming practices and class imbalance make transfer learning particularly challenging. We first select five crop classification datasets across five continents, normalizing for dataset size and harmonizing classes to focus on four major cereal grains: maize, soybean, rice, and wheat. We then compare three popular foundation models, pre-trained on SSL4EO-S12, SatlasPretrain, and ImageNet, using in-distribution (ID) and out-of-distribution (OOD) evaluation. Experiments show that pre-trained weights designed explicitly for Sentinel-2, such as SSL4EO-S12, outperform general pre-trained weights like ImageNet. Furthermore, while only 100 labeled images are sufficient for achieving high overall accuracy, 900 images are required to achieve high average accuracy due to class imbalance. All harmonized datasets and experimental code are open-source and available for download.",
    "pdfUrl": "https://arxiv.org/pdf/2409.09451",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.800021Z"
  },
  {
    "id": "f592fc44b77c2f7fb05712b37f0b281f",
    "title": "Feature-to-Image Data Augmentation: Improving Model Feature Extraction with Cluster-Guided Synthetic Samples",
    "slug": "feature-to-image-data-augmentation:-improving-model-feature-extraction-with-cluster-guided-synthetic-samples",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Yasaman Haghbin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "One of the growing trends in machine learning is the use of data generation techniques, since the performance of machine learning models is dependent on the quantity of the training dataset. However, in many real-world applications, particularly in medical and low-resource domains, collecting large datasets is challenging due to resource constraints, which leads to overfitting and poor generalization. This study introduces FICAug, a novel feature-to-image data augmentation framework designed to improve model generalization under limited data conditions by generating structured synthetic samples.\nFICAug first operates in the feature space, where original data are clustered using the k-means algorithm. Within pure-label clusters, synthetic data are generated through Gaussian sampling to increase diversity while maintaining label consistency. These synthetic features are then projected back into the image domain using a generative neural network, and a convolutional neural network is trained on the reconstructed images to learn enhanced representations.\nExperimental results demonstrate that FICAug significantly improves classification accuracy. In feature space, it achieved a cross-validation accuracy of 84.09%, while training a ResNet-18 model on the reconstructed images further boosted performance to 88.63%, illustrating the effectiveness of the proposed framework in extracting new and task-relevant features.",
    "pdfUrl": "https://arxiv.org/pdf/2409.17685",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:23.800277Z"
  },
  {
    "id": "2a92504d7bd7a9c1a6c52fb6c3095ed4",
    "title": "Convergence of Diffusion Models Under the Manifold Hypothesis in High-Dimensions",
    "slug": "convergence-of-diffusion-models-under-the-manifold-hypothesis-in-high-dimensions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Iskander Azangulov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Denoising Diffusion Probabilistic Models (DDPM) are powerful state-of-the-art methods used to generate synthetic data from high-dimensional data distributions and are widely used for image, audio, and video generation as well as many more applications in science and beyond. The \\textit{manifold hypothesis} states that high-dimensional data often lie on lower-dimensional manifolds within the ambient space, and is widely believed to hold in provided examples. While recent results have provided invaluable insight into how diffusion models adapt to the manifold hypothesis, they do not capture the great empirical success of these models, making this a very fruitful research direction.\nIn this work, we study DDPMs under the manifold hypothesis and prove that they achieve rates independent of the ambient dimension in terms of score learning. In terms of sampling complexity, we obtain rates independent of the ambient dimension w.r.t. the Kullback-Leibler divergence, and $O(\\sqrt{D})$ w.r.t. the Wasserstein distance. We do this by developing a new framework connecting diffusion models to the well-studied theory of extrema of Gaussian Processes.",
    "pdfUrl": "https://arxiv.org/pdf/2409.18804",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.800629Z"
  },
  {
    "id": "b222b309bb003b987f0dafcb3bb21174",
    "title": "Selective Attention Improves Transformer",
    "slug": "selective-attention-improves-transformer",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Yaniv Leviathan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Unneeded elements in the attention's context degrade performance. We introduce Selective Attention, a simple parameter-free change to the standard attention mechanism which reduces attention to unneeded elements. Selective attention consistently improves language modeling and downstream task performance in a variety of model sizes and context lengths. For example, transformers trained with the language modeling objective on C4 with selective attention perform language modeling equivalently to standard transformers with ~2X more heads and parameters in their attention modules. Selective attention also allows decreasing the size of the attention's context buffer, leading to meaningful reductions in the memory and compute requirements during inference. For example, transformers trained on C4 with context sizes of 512, 1,024, and 2,048 need 16X, 25X, and 47X less memory for their attention module, respectively, when equipped with selective attention, as those without selective attention, with the same validation perplexity.",
    "pdfUrl": "https://arxiv.org/pdf/2410.02703",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.800962Z"
  },
  {
    "id": "c3b6637c4e41139628922c27607bcd28",
    "title": "Linear Convergence of Diffusion Models Under the Manifold Hypothesis",
    "slug": "linear-convergence-of-diffusion-models-under-the-manifold-hypothesis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Peter Potaptchik",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Score-matching generative models have proven successful at sampling from complex high-dimensional data distributions. In many applications, this distribution is believed to concentrate on a much lower $d$-dimensional manifold embedded into $D$-dimensional space; this is known as the manifold hypothesis. The current best-known convergence guarantees are either linear in $D$ or polynomial (superlinear) in $d$. The latter exploits a novel integration scheme for the backward SDE. We take the best of both worlds and show that the number of steps diffusion models require in order to converge in Kullback-Leibler~(KL) divergence is linear (up to logarithmic terms) in the intrinsic dimension $d$. Moreover, we show that this linear dependency is sharp.",
    "pdfUrl": "https://arxiv.org/pdf/2410.09046",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.801228Z"
  },
  {
    "id": "7964ab47ce394f7625d138aaf054deb3",
    "title": "Automated Discovery of Operable Dynamics from Videos",
    "slug": "automated-discovery-of-operable-dynamics-from-videos",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Kuang Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dynamical systems form the foundation of scientific discovery, traditionally modeled with predefined state variables such as the angle and angular velocity, and differential equations such as the equation of motion for a single pendulum. We introduce a framework that automatically discovers a low-dimensional and operable representation of system dynamics, including a set of compact state variables that preserve the smoothness of the system dynamics and a differentiable vector field, directly from video without requiring prior domain-specific knowledge. The prominence and effectiveness of the proposed approach are demonstrated through both quantitative and qualitative analyses of a range of dynamical systems, including the identification of stable equilibria, the prediction of natural frequencies, and the detection of of chaotic and limit cycle behaviors. The results highlight the potential of our data-driven approach to advance automated scientific discovery.",
    "pdfUrl": "https://arxiv.org/pdf/2410.11894",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:23.801444Z"
  },
  {
    "id": "aa93147ada402e6a7ea36ffc8ecf5678",
    "title": "Parameter-Efficient Fine-Tuning in Large Models: A Survey of Methodologies",
    "slug": "parameter-efficient-fine-tuning-in-large-models:-a-survey-of-methodologies",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Luping Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The large models, as predicted by scaling raw forecasts, have made groundbreaking progress in many fields, particularly in natural language generation tasks, where they have approached or even surpassed human levels. However, the unprecedented scale of their parameters brings significant computational and storage costs. These large models require substantial computational resources and GPU memory to operate. When adapting large models to specific downstream tasks, their massive parameter scale poses a significant challenge in fine-tuning on hardware platforms with limited computational power and GPU memory. To address this issue, Parameter-Efficient Fine-Tuning (PEFT) offers a practical solution by efficiently adjusting the parameters of large pre-trained models to suit various downstream tasks. Specifically, PEFT adjusts the parameters of pre-trained large models to adapt to specific tasks or domains, minimizing the introduction of additional parameters and the computational resources required. This review mainly introduces the preliminary knowledge of PEFT, the core ideas and principles of various PEFT algorithms, the applications of PEFT, and potential future research directions. By reading this review, we believe that interested parties can quickly grasp the PEFT methodology, thereby accelerating its development and innovation.",
    "pdfUrl": "https://arxiv.org/pdf/2410.19878",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.801668Z"
  },
  {
    "id": "c92de303a3fd6b03e30801a989204398",
    "title": "AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation",
    "slug": "alphatrans:-a-neuro-symbolic-compositional-approach-for-repository-level-code-translation-and-validation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Ali Reza Ibrahimzada",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Code translation transforms programs from one programming language (PL) to another. Several rule-based transpilers have been designed to automate code translation between different pairs of PLs. However, the rules can become obsolete as the PLs evolve and cannot generalize to other PLs. Recent studies have explored the automation of code translation using Large Language Models (LLMs). One key observation is that such techniques may work well for crafted benchmarks but fail to generalize to the scale and complexity of real-world projects with dependencies, custom types, PL-specific features, etc. We propose AlphaTrans, a neuro-symbolic approach to automate repository-level code translation. AlphaTrans translates both source and test code, and employs multiple levels of validation to ensure the translation preserves the functionality of the source program. To break down the problem for LLMs, AlphaTrans leverages program analysis to decompose the program into fragments and translates them in the reverse call order. We leveraged AlphaTrans to translate ten real-world open-source projects consisting of <836, 8575, 2719> classes, methods, and tests. AlphaTrans breaks down these projects into 17874 fragments and translates the entire repository. 96.40% of the translated fragments are syntactically correct, and AlphaTrans validates the translations' runtime behavior and functional correctness for 27.03% and 25.14% of fragments. On average, the integrated translation and validation take 34 hours to translate a project, showing its scalability in practice. For the incorrect translations, AlphaTrans generates a report including existing translation, stack trace, test errors, or assertion failures. We provided these artifacts to two developers to fix the translation bugs in four projects. They were able to fix the issues in 20.1 hours on average and achieve all passing tests.",
    "pdfUrl": "https://arxiv.org/pdf/2410.24117",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:23.801887Z"
  },
  {
    "id": "7ae3d874b9548121c1da8d36057a314b",
    "title": "Exponentially Consistent Nonparametric Linkage-Based Clustering of Data Sequences",
    "slug": "exponentially-consistent-nonparametric-linkage-based-clustering-of-data-sequences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Bhupender Singh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we consider nonparametric clustering of $M$ independent and identically distributed (i.i.d.) data sequences generated from {\\em unknown} distributions. The distributions of the $M$ data sequences belong to $K$ underlying distribution clusters. Existing results on exponentially consistent nonparametric clustering algorithms, like single linkage-based (SLINK) clustering and $k$-medoids distribution clustering, assume that the maximum intra-cluster distance ($d_L$) is smaller than the minimum inter-cluster distance ($d_H$). First, in the fixed sample size (FSS) setting, we show that exponential consistency can be achieved for SLINK clustering under a less strict assumption, $d_I < d_H$, where $d_I$ is the maximum distance between any two sub-clusters of a cluster that partition the cluster. Note that $d_I < d_L$ in general. Thus, our results show that SLINK is exponentially consistent for a larger class of problems than previously known. In our simulations, we also identify examples where $k$-medoids clustering is unable to find the true clusters, but SLINK is exponentially consistent. Then, we propose a sequential clustering algorithm, named SLINK-SEQ, based on SLINK and prove that it is also exponentially consistent. Simulation results show that the SLINK-SEQ algorithm requires fewer expected number of samples than the FSS SLINK algorithm for the same probability of error.",
    "pdfUrl": "https://arxiv.org/pdf/2411.13922",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.802167Z"
  },
  {
    "id": "a08ef15a12c2c50bcc19963486166e34",
    "title": "Improved implicit diffusion model with knowledge distillation to estimate the spatial distribution density of carbon stock in remote sensing imagery",
    "slug": "improved-implicit-diffusion-model-with-knowledge-distillation-to-estimate-the-spatial-distribution-density-of-carbon-stock-in-remote-sensing-imagery",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Zhenyu Yu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The forest serves as the most significant terrestrial carbon stock mechanism, effectively reducing atmospheric CO2 concentrations and mitigating climate change. Remote sensing provides high data accuracy and enables large-scale observations. Optical images facilitate long-term monitoring, which is crucial for future carbon stock estimation studies. This study focuses on Huize County, Qujing City, Yunnan Province, China, utilizing GF-1 WFV satellite imagery. The KD-VGG and KD-UNet modules were introduced for initial feature extraction, and the improved implicit diffusion model (IIDM) was proposed. The results showed: (1) The VGG module improved initial feature extraction, improving accuracy, and reducing inference time with optimized model parameters. (2) The Cross-attention + MLPs module enabled effective feature fusion, establishing critical relationships between global and local features, achieving high-accuracy estimation. (3) The IIDM model, a novel contribution, demonstrated the highest estimation accuracy with an RMSE of 12.17%, significantly improving by 41.69% to 42.33% compared to the regression model. In carbon stock estimation, the generative model excelled in extracting deeper features, significantly outperforming other models, demonstrating the feasibility of AI-generated content in quantitative remote sensing. The 16-meter resolution estimates provide a robust basis for tailoring forest carbon sink regulations, enhancing regional carbon stock management.",
    "pdfUrl": "https://arxiv.org/pdf/2411.17973",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.802377Z"
  },
  {
    "id": "5c0b173898b5c56a7cc25c11e848b81e",
    "title": "Machine Learning-Based Automated Assessment of Intracorporeal Suturing in Laparoscopic Fundoplication",
    "slug": "machine-learning-based-automated-assessment-of-intracorporeal-suturing-in-laparoscopic-fundoplication",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Shekhar Madhav Khairnar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Automated assessment of surgical skills using artificial intelligence (AI) provides trainees with instantaneous feedback. After bimanual tool motions are captured, derived kinematic metrics are reliable predictors of performance in laparoscopic tasks. Implementing automated tool tracking requires time-intensive human annotation. We developed AI-based tool tracking using the Segment Anything Model (SAM) to eliminate the need for human annotators. Here, we describe a study evaluating the usefulness of our tool tracking model in automated assessment during a laparoscopic suturing task in the fundoplication procedure. An automated tool tracking model was applied to recorded videos of Nissen fundoplication on porcine bowel. Surgeons were grouped as novices (PGY1-2) and experts (PGY3-5, attendings). The beginning and end of each suturing step were segmented, and motions of the left and right tools were extracted. A low-pass filter with a 24 Hz cut-off frequency removed noise. Performance was assessed using supervised and unsupervised models, and an ablation study compared results. Kinematic features--RMS velocity, RMS acceleration, RMS jerk, total path length, and Bimanual Dexterity--were extracted and analyzed using Logistic Regression, Random Forest, Support Vector Classifier, and XGBoost. PCA was performed for feature reduction. For unsupervised learning, a Denoising Autoencoder (DAE) model with classifiers, such as a 1-D CNN and traditional models, was trained. Data were extracted for 28 participants (9 novices, 19 experts). Supervised learning with PCA and Random Forest achieved an accuracy of 0.795 and an F1 score of 0.778. The unsupervised 1-D CNN achieved superior results with an accuracy of 0.817 and an F1 score of 0.806, eliminating the need for kinematic feature computation. We demonstrated an AI model capable of automated performance classification, independent of human annotation.",
    "pdfUrl": "https://arxiv.org/pdf/2412.16195",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.802634Z"
  },
  {
    "id": "529fa6f2f5cac0c4b11c07225d490693",
    "title": "Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and Editable Policies",
    "slug": "neural-dnf-mt:-a-neuro-symbolic-approach-for-learning-interpretable-and-editable-policies",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Kexin Gu Baugh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Although deep reinforcement learning has been shown to be effective, the model's black-box nature presents barriers to direct policy interpretation. To address this problem, we propose a neuro-symbolic approach called neural DNF-MT for end-to-end policy learning. The differentiable nature of the neural DNF-MT model enables the use of deep actor-critic algorithms for training. At the same time, its architecture is designed so that trained models can be directly translated into interpretable policies expressed as standard (bivalent or probabilistic) logic programs. Moreover, additional layers can be included to extract abstract features from complex observations, acting as a form of predicate invention. The logic representations are highly interpretable, and we show how the bivalent representations of deterministic policies can be edited and incorporated back into a neural model, facilitating manual intervention and adaptation of learned policies. We evaluate our approach on a range of tasks requiring learning deterministic or stochastic behaviours from various forms of observations. Our empirical results show that our neural DNF-MT model performs at the level of competing black-box methods whilst providing interpretable policies.",
    "pdfUrl": "https://arxiv.org/pdf/2501.03888",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:23.802876Z"
  },
  {
    "id": "29a67a3170631971c0db3edf585210d7",
    "title": "Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics",
    "slug": "robotic-world-model:-a-neural-network-simulator-for-robust-policy-optimization-in-robotics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Chenhao Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Learning robust and generalizable world models is crucial for enabling efficient and scalable robotic control in real-world environments. In this work, we introduce a novel framework for learning world models that accurately capture complex, partially observable, and stochastic dynamics. The proposed method employs a dual-autoregressive mechanism and self-supervised training to achieve reliable long-horizon predictions without relying on domain-specific inductive biases, ensuring adaptability across diverse robotic tasks. We further propose a policy optimization framework that leverages world models for efficient training in imagined environments and seamless deployment in real-world systems. This work advances model-based reinforcement learning by addressing the challenges of long-horizon prediction, error accumulation, and sim-to-real transfer. By providing a scalable and robust framework, the introduced methods pave the way for adaptive and efficient robotic systems in real-world applications.",
    "pdfUrl": "https://arxiv.org/pdf/2501.10100",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:23.803073Z"
  },
  {
    "id": "9396061d15e3a69a115a2785556eae9d",
    "title": "Uncertainty Quantification With Noise Injection in Neural Networks: A Bayesian Perspective",
    "slug": "uncertainty-quantification-with-noise-injection-in-neural-networks:-a-bayesian-perspective",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Xueqiong Yuan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Model uncertainty quantification involves measuring and evaluating the uncertainty linked to a model's predictions, helping assess their reliability and confidence. Noise injection is a technique used to enhance the robustness of neural networks by introducing randomness. In this paper, we establish a connection between noise injection and uncertainty quantification from a Bayesian standpoint. We theoretically demonstrate that injecting noise into the weights of a neural network is equivalent to Bayesian inference on a deep Gaussian process. Consequently, we introduce a Monte Carlo Noise Injection (MCNI) method, which involves injecting noise into the parameters during training and performing multiple forward propagations during inference to estimate the uncertainty of the prediction. Through simulation and experiments on regression and classification tasks, our method demonstrates superior performance compared to the baseline model.",
    "pdfUrl": "https://arxiv.org/pdf/2501.12314",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.803283Z"
  },
  {
    "id": "7d0bc5b8a54249f4a496b74a95de906f",
    "title": "Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting",
    "slug": "large-image-object-detection-for-fine-grained-recognition-of-punches-patterns-in-medieval-panel-painting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Josh Bruegger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The attribution of the author of an art piece is typically a laborious manual process, usually relying on subjective evaluations of expert figures. However, there are some situations in which quantitative features of the artwork can support these evaluations. The extraction of these features can sometimes be automated, for instance, with the use of Machine Learning (ML) techniques. An example of these features is represented by repeated, mechanically impressed patterns, called punches, present chiefly in 13th and 14th-century panel paintings from Tuscany. Previous research in art history showcased a strong connection between the shapes of punches and specific artists or workshops, suggesting the possibility of using these quantitative cues to support the attribution. In the present work, we first collect a dataset of large-scale images of these panel paintings. Then, using YOLOv10, a recent and popular object detection model, we train a ML pipeline to perform object detection on the punches contained in the images. Due to the large size of the images, the detection procedure is split across multiple frames by adopting a sliding-window approach with overlaps, after which the predictions are combined for the whole image using a custom non-maximal suppression routine. Our results indicate how art historians working in the field can reliably use our method for the identification and extraction of punches.",
    "pdfUrl": "https://arxiv.org/pdf/2501.12489",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:23.803496Z"
  },
  {
    "id": "4bc1576379d550192ed099a6eb1733d9",
    "title": "Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?",
    "slug": "are-transformers-able-to-reason-by-connecting-separated-knowledge-in-training-data?",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Yutong Yin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Humans exhibit remarkable compositional reasoning by integrating knowledge from various sources. For example, if someone learns ( B = f(A) ) from one source and ( C = g(B) ) from another, they can deduce ( C=g(B)=g(f(A)) ) even without encountering ( ABC ) together, showcasing the generalization ability of human intelligence. In this paper, we introduce a synthetic learning task, \"FTCT\" (Fragmented at Training, Chained at Testing), to validate the potential of Transformers in replicating this skill and interpret its inner mechanism. In the training phase, data consist of separated knowledge fragments from an overall causal graph. During testing, Transformers must infer complete causal graph traces by integrating these fragments. Our findings demonstrate that few-shot Chain-of-Thought prompting enables Transformers to perform compositional reasoning on FTCT by revealing correct combinations of fragments, even if such combinations were absent in the training data. Furthermore, the emergence of compositional reasoning ability is strongly correlated with the model complexity and training-testing data similarity. We propose, both theoretically and empirically, that Transformers learn an underlying generalizable program from training, enabling effective compositional reasoning during testing.",
    "pdfUrl": "https://arxiv.org/pdf/2501.15857",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:23.803696Z"
  },
  {
    "id": "229259ad85197c71b9e2629d37dc072d",
    "title": "Prediction-Powered Inference with Imputed Covariates and Nonuniform Sampling",
    "slug": "prediction-powered-inference-with-imputed-covariates-and-nonuniform-sampling",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Methodology (stat.ME)",
    "author": {
      "name": "Dan M. Kluger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Machine learning models are increasingly used to produce predictions that serve as input data in subsequent statistical analyses. For example, computer vision predictions of economic and environmental indicators based on satellite imagery are used in downstream regressions; similarly, language models are widely used to approximate human ratings and opinions in social science research. However, failure to properly account for errors in the machine learning predictions renders standard statistical procedures invalid. Prior work uses what we call the Predict-Then-Debias estimator to give valid confidence intervals when machine learning algorithms impute missing variables, assuming a small complete sample from the population of interest. We expand the scope by introducing bootstrap confidence intervals that apply when the complete data is a nonuniform (i.e., weighted, stratified, or clustered) sample and to settings where an arbitrary subset of features is imputed. Importantly, the method can be applied to many settings without requiring additional calculations. We prove that these confidence intervals are valid under no assumptions on the quality of the machine learning model and are no wider than the intervals obtained by methods that do not use machine learning predictions.",
    "pdfUrl": "https://arxiv.org/pdf/2501.18577",
    "tags": [
      "Methodology (stat.ME)"
    ],
    "createdAt": "2025-04-25T15:49:23.803898Z"
  },
  {
    "id": "621ae814c9edc932f530f2277ddb24ef",
    "title": "Robot Pouring: Identifying Causes of Spillage and Selecting Alternative Action Parameters Using Probabilistic Actual Causation",
    "slug": "robot-pouring:-identifying-causes-of-spillage-and-selecting-alternative-action-parameters-using-probabilistic-actual-causation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Jaime Maldonado",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In everyday life, we perform tasks (e.g., cooking or cleaning) that involve a large variety of objects and goals. When confronted with an unexpected or unwanted outcome, we take corrective actions and try again until achieving the desired result. The reasoning performed to identify a cause of the observed outcome and to select an appropriate corrective action is a crucial aspect of human reasoning for successful task execution. Central to this reasoning is the assumption that a factor is responsible for producing the observed outcome. In this paper, we investigate the use of probabilistic actual causation to determine whether a factor is the cause of an observed undesired outcome. Furthermore, we show how the actual causation probabilities can be used to find alternative actions to change the outcome. We apply the probabilistic actual causation analysis to a robot pouring task. When spillage occurs, the analysis indicates whether a task parameter is the cause and how it should be changed to avoid spillage. The analysis requires a causal graph of the task and the corresponding conditional probability distributions. To fulfill these requirements, we perform a complete causal modeling procedure (i.e., task analysis, definition of variables, determination of the causal graph structure, and estimation of conditional probability distributions) using data from a realistic simulation of the robot pouring task, covering a large combinatorial space of task parameters. Based on the results, we discuss the implications of the variables' representation and how the alternative actions suggested by the actual causation analysis would compare to the alternative solutions proposed by a human observer. The practical use of the analysis of probabilistic actual causation to select alternative action parameters is demonstrated.",
    "pdfUrl": "https://arxiv.org/pdf/2502.09395",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:23.804120Z"
  },
  {
    "id": "d2edf207b5e8611c4c05fd6edb58d14d",
    "title": "Towards Reasoning Ability of Small Language Models",
    "slug": "towards-reasoning-ability-of-small-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Gaurav Srivastava",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Reasoning has long been viewed as an emergent property of large language models (LLMs), appearing at or above a certain scale ($\\sim$100B parameters). However, recent studies challenge this assumption, showing that small language models (SLMs) can also achieve competitive reasoning performance. SLMs are increasingly favored for their efficiency and deployability. However, there is a lack of systematic study on the reasoning abilities of diverse SLMs, including those trained from scratch or derived from LLMs through quantization, pruning, and distillation. This raises a critical question: Can SLMs achieve reasoning abilities comparable to LLMs? In this work, we systematically survey, benchmark, and analyze 72 SLMs from six model families across 14 reasoning benchmarks. For reliable evaluation, we examine four evaluation methods and compare four LLM judges against human evaluations on 800 data points. We repeat all experiments three times to ensure a robust performance assessment. Additionally, we analyze the impact of different prompting strategies in small models. Beyond accuracy, we also evaluate model robustness under adversarial conditions and intermediate reasoning steps. Our findings challenge the assumption that scaling is the only way to achieve strong reasoning. Instead, we foresee a future where SLMs with strong reasoning capabilities can be developed through structured training or post-training compression. They can serve as efficient alternatives to LLMs for reasoning-intensive tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2502.11569",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.804320Z"
  },
  {
    "id": "b9675ff8976e1b13afbcaa162d356d8c",
    "title": "Conformal prediction of future insurance claims in the regression problem",
    "slug": "conformal-prediction-of-future-insurance-claims-in-the-regression-problem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Liang Hong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the current insurance literature, prediction of insurance claims in the regression problem is often performed with a statistical model. This model-based approach may potentially suffer from several drawbacks: (i) model misspecification, (ii) selection effect, and (iii) lack of finite-sample validity. This article addresses these three issues simultaneously by employing conformal prediction -- a general machine learning strategy for valid predictions. The proposed method is both model-free and tuning-parameter-free. It also guarantees finite-sample validity at a pre-assigned coverage probability level. Examples, based on both simulated and real data, are provided to demonstrate the excellent performance of the proposed method and its applications in insurance, especially regarding meeting the solvency capital requirement of European insurance regulation, Solvency II.",
    "pdfUrl": "https://arxiv.org/pdf/2503.03659",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.804502Z"
  },
  {
    "id": "7a3938513794aa157331b6827b6a8ca7",
    "title": "SE(3)-Equivariant Robot Learning and Control: A Tutorial Survey",
    "slug": "se(3)-equivariant-robot-learning-and-control:-a-tutorial-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Joohwan Seo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advances in deep learning and Transformers have driven major breakthroughs in robotics by employing techniques such as imitation learning, reinforcement learning, and LLM-based multimodal perception and decision-making. However, conventional deep learning and Transformer models often struggle to process data with inherent symmetries and invariances, typically relying on large datasets or extensive data augmentation. Equivariant neural networks overcome these limitations by explicitly integrating symmetry and invariance into their architectures, leading to improved efficiency and generalization. This tutorial survey reviews a wide range of equivariant deep learning and control methods for robotics, from classic to state-of-the-art, with a focus on SE(3)-equivariant models that leverage the natural 3D rotational and translational symmetries in visual robotic manipulation and control design. Using unified mathematical notation, we begin by reviewing key concepts from group theory, along with matrix Lie groups and Lie algebras. We then introduce foundational group-equivariant neural network design and show how the group-equivariance can be obtained through their structure. Next, we discuss the applications of SE(3)-equivariant neural networks in robotics in terms of imitation learning and reinforcement learning. The SE(3)-equivariant control design is also reviewed from the perspective of geometric control. Finally, we highlight the challenges and future directions of equivariant methods in developing more robust, sample-efficient, and multi-modal real-world robotic systems.",
    "pdfUrl": "https://arxiv.org/pdf/2503.09829",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:23.804731Z"
  },
  {
    "id": "7a15aa8aaab260dc466c9b56af3ea393",
    "title": "HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks",
    "slug": "hyperdas:-towards-automating-mechanistic-interpretability-with-hypernetworks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Jiuding Sun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Mechanistic interpretability has made great strides in identifying neural network features (e.g., directions in hidden activation space) that mediate concepts(e.g., the birth year of a person) and enable predictable manipulation. Distributed alignment search (DAS) leverages supervision from counterfactual data to learn concept features within hidden states, but DAS assumes we can afford to conduct a brute force search over potential feature locations. To address this, we present HyperDAS, a transformer-based hypernetwork architecture that (1) automatically locates the token-positions of the residual stream that a concept is realized in and (2) constructs features of those residual stream vectors for the concept. In experiments with Llama3-8B, HyperDAS achieves state-of-the-art performance on the RAVEL benchmark for disentangling concepts in hidden states. In addition, we review the design decisions we made to mitigate the concern that HyperDAS (like all powerful interpretabilty methods) might inject new information into the target model rather than faithfully interpreting it.",
    "pdfUrl": "https://arxiv.org/pdf/2503.10894",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.804946Z"
  },
  {
    "id": "3857965be589e40f5196e8d380a81027",
    "title": "Long-term excitation energy transfer predicted by a modified convolutional neural networks in the FMO complexes",
    "slug": "long-term-excitation-energy-transfer-predicted-by-a-modified-convolutional-neural-networks-in-the-fmo-complexes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Chemical Physics (physics.chem-ph)",
    "author": {
      "name": "Yi-Meng Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In machine learning (ML), the risk of recursive strategies overfitting historical data has driven the development of convolutional neural networks (CNNs) in simulating quantum dissipative dynamics. In this work, we propose an efficient CNNs scheme incorporating novel redundant time-functions to predict 100 picosecond (ps) excitation energy transfer (EET) in Fenna-Matthews-Olson (FMO) complexes, in which the original time $t$ is normalized by mapping it to the [0, 1] range, allowing different functions focus on distinct time intervals, thereby effectively capturing the multi-timescale characteristics of EET dynamics. This method simplifies optimization and enhances learning efficiency, and demonstrate the accuracy, robustness, and efficiency of our approach in predicting quantum dissipative dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2503.17430",
    "tags": [
      "Chemical Physics (physics.chem-ph)"
    ],
    "createdAt": "2025-04-25T15:49:23.805158Z"
  },
  {
    "id": "826a8a3bc6623e1619c75bfac1dbe0da",
    "title": "Shared Global and Local Geometry of Language Model Embeddings",
    "slug": "shared-global-and-local-geometry-of-language-model-embeddings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Andrew Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Researchers have recently suggested that models share common representations. In our work, we find that token embeddings of language models exhibit common geometric structure. First, we find ``global'' similarities: token embeddings often share similar relative orientations. Next, we characterize local geometry in two ways: (1) by using Locally Linear Embeddings, and (2) by defining a simple measure for the intrinsic dimension of each token embedding. Our intrinsic dimension demonstrates that token embeddings lie on a lower dimensional manifold. We qualitatively show that tokens with lower intrinsic dimensions often have semantically coherent clusters, while those with higher intrinsic dimensions do not. Both characterizations allow us to find similarities in the local geometry of token embeddings. Perhaps most surprisingly, we find that alignment in token embeddings persists through the hidden states of language models, allowing us to develop an application for interpretability. Namely, we introduce Emb2Emb, a simple method to transfer steering vectors from one language model to another, despite the two models having different dimensions.",
    "pdfUrl": "https://arxiv.org/pdf/2503.21073",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:23.805357Z"
  },
  {
    "id": "51d0187e77771d5968bbb2b671f5bbc8",
    "title": "Sparse Gaussian Neural Processes",
    "slug": "sparse-gaussian-neural-processes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Tommy Rochussen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Despite significant recent advances in probabilistic meta-learning, it is common for practitioners to avoid using deep learning models due to a comparative lack of interpretability. Instead, many practitioners simply use non-meta-models such as Gaussian processes with interpretable priors, and conduct the tedious procedure of training their model from scratch for each task they encounter. While this is justifiable for tasks with a limited number of data points, the cubic computational cost of exact Gaussian process inference renders this prohibitive when each task has many observations. To remedy this, we introduce a family of models that meta-learn sparse Gaussian process inference. Not only does this enable rapid prediction on new tasks with sparse Gaussian processes, but since our models have clear interpretations as members of the neural process family, it also allows manual elicitation of priors in a neural process for the first time. In meta-learning regimes for which the number of observed tasks is small or for which expert domain knowledge is available, this offers a crucial advantage.",
    "pdfUrl": "https://arxiv.org/pdf/2504.01650",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.805557Z"
  },
  {
    "id": "fc42f900d06fb051584c45d57b80c28d",
    "title": "Engineering Artificial Intelligence: Framework, Challenges, and Future Direction",
    "slug": "engineering-artificial-intelligence:-framework,-challenges,-and-future-direction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Jay Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Over the past ten years, the application of artificial intelligence (AI) and machine learning (ML) in engineering domains has gained significant popularity, showcasing their potential in data-driven contexts. However, the complexity and diversity of engineering problems often require the development of domain-specific AI approaches, which are frequently hindered by a lack of systematic methodologies, scalability, and robustness during the development process. To address this gap, this paper introduces the \"ABCDE\" as the key elements of Engineering AI and proposes a unified, systematic engineering AI ecosystem framework, including eight essential layers, along with attributes, goals, and applications, to guide the development and deployment of AI solutions for specific engineering needs. Additionally, key challenges are examined, and eight future research directions are highlighted. By providing a comprehensive perspective, this paper aims to advance the strategic implementation of AI, fostering the development of next-generation engineering AI solutions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.02269",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:23.805762Z"
  },
  {
    "id": "4e97e384a7818ed0020dd1229d2668e5",
    "title": "Dexterous Manipulation through Imitation Learning: A Survey",
    "slug": "dexterous-manipulation-through-imitation-learning:-a-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Shan An",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dexterous manipulation, which refers to the ability of a robotic hand or multi-fingered end-effector to skillfully control, reorient, and manipulate objects through precise, coordinated finger movements and adaptive force modulation, enables complex interactions similar to human hand dexterity. With recent advances in robotics and machine learning, there is a growing demand for these systems to operate in complex and unstructured environments. Traditional model-based approaches struggle to generalize across tasks and object variations due to the high dimensionality and complex contact dynamics of dexterous manipulation. Although model-free methods such as reinforcement learning (RL) show promise, they require extensive training, large-scale interaction data, and carefully designed rewards for stability and effectiveness. Imitation learning (IL) offers an alternative by allowing robots to acquire dexterous manipulation skills directly from expert demonstrations, capturing fine-grained coordination and contact dynamics while bypassing the need for explicit modeling and large-scale trial-and-error. This survey provides an overview of dexterous manipulation methods based on imitation learning, details recent advances, and addresses key challenges in the field. Additionally, it explores potential research directions to enhance IL-driven dexterous manipulation. Our goal is to offer researchers and practitioners a comprehensive introduction to this rapidly evolving domain.",
    "pdfUrl": "https://arxiv.org/pdf/2504.03515",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:23.805999Z"
  },
  {
    "id": "3b3a660d5da8dfa09ce2d3f6f8d58db5",
    "title": "Machine Learning Reveals Composition Dependent Thermal Stability in Halide Perovskites",
    "slug": "machine-learning-reveals-composition-dependent-thermal-stability-in-halide-perovskites",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Materials Science (cond-mat.mtrl-sci)",
    "author": {
      "name": "Abigail R. Hering",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Halide perovskites exhibit unpredictable properties in response to environmental stressors, due to several composition-dependent degradation mechanisms. In this work, we apply data visualization and machine learning (ML) techniques to reveal unexpected correlations between composition, temperature, and material properties while using high throughput, in situ environmental photoluminescence (PL) experiments. Correlation heatmaps show the strong influence of Cs content on film degradation, and dimensionality reduction visualization methods uncover clear composition-based data clusters. An extreme gradient boosting algorithm (XGBoost) effectively forecasts PL features for ten perovskite films with both composition-agnostic (>85% accuracy) and composition-dependent (>75% accuracy) model approaches, while elucidating the relative feature importance of composition (up to 99%). This model validates a previously unseen anti-correlation between Cs content and material thermal stability. Our ML-based framework can be expanded to any perovskite family, significantly reducing the analysis time currently employed to identify stable options for photovoltaics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.04002",
    "tags": [
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "createdAt": "2025-04-25T15:49:23.806228Z"
  },
  {
    "id": "43750a7b29afcb5dbb04610f54d6d747",
    "title": "Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents",
    "slug": "throughput-optimal-scheduling-algorithms-for-llm-inference-and-ai-agents",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Yueying Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As demand for Large Language Models (LLMs) and AI agents rapidly grows, optimizing systems for efficient LLM inference becomes critical. While significant efforts have focused on system-level engineering, little is explored from a mathematical modeling and queuing perspective.\nIn this paper, we aim to develop the queuing fundamentals for large language model (LLM) inference, bridging the gap between the queueing theory and LLM system communities. In particular, we study the throughput aspect in LLM inference systems. We prove that a large class of 'work-conserving' scheduling algorithms can achieve maximum throughput for individual inference LLM engine, highlighting 'work-conserving' as a key design principle in practice. In a network of LLM agents, work-conserving scheduling alone is insufficient, particularly when facing specific workload structures and multi-class workflows that require more sophisticated scheduling strategies. Evaluations of real-world systems show that Orca and Sarathi-serve are throughput-optimal, reassuring practitioners, while FasterTransformer and vanilla vLLM are not maximally stable and should be used with caution. Our results highlight the substantial benefits that the queueing community can offer in improving LLM inference systems and call for more interdisciplinary development.",
    "pdfUrl": "https://arxiv.org/pdf/2504.07347",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:23.806439Z"
  },
  {
    "id": "3cd2c5357638d1c74e10b89f600e601d",
    "title": "Artifact detection and localization in single-channel mobile EEG for sleep research using deep learning and attention mechanisms",
    "slug": "artifact-detection-and-localization-in-single-channel-mobile-eeg-for-sleep-research-using-deep-learning-and-attention-mechanisms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Signal Processing (eess.SP)",
    "author": {
      "name": "Khrystyna Semkiv",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Artifacts in the electroencephalogram (EEG) degrade signal quality and impact the analysis of brain activity. Current methods for detecting artifacts in sleep EEG rely on simple threshold-based algorithms that require manual intervention, which is time-consuming and impractical due to the vast volume of data that novel mobile recording systems generate. We propose a convolutional neural network (CNN) model incorporating a convolutional block attention module (CNN-CBAM) to detect and identify the location of artifacts in the sleep EEG with attention maps. We benchmarked this model against six other machine learning and signal processing approaches. We trained/tuned all models on 72 manually annotated EEG recordings obtained during home-based monitoring from 18 healthy participants with a mean (SD) age of 68.05 y ($\\pm$5.02). We tested them on 26 separate recordings from 6 healthy participants with a mean (SD) age of 68.33 y ($\\pm$4.08), with contained artifacts in 4\\% of epochs. CNN-CBAM achieved the highest area under the receiver operating characteristic curve (0.88), sensitivity (0.81), and specificity (0.86) when compared to the other approaches. The attention maps from CNN-CBAM localized artifacts within the epoch with a sensitivity of 0.71 and specificity of 0.67. This work demonstrates the feasibility of automating the detection and localization of artifacts in wearable sleep EEG.",
    "pdfUrl": "https://arxiv.org/pdf/2504.08469",
    "tags": [
      "Signal Processing (eess.SP)"
    ],
    "createdAt": "2025-04-25T15:49:23.806647Z"
  },
  {
    "id": "20d53c106006fe8a682234d1a886f22f",
    "title": "EditLord: Learning Code Transformation Rules for Code Editing",
    "slug": "editlord:-learning-code-transformation-rules-for-code-editing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Weichen Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Code editing is a foundational task in software development, where its effectiveness depends on whether it introduces desired code property changes without changing the original code's intended functionality. Existing approaches often formulate code editing as an implicit end-to-end task, omitting the fact that code-editing procedures inherently consist of discrete and explicit steps. Thus, they suffer from suboptimal performance and lack of robustness and generalization. We introduce EditLord, a code editing framework that makes the code transformation steps explicit. Our key insight is to employ a language model (LM) as an inductive learner to extract code editing rules from the training code pairs as concise meta-rule sets. Such rule sets will be manifested for each training sample to augment them for finetuning or assist in prompting- and iterative-based code editing. EditLordoutperforms the state-of-the-art by an average of 22.7% in editing performance and 58.1% in robustness while achieving 20.2% higher functional correctness across critical software engineering and security applications, LM models, and editing modes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15284",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:23.806863Z"
  },
  {
    "id": "dae4b069b57b31eec40e03f04d87a5f0",
    "title": "A Study on Mixup-Inspired Augmentation Methods for Software Vulnerability Detection",
    "slug": "a-study-on-mixup-inspired-augmentation-methods-for-software-vulnerability-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Seyed Shayan Daneshvar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Various deep learning (DL) methods have recently been utilized to detect software vulnerabilities. Real-world software vulnerability datasets are rare and hard to acquire, as there is no simple metric for classifying vulnerability. Such datasets are heavily imbalanced, and none of the current datasets are considered huge for DL models. To tackle these problems, a recent work has tried to augment the dataset using the source code and generate realistic single-statement vulnerabilities, which is not quite practical and requires manual checking of the generated vulnerabilities. In this paper, we aim to explore the augmentation of vulnerabilities at the representation level to help current models learn better, which has never been done before to the best of our knowledge. We implement and evaluate five augmentation techniques that augment the embedding of the data and have recently been used for code search, which is a completely different software engineering task. We also introduced a conditioned version of those augmentation methods, which ensures the augmentation does not change the vulnerable section of the vector representation. We show that such augmentation methods can be helpful and increase the F1-score by up to 9.67%, yet they cannot beat Random Oversampling when balancing datasets, which increases the F1-score by 10.82%.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15632",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:23.807075Z"
  },
  {
    "id": "32f1696d20a747500c828d4db9409c22",
    "title": "SeizureFormer: A Transformer Model for IEA-Based Seizure Risk Forecasting",
    "slug": "seizureformer:-a-transformer-model-for-iea-based-seizure-risk-forecasting",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Signal Processing (eess.SP)",
    "author": {
      "name": "Tianning Feng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present SeizureFormer, a Transformer-based model for long-term seizure risk forecasting using interictal epileptiform activity (IEA) surrogate biomarkers and long episode (LE) biomarkers from responsive neurostimulation (RNS) systems. Unlike raw scalp EEG-based models, SeizureFormer leverages structured, clinically relevant features and integrates CNN-based patch embedding, multi-head self-attention, and squeeze-and-excitation blocks to model both short-term dynamics and long-term seizure cycles. Tested across five patients and multiple prediction windows (1 to 14 days), SeizureFormer achieved state-of-the-art performance with mean ROC AUC of 79.44 percent and mean PR AUC of 76.29 percent. Compared to statistical, machine learning, and deep learning baselines, it demonstrates enhanced generalizability and seizure risk forecasting performance under class imbalance. This work supports future clinical integration of interpretable and robust seizure forecasting tools for personalized epilepsy management.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16098",
    "tags": [
      "Signal Processing (eess.SP)"
    ],
    "createdAt": "2025-04-25T15:49:23.807298Z"
  },
  {
    "id": "a8bc4079927d3de26cf6d94083398b9e",
    "title": "MARFT: Multi-Agent Reinforcement Fine-Tuning",
    "slug": "marft:-multi-agent-reinforcement-fine-tuning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multiagent Systems (cs.MA)",
    "author": {
      "name": "Junwei Liao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LLM-based Multi-Agent Systems have demonstrated remarkable capabilities in addressing complex, agentic tasks requiring multifaceted reasoning and collaboration, from generating high-quality presentation slides to conducting sophisticated scientific research. Meanwhile, RL has been widely recognized for its effectiveness in enhancing agent intelligence, but limited research has investigated the fine-tuning of LaMAS using foundational RL techniques. Moreover, the direct application of MARL methodologies to LaMAS introduces significant challenges, stemming from the unique characteristics and mechanisms inherent to LaMAS. To address these challenges, this article presents a comprehensive study of LLM-based MARL and proposes a novel paradigm termed Multi-Agent Reinforcement Fine-Tuning (MARFT). We introduce a universal algorithmic framework tailored for LaMAS, outlining the conceptual foundations, key distinctions, and practical implementation strategies. We begin by reviewing the evolution from RL to Reinforcement Fine-Tuning, setting the stage for a parallel analysis in the multi-agent domain. In the context of LaMAS, we elucidate critical differences between MARL and MARFT. These differences motivate a transition toward a novel, LaMAS-oriented formulation of RFT. Central to this work is the presentation of a robust and scalable MARFT framework. We detail the core algorithm and provide a complete, open-source implementation to facilitate adoption and further research. The latter sections of the paper explore real-world application perspectives and opening challenges in MARFT. By bridging theoretical underpinnings with practical methodologies, this work aims to serve as a roadmap for researchers seeking to advance MARFT toward resilient and adaptive solutions in agentic systems. Our implementation of the proposed framework is publicly available at: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16129",
    "tags": [
      "Multiagent Systems (cs.MA)"
    ],
    "createdAt": "2025-04-25T15:49:23.807515Z"
  },
  {
    "id": "bdf7e06b439dc6956f622129966f6c9c",
    "title": "A Statistical Evaluation of Indoor LoRaWAN Environment-Aware Propagation for 6G: MLR, ANOVA, and Residual Distribution Analysis",
    "slug": "a-statistical-evaluation-of-indoor-lorawan-environment-aware-propagation-for-6g:-mlr,-anova,-and-residual-distribution-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Nahshon Mokua Obiri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Modeling path loss in indoor LoRaWAN technology deployments is inherently challenging due to structural obstructions, occupant density and activities, and fluctuating environmental conditions. This study proposes a two-stage approach to capture and analyze these complexities using an extensive dataset of 1,328,334 field measurements collected over six months in a single-floor office at the University of Siegen's Hoelderlinstrasse Campus, Germany. First, we implement a multiple linear regression model that includes traditional propagation metrics (distance, structural walls) and an extension with proposed environmental variables (relative humidity, temperature, carbon dioxide, particulate matter, and barometric pressure). Using analysis of variance, we demonstrate that adding these environmental factors can reduce unexplained variance by 42.32 percent. Secondly, we examine residual distributions by fitting five candidate probability distributions: Normal, Skew-Normal, Cauchy, Student's t, and Gaussian Mixture Models with one to five components. Our results show that a four-component Gaussian Mixture Model captures the residual heterogeneity of indoor signal propagation most accurately, significantly outperforming single-distribution approaches. Given the push toward ultra-reliable, context-aware communications in 6G networks, our analysis shows that environment-aware modeling can substantially improve LoRaWAN network design in dynamic indoor IoT deployments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16688",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:23.807715Z"
  },
  {
    "id": "22f55b83e2edfe7be40ef62851e1e032",
    "title": "Analyzing Value Functions of States in Parametric Markov Chains",
    "slug": "analyzing-value-functions-of-states-in-parametric-markov-chains",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic in Computer Science (cs.LO)",
    "author": {
      "name": "Kasper Engelen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Parametric Markov chains (pMC) are used to model probabilistic systems with unknown or partially known probabilities. Although (universal) pMC verification for reachability properties is known to be coETR-complete, there have been efforts to approach it using potentially easier-to-check properties such as asking whether the pMC is monotonic in certain parameters. In this paper, we first reduce monotonicity to asking whether the reachability probability from a given state is never less than that of another given state. Recent results for the latter property imply an efficient algorithm to collapse same-value equivalence classes, which in turn preserves verification results and monotonicity. We implement our algorithm to collapse \"trivial\" equivalence classes in the pMC and show empirical evidence for the following: First, the collapse gives reductions in size for some existing benchmarks and significant reductions on some custom benchmarks; Second, the collapse speeds up existing algorithms to check monotonicity and parameter lifting, and hence can be used as a fast pre-processing step in practice.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17020",
    "tags": [
      "Logic in Computer Science (cs.LO)"
    ],
    "createdAt": "2025-04-25T15:49:24.065000Z"
  },
  {
    "id": "823271cb010d56572226a0cff872da1b",
    "title": "First-order store and visibility in name-passing calculi",
    "slug": "first-order-store-and-visibility-in-name-passing-calculi",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic in Computer Science (cs.LO)",
    "author": {
      "name": "Daniel Hirschkoff",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The $\\pi$-calculus is the paradigmatical name-passing calculus. While being purely name-passing, it allows the representation of higher-order functions and store. We study how $\\pi$-calculus processes can be controlled so that computations can only involve storage of first-order values. The discipline is enforced by a type system that is based on the notion of visibility, coming from game semantics. We discuss the impact of visibility on the behavioural theory. We propose characterisations of may-testing and barbed equivalence, based on (variants of) trace equivalence and labelled bisimilarity, in the case where computation is sequential, and in the case where computation is well-bracketed.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17350",
    "tags": [
      "Logic in Computer Science (cs.LO)"
    ],
    "createdAt": "2025-04-25T15:49:24.065222Z"
  },
  {
    "id": "0250541b827c8c4f5a5c02f95a3a3a6d",
    "title": "A Constraint Opinion Model",
    "slug": "a-constraint-opinion-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic in Computer Science (cs.LO)",
    "author": {
      "name": "Fabio Gadducci",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces a generalised opinion model that extends the standard DeGroot model by representing agents' opinions and influences as soft constraints rather than single real values. This allows for modelling scenarios beyond the scope of the DeGroot model, such as agents sharing partial information and preferences, engaging in discussions on multiple topics simultaneously, and representing opinions with different degrees of uncertainty. By considering soft constraints as influences, the proposed model captures also situations where agents impose conditions on how others' opinions are integrated during belief revision. Finally, the flexibility offered by soft constraints allows us to introduce a novel polarisation measure that takes advantage of this generalised framework.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17605",
    "tags": [
      "Logic in Computer Science (cs.LO)"
    ],
    "createdAt": "2025-04-25T15:49:24.065431Z"
  },
  {
    "id": "b8fde1bd702210a1da00906199519b71",
    "title": "Rational Inference in Formal Concept Analysis",
    "slug": "rational-inference-in-formal-concept-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Lucas Carr",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Defeasible conditionals are a form of non-monotonic inference which enable the expression of statements like \"if $\\phi$ then normally $\\psi$\". The KLM framework defines a semantics for the propositional case of defeasible conditionals by construction of a preference ordering over possible worlds. The pattern of reasoning induced by these semantics is characterised by consequence relations satisfying certain desirable properties of non-monotonic reasoning. In FCA, implications are used to describe dependencies between attributes. However, these implications are unsuitable to reason with erroneous data or data prone to exceptions. Until recently, the topic of non-monotonic inference in FCA has remained largely uninvestigated. In this paper, we provide a construction of the KLM framework for defeasible reasoning in FCA and show that this construction remains faithful to the principle of non-monotonic inference described in the original framework. We present an additional argument that, while remaining consistent with the original ideas around non-monotonic reasoning, the defeasible reasoning we propose in FCA offers a more contextual view on inference, providing the ability for more relevant conclusions to be drawn when compared to the propositional case.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16938",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:24.065634Z"
  },
  {
    "id": "18faca217e2011e26bc95c2c4c24662c",
    "title": "Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification",
    "slug": "neural-theorem-proving:-generating-and-structuring-proofs-for-formal-verification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Balaji Rao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Formally verifying properties of software code has been a highly desirable task, especially with the emergence of LLM-generated code. In the same vein, they provide an interesting avenue for the exploration of formal verification and mechanistic interpretability. Since the introduction of code-specific models, despite their successes in generating code in Lean4 and Isabelle, the task of generalized theorem proving still remains far from being fully solved and will be a benchmark for reasoning capability in LLMs. In this work, we introduce a framework that generates whole proofs in a formal language to be used within systems that utilize the power of built-in tactics and off-the-shelf automated theorem provers. Our framework includes 3 components: generating natural language statements of the code to be verified, an LLM that generates formal proofs for the given statement, and a module employing heuristics for building the final proof. To train the LLM, we employ a 2-stage fine-tuning process, where we first use SFT-based training to enable the model to generate syntactically correct Isabelle code and then RL-based training that encourages the model to generate proofs verified by a theorem prover. We validate our framework using the miniF2F-test benchmark and the Isabelle proof assistant and design a use case to verify the correctness of the AWS S3 bucket access policy code. We also curate a dataset based on the FVEL\\textsubscript{\\textnormal{ER}} dataset for future training tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17017",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:24.065831Z"
  },
  {
    "id": "ac78e923d08f1d376162c710b6769ce0",
    "title": "Aczel-Mendler Bisimulations in a Regular Category",
    "slug": "aczel-mendler-bisimulations-in-a-regular-category",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic in Computer Science (cs.LO)",
    "author": {
      "name": "Jeremy Dubut",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Aczel-Mendler bisimulations are a coalgebraic extension of a variety of computational relations between systems. It is usual to assume that the underlying category satisfies some form of the axiom of choice, so that the collection of bisimulations enjoys desirable properties, such as closure under composition. In this paper, we accommodate the definition in general regular categories and toposes. We show that this general definition: 1) is closed under composition without using the axiom of choice, 2) coincides with other types of coalgebraic formulations under milder conditions, 3) coincides with the usual definition when the category satisfies the regular axiom of choice. In particular, the case of toposes heavily relies on power-objects, for which we recover some favourable properties along the way. Finally, we describe several examples in Stone spaces, toposes for name-passing, and modules over a ring.",
    "pdfUrl": "https://arxiv.org/pdf/2303.04442",
    "tags": [
      "Logic in Computer Science (cs.LO)"
    ],
    "createdAt": "2025-04-25T15:49:24.066019Z"
  },
  {
    "id": "c01cdcbbcfc5045c4a807e9f5ba4dc98",
    "title": "Automatic Generation of Safety-compliant Linear Temporal Logic via Large Language Model: A Self-supervised Framework",
    "slug": "automatic-generation-of-safety-compliant-linear-temporal-logic-via-large-language-model:-a-self-supervised-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic in Computer Science (cs.LO)",
    "author": {
      "name": "Junle Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Converting high-level tasks described by natural language into formal specifications like Linear Temporal Logic (LTL) is a key step towards providing formal safety guarantees over cyber-physical systems (CPS). While the compliance of the formal specifications themselves against the safety restrictions imposed on CPS is crucial for ensuring safety, most existing works only focus on translation consistency between natural languages and formal specifications. In this paper, we introduce AutoSafeLTL, a self-supervised framework that utilizes large language models (LLMs) to automate the generation of LTL specifications complying with a set of safety restrictions while preserving their logical consistency and semantic accuracy. As a key insight, our framework integrates Language Inclusion check with an automated counterexample-guided modification mechanism to ensure the safety-compliance of the resulting LTL specifications. In particular, we develop 1) an LLM-as-an-Aligner, which performs atomic proposition matching between generated LTL specifications and safety restrictions to enforce semantic alignment; and 2) an LLM-as-a-Critic, which automates LTL specification refinement by interpreting counterexamples derived from Language Inclusion checks. Experimental results demonstrate that our architecture effectively guarantees safety-compliance for the generated LTL specifications, achieving a 0% violation rate against imposed safety restrictions. This shows the potential of our work in synergizing AI and formal verification techniques, enhancing safety-aware specification generation and automatic verification for both AI and critical CPS applications.",
    "pdfUrl": "https://arxiv.org/pdf/2503.15840",
    "tags": [
      "Logic in Computer Science (cs.LO)"
    ],
    "createdAt": "2025-04-25T15:49:24.066207Z"
  },
  {
    "id": "529fa6f2f5cac0c4b11c07225d490693",
    "title": "Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and Editable Policies",
    "slug": "neural-dnf-mt:-a-neuro-symbolic-approach-for-learning-interpretable-and-editable-policies",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Kexin Gu Baugh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Although deep reinforcement learning has been shown to be effective, the model's black-box nature presents barriers to direct policy interpretation. To address this problem, we propose a neuro-symbolic approach called neural DNF-MT for end-to-end policy learning. The differentiable nature of the neural DNF-MT model enables the use of deep actor-critic algorithms for training. At the same time, its architecture is designed so that trained models can be directly translated into interpretable policies expressed as standard (bivalent or probabilistic) logic programs. Moreover, additional layers can be included to extract abstract features from complex observations, acting as a form of predicate invention. The logic representations are highly interpretable, and we show how the bivalent representations of deterministic policies can be edited and incorporated back into a neural model, facilitating manual intervention and adaptation of learned policies. We evaluate our approach on a range of tasks requiring learning deterministic or stochastic behaviours from various forms of observations. Our empirical results show that our neural DNF-MT model performs at the level of competing black-box methods whilst providing interpretable policies.",
    "pdfUrl": "https://arxiv.org/pdf/2501.03888",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:24.066402Z"
  },
  {
    "id": "f7b738353cd9ad6bb36d0e8fbe3b8805",
    "title": "AGCo-MATA: Air-Ground Collaborative Multi-Agent Task Allocation in Mobile Crowdsensing",
    "slug": "agco-mata:-air-ground-collaborative-multi-agent-task-allocation-in-mobile-crowdsensing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multiagent Systems (cs.MA)",
    "author": {
      "name": "Tianhao Shao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Rapid progress in intelligent unmanned systems has presented new opportunities for mobile crowd sensing (MCS). Today, heterogeneous air-ground collaborative multi-agent framework, which comprise unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs), have presented superior flexibility and efficiency compared to traditional homogeneous frameworks in complex sensing tasks. Within this context, task allocation among different agents always play an important role in improving overall MCS quality. In order to better allocate tasks among heterogeneous collaborative agents, in this paper, we investigated two representative complex multi-agent task allocation scenarios with dual optimization objectives: (1) For AG-FAMT (Air-Ground Few Agents More Tasks) scenario, the objectives are to maximize the task completion while minimizing the total travel distance; (2) For AG-MAFT (Air-Ground More Agents Few Tasks) scenario, where the agents are allocated based on their locations, has the optimization objectives of minimizing the total travel distance while reducing travel time cost. To achieve this, we proposed a Multi-Task Minimum Cost Maximum Flow (MT-MCMF) optimization algorithm tailored for AG-FAMT, along with a multi-objective optimization algorithm called W-ILP designed for AG-MAFT, with a particular focus on optimizing the charging path planning of UAVs. Our experiments based on a large-scale real-world dataset demonstrated that the proposed two algorithms both outperform baseline approaches under varying experimental settings, including task quantity, task difficulty, and task distribution, providing a novel way to improve the overall quality of mobile crowdsensing tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17409",
    "tags": [
      "Multiagent Systems (cs.MA)"
    ],
    "createdAt": "2025-04-25T15:49:24.322526Z"
  },
  {
    "id": "2070e87d1ba1e3c2fd09cbce0af90dc5",
    "title": "A Multi-Agent, Laxity-Based Aggregation Strategy for Cost-Effective Electric Vehicle Charging and Local Transformer Overload Prevention",
    "slug": "a-multi-agent,-laxity-based-aggregation-strategy-for-cost-effective-electric-vehicle-charging-and-local-transformer-overload-prevention",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multiagent Systems (cs.MA)",
    "author": {
      "name": "Kristoffer Christensen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rapid electrification of transportation, driven by stringent decarbonization targets and supportive policies, poses significant challenges for distribution system operators (DSOs). When numerous electric vehicles (EVs) charge concurrently, local transformers risk overloading - a problem that current tariff-based strategies do not adequately address. This paper introduces an aggregator-based coordination mechanism that shifts EV charging from congested to underutilized periods using a rule-based scheduling algorithm. Unlike conventional methods that depend on complex real-time pricing signals or optimization-heavy solutions, the aggregator approach uses a simple yet effective \"laxity\" measure to prioritize charging flexibility. To assess technical and economic viability, a multi-agent simulation was developed to replicate residential user behavior and DSO constraints under the use of a 400 kVA low-voltage transformer. The results indicate that overloads are completely eliminated with minimal inconvenience to users, whose increased charging costs are offset by the aggregator at an annual total of under DKK 6000 - significantly lower than the cost of infrastructure reinforcement. This study contributes by (i) quantifying the compensation needed to prevent large-scale overloads, (ii) presenting a replicable, computationally feasible, rule-based aggregator model for DSOs, and (iii) comparing aggregator solutions to costly transformer upgrades, underscoring the aggregator's role as a viable tool for future distribution systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17575",
    "tags": [
      "Multiagent Systems (cs.MA)"
    ],
    "createdAt": "2025-04-25T15:49:24.322744Z"
  },
  {
    "id": "e4860845f7589c31593effe503de8db7",
    "title": "Towards a HIPAA Compliant Agentic AI System in Healthcare",
    "slug": "towards-a-hipaa-compliant-agentic-ai-system-in-healthcare",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multiagent Systems (cs.MA)",
    "author": {
      "name": "Subash Neupane",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Agentic AI systems powered by Large Language Models (LLMs) as their foundational reasoning engine, are transforming clinical workflows such as medical report generation and clinical summarization by autonomously analyzing sensitive healthcare data and executing decisions with minimal human oversight. However, their adoption demands strict compliance with regulatory frameworks such as Health Insurance Portability and Accountability Act (HIPAA), particularly when handling Protected Health Information (PHI). This work-in-progress paper introduces a HIPAA-compliant Agentic AI framework that enforces regulatory compliance through dynamic, context-aware policy enforcement. Our framework integrates three core mechanisms: (1) Attribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid PHI sanitization pipeline combining regex patterns and BERT-based model to minimize leakage, and (3) immutable audit trails for compliance verification.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17669",
    "tags": [
      "Multiagent Systems (cs.MA)"
    ],
    "createdAt": "2025-04-25T15:49:24.322968Z"
  },
  {
    "id": "05a766afb9699939ca5396288a4ccede",
    "title": "PACE: A Framework for Learning and Control in Linear Incomplete-Information Differential Games",
    "slug": "pace:-a-framework-for-learning-and-control-in-linear-incomplete-information-differential-games",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Seyed Yousef Soltanian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we address the problem of a two-player linear quadratic differential game with incomplete information, a scenario commonly encountered in multi-agent control, human-robot interaction (HRI), and approximation methods for solving general-sum differential games. While solutions to such linear differential games are typically obtained through coupled Riccati equations, the complexity increases when agents have incomplete information, particularly when neither is aware of the other's cost function. To tackle this challenge, we propose a model-based Peer-Aware Cost Estimation (PACE) framework for learning the cost parameters of the other agent. In PACE, each agent treats its peer as a learning agent rather than a stationary optimal agent, models their learning dynamics, and leverages this dynamic to infer the cost function parameters of the other agent. This approach enables agents to infer each other's objective function in real time based solely on their previous state observations and dynamically adapt their control policies. Furthermore, we provide a theoretical guarantee for the convergence of parameter estimation and the stability of system states in PACE. Additionally, in our numerical studies, we demonstrate how modeling the learning dynamics of the other agent benefits PACE, compared to approaches that approximate the other agent as having complete information, particularly in terms of stability and convergence speed.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17128",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:24.323166Z"
  },
  {
    "id": "5070e0388898d88eb1e79d09e34c8352",
    "title": "Communication-Efficient Personalized Distributed Learning with Data and Node Heterogeneity",
    "slug": "communication-efficient-personalized-distributed-learning-with-data-and-node-heterogeneity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Zhuojun Tian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "To jointly tackle the challenges of data and node heterogeneity in decentralized learning, we propose a distributed strong lottery ticket hypothesis (DSLTH), based on which a communication-efficient personalized learning algorithm is developed. In the proposed method, each local model is represented as the Hadamard product of global real-valued parameters and a personalized binary mask for pruning. The local model is learned by updating and fusing the personalized binary masks while the real-valued parameters are fixed among different agents. To further reduce the complexity of hardware implementation, we incorporate a group sparse regularization term in the loss function, enabling the learned local model to achieve structured sparsity. Then, a binary mask aggregation algorithm is designed by introducing an intermediate aggregation tensor and adding a personalized fine-tuning step in each iteration, which constrains model updates towards the local data distribution. The proposed method effectively leverages the relativity among agents while meeting personalized requirements in heterogeneous node conditions. We also provide a theoretical proof for the DSLTH, establishing it as the foundation of the proposed method. Numerical simulations confirm the validity of the DSLTH and demonstrate the effectiveness of the proposed algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17520",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:24.323369Z"
  },
  {
    "id": "a8bc4079927d3de26cf6d94083398b9e",
    "title": "MARFT: Multi-Agent Reinforcement Fine-Tuning",
    "slug": "marft:-multi-agent-reinforcement-fine-tuning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multiagent Systems (cs.MA)",
    "author": {
      "name": "Junwei Liao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LLM-based Multi-Agent Systems have demonstrated remarkable capabilities in addressing complex, agentic tasks requiring multifaceted reasoning and collaboration, from generating high-quality presentation slides to conducting sophisticated scientific research. Meanwhile, RL has been widely recognized for its effectiveness in enhancing agent intelligence, but limited research has investigated the fine-tuning of LaMAS using foundational RL techniques. Moreover, the direct application of MARL methodologies to LaMAS introduces significant challenges, stemming from the unique characteristics and mechanisms inherent to LaMAS. To address these challenges, this article presents a comprehensive study of LLM-based MARL and proposes a novel paradigm termed Multi-Agent Reinforcement Fine-Tuning (MARFT). We introduce a universal algorithmic framework tailored for LaMAS, outlining the conceptual foundations, key distinctions, and practical implementation strategies. We begin by reviewing the evolution from RL to Reinforcement Fine-Tuning, setting the stage for a parallel analysis in the multi-agent domain. In the context of LaMAS, we elucidate critical differences between MARL and MARFT. These differences motivate a transition toward a novel, LaMAS-oriented formulation of RFT. Central to this work is the presentation of a robust and scalable MARFT framework. We detail the core algorithm and provide a complete, open-source implementation to facilitate adoption and further research. The latter sections of the paper explore real-world application perspectives and opening challenges in MARFT. By bridging theoretical underpinnings with practical methodologies, this work aims to serve as a roadmap for researchers seeking to advance MARFT toward resilient and adaptive solutions in agentic systems. Our implementation of the proposed framework is publicly available at: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16129",
    "tags": [
      "Multiagent Systems (cs.MA)"
    ],
    "createdAt": "2025-04-25T15:49:24.323571Z"
  },
  {
    "id": "295aa11f54de52f51978448e2e9183e0",
    "title": "Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable Random Walks",
    "slug": "honeybee:-byzantine-tolerant-decentralized-peer-sampling-with-verifiable-random-walks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Yunqi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and table consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\\geq50\\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes.",
    "pdfUrl": "https://arxiv.org/pdf/2402.16201",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:24.323768Z"
  },
  {
    "id": "2f04694a80e004ca454d74bb3f17455a",
    "title": "Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness",
    "slug": "multifaceted-evaluation-of-audio-visual-capability-for-mllms:-effectiveness,-efficiency,-generalizability-and-robustness",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multimedia (cs.MM)",
    "author": {
      "name": "Yusheng Zhao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Multi-modal large language models (MLLMs) have recently achieved great success in processing and understanding information from diverse modalities (e.g., text, audio, and visual signals). Despite their growing popularity, there remains a lack of comprehensive evaluation measuring the audio-visual capabilities of these models, especially in diverse scenarios (e.g., distribution shifts and adversarial attacks). In this paper, we present a multifaceted evaluation of the audio-visual capability of MLLMs, focusing on four key dimensions: effectiveness, efficiency, generalizability, and robustness. Through extensive experiments, we find that MLLMs exhibit strong zero-shot and few-shot generalization abilities, enabling them to achieve great performance with limited data. However, their success relies heavily on the vision modality, which impairs performance when visual input is corrupted or missing. Additionally, while MLLMs are susceptible to adversarial samples, they demonstrate greater robustness compared to traditional models. The experimental results and our findings provide insights into the audio-visual capabilities of MLLMs, highlighting areas for improvement and offering guidance for future research.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16936",
    "tags": [
      "Multimedia (cs.MM)"
    ],
    "createdAt": "2025-04-25T15:49:24.596148Z"
  },
  {
    "id": "58b79d26bf907bf8f4e1ff9b5b29e549",
    "title": "Social sustainability through engagement in a training context with tools such as the Native Podcast and Facebook social network",
    "slug": "social-sustainability-through-engagement-in-a-training-context-with-tools-such-as-the-native-podcast-and-facebook-social-network",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Danielle Mbambe Bebey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The social dimension of sustainability seems to have been a notion rarely addressed in the literature (Dubois et al., 2001) until the early 2000s. The EUTIC 2023 symposium provides an opportunity to take up this topical issue. To this end, we are presenting an engagement process that is part of a sustainable development dynamic, based on digital tools inspired by everyday life, for applications in the context of training, with a view to lifelong learning. Our work, which stems from the information and communication sciences, is rooted in a multi-disciplinary approach that we believe can be echoed in a variety of disciplines, but which it is interesting to challenge, hence the purpose of this contribution.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16964",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:24.596357Z"
  },
  {
    "id": "69dbf2f95b69f4d99ccd3bce64ffd11c",
    "title": "Seeing The Words: Evaluating AI-generated Biblical Art",
    "slug": "seeing-the-words:-evaluating-ai-generated-biblical-art",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Hidde Makimei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The past years witnessed a significant amount of Artificial Intelligence (AI) tools that can generate images from texts. This triggers the discussion of whether AI can generate accurate images using text from the Bible with respect to the corresponding biblical contexts and backgrounds. Despite some existing attempts at a small scale, little work has been done to systematically evaluate these generated images. In this work, we provide a large dataset of over 7K images using biblical text as prompts. These images were evaluated with multiple neural network-based tools on various aspects. We provide an assessment of accuracy and some analysis from the perspective of religion and aesthetics. Finally, we discuss the use of the generated images and reflect on the performance of the AI generators.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16974",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:24.596566Z"
  },
  {
    "id": "516996b746f9c3d77816a8ecd1ed5e29",
    "title": "DIVE: Inverting Conditional Diffusion Models for Discriminative Tasks",
    "slug": "dive:-inverting-conditional-diffusion-models-for-discriminative-tasks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yinqi Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Diffusion models have shown remarkable progress in various generative tasks such as image and video generation. This paper studies the problem of leveraging pretrained diffusion models for performing discriminative tasks. Specifically, we extend the discriminative capability of pretrained frozen generative diffusion models from the classification task to the more complex object detection task, by \"inverting\" a pretrained layout-to-image diffusion model. To this end, a gradient-based discrete optimization approach for replacing the heavy prediction enumeration process, and a prior distribution model for making more accurate use of the Bayes' rule, are proposed respectively. Empirical results show that this method is on par with basic discriminative object detection baselines on COCO dataset. In addition, our method can greatly speed up the previous diffusion-based method for classification without sacrificing accuracy. Code and models are available at this https URL .",
    "pdfUrl": "https://arxiv.org/pdf/2504.17253",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:24.596788Z"
  },
  {
    "id": "8868fd8cd439e935c2fcb50a6a91d905",
    "title": "MV-Crafter: An Intelligent System for Music-guided Video Generation",
    "slug": "mv-crafter:-an-intelligent-system-for-music-guided-video-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Human-Computer Interaction (cs.HC)",
    "author": {
      "name": "Chuer Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Music videos, as a prevalent form of multimedia entertainment, deliver engaging audio-visual experiences to audiences and have gained immense popularity among singers and fans. Creators can express their interpretations of music naturally through visual elements. However, the creation process of music video demands proficiency in script design, video shooting, and music-video synchronization, posing significant challenges for non-professionals. Previous work has designed automated music video generation frameworks. However, they suffer from complexity in input and poor output quality. In response, we present MV-Crafter, a system capable of producing high-quality music videos with synchronized music-video rhythm and style. Our approach involves three technical modules that simulate the human creation process: the script generation module, video generation module, and music-video synchronization module. MV-Crafter leverages a large language model to generate scripts considering the musical semantics. To address the challenge of synchronizing short video clips with music of varying lengths, we propose a dynamic beat matching algorithm and visual envelope-induced warping method to ensure precise, monotonic music-video synchronization. Besides, we design a user-friendly interface to simplify the creation process with intuitive editing features. Extensive experiments have demonstrated that MV-Crafter provides an effective solution for improving the quality of generated music videos.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17267",
    "tags": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "createdAt": "2025-04-25T15:49:24.597004Z"
  },
  {
    "id": "c5f51ddf1e236c42a1010be74ea43d8a",
    "title": "M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction",
    "slug": "m-mre:-extending-the-mutual-reinforcement-effect-to-multimodal-information-extraction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Chengguang Gan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Mutual Reinforcement Effect (MRE) is an emerging subfield at the intersection of information extraction and model interpretability. MRE aims to leverage the mutual understanding between tasks of different granularities, enhancing the performance of both coarse-grained and fine-grained tasks through joint modeling. While MRE has been explored and validated in the textual domain, its applicability to visual and multimodal domains remains unexplored. In this work, we extend MRE to the multimodal information extraction domain for the first time. Specifically, we introduce a new task: Multimodal Mutual Reinforcement Effect (M-MRE), and construct a corresponding dataset to support this task. To address the challenges posed by M-MRE, we further propose a Prompt Format Adapter (PFA) that is fully compatible with various Large Vision-Language Models (LVLMs). Experimental results demonstrate that MRE can also be observed in the M-MRE task, a multimodal text-image understanding scenario. This provides strong evidence that MRE facilitates mutual gains across three interrelated tasks, confirming its generalizability beyond the textual domain.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17353",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:24.597233Z"
  },
  {
    "id": "8e60d7b4c054c53ea70891d463198dde",
    "title": "A Comprehensive Survey of Knowledge-Based Vision Question Answering Systems: The Lifecycle of Knowledge in Visual Reasoning Task",
    "slug": "a-comprehensive-survey-of-knowledge-based-vision-question-answering-systems:-the-lifecycle-of-knowledge-in-visual-reasoning-task",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Jiaqi Deng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Knowledge-based Vision Question Answering (KB-VQA) extends general Vision Question Answering (VQA) by not only requiring the understanding of visual and textual inputs but also extensive range of knowledge, enabling significant advancements across various real-world applications. KB-VQA introduces unique challenges, including the alignment of heterogeneous information from diverse modalities and sources, the retrieval of relevant knowledge from noisy or large-scale repositories, and the execution of complex reasoning to infer answers from the combined context. With the advancement of Large Language Models (LLMs), KB-VQA systems have also undergone a notable transformation, where LLMs serve as powerful knowledge repositories, retrieval-augmented generators and strong reasoners. Despite substantial progress, no comprehensive survey currently exists that systematically organizes and reviews the existing KB-VQA methods. This survey aims to fill this gap by establishing a structured taxonomy of KB-VQA approaches, and categorizing the systems into main stages: knowledge representation, knowledge retrieval, and knowledge reasoning. By exploring various knowledge integration techniques and identifying persistent challenges, this work also outlines promising future research directions, providing a foundation for advancing KB-VQA models and their applications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17547",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:24.597439Z"
  },
  {
    "id": "b53723b0cd3055d810272f384041da44",
    "title": "CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos",
    "slug": "casualhdrsplat:-robust-high-dynamic-range-3d-gaussian-splatting-from-casually-captured-videos",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Graphics (cs.GR)",
    "author": {
      "name": "Shucheng Gong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, photo-realistic novel view synthesis from multi-view images, such as neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered widespread attention due to their superior performance. However, most works rely on low dynamic range (LDR) images, which limits the capturing of richer scene details. Some prior works have focused on high dynamic range (HDR) scene reconstruction, typically require capturing of multi-view sharp images with different exposure times at fixed camera positions during exposure times, which is time-consuming and challenging in practice. For a more flexible data acquisition, we propose a one-stage method: \\textbf{CasualHDRSplat} to easily and robustly reconstruct the 3D HDR scene from casually captured videos with auto-exposure enabled, even in the presence of severe motion blur and varying unknown exposure time. \\textbf{CasualHDRSplat} contains a unified differentiable physical imaging model which first applies continuous-time trajectory constraint to imaging process so that we can jointly optimize exposure time, camera response function (CRF), camera poses, and sharp 3D HDR scene. Extensive experiments demonstrate that our approach outperforms existing methods in terms of robustness and rendering quality. Our source code will be available at this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17728",
    "tags": [
      "Graphics (cs.GR)"
    ],
    "createdAt": "2025-04-25T15:49:24.597667Z"
  },
  {
    "id": "878703f7d64525802838da0836ea7abf",
    "title": "FMNV: A Dataset of Media-Published News Videos for Fake News Detection",
    "slug": "fmnv:-a-dataset-of-media-published-news-videos-for-fake-news-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Yihao Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "News media, particularly video-based platforms, have become deeply embedded in daily life, concurrently amplifying risks of misinformation dissemination. Consequently, multimodal fake news detection has garnered significant research attention. However, existing datasets predominantly comprise user-generated videos characterized by crude editing and limited public engagement, whereas professionally crafted fake news videos disseminated by media outlets, often politically or virally motivated-pose substantially greater societal harm. To address this gap, we construct FMNV, a novel dataset exclusively composed of news videos published by media organizations. Through empirical analysis of existing datasets and our curated collection, we categorize fake news videos into four distinct types. Building upon this taxonomy, we employ Large Language Models (LLMs) to automatically generate deceptive content by manipulating authentic media-published news videos. Furthermore, we propose FMNVD, a baseline model featuring a dual-stream architecture integrating CLIP and Faster R-CNN for video feature extraction, enhanced by co-attention mechanisms for feature refinement and multimodal aggregation. Comparative experiments demonstrate both the generalization capability of FMNV across multiple baselines and the superior detection efficacy of FMNVD. This work establishes critical benchmarks for detecting high-impact fake news in media ecosystems while advancing methodologies for cross-modal inconsistency analysis.",
    "pdfUrl": "https://arxiv.org/pdf/2504.07687",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:24.597861Z"
  },
  {
    "id": "85b90d4fa9b28cd51ecda68c42b6bdc2",
    "title": "Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark",
    "slug": "can-large-language-models-help-multimodal-language-analysis?-mmla:-a-comprehensive-benchmark",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Hanlei Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Multimodal language analysis is a rapidly evolving field that leverages multiple modalities to enhance the understanding of high-level semantics underlying human conversational utterances. Despite its significance, little research has investigated the capability of multimodal large language models (MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce MMLA, a comprehensive benchmark specifically designed to address this gap. MMLA comprises over 61K multimodal utterances drawn from both staged and real-world scenarios, covering six core dimensions of multimodal semantics: intent, emotion, dialogue act, sentiment, speaking style, and communication behavior. We evaluate eight mainstream branches of LLMs and MLLMs using three methods: zero-shot inference, supervised fine-tuning, and instruction tuning. Extensive experiments reveal that even fine-tuned models achieve only about 60%~70% accuracy, underscoring the limitations of current MLLMs in understanding complex human language. We believe that MMLA will serve as a solid foundation for exploring the potential of large language models in multimodal language analysis and provide valuable resources to advance this field. The datasets and code are open-sourced at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16427",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:24.598095Z"
  },
  {
    "id": "6bb7e2b20ec63d318a36e46288e5bd44",
    "title": "Parameter Estimation in ODE Models with Certified Polynomial System Solving",
    "slug": "parameter-estimation-in-ode-models-with-certified-polynomial-system-solving",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Symbolic Computation (cs.SC)",
    "author": {
      "name": "Alexander Demin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider dynamical models given by rational ODE systems. Parameter estimation is an important and challenging task of recovering parameter values from observed data. Recently, a method based on differential algebra and rational interpolation was proposed to express parameter estimation in terms of polynomial system solving. Typically, polynomial system solving is a bottleneck, hence the choice of the polynomial solver is crucial. In this contribution, we compare two polynomial system solvers applied to parameter estimation: homotopy continuation solver from this http URL and our new implementation of a certified solver based on rational univariate representation (RUR) and real root isolation. We show how the new RUR solver can tackle examples that are out of reach for the homotopy methods and vice versa.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17268",
    "tags": [
      "Symbolic Computation (cs.SC)"
    ],
    "createdAt": "2025-04-25T15:49:24.813889Z"
  },
  {
    "id": "b1292a6001a27bdb5368c9e845d1f495",
    "title": "Universal Methods for Nonlinear Spectral Problems",
    "slug": "universal-methods-for-nonlinear-spectral-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Matthew J. Colbrook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Nonlinear spectral problems arise across a range of fields, including mechanical vibrations, fluid-solid interactions, and photonic crystals. Discretizing infinite-dimensional nonlinear spectral problems often introduces significant computational challenges, particularly spectral pollution and invisibility, which can distort or obscure the true underlying spectrum. We present the first general, convergent computational method for computing the spectra and pseudospectra of nonlinear spectral problems. Our approach uses new results on nonlinear injection moduli and requires only minimal continuity assumptions: specifically, continuity with respect to the gap metric on operator graphs, making it applicable to a broad class of problems. We use the Solvability Complexity Index (SCI) hierarchy, which has recently been used to resolve the classical linear problem, to systematically classify the computational complexity of nonlinear spectral problems. Our results establish the optimality of the method and reveal that Hermiticity does not necessarily simplify the computational complexity of these nonlinear problems. Comprehensive examples -- including nonlinear shifts, Klein--Gordon equations, wave equations with acoustic boundary conditions, time-fractional beam equations, and biologically inspired delay differential equations -- demonstrate the robustness, accuracy, and broad applicability of our methodology.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17012",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.113703Z"
  },
  {
    "id": "021c0af10ace6d6481216d5e66ab4321",
    "title": "An Adaptive Finite Element DtN Method for the Acoustic-Elastic Interaction Problem in Periodic Structures",
    "slug": "an-adaptive-finite-element-dtn-method-for-the-acoustic-elastic-interaction-problem-in-periodic-structures",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Lei Lin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Consider a time-harmonic acoustic plane wave incident onto an elastic body with an unbounded periodic surface. The medium above the surface is supposed to be filled with a homogeneous compressible inviscid air/fluid of constant mass density, while the elastic body is assumed to be isotropic and linear. By introducing the Dirichlet-to-Neumann (DtN) operators for acoustic and elastic waves simultaneously, the model is formulated as an acoustic-elastic interaction problem in periodic structures. Based on a duality argument, an a posteriori error estimate is derived for the associated truncated finite element approximation. The a posteriori error estimate consists of the finite element approximation error and the truncation error of two different DtN operators, where the latter decays exponentially with respect to the truncation parameter. Based on the a posteriori error, an adaptive finite element algorithm is proposed for solving the acoustic-elastic interaction problem in periodic structures. Numerical experiments are presented to demonstrate the effectiveness of the proposed algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17233",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.113914Z"
  },
  {
    "id": "fbd4f494e7cdb21b07eeb4cf4af943c4",
    "title": "On Runge-Kutta methods of order 10",
    "slug": "on-runge-kutta-methods-of-order-10",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Misha Stepanov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A family of explicit 15-stage Runge-Kutta methods of order 10 is derived.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17329",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.114105Z"
  },
  {
    "id": "0f99a0ef3a8fecec27e97a45b7d18a88",
    "title": "On Josephy-Halley method for generalized equations",
    "slug": "on-josephy-halley-method-for-generalized-equations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Tom Roubal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We extend the classical third-order Halley iteration to the setting of generalized equations of the form \\[ 0 \\in f(x) + F(x), \\] where \\(f\\colon X\\longrightarrow Y\\) is twice continuously Frchet-differentiable on Banach spaces and \\(F\\colon X\\tto Y\\) is a set-valued mapping with closed graph. Building on predictor-corrector framework, our scheme first solves a partially linearized inclusion to produce a predictor \\(u_{k+1}\\), then incorporates second-order information in a Halley-type corrector step to obtain \\(x_{k+1}\\). Under metric regularity of the linearization at a reference solution and Hlder continuity of \\(f''\\), we prove that the iterates converge locally with order \\(2+p\\) (cubically when \\(p=1\\)). Moreover, by constructing a suitable scalar majorant function we derive semilocal Kantorovich-type conditions guaranteeing well-definedness and R-cubic convergence from an explicit neighbourhood of the initial guess. Numerical experiments-including one- and two-dimensional test problems confirm the theoretical convergence rates and illustrate the efficiency of the Josephy-Halley method compared to its Josephy-Newton counterpart.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17649",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.114304Z"
  },
  {
    "id": "3d5f6c0e1b8158fc903eaeae747e9906",
    "title": "Fully-Mixed Virtual Element Method for the Biot Problem",
    "slug": "fully-mixed-virtual-element-method-for-the-biot-problem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Michele Botti",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Poroelasticity describes the interaction of deformation and fluid flow in saturated porous media. A fully-mixed formulation of Biot's poroelasticity problem has the advantage of producing a better approximation of the Darcy velocity and stress field, as well as satisfying local mass and momentum conservation. In this work, we focus on a novel four-fields Virtual Element discretization of Biot's equations. The stress symmetry is strongly imposed in the definition of the discrete space, thus avoiding the use of an additional Lagrange multiplier. A complete a priori analysis is performed, showing the robustness of the proposed numerical method with respect to limiting material properties. The first order convergence of the lowest-order fully-discrete numerical method, which is obtained by coupling the spatial approximation with the backward Euler time-advancing scheme, is confirmed by a complete 3D numerical validation. A well known poroelasticity benchmark is also considered to assess the robustness properties and computational performance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17729",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.114506Z"
  },
  {
    "id": "40711ba97c4025a7f41de20ddb1fd368",
    "title": "Physics-informed features in supervised machine learning",
    "slug": "physics-informed-features-in-supervised-machine-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Margherita Lampani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Supervised machine learning involves approximating an unknown functional relationship from a limited dataset of features and corresponding labels. The classical approach to feature-based machine learning typically relies on applying linear regression to standardized features, without considering their physical meaning. This may limit model explainability, particularly in scientific applications. This study proposes a physics-informed approach to feature-based machine learning that constructs non-linear feature maps informed by physical laws and dimensional analysis. These maps enhance model interpretability and, when physical laws are unknown, allow for the identification of relevant mechanisms through feature ranking. The method aims to improve both predictive performance in regression tasks and classification skill scores by integrating domain knowledge into the learning process, while also enabling the potential discovery of new physical equations within the context of explainable machine learning.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17112",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:25.114703Z"
  },
  {
    "id": "f7b9f15dca4273c7dd9001b9856525b8",
    "title": "Rescaling and unconstrained minimisation of convex quadratic maps",
    "slug": "rescaling-and-unconstrained-minimisation-of-convex-quadratic-maps",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Alexandra Zverovich",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the properties of a class of piecewise-fractional maps arising from the introduction of an invariance under rescaling into convex quadratic maps. The subsequent maps are quasiconvex, and pseudoconvex on specific convex cones; they can be optimised via exact line search along admissible directions, and the iterates then inherit a bidimensional optimality property. We study the minimisation of such relaxed maps via coordinate descents with gradient-based rules, placing a special emphasis on coordinate directions verifying a maximum-alignment property in the reproducing kernel Hilbert spaces related to the underlying positive-semidefinite matrices. In this setting, we illustrate that accounting for the optimal rescaling of the iterates can in certain situations substantially accelerate the unconstrained minimisation of convex quadratic maps.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17596",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:25.114899Z"
  },
  {
    "id": "fc025c08596d526d8fec7ffd34c017d8",
    "title": "Convolution Quadrature for the quasilinear subdiffusion equation",
    "slug": "convolution-quadrature-for-the-quasilinear-subdiffusion-equation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Maria Lpez-Fernndez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We construct a Convolution Quadrature (CQ) scheme for the quasilinear subdiffusion equation of order $\\alpha$ and supply it with the fast and oblivious implementation. In particular, we find a condition for the CQ to be admissible and discretize the spatial part of the equation with the Finite Element Method. We prove the unconditional stability and convergence of the scheme and find a bound on the error. Our estimates are globally optimal for all $0<\\alpha<1$ and pointwise for $\\alpha\\geq 1/2$ in the sense that they reduce to the well-known results for the linear equation. For the semilinear case, our estimates are optimal both globally and locally. As a passing result, we also obtain a discrete Grnwall inequality for the CQ, which is a crucial ingredient in our convergence proof based on the energy method. The paper is concluded with numerical examples verifying convergence and computation time reduction when using fast and oblivious quadrature.",
    "pdfUrl": "https://arxiv.org/pdf/2311.00081",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.115086Z"
  },
  {
    "id": "bb22d8c020c6be3032a545a2ca34b7f5",
    "title": "Analysis and improvement of a semi-Lagrangian exponential scheme for the shallow-water equations on the rotating sphere",
    "slug": "analysis-and-improvement-of-a-semi-lagrangian-exponential-scheme-for-the-shallow-water-equations-on-the-rotating-sphere",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Joo Guilherme Caldas Steinstraesser",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, we study and extend a class of semi-Lagrangian exponential methods, which combine exponential time integration techniques, suitable for integrating stiff linear terms, with a semi-Lagrangian treatment of nonlinear advection terms. Partial differential equations involving both processes arise for instance in atmospheric circulation models. Through a truncation error analysis, we show that previously formulated semi-Lagrangian exponential schemes are limited to first-order accuracy due to the approximation of the integration factor acting on the discretization of the linear term; we then formulate a new discretization leading to second-order accuracy. Also, a detailed stability study is conducted to compare several Eulerian and semi-Lagrangian exponential schemes, as well as a well-established semi-Lagrangian semi-implicit method, which is used in operational atmospheric models. Numerical simulations of the shallow-water equations on the rotating sphere are performed to assess the orders of convergence, stability properties, and computational cost of each method. The proposed second-order semi-Lagrangian exponential method was shown to be more stable and accurate than the previously formulated schemes of the same class at the expense of larger wall-clock times; however, the method is more stable and has a similar cost compared to the well-established semi-Lagrangian semi-implicit method; therefore, it is a competitive candidate for potential operational applications in atmospheric circulation modeling.",
    "pdfUrl": "https://arxiv.org/pdf/2405.02237",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.115281Z"
  },
  {
    "id": "d9ce02f0ffaeea3c37217a3f7fc6700c",
    "title": "A Random Integration Algorithm for High-dimensional Function Spaces",
    "slug": "a-random-integration-algorithm-for-high-dimensional-function-spaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Liang Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a novel random integration algorithm that boasts both high convergence order and polynomial tractability for functions characterized by sparse frequencies or rapidly decaying Fourier coefficients. Specifically, for integration in periodic isotropic Sobolev space and the isotropic Sobolev space with compact support, our approach attains a nearly optimal root mean square error (RMSE) bound. In contrast to previous nearly optimal algorithms, our method exhibits polynomial tractability, ensuring that the number of samples does not scale exponentially with increasing dimensions. Our integration algorithm also enjoys nearly optimal bound for weighted Korobov space. Furthermore, the algorithm can be applied without the need for prior knowledge of weights, distinguishing it from the component-by-component algorithm. For integration in the Wiener algebra, the sample complexity of our algorithm is independent of the decay rate of Fourier coefficients. The effectiveness of the integration is confirmed through numerical experiments.",
    "pdfUrl": "https://arxiv.org/pdf/2406.16627",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.115470Z"
  },
  {
    "id": "58163cc9677633570016cb43734f9baf",
    "title": "Superlinear Convergence of GMRES for clustered eigenvalues and its application to least squares problems",
    "slug": "superlinear-convergence-of-gmres-for-clustered-eigenvalues-and-its-application-to-least-squares-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Zeyu Liao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The objective of this paper is to understand the superlinear convergence behavior of the GMRES method when the coefficient matrix has clustered eigenvalues. In order to understand the phenomenon, we analyze the convergence using the Vandermonde matrix which is defined using the eigenvalues of the coefficient matrix. Although eigenvalues alone cannot explain the convergence, they may provide an upper bound of the residual, together with the right hand side vector and the eigenvectors of the coefficient matrix. We show that when the coefficient matrix is diagonalizable, if the eigenvalues of the coefficient matrix are clustered, the upper bound of the convergence curve shows superlinear convergence, when the norm of the matrix obtained by decomposing the right hand side vector into the eigenvector components is not so large. We apply the analysis to explain the convergence of inner-iteration preconditioned GMRES for least squares problems.",
    "pdfUrl": "https://arxiv.org/pdf/2408.00693",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.115663Z"
  },
  {
    "id": "6e851a058b8fa6a87fce55f46e6f3262",
    "title": "Higher order error estimates for regularization of inverse problems under non-additive noise",
    "slug": "higher-order-error-estimates-for-regularization-of-inverse-problems-under-non-additive-noise",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Diana-Elena Mirciu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work we derive higher order error estimates for inverse problems distorted by non-additive noise, in terms of Bregman distances. The results are obtained by means of a novel source condition, inspired by the dual problem. Specifically, we focus on variational regularization having the Kullback-Leibler divergence as data-fidelity, and a convex penalty term. In this framework, we provide an interpretation of the new source condition, and present error estimates also when a variational formulation of the source condition is employed. We show that this approach can be extended to variational regularization that incorporates more general convex data fidelities.",
    "pdfUrl": "https://arxiv.org/pdf/2411.19736",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.115854Z"
  },
  {
    "id": "cd82e49693cf660d6eb28c74a5ab5568",
    "title": "Deep Univariate Polynomial and Conformal Approximation",
    "slug": "deep-univariate-polynomial-and-conformal-approximation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Kingsley Yeon",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A deep approximation is an approximating function defined by composing more than one layer of simple functions. We study deep approximations of functions of one variable using layers consisting of low-degree polynomials or simple conformal transformations. We show that deep approximations to $|x|$ on $[-1,1]$ achieve exponential convergence with respect to the degrees of freedom. Computational experiments suggest that a composite of two and three polynomial layers can give more accurate approximations than a single polynomial with the same number of coefficients. We also study the related problem of reducing the Runge phenomenon by composing polynomials with conformal transformations.",
    "pdfUrl": "https://arxiv.org/pdf/2503.00698",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.116032Z"
  },
  {
    "id": "722d30dfe9f4c6ce4390e02481b7618c",
    "title": "The Resonance Bias Framework: Resonance, Structure, and Arithmetic in Quadrature Error",
    "slug": "the-resonance-bias-framework:-resonance,-structure,-and-arithmetic-in-quadrature-error",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "William Cook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the trapezoidal rule for periodic functions on uniform grids and show that the quadrature error exhibits a rich deterministic structure, beyond traditional asymptotic or statistical interpretations. Focusing on the prototype function f(x) = sin^2(2 pi k x), we derive an analytical expression for the error governed by a resonance function chi_P(y), closely related to the Dirichlet kernel, roots of unity, and discrete Fourier analysis on the group Z/PZ. This function acts as a spectral filter, connecting the integration error to arithmetic properties such as k/P and geometric phase cancellation, visualized as vector averaging on the unit circle. We introduce the Resonance Bias Framework (RBF), a generalization to arbitrary smooth periodic functions, leading to the error representation B_P[f] = sum_{k != 0} c_k chi_P(k/P). Although this is mathematically equivalent to the classical aliasing sum, it reveals a deeper mechanism: the quadrature error arises from structured resonance rather than random aliasing noise. The RBF thus provides an interpretable framework for understanding integration errors at finite resolution, grounded in number theory and geometry.",
    "pdfUrl": "https://arxiv.org/pdf/2503.12117",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.116219Z"
  },
  {
    "id": "2e4004912c129e2bb7ef5a5ea986d196",
    "title": "Quasitubal Tensor Algebra Over Separable Hilbert Spaces",
    "slug": "quasitubal-tensor-algebra-over-separable-hilbert-spaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Uria Mor",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The tubal tensor framework provides a clean and effective algebraic setting for tensor computations, supporting matrix-mimetic features like Singular Value Decomposition and Eckart-Young-like optimality results. Underlying the tubal tensor framework is a view of a tensor as a matrix of finite sized tubes. In this work, we lay the mathematical and computational foundations for working with tensors with infinite size tubes: matrices whose elements are elements from a separable Hilbert space. A key challenge is that existence of important desired matrix-mimetic features of tubal tensors rely on the existence of a unit element in the ring of tubes. Such unit element cannot exist for tubes which are elements of an infinite-dimensional Hilbert space. We sidestep this issue by embedding the tubal space in a commutative unital C*-algebra of bounded operators. The resulting quasitubal algebra recovers the structural properties needed for decomposition and low-rank approximation. In addition to laying the theoretical groundwork for working with tubal tensors with infinite dimensional tubes, we discuss computational aspects of our construction, and provide a numerical illustration where we compute a finite dimensional approximation to a infinitely-sized synthetic tensor using our theory. We believe our theory opens new exciting avenues for applying matrix mimetic tensor framework in the context of inherently infinite dimensional problems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16231",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:25.116411Z"
  },
  {
    "id": "11a5d12fecf239c495a10b65edd6bed1",
    "title": "Exponential speed up in Monte Carlo sampling through Radial Updates",
    "slug": "exponential-speed-up-in-monte-carlo-sampling-through-radial-updates",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Physics (physics.comp-ph)",
    "author": {
      "name": "Johann Ostmeyer",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, it has been shown that the hybrid Monte Carlo (HMC) algorithm is guaranteed to converge exponentially to a given target probability distribution $p(x)\\propto e^{-V(x)}$ on non-compact spaces if augmented by an appropriate radial update. In this work we present a simple way to derive efficient radial updates meeting the necessary requirements for any potential $V$. We reduce the problem to finding a substitution for the radial direction $||x||=f(z)$ so that the effective potential $V(f(z))$ grows exponentially with $z\\rightarrow\\pm\\infty$. Any additive update of $z$ then leads to the desired convergence. We show that choosing this update from a normal distribution with standard deviation $\\sigma\\approx 1/\\sqrt{d}$ in $d$ dimensions yields very good results. We further generalise the previous results on radial updates to a wide class of Markov chain Monte Carlo (MCMC) algorithms beyond the HMC and we quantify the convergence behaviour of MCMC algorithms with badly chosen radial update. Finally, we apply the radial update to the sampling of heavy-tailed distributions and achieve a speed up of many orders of magnitude.",
    "pdfUrl": "https://arxiv.org/pdf/2411.18218",
    "tags": [
      "Computational Physics (physics.comp-ph)"
    ],
    "createdAt": "2025-04-25T15:49:25.116602Z"
  },
  {
    "id": "30c4e0c88a086d3a99cf48a9496ae3cd",
    "title": "A Diffuse Domain Approximation with Transmission-Type Boundary Conditions I: Asymptotic Analysis and Numerics",
    "slug": "a-diffuse-domain-approximation-with-transmission-type-boundary-conditions-i:-asymptotic-analysis-and-numerics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Toai Luong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Diffuse domain methods (DDMs) have garnered significant attention for approximating solutions to partial differential equations on complex geometries. These methods implicitly represent the geometry by replacing the sharp boundary interface with a diffuse layer of thickness $\\varepsilon$, which scales with the minimum grid size. This approach reformulates the original equations on an extended regular domain, incorporating boundary conditions through singular source terms. In this work, we conduct a matched asymptotic analysis of a DDM for a two-sided problem with transmission-type Robin boundary conditions. Our results show that, in the one dimensional space, the solution of the diffuse domain approximation asymptotically converges to the solution of the original problem, with exactly first-order accuracy in $\\varepsilon$. Furthermore, we provide numerical simulations that validate and illustrate the analytical result.",
    "pdfUrl": "https://arxiv.org/pdf/2412.07007",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:25.116793Z"
  },
  {
    "id": "6d85aefa62e5488082ac715d54550f72",
    "title": "A Robust Model-Based Approach for Continuous-Time Policy Evaluation with Unknown Lvy Process Dynamics",
    "slug": "a-robust-model-based-approach-for-continuous-time-policy-evaluation-with-unknown-lvy-process-dynamics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Qihao Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper develops a model-based framework for continuous-time policy evaluation (CTPE) in reinforcement learning, incorporating both Brownian and Lvy noise to model stochastic dynamics influenced by rare and extreme events. Our approach formulates the policy evaluation problem as solving a partial integro-differential equation (PIDE) for the value function with unknown coefficients. A key challenge in this setting is accurately recovering the unknown coefficients in the stochastic dynamics, particularly when driven by Lvy processes with heavy tail effects. To address this, we propose a robust numerical approach that effectively handles both unbiased and censored trajectory datasets. This method combines maximum likelihood estimation with an iterative tail correction mechanism, improving the stability and accuracy of coefficient recovery. Additionally, we establish a theoretical bound for the policy evaluation error based on coefficient recovery error. Through numerical experiments, we demonstrate the effectiveness and robustness of our method in recovering heavy-tailed Lvy dynamics and verify the theoretical error analysis in policy evaluation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.01482",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:25.116990Z"
  },
  {
    "id": "53b162b81d925106ab0c0a24f0a385f9",
    "title": "Optimal Distribution of Solutions for Crowding Distance on Linear Pareto Fronts of Two-Objective Optimization Problems",
    "slug": "optimal-distribution-of-solutions-for-crowding-distance-on-linear-pareto-fronts-of-two-objective-optimization-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "Hisao Ishibuchi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Characteristics of an evolutionary multi-objective optimization (EMO) algorithm can be explained using its best solution set. For example, the best solution set for SMS-EMOA is the same as the optimal distribution of solutions for hypervolume maximization. For NSGA-III, if the Pareto front has intersection points with all reference lines, all of those intersection points are the best solution set. For MOEA/D, the best solution set is the set of the optimal solution of each sub-problem. Whereas these EMO algorithms can be analyzed in this manner, the best solution set for the most well-known and frequently-used EMO algorithm NSGA-II has not been discussed in the literature. This is because NSGA-II is not based on any clear criterion to be optimized (e.g., hypervolume maximization, distance minimization to the nearest reference line). As the first step toward the best solution set analysis for NSGA-II, we discuss the optimal distribution of solutions for the crowding distance under the simplest setting: the maximization of the minimum crowding distance on linear Pareto fronts of two-objective optimization problems. That is, we discuss the optimal distribution of solutions on a straight line. Our theoretical analysis shows that the uniformly distributed solutions are not the best solution set. However, it is also shown by computational experiments that the uniformly distributed solutions (except for the duplicated two extreme solutions at each edge of the Pareto front) are obtained from a modified NSGA-II with the ($\\mu$ + 1) generation update scheme.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17222",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:25.406263Z"
  },
  {
    "id": "3dc4e86b957f2aeb9fb994338ff8460d",
    "title": "Dual-Individual Genetic Algorithm: A Dual-Individual Approach for Efficient Training of Multi-Layer Neural Networks",
    "slug": "dual-individual-genetic-algorithm:-a-dual-individual-approach-for-efficient-training-of-multi-layer-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "Tran Thuy Nga Truong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces an enhanced Genetic Algorithm technique called Dual-Individual Genetic Algorithm (Dual-Individual GA), which optimizes neural networks for binary image classification tasks, such as cat vs. non-cat classification. The proposed method employs only two individuals for crossover, represented by two parameter sets: Leader and Follower. The Leader focuses on exploitation, representing the primary optimal solution at even-indexed positions (0, 2, 4, ...), while the Follower promotes exploration by preserving diversity and avoiding premature convergence, operating at odd-indexed positions (1, 3, 5, ...). Leader and Follower are modeled as two phases or roles. The key contributions of this work are threefold: (1) a self-adaptive layer dimension mechanism that eliminates the need for manual tuning of layer architectures; (2) generates two parameter sets, leader and follower parameter sets, with 10 layer architecture configurations (5 for each set), ranked by Pareto dominance and cost. post-optimization; and (3) demonstrated superior performance compared to traditional gradient-based methods. Experimental results show that the Dual-Individual GA achieves 99.04% training accuracy and 80% testing accuracy (cost = 0.034) on a three-layer network with architecture [12288, 17, 4, 1], outperforming a gradient-based approach that achieves 98% training accuracy and 80% testing accuracy (cost = 0.092) on a four-layer network with architecture [12288, 20, 7, 5, 1]. These findings highlight the efficiency and effectiveness of the proposed method in optimizing neural networks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17346",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:25.406467Z"
  },
  {
    "id": "5a9120261a772515008e3e60e1f5c715",
    "title": "An approach based on metaheuristic algorithms to the timetabling problem in deregulated railway markets",
    "slug": "an-approach-based-on-metaheuristic-algorithms-to-the-timetabling-problem-in-deregulated-railway-markets",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "David Muoz-Valero",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The train timetabling problem in liberalized railway markets represents a challenge to the coordination between infrastructure managers and railway undertakings. Efficient scheduling is critical in maximizing infrastructure capacity and utilization while adhering as closely as possible to the requests of railway undertakings. These objectives ultimately contribute to maximizing the infrastructure manager's revenues. This paper sets out a modular simulation framework to reproduce the dynamics of deregulated railway systems. Ten metaheuristic algorithms using the MEALPY Python library are then evaluated in order to optimize train schedules in the liberalized Spanish railway market. The results show that the Genetic Algorithm outperforms others in revenue optimization, convergence speed, and schedule adherence. Alternatives, such as Particle Swarm Optimization and Ant Colony Optimization Continuous, show slower convergence and higher variability. The results emphasize the trade-off between scheduling more trains and adhering to requested times, providing insights into solving complex scheduling problems in deregulated railway systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17455",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:25.406678Z"
  },
  {
    "id": "a2fac57acaf98c4f045245385fb5e324",
    "title": "Towards Equitable Rail Service Allocation Through Fairness-Oriented Timetabling in Liberalized Markets",
    "slug": "towards-equitable-rail-service-allocation-through-fairness-oriented-timetabling-in-liberalized-markets",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "David Muoz-Valero",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Over the last few decades, European rail transport has undergone major changes as part of the process of liberalization set out in European regulations. In this context of liberalization, railway undertakings compete with each other for the limited infrastructure capacity available to offer their rail services. The infrastructure manager is responsible for the equitable allocation of infrastructure between all companies in the market, which is essential to ensure the efficiency and sustainability of this competitive ecosystem. In this paper, a methodology based on Jain, Gini and Atkinson equity metrics is used to solve the rail service allocation problem in a liberalized railway market, analyzing the solutions obtained. The results show that the proposed methodology and the equity metrics used allow for equitable planning in different competitiveness scenarios. These results contrast with solutions where the objective of the infrastructure manager is to maximize its own profit, without regard for the equitable allocation of infrastructure. Therefore, the computational tests support the methodology and metrics used as a planning and decision support tool in a liberalized railway market.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17489",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:25.406883Z"
  },
  {
    "id": "a80e143e272ed717d1d35a05efdfb750",
    "title": "A Systematic Study on the Design of Odd-Sized Highly Nonlinear Boolean Functions via Evolutionary Algorithms",
    "slug": "a-systematic-study-on-the-design-of-odd-sized-highly-nonlinear-boolean-functions-via-evolutionary-algorithms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "Claude Carlet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper focuses on the problem of evolving Boolean functions of odd sizes with high nonlinearity, a property of cryptographic relevance. Despite its simple formulation, this problem turns out to be remarkably difficult. We perform a systematic evaluation by considering three solution encodings and four problem instances, analyzing how well different types of evolutionary algorithms behave in finding a maximally nonlinear Boolean function. Our results show that genetic programming generally outperforms other evolutionary algorithms, although it falls short of the best-known results achieved by ad-hoc heuristics. Interestingly, by adding local search and restricting the space to rotation symmetric Boolean functions, we show that a genetic algorithm with the bitstring encoding manages to evolve a $9$-variable Boolean function with nonlinearity 241.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17666",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:25.407091Z"
  },
  {
    "id": "5e9d323dc8d0bb34133562bb1cf2adba",
    "title": "Revisiting Reset Mechanisms in Spiking Neural Networks for Sequential Modeling: Specialized Discretization for Binary Activated RNN",
    "slug": "revisiting-reset-mechanisms-in-spiking-neural-networks-for-sequential-modeling:-specialized-discretization-for-binary-activated-rnn",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "Enqi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the field of image recognition, spiking neural networks (SNNs) have achieved performance comparable to conventional artificial neural networks (ANNs). In such applications, SNNs essentially function as traditional neural networks with quantized activation values. This article focuses on an another alternative perspective,viewing SNNs as binary-activated recurrent neural networks (RNNs) for sequential modeling this http URL this viewpoint, current SNN architectures face several fundamental challenges in sequence modeling: (1) Traditional models lack effective memory mechanisms for long-range sequence modeling; (2) The biological-inspired components in SNNs (such as reset mechanisms and refractory period applications) remain theoretically under-explored for sequence tasks; (3) The RNN-like computational paradigm in SNNs prevents parallel training across different this http URL address these challenges, this study conducts a systematic analysis of the fundamental mechanisms underlying reset operations and refractory periods in binary-activated RNN-based SNN sequence models. We re-examine whether such biological mechanisms are strictly necessary for generating sparse spiking patterns, provide new theoretical explanations and insights, and ultimately propose the fixed-refractory-period SNN architecture for sequence modeling.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17751",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:25.407277Z"
  },
  {
    "id": "77e8ca97d3099e42cee85ef12f6763d3",
    "title": "Advancing CMA-ES with Learning-Based Cooperative Coevolution for Scalable Optimization",
    "slug": "advancing-cma-es-with-learning-based-cooperative-coevolution-for-scalable-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hongshu Guo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent research in Cooperative Coevolution~(CC) have achieved promising progress in solving large-scale global optimization problems. However, existing CC paradigms have a primary limitation in that they require deep expertise for selecting or designing effective variable decomposition strategies. Inspired by advancements in Meta-Black-Box Optimization, this paper introduces LCC, a pioneering learning-based cooperative coevolution framework that dynamically schedules decomposition strategies during optimization processes. The decomposition strategy selector is parameterized through a neural network, which processes a meticulously crafted set of optimization status features to determine the optimal strategy for each optimization step. The network is trained via the Proximal Policy Optimization method in a reinforcement learning manner across a collection of representative problems, aiming to maximize the expected optimization performance. Extensive experimental results demonstrate that LCC not only offers certain advantages over state-of-the-art baselines in terms of optimization effectiveness and resource consumption, but it also exhibits promising transferability towards unseen problems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17578",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:25.407486Z"
  },
  {
    "id": "52d1fcad876ab3e352980db7dc978710",
    "title": "Runtime Performance of Evolutionary Algorithms for the Chance-constrained Makespan Scheduling Problem",
    "slug": "runtime-performance-of-evolutionary-algorithms-for-the-chance-constrained-makespan-scheduling-problem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "Feng Shi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Makespan Scheduling problem is an extensively studied NP-hard problem, and its simplest version looks for an allocation approach for a set of jobs with deterministic processing times to two identical machines such that the makespan is minimized. However, in real life scenarios, the actual processing time of each job may be stochastic around the expected value with a variance, under the influence of external factors, and the actual processing times of these jobs may be correlated with covariances. Thus within this paper, we propose a chance-constrained version of the Makespan Scheduling problem and investigate the theoretical performance of the classical Randomized Local Search and (1+1) EA for it. More specifically, we first study two variants of the Chance-constrained Makespan Scheduling problem and their computational complexities, then separately analyze the expected runtime of the two algorithms to obtain an optimal solution or almost optimal solution to the instances of the two variants. In addition, we investigate the experimental performance of the two algorithms for the two variants.",
    "pdfUrl": "https://arxiv.org/pdf/2212.11478",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:25.407693Z"
  },
  {
    "id": "31e8426bc33676897f19a44c54347518",
    "title": "Delving Deeper Into Astromorphic Transformers",
    "slug": "delving-deeper-into-astromorphic-transformers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Neural and Evolutionary Computing (cs.NE)",
    "author": {
      "name": "Md Zesun Ahmed Mia",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Preliminary attempts at incorporating the critical role of astrocytes - cells that constitute more than 50\\% of human brain cells - in brain-inspired neuromorphic computing remain in infancy. This paper seeks to delve deeper into various key aspects of neuron-synapse-astrocyte interactions to mimic self-attention mechanisms in Transformers. The cross-layer perspective explored in this work involves bioplausible modeling of Hebbian and presynaptic plasticities in neuron-astrocyte networks, incorporating effects of non-linearities and feedback along with algorithmic formulations to map the neuron-astrocyte computations to self-attention mechanism and evaluating the impact of incorporating bio-realistic effects from the machine learning application side. Our analysis on sentiment and image classification tasks (IMDB and CIFAR10 datasets) highlights the advantages of Astromorphic Transformers, offering improved accuracy and learning speed. Furthermore, the model demonstrates strong natural language generation capabilities on the WikiText-2 dataset, achieving better perplexity compared to conventional models, thus showcasing enhanced generalization and stability across diverse machine learning tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2312.10925",
    "tags": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "createdAt": "2025-04-25T15:49:25.407885Z"
  },
  {
    "id": "e21b3ba91ca69fa3bed8001569de3637",
    "title": "A Simple and Efficient Approach to Batch Bayesian Optimization",
    "slug": "a-simple-and-efficient-approach-to-batch-bayesian-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Dawei Zhan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Extending Bayesian optimization to batch evaluation can enable the designer to make the most use of parallel computing technology. However, most of current batch approaches do not scale well with the batch size. That is, their performances deteriorate dramatically as the batch size increases. To address this issue, we propose a simple and efficient approach to extend Bayesian optimization to large-scale batch evaluation in this work. Different from existing batch approaches, the idea of the new approach is to draw a batch of axis-aligned subspaces of the original problem and select one acquisition point from each subspace. To achieve this, we propose the expected subspace improvement criterion to measure the amount of the improvement that a candidate point can achieve within a certain axis-aligned subspace. By optimizing these expected subspace improvement functions simultaneously, we can get a batch of query points for parallel evaluation. Numerical experiments show that our proposed approach can speedup the convergence significantly when compared with the sequential Bayesian optimization algorithm, and performs very competitively when compared with seven batch Bayesian optimization algorithms. A Matlab implementation of the proposed approach is available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2411.16206",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:25.408076Z"
  },
  {
    "id": "f6f8e51cc1b0f723a35795c0b7fa8281",
    "title": "Enhanced load balancing technique for SDN controllers: A multi-threshold approach with migration of switches",
    "slug": "enhanced-load-balancing-technique-for-sdn-controllers:-a-multi-threshold-approach-with-migration-of-switches",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Mohammad Kazemiesfeh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Deploying multiple controllers in the control panel of software-defined networks increases scalability, availability, and performance, but it also brings challenges, such as controller overload. To address this, load-balancing techniques are employed in software-defined networks. Controller load balancing can be categorized into two main approaches: (1) single-level thresholds and (2) multi-level thresholds. However, previous studies have predominantly relied on single-level thresholds, which result in an imprecise classification of controllers or have assumed uniform controller capacities in multi-level threshold methods. This study explores controller load balancing with a focus on utilizing multi-level thresholds to accurately assess controller status. Switch migration operations are utilized to achieve load balancing, considering factors such as the degree of load imbalance of the target controller and migration efficiency. This includes evaluating the post-migration status of the target controller and the distance between the migrating switch and the target controller to select the appropriate target controller and migrating switch. The proposed scheme reduces controller response time, migration costs, communication overhead, and throughput rate. Results demonstrate that our scheme outperforms others regarding response time and overall performance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17046",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:25.673558Z"
  },
  {
    "id": "cb2252b41e6937011b28a9c3b3d0130b",
    "title": "An Extensible Software Transport Layer for GPU Networking",
    "slug": "an-extensible-software-transport-layer-for-gpu-networking",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Yang Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Fast-evolving machine learning (ML) workloads have increasing requirements for networking. However, host network transport on RDMA NICs is hard to evolve, causing problems for ML workloads. For example, single-path RDMA traffic is prone to flow collisions that severely degrade collective communication performance. We present UCCL, an extensible software transport layer to evolve GPU networking. UCCL decouples the data path and control path of existing RDMA NICs and efficiently runs the control-path transport on host CPUs. This software extensibility brings in transport innovations that cannot be achieved in hardware for ML workloads, e.g., a multipath transport to resolve flow collisions. ML collectives atop UCCL achieve up to 3.3x higher performance compared to an industry solution.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17307",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:25.673936Z"
  },
  {
    "id": "f341db328f467392bdc50c556d51ebf0",
    "title": "An All-Optical Metro Network Architecture and QoS-Aware Wavelength Allocation Study for Converged Fixed, Mobile, and Edge Computing Multi-Granular Traffic",
    "slug": "an-all-optical-metro-network-architecture-and-qos-aware-wavelength-allocation-study-for-converged-fixed,-mobile,-and-edge-computing-multi-granular-traffic",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "David Georgantas",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we introduce an all-optical metro network architecture, called MOON, to serve converged multigranular traffic from fixed, mobile, and edge computing services. Since traffic is characterized by high dynamicity and diverse access requirements, MOON uses network slicing to provide quality of service (QoS) aware wavelength allocation to fulfill the various applications traffic demands. MOON incorporates hybrid optical switching (HOS) combining optical circuit switching (OCS) and optical time slotted switching (OTS) capabilities that appropriately maps different traffic types to them. Specifically, the OCS network slice explicitly serves aggregated traffic of long duration and high volume, while OTS network slice serves short bursty traffic. In order to provide flexibility, separate sets of wavelengths are used for OCS and OTS traffic service, both within a metro-access network (MAN) (intra-MAN) and between different MANs (inter-MAN). We extensively study the required number of wavelengths to efficiently serve OCS and OTS traffic for intra- and inter-MAN communication scenarios, taking into account their specific traffic access requirements in an effort to optimize wavelengths utilization. In our study, we assume nonblocking OCS communication for immediate access; therefore the number of required OCS wavelengths depends only on the number of nodes, while the number of required OTS wavelengths to obtain a desired QoS and latency level is independent from the number for OCS wavelengths. Simulation results show that within an OTS intra-MAN we achieve end-to-end (E2E) latency in submilliseconds scale, suitable for dynamic bursty traffic, while it is an decreasing function of the number of used OTS wavelengths.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17310",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:25.674184Z"
  },
  {
    "id": "c78f59b1f8fb8529dbe0a6f57d8be590",
    "title": "Mitigating xApp conflicts for efficient network slicing in 6G O-RAN: a graph convolutional-based attention network approach",
    "slug": "mitigating-xapp-conflicts-for-efficient-network-slicing-in-6g-o-ran:-a-graph-convolutional-based-attention-network-approach",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Sihem Bakri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "O-RAN (Open-Radio Access Network) offers a flexible, open architecture for next-generation wireless networks. Network slicing within O-RAN allows network operators to create customized virtual networks, each tailored to meet the specific needs of a particular application or service. Efficiently managing these slices is crucial for future 6G networks. O-RAN introduces specialized software applications called xApps that manage different network functions. In network slicing, an xApp can be responsible for managing a separate network slice. To optimize resource allocation across numerous network slices, these xApps must coordinate. Traditional methods where all xApps communicate freely can lead to excessive overhead, hindering network performance. In this paper, we address the issue of xApp conflict mitigation by proposing an innovative Zero-Touch Management (ZTM) solution for radio resource management in O-RAN. Our approach leverages Multi-Agent Reinforcement Learning (MARL) to enable xApps to learn and optimize resource allocation without the need for constant manual intervention. We introduce a Graph Convolutional Network (GCN)-based attention mechanism to streamline communication among xApps, reducing overhead and improving overall system efficiency. Our results compare traditional MARL, where all xApps communicate, against our MARL GCN-based attention method. The findings demonstrate the superiority of our approach, especially as the number of xApps increases, ultimately providing a scalable and efficient solution for optimal network slicing management in O-RAN.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17590",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:25.674390Z"
  },
  {
    "id": "df86f05bf83a451f57a0132d1ea7b122",
    "title": "STGen: A Novel Lightweight IoT Testbed for Generating Sensor Traffic for the Experimentation of IoT Protocol and its Application in Hybrid Network",
    "slug": "stgen:-a-novel-lightweight-iot-testbed-for-generating-sensor-traffic-for-the-experimentation-of-iot-protocol-and-its-application-in-hybrid-network",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Hasan MA Islam",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A Wireless Sensor Network (WSN) is a network that does not rely on a fixed infrastructure and consists of numerous sensors, such as temperature, humidity, GPS, and cameras, equipped with onboard processors that manage and monitor the environment in a specific area. As a result, building a real sensor network testbed for verifying, validating, or experimenting with a newly designed protocol presents considerable challenges in adapting a laboratory scenario due to the significant financial and logistical barriers, such as the need for specialized hardware and large-scale deployments. Additionally, WSN suffers from severe constraints such as restricted power supply, short communication range, limited bandwidth availability, and restricted memory storage. Addressing these challenges, this work presents a flexible testbed solution named STGen that enables researchers to experiment with IoT protocols in a hybrid environment that emulates WSN implementations with the physical Internet through a dedicated physical server named STGen core, which receives sensor traffic and processes it for further actions. The STGen testbed is lightweight in memory usage and easy to deploy. Most importantly, STGen supports large-scale distributed systems, facilitates experimentation with IoT protocols, and enables integration with back-end services for big data analytics and statistical insights. The key feature of STGen is the integration of real-world IoT protocols and their applications with WSN. Its modular and lightweight design makes STGen efficient and enables it to outperform other popular testbeds, such as Gotham and GothX, reducing memory usage by 89\\%. While GothX takes approximately 26 minutes to establish a large topology with four VM nodes and 498 Docker nodes, STGen requires only 1.645 seconds to initialize the platform with 500 sensor nodes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17725",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:25.674614Z"
  },
  {
    "id": "33dd420a292442bb3c78611fa21c5e85",
    "title": "Quantum Technologies for Beyond 5G and 6G Networks: Applications, Opportunities, and Challenges",
    "slug": "quantum-technologies-for-beyond-5g-and-6g-networks:-applications,-opportunities,-and-challenges",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Engin Zeydan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As the world prepares for the advent of 6G networks, quantum technologies are becoming critical enablers of the next generation of communication systems. This survey paper investigates the convergence of quantum technologies and 6G networks, focusing on their applications, opportunities and challenges. We begin with an examination of the motivations for integrating quantum technologies into 6G, investigating the potential to overcome the limits of classical computing and cryptography. We then highlight key research gaps, particularly in quantum communication, quantum computing integration and security enhancement. A comprehensive overview of quantum technologies relevant to 6G, including quantum communication devices, quantum computing paradigms, and hybrid quantum-classical approaches is provided. A particular focus is on the role of quantum technologies in enhancing 6G Radio Access Networks (RAN), 6G core and edge network optimization, and 6G security. The survey paper also explores the application of quantum cryptography with a focus on Quantum Key Distribution (QKD), Quantum Secure Direct Communication (QSDC) and quantum-resistant cryptographic algorithms and assesses their implementation challenges and potential impact on 6G networks. We also discuss the significant challenges associated with integrating quantum technologies into existing communications infrastructures, including issues of technological maturity, standardization, and economic considerations. Finally, we summarize the lessons learned from current research and outline future research directions to guide the ongoing development of quantum-enabled 6G networks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17133",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:25.674829Z"
  },
  {
    "id": "295aa11f54de52f51978448e2e9183e0",
    "title": "Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable Random Walks",
    "slug": "honeybee:-byzantine-tolerant-decentralized-peer-sampling-with-verifiable-random-walks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Yunqi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and table consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\\geq50\\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes.",
    "pdfUrl": "https://arxiv.org/pdf/2402.16201",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:25.675026Z"
  },
  {
    "id": "839059ca739a87188ad01b6a5621c0fa",
    "title": "Optimization of BLE Broadcast Mode in Offline Finding Network",
    "slug": "optimization-of-ble-broadcast-mode-in-offline-finding-network",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "L Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the Offline Finding Network(OFN), offline Bluetooth tags broadcast to the surrounding area, the finder devices receiving the broadcast signal and upload location information to the IoT(Internet of Things) cloud servers, thereby achieving offline finding of lost items. This process is essentially a Bluetooth low energy (BLE) neighbor discovery process(NDP). In the process, the variety of Bluetooth scan modes caused by the scan interval and scan window settings affects the discovery latency of finder devices finding the tag broadcast packets. To optimize the experience of searching for lost devices, we propose the CPBIS-mechanism, a certain proportion broadcast-intervals screening mechanism that calculates the most suitable two broadcast intervals and their proportion for offline tags. This reduces discovery latency in the BLE NDP, improves the discovery success rate, further enhances the user experience. To our knowledge, we are the first to propose a comprehensive solution for configuring the broadcast interval parameters of advertisers in BLE NDP, particularly for configurations involving two or more broadcast intervals. We evaluated the results obtained by CPBIS on the nRF52832 chip. The data shows that the CPBIS-mechanism achieves relatively low discovery latencies for multiple scan modes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.01422",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:25.675216Z"
  },
  {
    "id": "bdf7e06b439dc6956f622129966f6c9c",
    "title": "A Statistical Evaluation of Indoor LoRaWAN Environment-Aware Propagation for 6G: MLR, ANOVA, and Residual Distribution Analysis",
    "slug": "a-statistical-evaluation-of-indoor-lorawan-environment-aware-propagation-for-6g:-mlr,-anova,-and-residual-distribution-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Networking and Internet Architecture (cs.NI)",
    "author": {
      "name": "Nahshon Mokua Obiri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Modeling path loss in indoor LoRaWAN technology deployments is inherently challenging due to structural obstructions, occupant density and activities, and fluctuating environmental conditions. This study proposes a two-stage approach to capture and analyze these complexities using an extensive dataset of 1,328,334 field measurements collected over six months in a single-floor office at the University of Siegen's Hoelderlinstrasse Campus, Germany. First, we implement a multiple linear regression model that includes traditional propagation metrics (distance, structural walls) and an extension with proposed environmental variables (relative humidity, temperature, carbon dioxide, particulate matter, and barometric pressure). Using analysis of variance, we demonstrate that adding these environmental factors can reduce unexplained variance by 42.32 percent. Secondly, we examine residual distributions by fitting five candidate probability distributions: Normal, Skew-Normal, Cauchy, Student's t, and Gaussian Mixture Models with one to five components. Our results show that a four-component Gaussian Mixture Model captures the residual heterogeneity of indoor signal propagation most accurately, significantly outperforming single-distribution approaches. Given the push toward ultra-reliable, context-aware communications in 6G networks, our analysis shows that environment-aware modeling can substantially improve LoRaWAN network design in dynamic indoor IoT deployments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16688",
    "tags": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "createdAt": "2025-04-25T15:49:25.675413Z"
  },
  {
    "id": "6fad4474153f437311df4a1110590a3c",
    "title": "THEMIS: Time, Heterogeneity, and Energy Minded Scheduling for Fair Multi-Tenant Use in FPGAs",
    "slug": "themis:-time,-heterogeneity,-and-energy-minded-scheduling-for-fair-multi-tenant-use-in-fpgas",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operating Systems (cs.OS)",
    "author": {
      "name": "Emre Karabulut",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Using correct design metrics and understanding the limitations of the underlying technology is critical to developing effective scheduling algorithms. Unfortunately, existing scheduling techniques used \\emph{incorrect} metrics and had \\emph{unrealistic} assumptions for fair scheduling of multi-tenant FPGAs where each tenant is aimed to share approximately the same number of resources both spatially and temporally.\nThis paper introduces an enhanced fair scheduling algorithm for multi-tenant FPGA use, addressing previous metric and assumption issues, with three specific improvements claimed First, our method ensures spatiotemporal fairness by considering both spatial and temporal aspects, addressing the limitation of prior work that assumed uniform task latency. Second, we incorporate energy considerations into fairness by adjusting scheduling intervals and accounting for energy overhead, thereby balancing energy efficiency with fairness. Third, we acknowledge overlooked aspects of FPGA multi-tenancy, including heterogeneous regions and the constraints on dynamically merging/splitting partially reconfigurable regions. We develop and evaluate our improved fair scheduling algorithm with these three enhancements. Inspired by the Greek goddess of law and personification of justice, we name our fair scheduling solution THEMIS: \\underline{T}ime, \\underline{H}eterogeneity, and \\underline{E}nergy \\underline{Mi}nded \\underline{S}cheduling.\nWe used the Xilinx Zedboard XC7Z020 to quantify our approach's savings. Compared to previous algorithms, our improved scheduling algorithm enhances fairness between 24.2--98.4\\% and allows a trade-off between 55.3$\\times$ in energy vs. 69.3$\\times$ in fairness. The paper thus informs cloud providers about future scheduling optimizations for fairness with related challenges and opportunities.",
    "pdfUrl": "https://arxiv.org/pdf/2404.00507",
    "tags": [
      "Operating Systems (cs.OS)"
    ],
    "createdAt": "2025-04-25T15:49:26.099006Z"
  },
  {
    "id": "925564689ecd5beda55f4ce24ac664fe",
    "title": "Rethinking Programmed I/O for Fast Devices, Cheap Cores, and Coherent Interconnects",
    "slug": "rethinking-programmed-i/o-for-fast-devices,-cheap-cores,-and-coherent-interconnects",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Anastasiia Ruzhanskaia",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Conventional wisdom holds that an efficient interface between an OS running on a CPU and a high-bandwidth I/O device should use Direct Memory Access (DMA) to offload data transfer, descriptor rings for buffering and queuing, and interrupts for asynchrony between cores and device.\nIn this paper we question this wisdom in the light of two trends: modern and emerging cache-coherent interconnects like CXL3.0, and workloads, particularly microservices and serverless computing. Like some others before us, we argue that the assumptions of the DMA-based model are obsolete, and in many use-cases programmed I/O, where the CPU explicitly transfers data and control information to and from a device via loads and stores, delivers a more efficient system.\nHowever, we push this idea much further. We show, in a real hardware implementation, the gains in latency for fine-grained communication achievable using an open cache-coherence protocol which exposes cache transitions to a smart device, and that throughput is competitive with DMA over modern interconnects. We also demonstrate three use-cases: fine-grained RPC-style invocation of functions on an accelerator, offloading of operators in a streaming dataflow engine, and a network interface targeting serverless functions, comparing our use of coherence with both traditional DMA-style interaction and a highly-optimized implementation using memory-mapped programmed I/O over PCIe.",
    "pdfUrl": "https://arxiv.org/pdf/2409.08141",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:26.099217Z"
  },
  {
    "id": "4efdc5051afd45ce179ec49eb9110494",
    "title": "Operational Semantics for Crystality: A Smart Contract Language for Parallel EVMs",
    "slug": "operational-semantics-for-crystality:-a-smart-contract-language-for-parallel-evms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Programming Languages (cs.PL)",
    "author": {
      "name": "Ziyun Xu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The increasing demand for scalable blockchain has driven research into parallel execution models for smart contracts. Crystality is a novel smart contract programming language designed for parallel Ethereum Virtual Machines (EVMs), enabling fine-grained concurrency through Programmable Contract Scopes and Asynchronous Functional Relay. This paper presents the first formal structural operational semantics for Crystality, providing a rigorous framework to reason about its execution. We mechanize the syntax and semantics of Crystality in the theorem-proving assistant Coq, enabling formal verification of correctness properties. As a case study, we verify a simplified token transfer function, demonstrating the applicability of our semantics in ensuring smart contract correctness. Our work lays the foundation for formally verified parallel smart contracts, contributing to the security and scalability of blockchain systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17336",
    "tags": [
      "Programming Languages (cs.PL)"
    ],
    "createdAt": "2025-04-25T15:49:26.673536Z"
  },
  {
    "id": "5099595e96b7af7ca21f19552759f7e4",
    "title": "Encode the $\\forall\\exists$ Relational Hoare Logic into Standard Hoare Logic",
    "slug": "encode-the-$\\forall\\exists$-relational-hoare-logic-into-standard-hoare-logic",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Programming Languages (cs.PL)",
    "author": {
      "name": "Shushu WU",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Verifying a real-world program's functional correctness can be decomposed into (1) a refinement proof showing that the program implements a more abstract high-level program and (2) an algorithm correctness proof at the high level. Relational Hoare logic serves as a powerful tool to establish refinement but often necessitates formalization beyond standard Hoare logic. Particularly in the nondeterministic setting, the $\\forall\\exists$ relational Hoare logic is required. Existing approaches encode this logic into a Hoare logic with ghost states and invariants, yet these extensions significantly increase formalization complexity and soundness proof overhead. This paper proposes a generic encoding theory that reduces the $\\forall\\exists$ relational Hoare logic to standard (unary) Hoare logic. Precisely, we propose to redefine the validity of relational Hoare triples while reserving the original proof rules and then encapsulate the $\\forall\\exists$ pattern within assertions. We have proved that the validity of encoded standard Hoare triples is equivalent to the validity of the desired relational Hoare triples. Moreover, the encoding theory demonstrates how common relational Hoare logic proof rules are indeed special cases of standard Hoare logic proof rules, and relational proof steps correspond to standard proof steps. Our theory enables standard Hoare logic to prove $\\forall\\exists$ relational properties by defining a predicate Exec, without requiring modifications to the logic framework or re-verification of soundness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17444",
    "tags": [
      "Programming Languages (cs.PL)"
    ],
    "createdAt": "2025-04-25T15:49:26.673743Z"
  },
  {
    "id": "f600bd71519c3a0038eb9f34df9bcb20",
    "title": "A Lightweight Method for Generating Multi-Tier JIT Compilation Virtual Machine in a Meta-Tracing Compiler Framework",
    "slug": "a-lightweight-method-for-generating-multi-tier-jit-compilation-virtual-machine-in-a-meta-tracing-compiler-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Programming Languages (cs.PL)",
    "author": {
      "name": "Yusuke Izawa",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Meta-compiler frameworks, such as RPython and Graal/Truffle, generate high-performance virtual machines (VMs) from interpreter definitions. Although they generate VMs with high-quality just-in-time (JIT) compilers, they still lack an important feature that dedicated VMs (i.e., VMs that are developed for specific languages) have, namely \\emph{multi-tier compilation}. Multi-tier compilation uses light-weight compilers at early stages and highly-optimizing compilers at later stages in order to balance between compilation overheads and code quality.\nWe propose a novel approach to enabling multi-tier compilation in the VMs generated by a meta-compiler framework. Instead of extending the JIT compiler backend of the framework, our approach drives an existing (heavyweight) compiler backend in the framework to quickly generate unoptimized native code by merely embedding directives and compile-time operations into interpreter definitions.\nAs a validation of the approach, we developed 2SOM, a Simple Object Machine with a two-tier JIT compiler based on RPython. 2SOM first applies the tier-1 threaded code generator that is generated by our proposed technique, then, to the loops that exceed a threshold, applies the tier-2 tracing JIT compiler that is generated by the original RPython framework. Our performance evaluation that runs a program with a realistic workload showed that 2SOM improved, when compared against an RPython-based VM, warm-up performance by 15\\%, with merely a 5\\% reduction in peak performance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17460",
    "tags": [
      "Programming Languages (cs.PL)"
    ],
    "createdAt": "2025-04-25T15:49:26.673976Z"
  },
  {
    "id": "83d28e65cdc6e5be294367de53269314",
    "title": "Portability of Optimizations from SC to TSO",
    "slug": "portability-of-optimizations-from-sc-to-tso",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Programming Languages (cs.PL)",
    "author": {
      "name": "Akshay Gopalakrishnan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is well recognized that the safety of compiler optimizations is at risk in a concurrent context. Existing approaches primarily rely on context-free thread-local guarantees, and prohibit optimizations that introduce a data-race. However, compilers utilize global context-specific information, exposing safe optimizations that may violate such guarantees as well as introduce a race. Such optimizations need to individually be proven safe for each language model. An alternate approach to this would be proving them safe for an intuitive model (like interleaving semantics), and then determine their portability across other concurrent models. In this paper, we address this problem of porting across models of concurrency. We first identify a global guarantee on optimizations portable from Sequential Consistency (SC) to Total Store Order (TSO). Our guarantee is in the form of constraints specifying the syntactic changes an optimization must not incur. We then show these constraints correlate to prohibiting the introduction of triangular races, a subset of data-race relevant to TSO. We conclude by showing how such race inducing optimizations relate to porting across Strong Release Acquire (SRA), a known causally consistent memory model.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17646",
    "tags": [
      "Programming Languages (cs.PL)"
    ],
    "createdAt": "2025-04-25T15:49:26.674180Z"
  },
  {
    "id": "0bac01bfe2434de2a096558a83850133",
    "title": "Efficient, Portable, Census-Polymorphic Choreographic Programming",
    "slug": "efficient,-portable,-census-polymorphic-choreographic-programming",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Programming Languages (cs.PL)",
    "author": {
      "name": "Mako Bates",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Choreographic programming (CP) is a paradigm for implementing distributed systems that uses a single global program to define the actions and interactions of all participants. Library-level CP implementations, like HasChor, integrate well with mainstream programming languages but have several limitations: Their conditionals require extra communication; they require specific host-language features (e.g., monads); and they lack support for programming patterns that are essential for implementing realistic distributed applications.\nWe make three contributions to library-level CP to specifically address these challenges. First, we propose and formalize conclaves and multiply-located values, which enable efficient conditionals in library-level CP without redundant communication. Second, we propose end-point projection as dependency injection, a design pattern that enables library-level CP in host languages without support for monads. Third, we propose census polymorphism, a technique for abstracting over the number of participants in a choreography. We demonstrate these contributions via implementations in Haskell, Rust, and TypeScript.",
    "pdfUrl": "https://arxiv.org/pdf/2412.02107",
    "tags": [
      "Programming Languages (cs.PL)"
    ],
    "createdAt": "2025-04-25T15:49:26.674401Z"
  },
  {
    "id": "e91a04161d79f70ba38770fb720c4a84",
    "title": "Rel: A Programming Language for Relational Data",
    "slug": "rel:-a-programming-language-for-relational-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Molham Aref",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "From the moment of their inception, languages for relational data have been described as sublanguages embedded in a host programming language. Rel is a new relational language whose key design goal is to go beyond this paradigm with features that allow for programming in the large, making it possible to fully describe end to end application semantics. With the new approach we can model the semantics of entire enterprise applications relationally, which helps significantly reduce architecture complexity and avoid the well-known impedance mismatch problem. This paradigm shift is enabled by 50 years of database research, making it possible to revisit the sublanguage/host language paradigm, starting from the fundamental principles. We present the main features of Rel: those that give it the power to express traditional query language operations and those that are designed to grow the language and allow programming in the large.",
    "pdfUrl": "https://arxiv.org/pdf/2504.10323",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:26.674635Z"
  },
  {
    "id": "d5c4dbae201c390314da4d74dfc7f0c1",
    "title": "Robo-Troj: Attacking LLM-based Task Planners",
    "slug": "robo-troj:-attacking-llm-based-task-planners",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Mohaiminul Al Nahian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Robots need task planning methods to achieve goals that require more than individual actions. Recently, large language models (LLMs) have demonstrated impressive performance in task planning. LLMs can generate a step-by-step solution using a description of actions and the goal. Despite the successes in LLM-based task planning, there is limited research studying the security aspects of those systems. In this paper, we develop Robo-Troj, the first multi-trigger backdoor attack for LLM-based task planners, which is the main contribution of this work. As a multi-trigger attack, Robo-Troj is trained to accommodate the diversity of robot application domains. For instance, one can use unique trigger words, e.g., \"herical\", to activate a specific malicious behavior, e.g., cutting hand on a kitchen robot. In addition, we develop an optimization method for selecting the trigger words that are most effective. Through demonstrating the vulnerability of LLM-based planners, we aim to promote the development of secured robot systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17070",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.261731Z"
  },
  {
    "id": "6fd016890b4358ddb3ba47166ded96a7",
    "title": "Geometric Formulation of Unified Force-Impedance Control on SE(3) for Robotic Manipulators",
    "slug": "geometric-formulation-of-unified-force-impedance-control-on-se(3)-for-robotic-manipulators",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Joohwan Seo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we present an impedance control framework on the SE(3) manifold, which enables force tracking while guaranteeing passivity. Building upon the unified force-impedance control (UFIC) and our previous work on geometric impedance control (GIC), we develop the geometric unified force impedance control (GUFIC) to account for the SE(3) manifold structure in the controller formulation using a differential geometric perspective. As in the case of the UFIC, the GUFIC utilizes energy tank augmentation for both force-tracking and impedance control to guarantee the manipulator's passivity relative to external forces. This ensures that the end effector maintains safe contact interaction with uncertain environments and tracks a desired interaction force. Moreover, we resolve a non-causal implementation problem in the UFIC formulation by introducing velocity and force fields. Due to its formulation on SE(3), the proposed GUFIC inherits the desirable SE(3) invariance and equivariance properties of the GIC, which helps increase sample efficiency in machine learning applications where a learning algorithm is incorporated into the control law. The proposed control law is validated in a simulation environment under scenarios requiring tracking an SE(3) trajectory, incorporating both position and orientation, while exerting a force on a surface. The codes are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17080",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.261967Z"
  },
  {
    "id": "e9a193be5f9f9316ec690845d0f94ba6",
    "title": "Subframework-based Bearing Rigidity Maintenance Control in Multirobot Networks",
    "slug": "subframework-based-bearing-rigidity-maintenance-control-in-multirobot-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "J. Francisco Presenza",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This work presents a novel approach for analyzing and controlling bearing rigidity in multi-robot networks with dynamic topology. By decomposing the system's framework into subframeworks, we express bearing rigidity, a global property, as a set of local properties, with rigidity eigenvalues serving as natural local rigidity metrics. We propose a decentralized, scalable, gradient-based controller that uses only bearing measurements to execute mission-specific commands. The controller preserves bearing rigidity by maintaining rigidity eigenvalues above a threshold, and also avoids inter-robot collisions. Simulations confirm the scheme's effectiveness, with information exchange confined to subframeworks, underscoring its scalability and practicality.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17103",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.262182Z"
  },
  {
    "id": "d3d8c269925e311d9d51d7862f3a23ea",
    "title": "MAT-DiSMech: A Discrete Differential Geometry-based Computational Tool for Simulation of Rods, Shells, and Soft Robots",
    "slug": "mat-dismech:-a-discrete-differential-geometry-based-computational-tool-for-simulation-of-rods,-shells,-and-soft-robots",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Radha Lahoti",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate and efficient simulation tools are essential in robotics, enabling the visualization of system dynamics and the validation of control laws before committing resources to physical experimentation. Developing physically accurate simulation tools is particularly challenging in soft robotics, largely due to the prevalence of geometrically nonlinear deformation. A variety of robot simulators tackle this challenge by using simplified modeling techniques -- such as lumped mass models -- which lead to physical inaccuracies in real-world applications. On the other hand, high-fidelity simulation methods for soft structures, like finite element analysis, offer increased accuracy but lead to higher computational costs. In light of this, we present a Discrete Differential Geometry-based simulator that provides a balance between physical accuracy and computational speed. Building on an extensive body of research on rod and shell-based representations of soft robots, our tool provides a pathway to accurately model soft robots in a computationally tractable manner. Our open-source MATLAB-based framework is capable of simulating the deformations of rods, shells, and their combinations, primarily utilizing implicit integration techniques. The software design is modular for the user to customize the code, for example, add new external forces and impose custom boundary conditions. The implementations for prevalent forces encountered in robotics, including gravity, contact, kinetic and viscous friction, and aerodynamic drag, have been provided. We provide several illustrative examples that showcase the capabilities and validate the physical accuracy of the simulator. The open-source code is available at this https URL. We anticipate that the proposed simulator can serve as an effective digital twin tool, enhancing the Sim2Real pathway in soft robotics research.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17186",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.262400Z"
  },
  {
    "id": "8299b641d930226c703a27f3ea77616c",
    "title": "Simultaneous Collision Detection and Force Estimation for Dynamic Quadrupedal Locomotion",
    "slug": "simultaneous-collision-detection-and-force-estimation-for-dynamic-quadrupedal-locomotion",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Ziyi Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper we address the simultaneous collision detection and force estimation problem for quadrupedal locomotion using joint encoder information and the robot dynamics only. We design an interacting multiple-model Kalman filter (IMM-KF) that estimates the external force exerted on the robot and multiple possible contact modes. The method is invariant to any gait pattern design. Our approach leverages pseudo-measurement information of the external forces based on the robot dynamics and encoder information. Based on the estimated contact mode and external force, we design a reflex motion and an admittance controller for the swing leg to avoid collisions by adjusting the leg's reference motion. Additionally, we implement a force-adaptive model predictive controller to enhance balancing. Simulation ablatation studies and experiments show the efficacy of the approach.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17201",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.262606Z"
  },
  {
    "id": "99907ae57706c8d732157d84d0f3d0dc",
    "title": "Robotic Grinding Skills Learning Based on Geodesic Length Dynamic Motion Primitives",
    "slug": "robotic-grinding-skills-learning-based-on-geodesic-length-dynamic-motion-primitives",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Shuai Ke",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Learning grinding skills from human craftsmen via imitation learning has become a key research topic in robotic machining. Due to their strong generalization and robustness to external disturbances, Dynamical Movement Primitives (DMPs) offer a promising approach for robotic grinding skill learning. However, directly applying DMPs to grinding tasks faces challenges, such as low orientation accuracy, unsynchronized position-orientation-force, and limited generalization for surface trajectories. To address these issues, this paper proposes a robotic grinding skill learning method based on geodesic length DMPs (Geo-DMPs). First, a normalized 2D weighted Gaussian kernel and intrinsic mean clustering algorithm are developed to extract geometric features from multiple demonstrations. Then, an orientation manifold distance metric removes the time dependency in traditional orientation DMPs, enabling accurate orientation learning via Geo-DMPs. A synchronization encoding framework is further proposed to jointly model position, orientation, and force using a geodesic length-based phase function. This framework enables robotic grinding actions to be generated between any two surface points. Experiments on robotic chamfer grinding and free-form surface grinding validate that the proposed method achieves high geometric accuracy and generalization in skill encoding and generation. To our knowledge, this is the first attempt to use DMPs for jointly learning and generating grinding skills in position, orientation, and force on model-free surfaces, offering a novel path for robotic grinding.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17216",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.262818Z"
  },
  {
    "id": "b6c9beb56cf826a9d252e19b5a0546ef",
    "title": "Demonstrating Berkeley Humanoid Lite: An Open-source, Accessible, and Customizable 3D-printed Humanoid Robot",
    "slug": "demonstrating-berkeley-humanoid-lite:-an-open-source,-accessible,-and-customizable-3d-printed-humanoid-robot",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Yufeng Chi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Despite significant interest and advancements in humanoid robotics, most existing commercially available hardware remains high-cost, closed-source, and non-transparent within the robotics community. This lack of accessibility and customization hinders the growth of the field and the broader development of humanoid technologies. To address these challenges and promote democratization in humanoid robotics, we demonstrate Berkeley Humanoid Lite, an open-source humanoid robot designed to be accessible, customizable, and beneficial for the entire community. The core of this design is a modular 3D-printed gearbox for the actuators and robot body. All components can be sourced from widely available e-commerce platforms and fabricated using standard desktop 3D printers, keeping the total hardware cost under $5,000 (based on U.S. market prices). The design emphasizes modularity and ease of fabrication. To address the inherent limitations of 3D-printed gearboxes, such as reduced strength and durability compared to metal alternatives, we adopted a cycloidal gear design, which provides an optimal form factor in this context. Extensive testing was conducted on the 3D-printed actuators to validate their durability and alleviate concerns about the reliability of plastic components. To demonstrate the capabilities of Berkeley Humanoid Lite, we conducted a series of experiments, including the development of a locomotion controller using reinforcement learning. These experiments successfully showcased zero-shot policy transfer from simulation to hardware, highlighting the platform's suitability for research validation. By fully open-sourcing the hardware design, embedded code, and training and deployment frameworks, we aim for Berkeley Humanoid Lite to serve as a pivotal step toward democratizing the development of humanoid robotics. All resources are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17249",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.263053Z"
  },
  {
    "id": "85ae4a0a4d885e2909c6587bfa3af3e7",
    "title": "Bias-Eliminated PnP for Stereo Visual Odometry: Provably Consistent and Large-Scale Localization",
    "slug": "bias-eliminated-pnp-for-stereo-visual-odometry:-provably-consistent-and-large-scale-localization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Guangyang Zeng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we first present a bias-eliminated weighted (Bias-Eli-W) perspective-n-point (PnP) estimator for stereo visual odometry (VO) with provable consistency. Specifically, leveraging statistical theory, we develop an asymptotically unbiased and $\\sqrt {n}$-consistent PnP estimator that accounts for varying 3D triangulation uncertainties, ensuring that the relative pose estimate converges to the ground truth as the number of features increases. Next, on the stereo VO pipeline side, we propose a framework that continuously triangulates contemporary features for tracking new frames, effectively decoupling temporal dependencies between pose and 3D point errors. We integrate the Bias-Eli-W PnP estimator into the proposed stereo VO pipeline, creating a synergistic effect that enhances the suppression of pose estimation errors. We validate the performance of our method on the KITTI and Oxford RobotCar datasets. Experimental results demonstrate that our method: 1) achieves significant improvements in both relative pose error and absolute trajectory error in large-scale environments; 2) provides reliable localization under erratic and unpredictable robot motions. The successful implementation of the Bias-Eli-W PnP in stereo VO indicates the importance of information screening in robotic estimation tasks with high-uncertainty measurements, shedding light on diverse applications where PnP is a key ingredient.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17410",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.263272Z"
  },
  {
    "id": "e93f1766d6ff077bca42b95d361175be",
    "title": "Object Pose Estimation by Camera Arm Control Based on the Next Viewpoint Estimation",
    "slug": "object-pose-estimation-by-camera-arm-control-based-on-the-next-viewpoint-estimation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Tomoki Mizuno",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We have developed a new method to estimate a Next Viewpoint (NV) which is effective for pose estimation of simple-shaped products for product display robots in retail stores. Pose estimation methods using Neural Networks (NN) based on an RGBD camera are highly accurate, but their accuracy significantly decreases when the camera acquires few texture and shape features at a current view point. However, it is difficult for previous mathematical model-based methods to estimate effective NV which is because the simple shaped objects have few shape features. Therefore, we focus on the relationship between the pose estimation and NV estimation. When the pose estimation is more accurate, the NV estimation is more accurate. Therefore, we develop a new pose estimation NN that estimates NV simultaneously. Experimental results showed that our NV estimation realized a pose estimation success rate 77.3\\%, which was 7.4pt higher than the mathematical model-based NV calculation did. Moreover, we verified that the robot using our method displayed 84.2\\% of products.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17424",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.263471Z"
  },
  {
    "id": "77c608305c805b4926914ad5be12a9fc",
    "title": "Flying through cluttered and dynamic environments with LiDAR",
    "slug": "flying-through-cluttered-and-dynamic-environments-with-lidar",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Huajie Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Navigating unmanned aerial vehicles (UAVs) through cluttered and dynamic environments remains a significant challenge, particularly when dealing with fast-moving or sudden-appearing obstacles. This paper introduces a complete LiDAR-based system designed to enable UAVs to avoid various moving obstacles in complex environments. Benefiting the high computational efficiency of perception and planning, the system can operate in real time using onboard computing resources with low latency. For dynamic environment perception, we have integrated our previous work, M-detector, into the system. M-detector ensures that moving objects of different sizes, colors, and types are reliably detected. For dynamic environment planning, we incorporate dynamic object predictions into the integrated planning and control (IPC) framework, namely DynIPC. This integration allows the UAV to utilize predictions about dynamic obstacles to effectively evade them. We validate our proposed system through both simulations and real-world experiments. In simulation tests, our system outperforms state-of-the-art baselines across several metrics, including success rate, time consumption, average flight time, and maximum velocity. In real-world trials, our system successfully navigates through forests, avoiding moving obstacles along its path.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17569",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.263685Z"
  },
  {
    "id": "3bd24fc66358c2c89f8f1f3aedb02f22",
    "title": "Unifying Complementarity Constraints and Control Barrier Functions for Safe Whole-Body Robot Control",
    "slug": "unifying-complementarity-constraints-and-control-barrier-functions-for-safe-whole-body-robot-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Rafael I. Cabral Muchacho",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Safety-critical whole-body robot control demands reactive methods that ensure collision avoidance in real-time. Complementarity constraints and control barrier functions (CBF) have emerged as core tools for ensuring such safety constraints, and each represents a well-developed field. Despite addressing similar problems, their connection remains largely unexplored. This paper bridges this gap by formally proving the equivalence between these two methodologies for sampled-data, first-order systems, considering both single and multiple constraint scenarios. By demonstrating this equivalence, we provide a unified perspective on these techniques. This unification has theoretical and practical implications, facilitating the cross-application of robustness guarantees and algorithmic improvements between complementarity and CBF frameworks. We discuss these synergistic benefits and motivate future work in the comparison of the methods in more general cases.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17647",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.263885Z"
  },
  {
    "id": "8c307911f3454941d9066256ce2f03ff",
    "title": "BIM-Constrained Optimization for Accurate Localization and Deviation Correction in Construction Monitoring",
    "slug": "bim-constrained-optimization-for-accurate-localization-and-deviation-correction-in-construction-monitoring",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Asier Bikandi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Augmented reality (AR) applications for construction monitoring rely on real-time environmental tracking to visualize architectural elements. However, construction sites present significant challenges for traditional tracking methods due to featureless surfaces, dynamic changes, and drift accumulation, leading to misalignment between digital models and the physical world. This paper proposes a BIM-aware drift correction method to address these challenges. Instead of relying solely on SLAM-based localization, we align ``as-built\" detected planes from the real-world environment with ``as-planned\" architectural planes in BIM. Our method performs robust plane matching and computes a transformation (TF) between SLAM (S) and BIM (B) origin frames using optimization techniques, minimizing drift over time. By incorporating BIM as prior structural knowledge, we can achieve improved long-term localization and enhanced AR visualization accuracy in noisy construction environments. The method is evaluated through real-world experiments, showing significant reductions in drift-induced errors and optimized alignment consistency. On average, our system achieves a reduction of 52.24% in angular deviations and a reduction of 60.8% in the distance error of the matched walls compared to the initial manual alignment by the user.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17693",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.264260Z"
  },
  {
    "id": "8c04a4af5b5e65411fadd53d9144aa95",
    "title": "Robotic Task Ambiguity Resolution via Natural Language Interaction",
    "slug": "robotic-task-ambiguity-resolution-via-natural-language-interaction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Eugenio Chisari",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Language-conditioned policies have recently gained substantial adoption in robotics as they allow users to specify tasks using natural language, making them highly versatile. While much research has focused on improving the action prediction of language-conditioned policies, reasoning about task descriptions has been largely overlooked. Ambiguous task descriptions often lead to downstream policy failures due to misinterpretation by the robotic agent. To address this challenge, we introduce AmbResVLM, a novel method that grounds language goals in the observed scene and explicitly reasons about task ambiguity. We extensively evaluate its effectiveness in both simulated and real-world domains, demonstrating superior task ambiguity detection and resolution compared to recent state-of-the-art baselines. Finally, real robot experiments show that our model improves the performance of downstream robot policies, increasing the average success rate from 69.6% to 97.1%. We make the data, code, and trained models publicly available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17748",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.264595Z"
  },
  {
    "id": "92105dc5bd3557801fdb82e6e2d2ae41",
    "title": "Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control",
    "slug": "integrating-learning-based-manipulation-and-physics-based-locomotion-for-whole-body-badminton-robot-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Haochen Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Learning-based methods, such as imitation learning (IL) and reinforcement learning (RL), can produce excel control policies over challenging agile robot tasks, such as sports robot. However, no existing work has harmonized learning-based policy with model-based methods to reduce training complexity and ensure the safety and stability for agile badminton robot control. In this paper, we introduce \\ourmethod, a novel hybrid control system for agile badminton robots. Specifically, we propose a model-based strategy for chassis locomotion which provides a base for arm policy. We introduce a physics-informed ``IL+RL'' training framework for learning-based arm policy. In this train framework, a model-based strategy with privileged information is used to guide arm policy training during both IL and RL phases. In addition, we train the critic model during IL phase to alleviate the performance drop issue when transitioning from IL to RL. We present results on our self-engineered badminton robot, achieving 94.5% success rate against the serving machine and 90.7% success rate against human players. Our system can be easily generalized to other agile mobile manipulation tasks such as agile catching and table tennis. Our project website: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17771",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.264850Z"
  },
  {
    "id": "9c608016eecad49ce398263e0c50e444",
    "title": "Gripper Keypose and Object Pointflow as Interfaces for Bimanual Robotic Manipulation",
    "slug": "gripper-keypose-and-object-pointflow-as-interfaces-for-bimanual-robotic-manipulation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Yuyin Yang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Bimanual manipulation is a challenging yet crucial robotic capability, demanding precise spatial localization and versatile motion trajectories, which pose significant challenges to existing approaches. Existing approaches fall into two categories: keyframe-based strategies, which predict gripper poses in keyframes and execute them via motion planners, and continuous control methods, which estimate actions sequentially at each timestep. The keyframe-based method lacks inter-frame supervision, struggling to perform consistently or execute curved motions, while the continuous method suffers from weaker spatial perception. To address these issues, this paper introduces an end-to-end framework PPI (keyPose and Pointflow Interface), which integrates the prediction of target gripper poses and object pointflow with the continuous actions estimation. These interfaces enable the model to effectively attend to the target manipulation area, while the overall framework guides diverse and collision-free trajectories. By combining interface predictions with continuous actions estimation, PPI demonstrates superior performance in diverse bimanual manipulation tasks, providing enhanced spatial localization and satisfying flexibility in handling movement restrictions. In extensive evaluations, PPI significantly outperforms prior methods in both simulated and real-world experiments, achieving state-of-the-art performance with a +16.1% improvement on the RLBench2 simulation benchmark and an average of +27.5% gain across four challenging real-world tasks. Notably, PPI exhibits strong stability, high precision, and remarkable generalization capabilities in real-world scenarios. Project page: this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.17784",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.265101Z"
  },
  {
    "id": "e52c6575d55fa526ffab0b0235110f69",
    "title": "A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs",
    "slug": "a-systematic-approach-to-design-real-world-human-in-the-loop-deep-reinforcement-learning:-salient-features,-challenges-and-trade-offs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Jalal Arabneydi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "With the growing popularity of deep reinforcement learning (DRL), human-in-the-loop (HITL) approach has the potential to revolutionize the way we approach decision-making problems and create new opportunities for human-AI collaboration. In this article, we introduce a novel multi-layered hierarchical HITL DRL algorithm that comprises three types of learning: self learning, imitation learning and transfer learning. In addition, we consider three forms of human inputs: reward, action and demonstration. Furthermore, we discuss main challenges, trade-offs and advantages of HITL in solving complex problems and how human information can be integrated in the AI solution systematically. To verify our technical results, we present a real-world unmanned aerial vehicles (UAV) problem wherein a number of enemy drones attack a restricted area. The objective is to design a scalable HITL DRL algorithm for ally drones to neutralize the enemy drones before they reach the area. To this end, we first implement our solution using an award-winning open-source HITL software called Cogment. We then demonstrate several interesting results such as (a) HITL leads to faster training and higher performance, (b) advice acts as a guiding direction for gradient methods and lowers variance, and (c) the amount of advice should neither be too large nor too small to avoid over-training and under-training. Finally, we illustrate the role of human-AI cooperation in solving two real-world complex scenarios, i.e., overloaded and decoy attacks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17006",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:27.265363Z"
  },
  {
    "id": "673e7953462a127698e8c5399a5c3855",
    "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference",
    "slug": "peer-aware-cost-estimation-in-nonlinear-general-sum-dynamic-games-for-mutual-learning-and-intent-inference",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Seyed Yousef Soltanian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Human-robot interactions can be modeled as incomplete-information general-sum dynamic games since the objective functions of both agents are not explicitly known to each other. However, solving for equilibrium policies for such games presents a major challenge, especially if the games involve nonlinear underlying dynamics. To simplify the problem, existing work often assumes that one agent is an expert with complete information about its peer, which can lead to biased estimates and failures in coordination. To address this challenge, we propose a nonlinear peer-aware cost estimation (N-PACE) algorithm for general-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ) approximation of the nonlinear general-sum game, each agent explicitly models the learning dynamics of its peer agent while inferring their objective functions, leading to unbiased fast learning in inferring the unknown objective function of the peer agent, which is critical for task completion and safety assurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent communication} in such multi-agent systems by explicitly modeling the peer's learning dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17129",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:27.265564Z"
  },
  {
    "id": "23250d3e259b598c5893300cc6a8ca00",
    "title": "Advancing Frontiers of Path Integral Theory for Stochastic Optimal Control",
    "slug": "advancing-frontiers-of-path-integral-theory-for-stochastic-optimal-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Apurva Patil",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Stochastic Optimal Control (SOC) problems arise in systems influenced by uncertainty, such as autonomous robots or financial models. Traditional methods like dynamic programming are often intractable for high-dimensional, nonlinear systems due to the curse of dimensionality. This dissertation explores the path integral control framework as a scalable, sampling-based alternative. By reformulating SOC problems as expectations over stochastic trajectories, it enables efficient policy synthesis via Monte Carlo sampling and supports real-time implementation through GPU parallelization.\nWe apply this framework to six classes of SOC problems: Chance-Constrained SOC, Stochastic Differential Games, Deceptive Control, Task Hierarchical Control, Risk Mitigation of Stealthy Attacks, and Discrete-Time LQR. A sample complexity analysis for the discrete-time case is also provided. These contributions establish a foundation for simulator-driven autonomy in complex, uncertain environments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17154",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:27.265752Z"
  },
  {
    "id": "10536ca35011acc43f303910cb696ecc",
    "title": "AUTHENTICATION: Identifying Rare Failure Modes in Autonomous Vehicle Perception Systems using Adversarially Guided Diffusion Models",
    "slug": "authentication:-identifying-rare-failure-modes-in-autonomous-vehicle-perception-systems-using-adversarially-guided-diffusion-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Mohammad Zarei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autonomous Vehicles (AVs) rely on artificial intelligence (AI) to accurately detect objects and interpret their surroundings. However, even when trained using millions of miles of real-world data, AVs are often unable to detect rare failure modes (RFMs). The problem of RFMs is commonly referred to as the \"long-tail challenge\", due to the distribution of data including many instances that are very rarely seen. In this paper, we present a novel approach that utilizes advanced generative and explainable AI techniques to aid in understanding RFMs. Our methods can be used to enhance the robustness and reliability of AVs when combined with both downstream model training and testing. We extract segmentation masks for objects of interest (e.g., cars) and invert them to create environmental masks. These masks, combined with carefully crafted text prompts, are fed into a custom diffusion model. We leverage the Stable Diffusion inpainting model guided by adversarial noise optimization to generate images containing diverse environments designed to evade object detection models and expose vulnerabilities in AI systems. Finally, we produce natural language descriptions of the generated RFMs that can guide developers and policymakers to improve the safety and reliability of AV systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17179",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:27.265967Z"
  },
  {
    "id": "3123c72f13390e6fd602bcbd63f9bf35",
    "title": "S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in LiDAR-Based Collective Perception",
    "slug": "s2s-net:-addressing-the-domain-gap-of-heterogeneous-sensor-systems-in-lidar-based-collective-perception",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Sven Teufel",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Collective Perception (CP) has emerged as a promising approach to overcome the limitations of individual perception in the context of autonomous driving. Various approaches have been proposed to realize collective perception; however, the Sensor2Sensor domain gap that arises from the utilization of different sensor systems in Connected and Automated Vehicles (CAVs) remains mostly unaddressed. This is primarily due to the paucity of datasets containing heterogeneous sensor setups among the CAVs. The recently released SCOPE datasets address this issue by providing data from three different LiDAR sensors for each CAV. This study is the first to tackle the Sensor2Sensor domain gap in vehicle to vehicle (V2V) collective perception. First, we present our sensor-domain robust architecture S2S-Net. Then an in-depth analysis of the Sensor2Sensor domain adaptation capabilities of S2S-Net on the SCOPE dataset is conducted. S2S-Net demonstrates the capability to maintain very high performance in unseen sensor domains and achieved state-of-the-art results on the SCOPE dataset.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17399",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:27.266172Z"
  },
  {
    "id": "84cb1e3a81eed696ddb0afbfcf7c91d7",
    "title": "Longitudinal Control for Autonomous Racing with Combustion Engine Vehicles",
    "slug": "longitudinal-control-for-autonomous-racing-with-combustion-engine-vehicles",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Phillip Pitschi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Usually, a controller for path- or trajectory tracking is employed in autonomous driving. Typically, these controllers generate high-level commands like longitudinal acceleration or force. However, vehicles with combustion engines expect different actuation inputs. This paper proposes a longitudinal control concept that translates high-level trajectory-tracking commands to the required low-level vehicle commands such as throttle, brake pressure and a desired gear. We chose a modular structure to easily integrate different trajectory-tracking control algorithms and vehicles. The proposed control concept enables a close tracking of the high-level control command. An anti-lock braking system, traction control, and brake warmup control also ensure a safe operation during real-world tests. We provide experimental validation of our concept using real world data with longitudinal accelerations reaching up to $25 \\, \\frac{\\mathrm{m}}{\\mathrm{s}^2}$. The experiments were conducted using the EAV24 racecar during the first event of the Abu Dhabi Autonomous Racing League on the Yas Marina Formula 1 Circuit.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17418",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:27.266388Z"
  },
  {
    "id": "71da74e13beb4c9ecfb43428d37ddf61",
    "title": "LiDPM: Rethinking Point Diffusion for Lidar Scene Completion",
    "slug": "lidpm:-rethinking-point-diffusion-for-lidar-scene-completion",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Tetiana Martyniuk",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Training diffusion models that work directly on lidar points at the scale of outdoor scenes is challenging due to the difficulty of generating fine-grained details from white noise over a broad field of view. The latest works addressing scene completion with diffusion models tackle this problem by reformulating the original DDPM as a local diffusion process. It contrasts with the common practice of operating at the level of objects, where vanilla DDPMs are currently used. In this work, we close the gap between these two lines of work. We identify approximations in the local diffusion formulation, show that they are not required to operate at the scene level, and that a vanilla DDPM with a well-chosen starting point is enough for completion. Finally, we demonstrate that our method, LiDPM, leads to better results in scene completion on SemanticKITTI. The project page is this https URL .",
    "pdfUrl": "https://arxiv.org/pdf/2504.17791",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:27.266604Z"
  },
  {
    "id": "3a431d9aa63140eeb2449e4da7538057",
    "title": "CoPAL: Corrective Planning of Robot Actions with Large Language Models",
    "slug": "copal:-corrective-planning-of-robot-actions-with-large-language-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Frank Joublin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the pursuit of fully autonomous robotic systems capable of taking over tasks traditionally performed by humans, the complexity of open-world environments poses a considerable challenge. Addressing this imperative, this study contributes to the field of Large Language Models (LLMs) applied to task and motion planning for robots. We propose a system architecture that orchestrates a seamless interplay between multiple cognitive levels, encompassing reasoning, planning, and motion generation. At its core lies a novel replanning strategy that handles physically grounded, logical, and semantic errors in the generated plans. We demonstrate the efficacy of the proposed feedback architecture, particularly its impact on executability, correctness, and time complexity via empirical evaluation in the context of a simulation and two intricate real-world scenarios: blocks world, barman and pizza preparation.",
    "pdfUrl": "https://arxiv.org/pdf/2310.07263",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.266840Z"
  },
  {
    "id": "51afda09c5afa2ccc0fcefcedab92d2e",
    "title": "RABBIT: A Robot-Assisted Bed Bathing System with Multimodal Perception and Integrated Compliance",
    "slug": "rabbit:-a-robot-assisted-bed-bathing-system-with-multimodal-perception-and-integrated-compliance",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Rishabh Madan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces RABBIT, a novel robot-assisted bed bathing system designed to address the growing need for assistive technologies in personal hygiene tasks. It combines multimodal perception and dual (software and hardware) compliance to perform safe and comfortable physical human-robot interaction. Using RGB and thermal imaging to segment dry, soapy, and wet skin regions accurately, RABBIT can effectively execute washing, rinsing, and drying tasks in line with expert caregiving practices. Our system includes custom-designed motion primitives inspired by human caregiving techniques, and a novel compliant end-effector called Scrubby, optimized for gentle and effective interactions. We conducted a user study with 12 participants, including one participant with severe mobility limitations, demonstrating the system's effectiveness and perceived comfort. Supplementary material and videos can be found on our website this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2401.15159",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.267061Z"
  },
  {
    "id": "236c42ab71895b68c52db612fa522b4c",
    "title": "To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions",
    "slug": "to-help-or-not-to-help:-llm-based-attentive-support-for-human-robot-group-interactions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Daniel Tanneberg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "How can a robot provide unobtrusive physical support within a group of humans? We present Attentive Support, a novel interaction concept for robots to support a group of humans. It combines scene perception, dialogue acquisition, situation understanding, and behavior generation with the common-sense reasoning capabilities of Large Language Models (LLMs). In addition to following user instructions, Attentive Support is capable of deciding when and how to support the humans, and when to remain silent to not disturb the group. With a diverse set of scenarios, we show and evaluate the robot's attentive behavior, which supports and helps the humans when required, while not disturbing if no help is needed.",
    "pdfUrl": "https://arxiv.org/pdf/2403.12533",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.267289Z"
  },
  {
    "id": "d781c08b5e7716742b51e88e939d58ee",
    "title": "Label-Free Model Failure Detection for Lidar-based Point Cloud Segmentation",
    "slug": "label-free-model-failure-detection-for-lidar-based-point-cloud-segmentation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Daniel Bogdoll",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Autonomous vehicles drive millions of miles on the road each year. Under such circumstances, deployed machine learning models are prone to failure both in seemingly normal situations and in the presence of outliers. However, in the training phase, they are only evaluated on small validation and test sets, which are unable to reveal model failures due to their limited scenario coverage. While it is difficult and expensive to acquire large and representative labeled datasets for evaluation, large-scale unlabeled datasets are typically available. In this work, we introduce label-free model failure detection for lidar-based point cloud segmentation, taking advantage of the abundance of unlabeled data available. We leverage different data characteristics by training a supervised and self-supervised stream for the same task to detect failure modes. We perform a large-scale qualitative analysis and present LidarCODA, the first publicly available dataset with labeled anomalies in real-world lidar data, for an extensive quantitative analysis.",
    "pdfUrl": "https://arxiv.org/pdf/2407.14306",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.267505Z"
  },
  {
    "id": "fd75e541780e11118ca3f4c8e1eaadb1",
    "title": "Efficient Iterative Proximal Variational Inference Motion Planning",
    "slug": "efficient-iterative-proximal-variational-inference-motion-planning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Zinuo Chang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Motion planning under uncertainty can be cast as a stochastic optimal control problem where the optimal posterior distribution has an explicit form. To approximate this posterior, this work frames an optimization problem in the space of Gaussian distributions by solving a Variational Inference (VI) in the path distribution space. For linear-Gaussian stochastic dynamics, we propose a proximal algorithm to solve for an optimal Gaussian proposal iteratively. The computational bottleneck is evaluating the gradients with respect to the proposal over a dense trajectory. We exploit the sparse motion planning factor graph and Gaussian Belief Propagation (GBP), allowing for parallel computing of these gradients on Graphics Processing Units (GPUs). We term the novel paradigm as the Parallel Gaussian Variational Inference Motion Planning (P-GVIMP). Building on the efficient algorithm for linear Gaussian systems, we then propose an iterative paradigm based on Statistical Linear Regression (SLR) techniques to solve motion planning for nonlinear stochastic systems, where the P-GVIMP serves as a sub-routine for the linearized time-varying system. We validate the proposed framework on various robotic systems, demonstrating significant speed acceleration achieved by leveraging parallel computation and successful planning solutions for nonlinear systems under uncertainty. An open-sourced implementation is presented at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2411.03416",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.267713Z"
  },
  {
    "id": "ff5297fd35f0d2256b588c598197fdd6",
    "title": "SHIFT Planner: Speedy Hybrid Iterative Field and Segmented Trajectory Optimization with IKD-tree for Uniform Lightweight Coverage",
    "slug": "shift-planner:-speedy-hybrid-iterative-field-and-segmented-trajectory-optimization-with-ikd-tree-for-uniform-lightweight-coverage",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Zexuan Fan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces a comprehensive planning and navigation framework that address these limitations by integrating semantic mapping, adaptive coverage planning, dynamic obstacle avoidance and precise trajectory tracking. Our framework begins by generating panoptic occupancy local semantic maps and accurate localization information from data aligned between a monocular camera, IMU, and GPS. This information is combined with input terrain point clouds or preloaded terrain information to initialize the planning process. We propose the Radiant Field-Informed Coverage Planning algorithm, which utilizes a diffusion field model to dynamically adjust the robot's coverage trajectory and speed based on environmental attributes such as dirtiness and dryness. By modeling the spatial influence of the robot's actions using a Gaussian field, ensures a speed-optimized, uniform coverage trajectory while adapting to varying environmental conditions.",
    "pdfUrl": "https://arxiv.org/pdf/2412.10706",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.267936Z"
  },
  {
    "id": "ba9ee4c5d16f9f155de949be5cc8998f",
    "title": "QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning",
    "slug": "quart-online:-latency-free-large-multimodal-language-model-for-quadruped-robot-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Xinyang Tong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper addresses the inherent inference latency challenges associated with deploying multimodal large language models (MLLM) in quadruped vision-language-action (QUAR-VLA) tasks. Our investigation reveals that conventional parameter reduction techniques ultimately impair the performance of the language foundation model during the action instruction tuning phase, making them unsuitable for this purpose. We introduce a novel latency-free quadruped MLLM model, dubbed QUART-Online, designed to enhance inference efficiency without degrading the performance of the language foundation model. By incorporating Action Chunk Discretization (ACD), we compress the original action representation space, mapping continuous action values onto a smaller set of discrete representative vectors while preserving critical information. Subsequently, we fine-tune the MLLM to integrate vision, language, and compressed actions into a unified semantic space. Experimental results demonstrate that QUART-Online operates in tandem with the existing MLLM system, achieving real-time inference in sync with the underlying controller frequency, significantly boosting the success rate across various tasks by 65%. Our project page is this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2412.15576",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.268179Z"
  },
  {
    "id": "3ee43364d1f7e0fbba22bc19554f53d4",
    "title": "Empirical Comparison of Four Stereoscopic Depth Sensing Cameras for Robotics Applications",
    "slug": "empirical-comparison-of-four-stereoscopic-depth-sensing-cameras-for-robotics-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Lukas Rustler",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Depth sensing is an essential technology in robotics and many other fields. Many depth sensing (or RGB-D) cameras are available on the market and selecting the best one for your application can be challenging. In this work, we tested four stereoscopic RGB-D cameras that sense the distance by using two images from slightly different views. We empirically compared four cameras (Intel RealSense D435, Intel RealSense D455, StereoLabs ZED 2, and Luxonis OAK-D Pro) in three scenarios: (i) planar surface perception, (ii) plastic doll perception, (iii) household object perception (YCB dataset). We recorded and evaluated more than 3,000 RGB-D frames for each camera. For table-top robotics scenarios with distance to objects up to one meter, the best performance is provided by the D435 camera that is able to perceive with an error under 1 cm in all of the tested scenarios. For longer distances, the other three models perform better, making them more suitable for some mobile robotics applications. OAK-D Pro additionally offers integrated AI modules (e.g., object and human keypoint detection). ZED 2 is overall the best camera which is able to keep the error under 3 cm even at 4 meters. However, it is not a standalone device and requires a computer with a GPU for depth data acquisition. All data (more than 12,000 RGB-D frames) are publicly available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2501.07421",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.268384Z"
  },
  {
    "id": "29a67a3170631971c0db3edf585210d7",
    "title": "Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics",
    "slug": "robotic-world-model:-a-neural-network-simulator-for-robust-policy-optimization-in-robotics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Chenhao Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Learning robust and generalizable world models is crucial for enabling efficient and scalable robotic control in real-world environments. In this work, we introduce a novel framework for learning world models that accurately capture complex, partially observable, and stochastic dynamics. The proposed method employs a dual-autoregressive mechanism and self-supervised training to achieve reliable long-horizon predictions without relying on domain-specific inductive biases, ensuring adaptability across diverse robotic tasks. We further propose a policy optimization framework that leverages world models for efficient training in imagined environments and seamless deployment in real-world systems. This work advances model-based reinforcement learning by addressing the challenges of long-horizon prediction, error accumulation, and sim-to-real transfer. By providing a scalable and robust framework, the introduced methods pave the way for adaptive and efficient robotic systems in real-world applications.",
    "pdfUrl": "https://arxiv.org/pdf/2501.10100",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.268577Z"
  },
  {
    "id": "f302432a22491361c6f15ddf4938de5a",
    "title": "Demonstrating CavePI: Autonomous Exploration of Underwater Caves by Semantic Guidance",
    "slug": "demonstrating-cavepi:-autonomous-exploration-of-underwater-caves-by-semantic-guidance",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Alankrit Gupta",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Enabling autonomous robots to safely and efficiently navigate, explore, and map underwater caves is of significant importance to water resource management, hydrogeology, archaeology, and marine robotics. In this work, we demonstrate the system design and algorithmic integration of a visual servoing framework for semantically guided autonomous underwater cave exploration. We present the hardware and edge-AI design considerations to deploy this framework on a novel AUV (Autonomous Underwater Vehicle) named CavePI. The guided navigation is driven by a computationally light yet robust deep visual perception module, delivering a rich semantic understanding of the environment. Subsequently, a robust control mechanism enables CavePI to track the semantic guides and navigate within complex cave structures. We evaluate the system through field experiments in natural underwater caves and spring-water sites and further validate its ROS (Robot Operating System)-based digital twin in a simulation environment. Our results highlight how these integrated design choices facilitate reliable navigation under feature-deprived, GPS-denied, and low-visibility conditions.",
    "pdfUrl": "https://arxiv.org/pdf/2502.05384",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.268794Z"
  },
  {
    "id": "57f2aaa54af031b75e4b78af279fa03b",
    "title": "Deployment-friendly Lane-changing Intention Prediction Powered by Brain-inspired Spiking Neural Networks",
    "slug": "deployment-friendly-lane-changing-intention-prediction-powered-by-brain-inspired-spiking-neural-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Shuqi Shen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate and real-time prediction of surrounding vehicles' lane-changing intentions is a critical challenge in deploying safe and efficient autonomous driving systems in open-world scenarios. Existing high-performing methods remain hard to deploy due to their high computational cost, long training times, and excessive memory requirements. Here, we propose an efficient lane-changing intention prediction approach based on brain-inspired Spiking Neural Networks (SNN). By leveraging the event-driven nature of SNN, the proposed approach enables us to encode the vehicle's states in a more efficient manner. Comparison experiments conducted on HighD and NGSIM datasets demonstrate that our method significantly improves training efficiency and reduces deployment costs while maintaining comparable prediction accuracy. Particularly, compared to the baseline, our approach reduces training time by 75% and memory usage by 99.9%. These results validate the efficiency and reliability of our method in lane-changing predictions, highlighting its potential for safe and efficient autonomous driving systems while offering significant advantages in deployment, including reduced training time, lower memory usage, and faster inference.",
    "pdfUrl": "https://arxiv.org/pdf/2502.08659",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.269001Z"
  },
  {
    "id": "621ae814c9edc932f530f2277ddb24ef",
    "title": "Robot Pouring: Identifying Causes of Spillage and Selecting Alternative Action Parameters Using Probabilistic Actual Causation",
    "slug": "robot-pouring:-identifying-causes-of-spillage-and-selecting-alternative-action-parameters-using-probabilistic-actual-causation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Jaime Maldonado",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In everyday life, we perform tasks (e.g., cooking or cleaning) that involve a large variety of objects and goals. When confronted with an unexpected or unwanted outcome, we take corrective actions and try again until achieving the desired result. The reasoning performed to identify a cause of the observed outcome and to select an appropriate corrective action is a crucial aspect of human reasoning for successful task execution. Central to this reasoning is the assumption that a factor is responsible for producing the observed outcome. In this paper, we investigate the use of probabilistic actual causation to determine whether a factor is the cause of an observed undesired outcome. Furthermore, we show how the actual causation probabilities can be used to find alternative actions to change the outcome. We apply the probabilistic actual causation analysis to a robot pouring task. When spillage occurs, the analysis indicates whether a task parameter is the cause and how it should be changed to avoid spillage. The analysis requires a causal graph of the task and the corresponding conditional probability distributions. To fulfill these requirements, we perform a complete causal modeling procedure (i.e., task analysis, definition of variables, determination of the causal graph structure, and estimation of conditional probability distributions) using data from a realistic simulation of the robot pouring task, covering a large combinatorial space of task parameters. Based on the results, we discuss the implications of the variables' representation and how the alternative actions suggested by the actual causation analysis would compare to the alternative solutions proposed by a human observer. The practical use of the analysis of probabilistic actual causation to select alternative action parameters is demonstrated.",
    "pdfUrl": "https://arxiv.org/pdf/2502.09395",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.269217Z"
  },
  {
    "id": "7a3938513794aa157331b6827b6a8ca7",
    "title": "SE(3)-Equivariant Robot Learning and Control: A Tutorial Survey",
    "slug": "se(3)-equivariant-robot-learning-and-control:-a-tutorial-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Joohwan Seo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advances in deep learning and Transformers have driven major breakthroughs in robotics by employing techniques such as imitation learning, reinforcement learning, and LLM-based multimodal perception and decision-making. However, conventional deep learning and Transformer models often struggle to process data with inherent symmetries and invariances, typically relying on large datasets or extensive data augmentation. Equivariant neural networks overcome these limitations by explicitly integrating symmetry and invariance into their architectures, leading to improved efficiency and generalization. This tutorial survey reviews a wide range of equivariant deep learning and control methods for robotics, from classic to state-of-the-art, with a focus on SE(3)-equivariant models that leverage the natural 3D rotational and translational symmetries in visual robotic manipulation and control design. Using unified mathematical notation, we begin by reviewing key concepts from group theory, along with matrix Lie groups and Lie algebras. We then introduce foundational group-equivariant neural network design and show how the group-equivariance can be obtained through their structure. Next, we discuss the applications of SE(3)-equivariant neural networks in robotics in terms of imitation learning and reinforcement learning. The SE(3)-equivariant control design is also reviewed from the perspective of geometric control. Finally, we highlight the challenges and future directions of equivariant methods in developing more robust, sample-efficient, and multi-modal real-world robotic systems.",
    "pdfUrl": "https://arxiv.org/pdf/2503.09829",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.269458Z"
  },
  {
    "id": "4e97e384a7818ed0020dd1229d2668e5",
    "title": "Dexterous Manipulation through Imitation Learning: A Survey",
    "slug": "dexterous-manipulation-through-imitation-learning:-a-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Shan An",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dexterous manipulation, which refers to the ability of a robotic hand or multi-fingered end-effector to skillfully control, reorient, and manipulate objects through precise, coordinated finger movements and adaptive force modulation, enables complex interactions similar to human hand dexterity. With recent advances in robotics and machine learning, there is a growing demand for these systems to operate in complex and unstructured environments. Traditional model-based approaches struggle to generalize across tasks and object variations due to the high dimensionality and complex contact dynamics of dexterous manipulation. Although model-free methods such as reinforcement learning (RL) show promise, they require extensive training, large-scale interaction data, and carefully designed rewards for stability and effectiveness. Imitation learning (IL) offers an alternative by allowing robots to acquire dexterous manipulation skills directly from expert demonstrations, capturing fine-grained coordination and contact dynamics while bypassing the need for explicit modeling and large-scale trial-and-error. This survey provides an overview of dexterous manipulation methods based on imitation learning, details recent advances, and addresses key challenges in the field. Additionally, it explores potential research directions to enhance IL-driven dexterous manipulation. Our goal is to offer researchers and practitioners a comprehensive introduction to this rapidly evolving domain.",
    "pdfUrl": "https://arxiv.org/pdf/2504.03515",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.269703Z"
  },
  {
    "id": "b4696d9c7ac3d39d598b73dd59889d7c",
    "title": "Latent Representations for Visual Proprioception in Inexpensive Robots",
    "slug": "latent-representations-for-visual-proprioception-in-inexpensive-robots",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Sahara Sheikholeslami",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Robotic manipulation requires explicit or implicit knowledge of the robot's joint positions. Precise proprioception is standard in high-quality industrial robots but is often unavailable in inexpensive robots operating in unstructured environments. In this paper, we ask: to what extent can a fast, single-pass regression architecture perform visual proprioception from a single external camera image, available even in the simplest manipulation settings? We explore several latent representations, including CNNs, VAEs, ViTs, and bags of uncalibrated fiducial markers, using fine-tuning techniques adapted to the limited data available. We evaluate the achievable accuracy through experiments on an inexpensive 6-DoF robot.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14634",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.269896Z"
  },
  {
    "id": "0d2f5ee4439c5061ae0bdea3ea6b7c2e",
    "title": "Fast Online Adaptive Neural MPC via Meta-Learning",
    "slug": "fast-online-adaptive-neural-mpc-via-meta-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Yu Mei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Data-driven model predictive control (MPC) has demonstrated significant potential for improving robot control performance in the presence of model uncertainties. However, existing approaches often require extensive offline data collection and computationally intensive training, limiting their ability to adapt online. To address these challenges, this paper presents a fast online adaptive MPC framework that leverages neural networks integrated with Model-Agnostic Meta-Learning (MAML). Our approach focuses on few-shot adaptation of residual dynamics - capturing the discrepancy between nominal and true system behavior - using minimal online data and gradient steps. By embedding these meta-learned residual models into a computationally efficient L4CasADi-based MPC pipeline, the proposed method enables rapid model correction, enhances predictive accuracy, and improves real-time control performance. We validate the framework through simulation studies on a Van der Pol oscillator, a Cart-Pole system, and a 2D quadrotor. Results show significant gains in adaptation speed and prediction accuracy over both nominal MPC and nominal MPC augmented with a freshly initialized neural network, underscoring the effectiveness of our approach for real-time adaptive robot control.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16369",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.270100Z"
  },
  {
    "id": "7128e76962318b4ee84ec949b4553ca1",
    "title": "DYNUS: Uncertainty-aware Trajectory Planner in Dynamic Unknown Environments",
    "slug": "dynus:-uncertainty-aware-trajectory-planner-in-dynamic-unknown-environments",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Kota Kondo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces DYNUS, an uncertainty-aware trajectory planner designed for dynamic unknown environments. Operating in such settings presents many challenges -- most notably, because the agent cannot predict the ground-truth future paths of obstacles, a previously planned trajectory can become unsafe at any moment, requiring rapid replanning to avoid collisions.\nRecently developed planners have used soft-constraint approaches to achieve the necessary fast computation times; however, these methods do not guarantee collision-free paths even with static obstacles. In contrast, hard-constraint methods ensure collision-free safety, but typically have longer computation times.\nTo address these issues, we propose three key contributions. First, the DYNUS Global Planner (DGP) and Temporal Safe Corridor Generation operate in spatio-temporal space and handle both static and dynamic obstacles in the 3D environment. Second, the Safe Planning Framework leverages a combination of exploratory, safe, and contingency trajectories to flexibly re-route when potential future collisions with dynamic obstacles are detected. Finally, the Fast Hard-Constraint Local Trajectory Formulation uses a variable elimination approach to reduce the problem size and enable faster computation by pre-computing dependencies between free and dependent variables while still ensuring collision-free trajectories.\nWe evaluated DYNUS in a variety of simulations, including dense forests, confined office spaces, cave systems, and dynamic environments. Our experiments show that DYNUS achieves a success rate of 100% and travel times that are approximately 25.0% faster than state-of-the-art methods. We also evaluated DYNUS on multiple platforms -- a quadrotor, a wheeled robot, and a quadruped -- in both simulation and hardware experiments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16734",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:27.270325Z"
  },
  {
    "id": "fb55b6fbe118dd8379de091a00fdce31",
    "title": "Learning Type-Generalized Actions for Symbolic Planning",
    "slug": "learning-type-generalized-actions-for-symbolic-planning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Artificial Intelligence (cs.AI)",
    "author": {
      "name": "Daniel Tanneberg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Symbolic planning is a powerful technique to solve complex tasks that require long sequences of actions and can equip an intelligent agent with complex behavior. The downside of this approach is the necessity for suitable symbolic representations describing the state of the environment as well as the actions that can change it. Traditionally such representations are carefully hand-designed by experts for distinct problem domains, which limits their transferability to different problems and environment complexities. In this paper, we propose a novel concept to generalize symbolic actions using a given entity hierarchy and observed similar behavior. In a simulated grid-based kitchen environment, we show that type-generalized actions can be learned from few observations and generalize to novel situations. Incorporating an additional on-the-fly generalization mechanism during planning, unseen task combinations, involving longer sequences, novel entities and unexpected environment behavior, can be solved.",
    "pdfUrl": "https://arxiv.org/pdf/2308.04867",
    "tags": [
      "Artificial Intelligence (cs.AI)"
    ],
    "createdAt": "2025-04-25T15:49:27.270523Z"
  },
  {
    "id": "5be04c9b5aaa0e38422a6c43370e2f22",
    "title": "MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations",
    "slug": "muvo:-a-multimodal-generative-world-model-for-autonomous-driving-with-geometric-representations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Daniel Bogdoll",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "World models for autonomous driving have the potential to dramatically improve the reasoning capabilities of today's systems. However, most works focus on camera data, with only a few that leverage lidar data or combine both to better represent autonomous vehicle sensor setups. In addition, raw sensor predictions are less actionable than 3D occupancy predictions, but there are no works examining the effects of combining both multimodal sensor data and 3D occupancy prediction. In this work, we perform a set of experiments with a MUltimodal World Model with Geometric VOxel representations (MUVO) to evaluate different sensor fusion strategies to better understand the effects on sensor data prediction. We also analyze potential weaknesses of current sensor fusion approaches and examine the benefits of additionally predicting 3D occupancy.",
    "pdfUrl": "https://arxiv.org/pdf/2311.11762",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:27.270737Z"
  },
  {
    "id": "a8bc4079927d3de26cf6d94083398b9e",
    "title": "MARFT: Multi-Agent Reinforcement Fine-Tuning",
    "slug": "marft:-multi-agent-reinforcement-fine-tuning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multiagent Systems (cs.MA)",
    "author": {
      "name": "Junwei Liao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LLM-based Multi-Agent Systems have demonstrated remarkable capabilities in addressing complex, agentic tasks requiring multifaceted reasoning and collaboration, from generating high-quality presentation slides to conducting sophisticated scientific research. Meanwhile, RL has been widely recognized for its effectiveness in enhancing agent intelligence, but limited research has investigated the fine-tuning of LaMAS using foundational RL techniques. Moreover, the direct application of MARL methodologies to LaMAS introduces significant challenges, stemming from the unique characteristics and mechanisms inherent to LaMAS. To address these challenges, this article presents a comprehensive study of LLM-based MARL and proposes a novel paradigm termed Multi-Agent Reinforcement Fine-Tuning (MARFT). We introduce a universal algorithmic framework tailored for LaMAS, outlining the conceptual foundations, key distinctions, and practical implementation strategies. We begin by reviewing the evolution from RL to Reinforcement Fine-Tuning, setting the stage for a parallel analysis in the multi-agent domain. In the context of LaMAS, we elucidate critical differences between MARL and MARFT. These differences motivate a transition toward a novel, LaMAS-oriented formulation of RFT. Central to this work is the presentation of a robust and scalable MARFT framework. We detail the core algorithm and provide a complete, open-source implementation to facilitate adoption and further research. The latter sections of the paper explore real-world application perspectives and opening challenges in MARFT. By bridging theoretical underpinnings with practical methodologies, this work aims to serve as a roadmap for researchers seeking to advance MARFT toward resilient and adaptive solutions in agentic systems. Our implementation of the proposed framework is publicly available at: this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16129",
    "tags": [
      "Multiagent Systems (cs.MA)"
    ],
    "createdAt": "2025-04-25T15:49:27.270944Z"
  },
  {
    "id": "6bb7e2b20ec63d318a36e46288e5bd44",
    "title": "Parameter Estimation in ODE Models with Certified Polynomial System Solving",
    "slug": "parameter-estimation-in-ode-models-with-certified-polynomial-system-solving",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Symbolic Computation (cs.SC)",
    "author": {
      "name": "Alexander Demin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider dynamical models given by rational ODE systems. Parameter estimation is an important and challenging task of recovering parameter values from observed data. Recently, a method based on differential algebra and rational interpolation was proposed to express parameter estimation in terms of polynomial system solving. Typically, polynomial system solving is a bottleneck, hence the choice of the polynomial solver is crucial. In this contribution, we compare two polynomial system solvers applied to parameter estimation: homotopy continuation solver from this http URL and our new implementation of a certified solver based on rational univariate representation (RUR) and real root isolation. We show how the new RUR solver can tackle examples that are out of reach for the homotopy methods and vice versa.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17268",
    "tags": [
      "Symbolic Computation (cs.SC)"
    ],
    "createdAt": "2025-04-25T15:49:27.507350Z"
  },
  {
    "id": "5c41330d0bba75b3f42ea6d973fe2344",
    "title": "Learning Isometric Embeddings of Road Networks using Multidimensional Scaling",
    "slug": "learning-isometric-embeddings-of-road-networks-using-multidimensional-scaling",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Juan Carlos Climent Pardo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The lack of generalization in learning-based autonomous driving applications is shown by the narrow range of road scenarios that vehicles can currently cover. A generalizable approach should capture many distinct road structures and topologies, as well as consider traffic participants, and dynamic changes in the environment, so that vehicles can navigate and perform motion planning tasks even in the most difficult situations. Designing suitable feature spaces for neural network-based motion planers that encapsulate all kinds of road scenarios is still an open research challenge. This paper tackles this learning-based generalization challenge and shows how graph representations of road networks can be leveraged by using multidimensional scaling (MDS) techniques in order to obtain such feature spaces. State-of-the-art graph representations and MDS approaches are analyzed for the autonomous driving use case. Finally, the option of embedding graph nodes is discussed in order to perform easier learning procedures and obtain dimensionality reduction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17534",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:27.507628Z"
  },
  {
    "id": "17a62f212eda66ee142f227f8e394012",
    "title": "Waveform-Logmel Audio Neural Networks for Respiratory Sound Classification",
    "slug": "waveform-logmel-audio-neural-networks-for-respiratory-sound-classification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Sound (cs.SD)",
    "author": {
      "name": "Jiadong Xie",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Auscultatory analysis using an electronic stethoscope has attracted increasing attention in the clinical diagnosis of respiratory diseases. Recently, neural networks have been applied to assist in respiratory sound classification with achievements. However, it remains challenging due to the scarcity of abnormal respiratory sound. In this paper, we propose a novel architecture, namely Waveform-Logmel audio neural networks (WLANN), which uses both waveform and log-mel spectrogram as the input features and uses Bidirectional Gated Recurrent Units (Bi-GRU) to context model the fused features. Experimental results of our WLANN applied to SPRSound respiratory dataset show that the proposed framework can effectively distinguish pathological respiratory sound classes, outperforming the previous studies, with 90.3% in sensitivity and 93.6% in total score. Our study demonstrates the high effectiveness of the WLANN in the diagnosis of respiratory diseases.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17156",
    "tags": [
      "Sound (cs.SD)"
    ],
    "createdAt": "2025-04-25T15:49:27.721478Z"
  },
  {
    "id": "d929cf19e79bd8ea829761f1d10bd063",
    "title": "A Machine Learning Approach for Denoising and Upsampling HRTFs",
    "slug": "a-machine-learning-approach-for-denoising-and-upsampling-hrtfs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Sound (cs.SD)",
    "author": {
      "name": "Xuyi Hu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The demand for realistic virtual immersive audio continues to grow, with Head-Related Transfer Functions (HRTFs) playing a key role. HRTFs capture how sound reaches our ears, reflecting unique anatomical features and enhancing spatial perception. It has been shown that personalized HRTFs improve localization accuracy, but their measurement remains time-consuming and requires a noise-free environment. Although machine learning has been shown to reduce the required measurement points and, thus, the measurement time, a controlled environment is still necessary. This paper proposes a method to address this constraint by presenting a novel technique that can upsample sparse, noisy HRTF measurements. The proposed approach combines an HRTF Denoisy U-Net for denoising and an Autoencoding Generative Adversarial Network (AE-GAN) for upsampling from three measurement points. The proposed method achieves a log-spectral distortion (LSD) error of 5.41 dB and a cosine similarity loss of 0.0070, demonstrating the method's effectiveness in HRTF upsampling.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17586",
    "tags": [
      "Sound (cs.SD)"
    ],
    "createdAt": "2025-04-25T15:49:27.721692Z"
  },
  {
    "id": "962d11fe76c014b731b98d25163d1baa",
    "title": "Unleashing the Power of Natural Audio Featuring Multiple Sound Sources",
    "slug": "unleashing-the-power-of-natural-audio-featuring-multiple-sound-sources",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Sound (cs.SD)",
    "author": {
      "name": "Xize Cheng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Universal sound separation aims to extract clean audio tracks corresponding to distinct events from mixed audio, which is critical for artificial auditory perception. However, current methods heavily rely on artificially mixed audio for training, which limits their ability to generalize to naturally mixed audio collected in real-world environments. To overcome this limitation, we propose ClearSep, an innovative framework that employs a data engine to decompose complex naturally mixed audio into multiple independent tracks, thereby allowing effective sound separation in real-world scenarios. We introduce two remix-based evaluation metrics to quantitatively assess separation quality and use these metrics as thresholds to iteratively apply the data engine alongside model training, progressively optimizing separation performance. In addition, we propose a series of training strategies tailored to these separated independent tracks to make the best use of them. Extensive experiments demonstrate that ClearSep achieves state-of-the-art performance across multiple sound separation tasks, highlighting its potential for advancing sound separation in natural audio scenarios. For more examples and detailed results, please visit our demo page at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17782",
    "tags": [
      "Sound (cs.SD)"
    ],
    "createdAt": "2025-04-25T15:49:27.721905Z"
  },
  {
    "id": "2f04694a80e004ca454d74bb3f17455a",
    "title": "Multifaceted Evaluation of Audio-Visual Capability for MLLMs: Effectiveness, Efficiency, Generalizability and Robustness",
    "slug": "multifaceted-evaluation-of-audio-visual-capability-for-mllms:-effectiveness,-efficiency,-generalizability-and-robustness",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Multimedia (cs.MM)",
    "author": {
      "name": "Yusheng Zhao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Multi-modal large language models (MLLMs) have recently achieved great success in processing and understanding information from diverse modalities (e.g., text, audio, and visual signals). Despite their growing popularity, there remains a lack of comprehensive evaluation measuring the audio-visual capabilities of these models, especially in diverse scenarios (e.g., distribution shifts and adversarial attacks). In this paper, we present a multifaceted evaluation of the audio-visual capability of MLLMs, focusing on four key dimensions: effectiveness, efficiency, generalizability, and robustness. Through extensive experiments, we find that MLLMs exhibit strong zero-shot and few-shot generalization abilities, enabling them to achieve great performance with limited data. However, their success relies heavily on the vision modality, which impairs performance when visual input is corrupted or missing. Additionally, while MLLMs are susceptible to adversarial samples, they demonstrate greater robustness compared to traditional models. The experimental results and our findings provide insights into the audio-visual capabilities of MLLMs, highlighting areas for improvement and offering guidance for future research.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16936",
    "tags": [
      "Multimedia (cs.MM)"
    ],
    "createdAt": "2025-04-25T15:49:27.722117Z"
  },
  {
    "id": "9c7bb30f7a69d23d799a99d283679d88",
    "title": "Unsupervised EEG-based decoding of absolute auditory attention with canonical correlation analysis",
    "slug": "unsupervised-eeg-based-decoding-of-absolute-auditory-attention-with-canonical-correlation-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Signal Processing (eess.SP)",
    "author": {
      "name": "Nicolas Heintz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a fully unsupervised algorithm that detects from encephalography (EEG) recordings when a subject actively listens to sound, versus when the sound is ignored. This problem is known as absolute auditory attention decoding (aAAD). We propose an unsupervised discriminative CCA model for feature extraction and combine it with an unsupervised classifier called minimally informed linear discriminant analysis (MILDA) for aAAD classification. Remarkably, the proposed unsupervised algorithm performs significantly better than a state-of-the-art supervised model. A key reason is that the unsupervised algorithm can successfully adapt to the non-stationary test data at a low computational cost. This opens the door to the analysis of the auditory attention of a subject using EEG signals with a model that automatically tunes itself to the subject without requiring an arduous supervised training session beforehand.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17724",
    "tags": [
      "Signal Processing (eess.SP)"
    ],
    "createdAt": "2025-04-25T15:49:27.722303Z"
  },
  {
    "id": "f38a8219e7f01e19ad0bdf4be04a5ca1",
    "title": "Predictive Process Monitoring: a comparison survey between different type of event logs",
    "slug": "predictive-process-monitoring:-a-comparison-survey-between-different-type-of-event-logs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Simona Fioretto",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The application of Predictive Process Monitoring (PPM) techniques is becoming increasingly widespread due to their capacity to provide organizations with accurate predictions regarding the future behavior of business processes, thereby facilitating more informed decision-making. A plethora of solutions have been proposed in the literature employing these techniques, yet they differ from one another due to a number of factors. However, in light of the growing recognition of the value of object-centric event logs, including in the context of PPM, this survey focuses on the differences among PPM techniques employed with different event logs, namely traditional event logs and object-centric event logs. In addition, the reviewed methods are classified according to the prediction task they address and the specific methodologies they employ.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16933",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.042847Z"
  },
  {
    "id": "18d8b13aa73f94489e2b6aea4ae1f42e",
    "title": "Finding Important Stack Frames in Large Systems",
    "slug": "finding-important-stack-frames-in-large-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Aleksandr Khvorov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, we developed, integrated, and tested a feature that automatically highlights potentially important frames in stack traces. The feature was implemented in the internal bug-processing tool at JetBrains that processes tens of millions of stack traces. We surveyed 18 developers at JetBrains who provided valuable feedback on the idea and the implementation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16934",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.043063Z"
  },
  {
    "id": "a0ea91d9356add9ed8a23834a16af81a",
    "title": "SCALAR: A Part-of-speech Tagger for Identifiers",
    "slug": "scalar:-a-part-of-speech-tagger-for-identifiers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Christian D. Newman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The paper presents the Source Code Analysis and Lexical Annotation Runtime (SCALAR), a tool specialized for mapping (annotating) source code identifier names to their corresponding part-of-speech tag sequence (grammar pattern). SCALAR's internal model is trained using scikit-learn's GradientBoostingClassifier in conjunction with a manually-curated oracle of identifier names and their grammar patterns. This specializes the tagger to recognize the unique structure of the natural language used by developers to create all types of identifiers (e.g., function names, variable names etc.). SCALAR's output is compared with a previous version of the tagger, as well as a modern off-the-shelf part-of-speech tagger to show how it improves upon other taggers' output for annotating identifiers. The code is available on Github",
    "pdfUrl": "https://arxiv.org/pdf/2504.17038",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.043340Z"
  },
  {
    "id": "37cfe4671915ec20172dd6abfad0f688",
    "title": "Exploring the Untapped: Student Perceptions and Participation in OSS",
    "slug": "exploring-the-untapped:-student-perceptions-and-participation-in-oss",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Italo Santos",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Open Source Software (OSS) projects offer valuable opportunities to train the next generation of software engineers while benefiting projects and society as a whole. While research has extensively explored student participation in OSS and its use in software engineering education, student participation in OSS is still low, and the perspectives of students who have never contributed remain underexplored. This study aims to investigate the relationship between students' interest in contributing to OSS and their perceptions of barriers and motivational factors. We developed a theoretical model to understand the relationship between students' perceptions of OSS and their interest in contributing. We then surveyed students majoring in computer science and related fields (N=241). Using structural equation modeling techniques, we tested the model and found that intrinsic and internalized extrinsic motivations are positively associated with interest in contributing to OSS projects, while the impact of extrinsic motivation varies by gender. Comparatively, we found no significant relationship between barriers and interest in contributing. Students suggested several ways to make projects more attractive, including increasing awareness of the importance of OSS. Our findings can help communities better prepare to integrate students and encourage educators to enhance interest in OSS by linking participation to specific motivational factors.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17051",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.043551Z"
  },
  {
    "id": "17d72407b45202249b781448188624a5",
    "title": "Automatically Generating Rules of Malicious Software Packages via Large Language Model",
    "slug": "automatically-generating-rules-of-malicious-software-packages-via-large-language-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "XiangRui Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Today's security tools predominantly rely on predefined rules crafted by experts, making them poorly adapted to the emergence of software supply chain attacks. To tackle this limitation, we propose a novel tool, RuleLLM, which leverages large language models (LLMs) to automate rule generation for OSS ecosystems. RuleLLM extracts metadata and code snippets from malware as its input, producing YARA and Semgrep rules that can be directly deployed in software development. Specifically, the rule generation task involves three subtasks: crafting rules, refining rules, and aligning rules. To validate RuleLLM's effectiveness, we implemented a prototype system and conducted experiments on the dataset of 1,633 malicious packages. The results are promising that RuleLLM generated 763 rules (452 YARA and 311 Semgrep) with a precision of 85.2\\% and a recall of 91.8\\%, outperforming state-of-the-art (SOTA) tools and scored-based approaches. We further analyzed generated rules and proposed a rule taxonomy: 11 categories and 38 subcategories.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17198",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.043768Z"
  },
  {
    "id": "3efed7474847b2feff2e6cb17b8a0fd2",
    "title": "Combining Static and Dynamic Approaches for Mining and Testing Constraints for RESTful API Testing",
    "slug": "combining-static-and-dynamic-approaches-for-mining-and-testing-constraints-for-restful-api-testing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Hieu Huynh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In API testing, deriving logical constraints on API response bodies is crucial in generating the test cases to cover various aspects of RESTful APIs. However, existing approaches are limited to dynamic analysis in which constraints are extracted from the execution of APIs as part of the system under test. The key limitation of such a dynamic approach is its under-estimation in which inputs in API executions are not sufficiently diverse to uncover actual constraints on API response bodies. In this paper, we propose to combine a novel static analysis approach (in which the constraints for API response bodies are mined from API specifications), with the dynamic approach (which relies on API execution data). We leverage large language models (LLMs) to comprehend the API specifications, mine constraints for response bodies, and generate test cases. To reduce LLMs' hallucination, we apply an Observation-Confirmation (OC) scheme which uses initial prompts to contextualize constraints. %, allowing subsequent prompts to more accurately confirm their presence. Our empirical results show that~LLMs with OC prompting achieve high precision in constraint mining with the average of 91.2%. When combining static and dynamic analysis, our tool, RBCTest , achieves a precision of 78.5%. RBCTest detects 107 constraints that the dynamic approach misses and 46 more precise constraints. We also use its generated test cases to detect 21 mismatches between the API specification and actual response data for 8 real-world APIs. Four of the mismatches were, in fact, reported in developers' forums.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17287",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.043967Z"
  },
  {
    "id": "0f8be74e048e78d20c9b7b1266dad516",
    "title": "How Do Communities of ML-Enabled Systems Smell? A Cross-Sectional Study on the Prevalence of Community Smells",
    "slug": "how-do-communities-of-ml-enabled-systems-smell?-a-cross-sectional-study-on-the-prevalence-of-community-smells",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Giusy Annunziata",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Effective software development relies on managing both collaboration and technology, but sociotechnical challenges can harm team dynamics and increase technical debt. Although teams working on ML enabled systems are interdisciplinary, research has largely focused on technical issues, leaving their socio-technical dynamics underexplored. This study aims to address this gap by examining the prevalence, evolution, and interrelations of community smells, in open-source ML projects. We conducted an empirical study on 188 repositories from the NICHE dataset using the CADOCS tool to identify and analyze community smells. Our analysis focused on their prevalence, interrelations, and temporal variations. We found that certain smells, such as Prima Donna Effects and Sharing Villainy, are more prevalent and fluctuate over time compared to others like Radio Silence or Organizational Skirmish. These insights might provide valuable support for ML project managers in addressing socio-technical issues and improving team coordination.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17419",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.044172Z"
  },
  {
    "id": "4208446f6ee8f21f5fbf5893657f3362",
    "title": "Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code",
    "slug": "towards-leveraging-large-language-model-summaries-for-topic-modeling-in-source-code",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Michele Carissimi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Understanding source code is a topic of great interest in the software engineering community, since it can help programmers in various tasks such as software maintenance and reuse. Recent advances in large language models (LLMs) have demonstrated remarkable program comprehension capabilities, while transformer-based topic modeling techniques offer effective ways to extract semantic information from text. This paper proposes and explores a novel approach that combines these strengths to automatically identify meaningful topics in a corpus of Python programs. Our method consists in applying topic modeling on the descriptions obtained by asking an LLM to summarize the code. To assess the internal consistency of the extracted topics, we compare them against topics inferred from function names alone, and those derived from existing docstrings. Experimental results suggest that leveraging LLM-generated summaries provides interpretable and semantically rich representation of code structure. The promising results suggest that our approach can be fruitfully applied in various software engineering tasks such as automatic documentation and tagging, code search, software reorganization and knowledge discovery in large repositories.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17426",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.044366Z"
  },
  {
    "id": "ea67458f049d3b3ab7ed934bc649ffed",
    "title": "Detection, Classification and Prevalence of Self-Admitted Aging Debt",
    "slug": "detection,-classification-and-prevalence-of-self-admitted-aging-debt",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Murali Sridharan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Context: Previous research on software aging is limited with focus on dynamic runtime indicators like memory and performance, often neglecting evolutionary indicators like source code comments and narrowly examining legacy issues within the TD context. Objective: We introduce the concept of Aging Debt (AD), representing the increased maintenance efforts and costs needed to keep software updated. We study AD through Self-Admitted Aging Debt (SAAD) observed in source code comments left by software developers. Method: We employ a mixed-methods approach, combining qualitative and quantitative analyses to detect and measure AD in software. This includes framing SAAD patterns from the source code comments after analysing the source code context, then utilizing the SAAD patterns to detect SAAD comments. In the process, we develop a taxonomy for SAAD that reflects the temporal aging of software and its associated debt. Then we utilize the taxonomy to quantify the different types of AD prevalent in OSS repositories. Results: Our proposed taxonomy categorizes temporal software aging into Active and Dormant types. Our extensive analysis of over 9,000+ Open Source Software (OSS) repositories reveals that more than 21% repositories exhibit signs of SAAD as observed from our gold standard SAAD dataset. Notably, Dormant AD emerges as the predominant category, highlighting a critical but often overlooked aspect of software maintenance. Conclusion: As software volume grows annually, so do evolutionary aging and maintenance challenges; our proposed taxonomy can aid researchers in detailed software aging studies and help practitioners develop improved and proactive maintenance strategies.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17428",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.044566Z"
  },
  {
    "id": "d3ee006c7341b38f4e9ce3829f0bba27",
    "title": "Wolves in the Repository: A Software Engineering Analysis of the XZ Utils Supply Chain Attack",
    "slug": "wolves-in-the-repository:-a-software-engineering-analysis-of-the-xz-utils-supply-chain-attack",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Piotr Przymus",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The digital economy runs on Open Source Software (OSS), with an estimated 90\\% of modern applications containing open-source components. While this widespread adoption has revolutionized software development, it has also created critical security vulnerabilities, particularly in essential but under-resourced projects. This paper examines a sophisticated attack on the XZ Utils project (CVE-2024-3094), where attackers exploited not just code, but the entire open-source development process to inject a backdoor into a fundamental Linux compression library. Our analysis reveals a new breed of supply chain attack that manipulates software engineering practices themselves -- from community management to CI/CD configurations -- to establish legitimacy and maintain long-term control. Through a comprehensive examination of GitHub events and development artifacts, we reconstruct the attack timeline, analyze the evolution of attacker tactics. Our findings demonstrate how attackers leveraged seemingly beneficial contributions to project infrastructure and maintenance to bypass traditional security measures. This work extends beyond traditional security analysis by examining how software engineering practices themselves can be weaponized, offering insights for protecting the open-source ecosystem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17473",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.044755Z"
  },
  {
    "id": "6b5463e1cbf7c6c265fb6aa4ece07263",
    "title": "Safe to Stay: Psychological Safety Sustains Participation in Pull-based Open Source Projects",
    "slug": "safe-to-stay:-psychological-safety-sustains-participation-in-pull-based-open-source-projects",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Emeralda Sesari",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Psychological safety is the belief that team members can speak up or make mistakes without fear of negative consequences. While it is recognized as important in traditional software teams, its role in open-source development remains understudied. Yet, open-source contributors often collaborate without formal roles or structures, where interpersonal relationship can make or break participation. In this study, we examine whether team-level psychological safety, inferred from code review activities, is associated with contributors' continued participation in open-source projects. Code review is a central and collaborative activity in modern software development, which offers a rich context for observing team interactions. Based on 60,684 pull requests, we construct a psychological safety index using cues such as merge decisions, comment activity, interaction diversity, and mentions. We analyze its relationship with contributors' short-term (after 1 year) and long-term (after 4-5 years) sustained participation using three logistic regression models. Our findings show that contributors are more likely to remain active in repositories with higher levels of psychological safety. Psychological safety is positively associated with both short-term and future sustained participation. However, when prior participation is included, it becomes the stronger predictor of future sustained participation, while the effect of psychological safety becomes smaller. This study introduces a scalable approach to study psychological safety through pull request data and provides new evidence that it matters in open-source development.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17510",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.044954Z"
  },
  {
    "id": "c52b88b92295567859e37bea23bfdc4c",
    "title": "Large Language Model-Driven Concolic Execution for Highly Structured Test Input Generation",
    "slug": "large-language-model-driven-concolic-execution-for-highly-structured-test-input-generation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Haoxin Tu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "How can we perform concolic execution to generate highly structured test inputs for systematically testing parsing programs? Existing concolic execution engines are significantly restricted by (1) input structure-agnostic path constraint selection, leading to the waste of testing effort or missing coverage; (2) limited constraint-solving capability, yielding many syntactically invalid test inputs; (3) reliance on manual acquisition of highly structured seed inputs, resulting in non-continuous testing.\nThis paper proposes Cottontail, a new Large Language Model (LLM)-driven concolic execution engine, to mitigate the above limitations. A more complete program path representation, named Expressive Structural Coverage Tree (ESCT), is first constructed to select structure-aware path constraints. Later, an LLM-driven constraint solver based on a Solve-Complete paradigm is designed to solve the path constraints smartly to get test inputs that are not only satisfiable to the constraints but also valid to the input syntax. Finally, a history-guided seed acquisition is employed to obtain new highly structured test inputs either before testing starts or after testing is saturated.\nWe implemented Cottontail on top of SymCC and evaluated eight extensively tested open-source libraries across four different formats (XML, SQL, JavaScript, and JSON). The experimental result is promising: it shows that Cottontail outperforms state-of-the-art approaches (SymCC and Marco) by 14.15% and 14.31% in terms of line coverage. Besides, Cottontail found 6 previously unknown vulnerabilities (six new CVEs have been assigned). We have reported these issues to developers, and 4 out of them have been fixed so far.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17542",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.045163Z"
  },
  {
    "id": "f245836d0dd27244923aa3fc95acd179",
    "title": "Modeling Communication Perception in Development Teams Using Monte Carlo Methods",
    "slug": "modeling-communication-perception-in-development-teams-using-monte-carlo-methods",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Marc Herrmann",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Software development is a collaborative task involving diverse development teams, where toxic communication can negatively impact team mood and project success. Mood surveys enable the early detection of underlying tensions or dissatisfaction within development teams, allowing communication issues to be addressed before they escalate, fostering a positive and productive work environment. The mood can be surveyed indirectly by analyzing the text-based communication of the team. However, emotional subjectivity leads to varying sentiment interpretations across team members; a statement perceived neutrally by one developer might be seen as problematic by another developer with a different conversational culture. Early identification of perception volatility can help prevent misunderstandings and enhance team morale while safeguarding the project. This paper analyzes the diversity of perceptions within arbitrary development teams and determines how many team members should report their sentiment to accurately reflect the team's mood. Through a Monte Carlo experiment involving 45 developers, we present a preliminary mathematical model to calculate the minimum agreement among a subset of developers based on the whole team's agreement. This model can guide leadership in mood assessment, demonstrating that omitting even a single member in an average-sized 7-member team can misrepresent the overall mood. Therefore, including all developers in mood surveying is recommended to ensure a reliable evaluation of the team's mood.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17610",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.045358Z"
  },
  {
    "id": "c01a743d3cfc9b890ab39841b429e227",
    "title": "Seamless Data Migration between Database Schemas with DAMI-Framework: An Empirical Study on Developer Experience",
    "slug": "seamless-data-migration-between-database-schemas-with-dami-framework:-an-empirical-study-on-developer-experience",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Delfina Ramos-Vidal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many businesses depend on legacy systems, which often use outdated technology that complicates maintenance and updates. Therefore, software modernization is essential, particularly data migration between different database schemas. Established methodologies, like model transformation and ETL tools, facilitate this migration; they require deep knowledge of database languages and both the source and target schemas. This necessity renders data migration an error-prone and cognitively demanding task. Our objective is to alleviate developers' workloads during schema evolution through our DAMI-Framework. This framework incorporates a domain-specific language (DSL) and a parser to facilitate data migration between database schemas. DAMI-DSL simplifies schema mapping while the parser automates SQL script generation. We assess developer experience in data migration by conducting an empirical evaluation with 21 developers to assess their experiences using our DSL versus traditional SQL. The study allows us to measure their perceptions of the DSL properties and user experience. The participants praised DAMI-DSL for its readability and ease of use. The findings indicate that our DSL reduces data migration efforts compared to SQL scripts.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17662",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.045561Z"
  },
  {
    "id": "26a0fa6d2730d30b7780ca8b2bb4dbf2",
    "title": "Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching",
    "slug": "whence-is-a-model-fair?-fixing-fairness-bugs-via-propensity-score-matching",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Kewen Peng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Fairness-aware learning aims to mitigate discrimination against specific protected social groups (e.g., those categorized by gender, ethnicity, age) while minimizing predictive performance loss. Despite efforts to improve fairness in machine learning, prior studies have shown that many models remain unfair when measured against various fairness metrics. In this paper, we examine whether the way training and testing data are sampled affects the reliability of reported fairness metrics. Since training and test sets are often randomly sampled from the same population, bias present in the training data may still exist in the test data, potentially skewing fairness assessments. To address this, we propose FairMatch, a post-processing method that applies propensity score matching to evaluate and mitigate bias. FairMatch identifies control and treatment pairs with similar propensity scores in the test set and adjusts decision thresholds for different subgroups accordingly. For samples that cannot be matched, we perform probabilistic calibration using fairness-aware loss functions. Experimental results demonstrate that our approach can (a) precisely locate subsets of the test data where the model is unbiased, and (b) significantly reduce bias on the remaining data. Overall, propensity score matching offers a principled way to improve both fairness evaluation and mitigation, without sacrificing predictive performance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17066",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:28.045755Z"
  },
  {
    "id": "ec0c518b558d85c5f1379bf1491ea55a",
    "title": "Transactional Cloud Applications: Status Quo, Challenges, and Opportunities",
    "slug": "transactional-cloud-applications:-status-quo,-challenges,-and-opportunities",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Databases (cs.DB)",
    "author": {
      "name": "Rodrigo Laigner",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Transactional cloud applications such as payment, booking, reservation systems, and complex business workflows are currently being rewritten for deployment in the cloud. This migration to the cloud is happening mainly for reasons of cost and scalability. Over the years, application developers have used different migration approaches, such as microservice frameworks, actors, and stateful dataflow systems.\nThe migration to the cloud has brought back data management challenges traditionally handled by database management systems. Those challenges include ensuring state consistency, maintaining durability, and managing the application lifecycle. At the same time, the shift to a distributed computing infrastructure introduced new issues, such as message delivery, task scheduling, containerization, and (auto)scaling.\nAlthough the data management community has made progress in developing analytical and transactional database systems, transactional cloud applications have received little attention in database research. This tutorial aims to highlight recent trends in the area and discusses open research challenges for the data management community.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17106",
    "tags": [
      "Databases (cs.DB)"
    ],
    "createdAt": "2025-04-25T15:49:28.045961Z"
  },
  {
    "id": "03cdc4a936ff64ef72d42dfd787feb85",
    "title": "FLAG: Formal and LLM-assisted SVA Generation for Formal Specifications of On-Chip Communication Protocols",
    "slug": "flag:-formal-and-llm-assisted-sva-generation-for-formal-specifications-of-on-chip-communication-protocols",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Hardware Architecture (cs.AR)",
    "author": {
      "name": "Yu-An Shih",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Formal specifications of on-chip communication protocols are crucial for system-on-chip (SoC) design and verification. However, manually constructing these formal specifications from informal documents remains a tedious and error-prone task. Although recent efforts have used Large Language Models (LLMs) to generate SystemVerilog Assertion (SVA) properties from design documents for Register-Transfer Level (RTL) design verification, in our experience these approaches have not shown promise in generating SVA properties for communication protocols. Since protocol specification documents are unstructured and ambiguous in nature, LLMs often fail to extract the necessary information and end up generating irrelevant or even incorrect properties. We propose FLAG, a two-stage framework to help construct formal protocol specifications from informal documents. In the first stage, a predefined template set is used to generate candidate SVA properties. To avoid missing necessary properties, we develop a grammar-based approach to generate comprehensive template sets that capture critical signal behaviors for various communication protocols. In the second stage, we utilize unambiguous timing diagrams in conjunction with textual descriptions from the specification documents to filter out incorrect properties. A formal approach is first implemented to check the candidate properties and filter out those inconsistent with the timing diagrams. An LLM is then consulted to further remove incorrect properties with respect to the textual description, obtaining the final property set. Experiments on various open-source communication protocols demonstrate the effectiveness of FLAG in generating SVA properties from informal documents.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17226",
    "tags": [
      "Hardware Architecture (cs.AR)"
    ],
    "createdAt": "2025-04-25T15:49:28.046168Z"
  },
  {
    "id": "5381171c08837df12674d14c7136156b",
    "title": "Identity Control Plane: The Unifying Layer for Zero Trust Infrastructure",
    "slug": "identity-control-plane:-the-unifying-layer-for-zero-trust-infrastructure",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Surya Teja Avirneni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces the Identity Control Plane (ICP), an architectural framework for enforcing identity-aware Zero Trust access across human users, workloads, and automation systems. The ICP model unifies SPIFFE-based workload identity, OIDC/SAML user identity, and scoped automation credentials via broker-issued transaction tokens. We propose a composable enforcement layer using ABAC policy engines (e.g., OPA, Cedar), aligned with IETF WIMSE drafts and OAuth transaction tokens. The paper includes architectural components, integration patterns, use cases, a comparative analysis with current models, and theorized performance metrics. A FedRAMP and SLSA compliance mapping is also presented. This is a theoretical infrastructure architecture paper intended for security researchers and platform architects. No prior version of this work has been published.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17759",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:28.046357Z"
  },
  {
    "id": "790a6d5aa0b4014ce7dcd0f71964a062",
    "title": "Understanding Practitioners' Expectations on Clear Code Review Comments",
    "slug": "understanding-practitioners'-expectations-on-clear-code-review-comments",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Junkai Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The code review comment (CRC) is pivotal in the process of modern code review. It provides reviewers with the opportunity to identify potential bugs, offer constructive feedback, and suggest improvements. Clear and concise code review comments (CRCs) facilitate the communication between developers and are crucial to the correct understanding of the identified issues and proposed solutions. Despite the importance of CRCs' clarity, there is still a lack of guidelines on what constitutes a good clarity and how to evaluate it. In this paper, we conduct a comprehensive study on understanding and evaluating the clarity of CRCs. We first derive a set of attributes related to the clarity of CRCs, namely RIE attributes (i.e., Relevance, Informativeness, and Expression), as well as their corresponding evaluation criteria based on our literature review and survey with practitioners. We then investigate the clarity of CRCs in open-source projects written in nine programming languages and find that a large portion (i.e., 28.8%) of the CRCs lack the clarity in at least one of the attributes. Finally, we explore the potential of automatically evaluating the clarity of CRCs by proposing ClearCRC. Experimental results show that ClearCRC with pre-trained language models is promising for effective evaluation of the clarity of CRCs, achieving a balanced accuracy up to 73.04% and a F-1 score up to 94.61%.",
    "pdfUrl": "https://arxiv.org/pdf/2410.06515",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.046570Z"
  },
  {
    "id": "c92de303a3fd6b03e30801a989204398",
    "title": "AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation",
    "slug": "alphatrans:-a-neuro-symbolic-compositional-approach-for-repository-level-code-translation-and-validation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Ali Reza Ibrahimzada",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Code translation transforms programs from one programming language (PL) to another. Several rule-based transpilers have been designed to automate code translation between different pairs of PLs. However, the rules can become obsolete as the PLs evolve and cannot generalize to other PLs. Recent studies have explored the automation of code translation using Large Language Models (LLMs). One key observation is that such techniques may work well for crafted benchmarks but fail to generalize to the scale and complexity of real-world projects with dependencies, custom types, PL-specific features, etc. We propose AlphaTrans, a neuro-symbolic approach to automate repository-level code translation. AlphaTrans translates both source and test code, and employs multiple levels of validation to ensure the translation preserves the functionality of the source program. To break down the problem for LLMs, AlphaTrans leverages program analysis to decompose the program into fragments and translates them in the reverse call order. We leveraged AlphaTrans to translate ten real-world open-source projects consisting of <836, 8575, 2719> classes, methods, and tests. AlphaTrans breaks down these projects into 17874 fragments and translates the entire repository. 96.40% of the translated fragments are syntactically correct, and AlphaTrans validates the translations' runtime behavior and functional correctness for 27.03% and 25.14% of fragments. On average, the integrated translation and validation take 34 hours to translate a project, showing its scalability in practice. For the incorrect translations, AlphaTrans generates a report including existing translation, stack trace, test errors, or assertion failures. We provided these artifacts to two developers to fix the translation bugs in four projects. They were able to fix the issues in 20.1 hours on average and achieve all passing tests.",
    "pdfUrl": "https://arxiv.org/pdf/2410.24117",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.046794Z"
  },
  {
    "id": "d250cfe033373fa7a73556164082e6a9",
    "title": "Less is More: Towards Green Code Large Language Models via Unified Structural Pruning",
    "slug": "less-is-more:-towards-green-code-large-language-models-via-unified-structural-pruning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Guang Yang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The extensive application of Large Language Models (LLMs) in generative coding tasks has raised concerns due to their high computational demands and energy consumption. Unlike previous structural pruning methods designed for classification models that deal with lowdimensional classification logits, generative Code LLMs produce high-dimensional token logit sequences, making traditional pruning objectives inherently limited. Moreover, existing single component pruning approaches further constrain the effectiveness when applied to generative Code LLMs. In response, we propose Flab-Pruner, an innovative unified structural pruning method that combines vocabulary, layer, and Feed-Forward Network (FFN) pruning. This approach effectively reduces model parameters while maintaining performance. Additionally, we introduce a customized code instruction data strategy for coding tasks to enhance the performance recovery efficiency of the pruned model. Through extensive evaluations on three state-of-the-art Code LLMs across multiple generative coding tasks, the results demonstrate that Flab-Pruner retains 97% of the original performance after pruning 22% of the parameters and achieves the same or even better performance after post-training. The pruned models exhibit significant improvements in storage, GPU usage, computational efficiency, and environmental impact, while maintaining well robustness. Our research provides a sustainable solution for green software engineering and promotes the efficient deployment of LLMs in real-world generative coding intelligence applications.",
    "pdfUrl": "https://arxiv.org/pdf/2412.15921",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.047011Z"
  },
  {
    "id": "a44ad10769288f8068a93cabf6d7fa12",
    "title": "CallNavi, A Challenge and Empirical Study on LLM Function Calling and Routing",
    "slug": "callnavi,-a-challenge-and-empirical-study-on-llm-function-calling-and-routing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Yewei Song",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "API-driven chatbot systems are increasingly integral to software engineering applications, yet their effectiveness hinges on accurately generating and executing API calls. This is particularly challenging in scenarios requiring multi-step interactions with complex parameterization and nested API dependencies. Addressing these challenges, this work contributes to the evaluation and assessment of AI-based software development through three key advancements: (1) the introduction of a novel dataset specifically designed for benchmarking API function selection, parameter generation, and nested API execution; (2) an empirical evaluation of state-of-the-art language models, analyzing their performance across varying task complexities in API function generation and parameter accuracy; and (3) a hybrid approach to API routing, combining general-purpose large language models for API selection with fine-tuned models and prompt engineering for parameter generation. These innovations significantly improve API execution in chatbot systems, offering practical methodologies for enhancing software design, testing, and operational workflows in real-world software engineering contexts.",
    "pdfUrl": "https://arxiv.org/pdf/2501.05255",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.047230Z"
  },
  {
    "id": "e273742695d0b561866d22e8b953cd39",
    "title": "SWE-PolyBench: A multi-language benchmark for repository level evaluation of coding agents",
    "slug": "swe-polybench:-a-multi-language-benchmark-for-repository-level-evaluation-of-coding-agents",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Muhammad Shihab Rashid",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Coding agents powered by large language models have shown impressive capabilities in software engineering tasks, but evaluating their performance across diverse programming languages and real-world scenarios remains challenging. We introduce SWE-PolyBench, a new multi-language benchmark for repository-level, execution-based evaluation of coding agents. SWE-PolyBench contains 2110 instances from 21 repositories and includes tasks in Java (165), JavaScript (1017), TypeScript (729) and Python (199), covering bug fixes, feature additions, and code refactoring. We provide a task and repository-stratified subsample (SWE-PolyBench500) and release an evaluation harness allowing for fully automated evaluation. To enable a more comprehensive comparison of coding agents, this work also presents a novel set of metrics rooted in syntax tree analysis. We evaluate leading open source coding agents on SWE-PolyBench, revealing their strengths and limitations across languages, task types, and complexity classes. Our experiments show that current agents exhibit uneven performances across languages and struggle with complex problems while showing higher performance on simpler tasks. SWE-PolyBench aims to drive progress in developing more versatile and robust AI coding assistants for real-world software engineering. Our datasets and code are available at: this https URL",
    "pdfUrl": "https://arxiv.org/pdf/2504.08703",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.047470Z"
  },
  {
    "id": "20d53c106006fe8a682234d1a886f22f",
    "title": "EditLord: Learning Code Transformation Rules for Code Editing",
    "slug": "editlord:-learning-code-transformation-rules-for-code-editing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Weichen Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Code editing is a foundational task in software development, where its effectiveness depends on whether it introduces desired code property changes without changing the original code's intended functionality. Existing approaches often formulate code editing as an implicit end-to-end task, omitting the fact that code-editing procedures inherently consist of discrete and explicit steps. Thus, they suffer from suboptimal performance and lack of robustness and generalization. We introduce EditLord, a code editing framework that makes the code transformation steps explicit. Our key insight is to employ a language model (LM) as an inductive learner to extract code editing rules from the training code pairs as concise meta-rule sets. Such rule sets will be manifested for each training sample to augment them for finetuning or assist in prompting- and iterative-based code editing. EditLordoutperforms the state-of-the-art by an average of 22.7% in editing performance and 58.1% in robustness while achieving 20.2% higher functional correctness across critical software engineering and security applications, LM models, and editing modes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15284",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.047671Z"
  },
  {
    "id": "dae4b069b57b31eec40e03f04d87a5f0",
    "title": "A Study on Mixup-Inspired Augmentation Methods for Software Vulnerability Detection",
    "slug": "a-study-on-mixup-inspired-augmentation-methods-for-software-vulnerability-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Software Engineering (cs.SE)",
    "author": {
      "name": "Seyed Shayan Daneshvar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Various deep learning (DL) methods have recently been utilized to detect software vulnerabilities. Real-world software vulnerability datasets are rare and hard to acquire, as there is no simple metric for classifying vulnerability. Such datasets are heavily imbalanced, and none of the current datasets are considered huge for DL models. To tackle these problems, a recent work has tried to augment the dataset using the source code and generate realistic single-statement vulnerabilities, which is not quite practical and requires manual checking of the generated vulnerabilities. In this paper, we aim to explore the augmentation of vulnerabilities at the representation level to help current models learn better, which has never been done before to the best of our knowledge. We implement and evaluate five augmentation techniques that augment the embedding of the data and have recently been used for code search, which is a completely different software engineering task. We also introduced a conditioned version of those augmentation methods, which ensures the augmentation does not change the vulnerable section of the vector representation. We show that such augmentation methods can be helpful and increase the F1-score by up to 9.67%, yet they cannot beat Random Oversampling when balancing datasets, which increases the F1-score by 10.82%.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15632",
    "tags": [
      "Software Engineering (cs.SE)"
    ],
    "createdAt": "2025-04-25T15:49:28.047873Z"
  },
  {
    "id": "aff718660d6028699b3a93012e4c9d3c",
    "title": "S2Vec: Self-Supervised Geospatial Embeddings",
    "slug": "s2vec:-self-supervised-geospatial-embeddings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Shushman Choudhury",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Scalable general-purpose representations of the built environment are crucial for geospatial artificial intelligence applications. This paper introduces S2Vec, a novel self-supervised framework for learning such geospatial embeddings. S2Vec uses the S2 Geometry library to partition large areas into discrete S2 cells, rasterizes built environment feature vectors within cells as images, and applies masked autoencoding on these rasterized images to encode the feature vectors. This approach yields task-agnostic embeddings that capture local feature characteristics and broader spatial relationships. We evaluate S2Vec on three large-scale socioeconomic prediction tasks, showing its competitive performance against state-of-the-art image-based embeddings. We also explore the benefits of combining S2Vec embeddings with image-based embeddings downstream, showing that such multimodal fusion can often improve performance. Our results highlight how S2Vec can learn effective general-purpose geospatial representations and how it can complement other data modalities in geospatial artificial intelligence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16942",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:28.321632Z"
  },
  {
    "id": "9ecda36eec5373fc55f5620571a41872",
    "title": "Burning some myths on privacy properties of social networks against active attacks",
    "slug": "burning-some-myths-on-privacy-properties-of-social-networks-against-active-attacks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Serafino Cicerone",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This work focuses on showing some arguments addressed to dismantle the extended idea about that social networks completely lacks of privacy properties. We consider the so-called active attacks to the privacy of social networks and the counterpart $(k,\\ell)$-anonymity measure, which is used to quantify the privacy satisfied by a social network against active attacks. To this end, we make use of the graph theoretical concept of $k$-metric antidimensional graphs for which the case $k=1$ represents those graphs achieving the worst scenario in privacy whilst considering the $(k,\\ell)$-anonymity measure.\nAs a product of our investigation, we present a large number of computational results stating that social networks might not be as insecure as one often thinks. In particular, we develop a large number of experiments on random graphs which show that the number of $1$-metric antidimensional graphs is indeed ridiculously small with respect to the total number of graphs that can be considered. Moreover, we search on several real networks in order to check if they are $1$-metric antidimensional, and obtain that none of them are such. Along the way, we show some theoretical studies on the mathematical properties of the $k$-metric antidimensional graphs for any suitable $k\\ge 1$. In addition, we also describe some operations on graphs that are $1$-metric antidimensional so that they get embedded into another larger graphs that are not such, in order to obscure their privacy properties against active attacks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16944",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:28.321844Z"
  },
  {
    "id": "90d69307046aade605be6617c2c77e30",
    "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation",
    "slug": "mobilecity:-an-efficient-framework-for-large-scale-urban-behavior-simulation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Xiaotong Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Generative agents offer promising capabilities for simulating realistic urban behaviors. However, existing methods oversimplify transportation choices in modern cities, and require prohibitive computational resources for large-scale population simulation. To address these limitations, we first present a virtual city that features multiple functional buildings and transportation modes. Then, we conduct extensive surveys to model behavioral choices and mobility preferences among population groups. Building on these insights, we introduce a simulation framework that captures the complexity of urban mobility while remaining scalable, enabling the simulation of over 4,000 agents. To assess the realism of the generated behaviors, we perform a series of micro and macro-level analyses. Beyond mere performance comparison, we explore insightful experiments, such as predicting crowd density from movement patterns and identifying trends in vehicle preferences across agent demographics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16946",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:28.322043Z"
  },
  {
    "id": "18c07979866354ecc3abba02ddc47d49",
    "title": "SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments",
    "slug": "scrag:-social-computing-based-retrieval-augmented-generation-for-community-response-forecasting-in-social-media-environments",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Dachun Sun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper introduces SCRAG, a prediction framework inspired by social computing, designed to forecast community responses to real or hypothetical social media posts. SCRAG can be used by public relations specialists (e.g., to craft messaging in ways that avoid unintended misinterpretations) or public figures and influencers (e.g., to anticipate social responses), among other applications related to public sentiment prediction, crisis management, and social what-if analysis. While large language models (LLMs) have achieved remarkable success in generating coherent and contextually rich text, their reliance on static training data and susceptibility to hallucinations limit their effectiveness at response forecasting in dynamic social media environments. SCRAG overcomes these challenges by integrating LLMs with a Retrieval-Augmented Generation (RAG) technique rooted in social computing. Specifically, our framework retrieves (i) historical responses from the target community to capture their ideological, semantic, and emotional makeup, and (ii) external knowledge from sources such as news articles to inject time-sensitive context. This information is then jointly used to forecast the responses of the target community to new posts or narratives. Extensive experiments across six scenarios on the X platform (formerly Twitter), tested with various embedding models and LLMs, demonstrate over 10% improvements on average in key evaluation metrics. A concrete example further shows its effectiveness in capturing diverse ideologies and nuances. Our work provides a social computing tool for applications where accurate and concrete insights into community responses are crucial.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16947",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:28.322256Z"
  },
  {
    "id": "478f43d6bac009014d7bc2df9c590e91",
    "title": "Network Sampling: An Overview and Comparative Analysis",
    "slug": "network-sampling:-an-overview-and-comparative-analysis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Quoc Chuong Nguyen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Network sampling is a crucial technique for analyzing large or partially observable networks. However, the effectiveness of different sampling methods can vary significantly depending on the context. In this study, we empirically compare representative methods from three main categories: node-based, edge-based, and exploration-based sampling. We used two real-world datasets for our analysis: a scientific collaboration network and a temporal message-sending network. Our results indicate that no single sampling method consistently outperforms the others in both datasets. Although advanced methods tend to provide better accuracy on static networks, they often perform poorly on temporal networks, where simpler techniques can be more effective. These findings suggest that the best sampling strategy depends not only on the structural characteristics of the network but also on the specific metrics that need to be preserved or analyzed. Our work offers practical insights for researchers in choosing sampling approaches that are tailored to different types of networks and analytical objectives.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17701",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:28.322450Z"
  },
  {
    "id": "730c0777825194d11ad30c53310b44bb",
    "title": "Graph Percolation as Decision Threshold for Risk Management in Cross-Country Thermal Soaring",
    "slug": "graph-percolation-as-decision-threshold-for-risk-management-in-cross-country-thermal-soaring",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Physics and Society (physics.soc-ph)",
    "author": {
      "name": "John J. Bird",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Long range flight by fixed-wing aircraft without propulsion systems can be accomplished by \"soaring\" -- exploiting randomly located updrafts to gain altitude which is expended in gliding flight. As the location of updrafts is uncertain and cannot be determined except through in situ observation, aircraft exploiting this energy source are at risk of failing to find a subsequent updraft. Determining when an updraft must be exploited to continue flight is essential to managing risk and optimizing speed. Graph percolation offers a theoretical explanation for this risk, and a framework for evaluating it using information available to the operator of a soaring aircraft in flight. The utility of graph percolation as a risk measure is examined by analyzing flight logs from human soaring pilots. This analysis indicates that in sport soaring pilots rarely operate in a condition which does not satisfy graph percolation, identifies an apparent desired minimum node degree, and shows that pilots accept reduced climb rates in order to maintain percolation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16945",
    "tags": [
      "Physics and Society (physics.soc-ph)"
    ],
    "createdAt": "2025-04-25T15:49:28.322632Z"
  },
  {
    "id": "58b79d26bf907bf8f4e1ff9b5b29e549",
    "title": "Social sustainability through engagement in a training context with tools such as the Native Podcast and Facebook social network",
    "slug": "social-sustainability-through-engagement-in-a-training-context-with-tools-such-as-the-native-podcast-and-facebook-social-network",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Danielle Mbambe Bebey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The social dimension of sustainability seems to have been a notion rarely addressed in the literature (Dubois et al., 2001) until the early 2000s. The EUTIC 2023 symposium provides an opportunity to take up this topical issue. To this end, we are presenting an engagement process that is part of a sustainable development dynamic, based on digital tools inspired by everyday life, for applications in the context of training, with a view to lifelong learning. Our work, which stems from the information and communication sciences, is rooted in a multi-disciplinary approach that we believe can be echoed in a variety of disciplines, but which it is interesting to challenge, hence the purpose of this contribution.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16964",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:28.322824Z"
  },
  {
    "id": "ee6e84100f3d520c07bde78af2d5e456",
    "title": "GeoRDF2Vec Learning Location-Aware Entity Representations in Knowledge Graphs",
    "slug": "geordf2vec-learning-location-aware-entity-representations-in-knowledge-graphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Martin Boeckling",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many knowledge graphs contain a substantial number of spatial entities, such as cities, buildings, and natural landmarks. For many of these entities, exact geometries are stored within the knowledge graphs. However, most existing approaches for learning entity representations do not take these geometries into account. In this paper, we introduce a variant of RDF2Vec that incorporates geometric information to learn location-aware embeddings of entities. Our approach expands different nodes by flooding the graph from geographic nodes, ensuring that each reachable node is considered. Based on the resulting flooded graph, we apply a modified version of RDF2Vec that biases graph walks using spatial weights. Through evaluations on multiple benchmark datasets, we demonstrate that our approach outperforms both non-location-aware RDF2Vec and GeoTransE.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17099",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:28.323019Z"
  },
  {
    "id": "b52bc1d1c0bd52fd2355ec944bf7ce8d",
    "title": "Utilizing Dynamic Time Warping for Pandemic Surveillance: Understanding the Relationship between Google Trends Network Metrics and COVID-19 Incidences",
    "slug": "utilizing-dynamic-time-warping-for-pandemic-surveillance:-understanding-the-relationship-between-google-trends-network-metrics-and-covid-19-incidences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Michael T. Lopez II",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The premise of network statistics derived from Google Trends data to foresee COVID-19 disease progression is gaining momentum in infodemiology. This approach was applied in Metro Manila, National Capital Region, Philippines. Through dynamic time warping (DTW), the temporal alignment was quantified between network metrics and COVID-19 case trajectories, and systematically explored 320 parameter configurations including two network metrics (network density and clustering coefficient), two data preprocessing methods (Rescaling Daily Data and MSV), multiple thresholds, two correlation window sizes, and Sakoe-Chiba band constraints. Results from the Kruskal-Wallis tests revealed that five of the six parameters significantly influenced alignment quality, with the disease comparison type (active cases vs. confirmed cases) demonstrating the strongest effect. The optimal configuration, which is using the network density statistic with a Rescaling Daily Data transformation, a threshold of 0.8, a 15-day window, and a 50-day radius constraint, achieved a DTW score of 36.30. This indicated substantial temporal alignment with the COVID-19 confirmed cases data. The discoveries demonstrate that network metrics rooted from online search behavior can serve as complementary indicators for epidemic surveillance in urban locations like Metro Manila. This strategy leverages the Philippines' extensive online usage during the pandemic to provide potentially valuable early signals of disease spread, and offers a supplementary tool for public health monitoring in resource-limited situations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17146",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:28.323214Z"
  },
  {
    "id": "e8a28888fff426f76bf5eb7800384dcc",
    "title": "Online posting effects: Unveiling the non-linear journeys of users in depression communities on Reddit",
    "slug": "online-posting-effects:-unveiling-the-non-linear-journeys-of-users-in-depression-communities-on-reddit",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Virginia Morini",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Social media platforms have become pivotal as self-help forums, enabling individuals to share personal experiences and seek support. However, on topics as sensitive as depression, what are the consequences of online self-disclosure? Here, we delve into the dynamics of mental health discourse on various Reddit boards focused on depression. To this aim, we introduce a data-informed framework reconstructing online dynamics from 303k users interacting over two years. Through user-generated content, we identify 4 distinct clusters representing different psychological states. Our analysis unveils online posting effects: a user can transition to another psychological state after online exposure to peers' emotional/semantic content. As described by conditional Markov chains and different levels of social exposure, users' transitions reveal navigation through both positive and negative phases in a spiral rather than a linear progression. Interpreted in light of psychological literature, related particularly to the Patient Health Engagement (PHE) model, our findings can provide evidence that the type and layout of online social interactions have an impact on users' \"journeys\" when posting about depression.",
    "pdfUrl": "https://arxiv.org/pdf/2311.17684",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:28.323437Z"
  },
  {
    "id": "d8b75d8e7e35b43d3c0ee3033fb4df9d",
    "title": "Exposing Cross-Platform Coordinated Inauthentic Activity in the Run-Up to the 2024 U.S. Election",
    "slug": "exposing-cross-platform-coordinated-inauthentic-activity-in-the-run-up-to-the-2024-u.s.-election",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Federico Cinus",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Coordinated information operations remain a persistent challenge on social media, despite platform efforts to curb them. While previous research has primarily focused on identifying these operations within individual platforms, this study shows that coordination frequently transcends platform boundaries. Leveraging newly collected data of online conversations related to the 2024 U.S. Election across $\\mathbb{X}$ (formerly, Twitter), Facebook, and Telegram, we construct similarity networks to detect coordinated communities exhibiting suspicious sharing behaviors within and across platforms. Proposing an advanced coordination detection model, we reveal evidence of potential foreign interference, with Russian-affiliated media being systematically promoted across Telegram and $\\mathbb{X}$. Our analysis also uncovers substantial intra- and cross-platform coordinated inauthentic activity, driving the spread of highly partisan, low-credibility, and conspiratorial content. These findings highlight the urgent need for regulatory measures that extend beyond individual platforms to effectively address the growing challenge of cross-platform coordinated influence campaigns.",
    "pdfUrl": "https://arxiv.org/pdf/2410.22716",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:28.323640Z"
  },
  {
    "id": "c74582cc6c72813c46774517ac1fd281",
    "title": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation",
    "slug": "post-hoc-study-of-climate-microtargeting-on-social-media-ads-with-llms:-thematic-insights-and-fairness-evaluation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computation and Language (cs.CL)",
    "author": {
      "name": "Tunazzina Islam",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Climate change communication on social media increasingly employs microtargeting strategies to effectively reach and influence specific demographic groups. This study presents a post-hoc analysis of microtargeting practices within climate campaigns by leveraging large language models (LLMs) to examine Facebook advertisements. Our analysis focuses on two key aspects: demographic targeting and fairness. We evaluate the ability of LLMs to accurately predict the intended demographic targets, such as gender and age group, achieving an overall accuracy of 88.55%. Furthermore, we instruct the LLMs to generate explanations for their classifications, providing transparent reasoning behind each decision. These explanations reveal the specific thematic elements used to engage different demographic segments, highlighting distinct strategies tailored to various audiences. Our findings show that young adults are primarily targeted through messages emphasizing activism and environmental consciousness, while women are engaged through themes related to caregiving roles and social advocacy. In addition to evaluating the effectiveness of LLMs in detecting microtargeted messaging, we conduct a comprehensive fairness analysis to identify potential biases in model predictions. Our findings indicate that while LLMs perform well overall, certain biases exist, particularly in the classification of senior citizens and male audiences. By showcasing the efficacy of LLMs in dissecting and explaining targeted communication strategies and by highlighting fairness concerns, this study provides a valuable framework for future research aimed at enhancing transparency, accountability, and inclusivity in social media-driven climate campaigns.",
    "pdfUrl": "https://arxiv.org/pdf/2410.05401",
    "tags": [
      "Computation and Language (cs.CL)"
    ],
    "createdAt": "2025-04-25T15:49:28.323828Z"
  },
  {
    "id": "746c83d2e7d10dcc3f6a05f74b9289d6",
    "title": "Evaluating DAO Sustainability and Longevity Through On-Chain Governance Metrics",
    "slug": "evaluating-dao-sustainability-and-longevity-through-on-chain-governance-metrics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computers and Society (cs.CY)",
    "author": {
      "name": "Silvio Meneguzzo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Decentralised Autonomous Organisations (DAOs) automate governance and resource allocation through smart contracts, aiming to shift decision-making to distributed token holders. However, many DAOs face sustainability challenges linked to limited user participation, concentrated voting power, and technical design constraints. This paper addresses these issues by identifying research gaps in DAO evaluation and introducing a framework of Key Performance Indicators (KPIs) that capture governance efficiency, financial robustness, decentralisation, and community engagement. We apply the framework to a custom-built dataset of real-world DAOs constructed from on-chain data and analysed using non-parametric methods. The results reveal recurring governance patterns, including low participation rates and high proposer concentration, which may undermine long-term viability. The proposed KPIs offer a replicable, data-driven method for assessing DAO governance structures and identifying potential areas for improvement. These findings support a multidimensional approach to evaluating decentralised systems and provide practical tools for researchers and practitioners working to improve the resilience and effectiveness of DAO-based governance models.",
    "pdfUrl": "https://arxiv.org/pdf/2504.11341",
    "tags": [
      "Computers and Society (cs.CY)"
    ],
    "createdAt": "2025-04-25T15:49:28.324022Z"
  },
  {
    "id": "cda84ffc834a46dd30383d2b06d0a6a3",
    "title": "Path Integral Methods for Synthesizing and Preventing Stealthy Attacks in Nonlinear Cyber-Physical Systems",
    "slug": "path-integral-methods-for-synthesizing-and-preventing-stealthy-attacks-in-nonlinear-cyber-physical-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Apurva Patil",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper studies the synthesis and mitigation of stealthy attacks in nonlinear cyber-physical systems (CPS). To quantify stealthiness, we employ the Kullback-Leibler (KL) divergence, a measure rooted in hypothesis testing and detection theory, which captures the trade-off between an attacker's desire to remain stealthy and her goal of degrading system performance. First, we synthesize the worst-case stealthy attack in nonlinear CPS using the path integral approach. Second, we consider how a controller can mitigate the impact of such stealthy attacks by formulating a minimax KL control problem, yielding a zero-sum game between the attacker and the controller. Again, we leverage a path integral-based solution that computes saddle-point policies for both players through Monte Carlo simulations. We validate our approach using unicycle navigation and cruise control problems, demonstrating how an attacker can covertly drive the system into unsafe regions, and how the controller can adapt her policy to combat the worst-case attacks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17118",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.679913Z"
  },
  {
    "id": "05a766afb9699939ca5396288a4ccede",
    "title": "PACE: A Framework for Learning and Control in Linear Incomplete-Information Differential Games",
    "slug": "pace:-a-framework-for-learning-and-control-in-linear-incomplete-information-differential-games",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Seyed Yousef Soltanian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we address the problem of a two-player linear quadratic differential game with incomplete information, a scenario commonly encountered in multi-agent control, human-robot interaction (HRI), and approximation methods for solving general-sum differential games. While solutions to such linear differential games are typically obtained through coupled Riccati equations, the complexity increases when agents have incomplete information, particularly when neither is aware of the other's cost function. To tackle this challenge, we propose a model-based Peer-Aware Cost Estimation (PACE) framework for learning the cost parameters of the other agent. In PACE, each agent treats its peer as a learning agent rather than a stationary optimal agent, models their learning dynamics, and leverages this dynamic to infer the cost function parameters of the other agent. This approach enables agents to infer each other's objective function in real time based solely on their previous state observations and dynamically adapt their control policies. Furthermore, we provide a theoretical guarantee for the convergence of parameter estimation and the stability of system states in PACE. Additionally, in our numerical studies, we demonstrate how modeling the learning dynamics of the other agent benefits PACE, compared to approaches that approximate the other agent as having complete information, particularly in terms of stability and convergence speed.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17128",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.680131Z"
  },
  {
    "id": "673e7953462a127698e8c5399a5c3855",
    "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference",
    "slug": "peer-aware-cost-estimation-in-nonlinear-general-sum-dynamic-games-for-mutual-learning-and-intent-inference",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Seyed Yousef Soltanian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Human-robot interactions can be modeled as incomplete-information general-sum dynamic games since the objective functions of both agents are not explicitly known to each other. However, solving for equilibrium policies for such games presents a major challenge, especially if the games involve nonlinear underlying dynamics. To simplify the problem, existing work often assumes that one agent is an expert with complete information about its peer, which can lead to biased estimates and failures in coordination. To address this challenge, we propose a nonlinear peer-aware cost estimation (N-PACE) algorithm for general-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ) approximation of the nonlinear general-sum game, each agent explicitly models the learning dynamics of its peer agent while inferring their objective functions, leading to unbiased fast learning in inferring the unknown objective function of the peer agent, which is critical for task completion and safety assurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent communication} in such multi-agent systems by explicitly modeling the peer's learning dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17129",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.680327Z"
  },
  {
    "id": "a2dacbc2e4066b2651a188571637fe09",
    "title": "Opt-ODENet: A Neural ODE Framework with Differentiable QP Layers for Safe and Stable Control Design (longer version)",
    "slug": "opt-odenet:-a-neural-ode-framework-with-differentiable-qp-layers-for-safe-and-stable-control-design-(longer-version)",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Keyan Miao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Designing controllers that achieve task objectives while ensuring safety is a key challenge in control systems. This work introduces Opt-ODENet, a Neural ODE framework with a differentiable Quadratic Programming (QP) optimization layer to enforce constraints as hard requirements. Eliminating the reliance on nominal controllers or large datasets, our framework solves the optimal control problem directly using Neural ODEs. Stability and convergence are ensured through Control Lyapunov Functions (CLFs) in the loss function, while Control Barrier Functions (CBFs) embedded in the QP layer enforce real-time safety. By integrating the differentiable QP layer with Neural ODEs, we demonstrate compatibility with the adjoint method for gradient computation, enabling the learning of the CBF class-$\\mathcal{K}$ function and control network parameters. Experiments validate its effectiveness in balancing safety and performance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17139",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.680559Z"
  },
  {
    "id": "205180aa6eecb55a31ac05fc0b15b6e4",
    "title": "Breaking the Flow and the Bank: Stealthy Cyberattacks on Water Network Hydraulics",
    "slug": "breaking-the-flow-and-the-bank:-stealthy-cyberattacks-on-water-network-hydraulics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Abdallah Alalem Albustami",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As water distribution networks (WDNs) become increasingly connected with digital infrastructures, they face greater exposure to cyberattacks that threaten their operational integrity. Stealthy False Data Injection Attacks (SFDIAs) are particularly concerning, as they manipulate sensor data to compromise system operations while avoiding detection. While existing studies have focused on either detection methods or specific attack formulations, the relationship between attack sophistication, system knowledge requirements, and achievable impact remains unexplored. This paper presents a systematic analysis of sensor attacks against WDNs, investigating different combinations of physical constraints, state monitoring requirements, and intrusion detection evasion conditions. We propose several attack formulations that range from tailored strategies satisfying both physical and detection constraints to simpler measurement manipulations. The proposed attacks are simple and local -- requiring knowledge only of targeted sensors and their hydraulic connections -- making them scalable and practical. Through case studies on Net1 and Net3 benchmark networks, we demonstrate how these attacks can persistently increase operational costs and alter water flows while remaining undetected by monitoring systems for extended periods. The analysis provides utilities with insights for vulnerability assessment and motivates the development of protection strategies that combine physical and statistical security mechanisms.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17211",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.680751Z"
  },
  {
    "id": "b0791fc3ec2c7bcdf1b574e328749fd7",
    "title": "Analysis and Mitigation of Data injection Attacks against Data-Driven Control",
    "slug": "analysis-and-mitigation-of-data-injection-attacks-against-data-driven-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Sribalaji C. Anand",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper investigates the impact of false data injection attacks on data-driven control systems. Specifically, we consider an adversary injecting false data into the sensor channels during the learning phase. When the operator seeks to learn a stable state-feedback controller, we propose an attack strategy capable of misleading the operator into learning an unstable feedback gain. We also investigate the effects of constant-bias injection attacks on data-driven linear quadratic regulation (LQR). Finally, we explore potential mitigation strategies and support our findings with numerical examples.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17347",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.680941Z"
  },
  {
    "id": "d94ccc5fe198cb25b030b80b602a1fbe",
    "title": "Finding Conditions for Target Controllability under Christmas Trees",
    "slug": "finding-conditions-for-target-controllability-under-christmas-trees",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Marco Peruzzo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper presents new graph-theoretic conditions for structural target controllability of directed networks. After reviewing existing conditions and highlighting some gaps in the literature, we introduce a new class of network systems, named Christmas trees, which generalizes trees and cacti. We then establish a graph-theoretic characterization of sets of nodes that are structurally target controllable for a simple subclass of Christmas trees. Our characterization applies to general network systems by considering spanning subgraphs of Christmas tree class and allows us to uncover target controllable sets that existing criteria fail to identify.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17406",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.681139Z"
  },
  {
    "id": "84cb1e3a81eed696ddb0afbfcf7c91d7",
    "title": "Longitudinal Control for Autonomous Racing with Combustion Engine Vehicles",
    "slug": "longitudinal-control-for-autonomous-racing-with-combustion-engine-vehicles",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Phillip Pitschi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Usually, a controller for path- or trajectory tracking is employed in autonomous driving. Typically, these controllers generate high-level commands like longitudinal acceleration or force. However, vehicles with combustion engines expect different actuation inputs. This paper proposes a longitudinal control concept that translates high-level trajectory-tracking commands to the required low-level vehicle commands such as throttle, brake pressure and a desired gear. We chose a modular structure to easily integrate different trajectory-tracking control algorithms and vehicles. The proposed control concept enables a close tracking of the high-level control command. An anti-lock braking system, traction control, and brake warmup control also ensure a safe operation during real-world tests. We provide experimental validation of our concept using real world data with longitudinal accelerations reaching up to $25 \\, \\frac{\\mathrm{m}}{\\mathrm{s}^2}$. The experiments were conducted using the EAV24 racecar during the first event of the Abu Dhabi Autonomous Racing League on the Yas Marina Formula 1 Circuit.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17418",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.681344Z"
  },
  {
    "id": "4c645c792f6fa2c8521d16f6bde3b696",
    "title": "Admittance Identification of Grid-Forming Inverters Using Time and Frequency-Domain Techniques",
    "slug": "admittance-identification-of-grid-forming-inverters-using-time-and-frequency-domain-techniques",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Andres Intriago",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The increasing integration of inverter-based resources (IBRs) into the power grid introduces new challenges, requiring detailed electromagnetic transient (EMT) studies to analyze system interactions. Despite these needs, access to the internal firmware of power electronic devices remains restricted due to stringent nondisclosure agreements enforced by manufacturers. To address this, we explore three system identification techniques: sweep frequency response analysis (SFRA), step excitation method (SEM), and eigensystem realization algorithm (ERA). SFRA employs sinusoidal signals of varying frequencies to measure the system's frequency response, while SEM and ERA utilize step functions to derive time-domain responses and transform them into Laplace-domain transfer functions. All three approaches are shown to provide consistent results in identifying the dq admittance of grid-forming inverters (GFM) over a frequency range of 1 Hz to 100 Hz.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17512",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.681549Z"
  },
  {
    "id": "48db41a90ca40bf973730c4dc61e4a7d",
    "title": "On the Eigenvalue Tracking of Large-Scale Systems",
    "slug": "on-the-eigenvalue-tracking-of-large-scale-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Andreas Bouterakos",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The paper focuses on the problem of tracking eigenvalue trajectories in large-scale power system models as system parameters vary. A continuation-based formulation is presented for tracing any single eigenvalue of interest, which supports sparse matrix representations and accommodates both explicit and semi-implicit differential-algebraic models. Key implementation aspects, such as numerical integration, matrix updates, derivative approximations, and handling defective eigenvalues, are discussed in detail and practical recommendations are duly provided. The tracking approach is demonstrated through a comprehensive case study on the IEEE 39-bus system, as well as on a realistic dynamic model of the Irish transmission system.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17571",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.681743Z"
  },
  {
    "id": "e6464f89f7c5778ec5ce08ff2e5443c5",
    "title": "SAPO-RL: Sequential Actuator Placement Optimization for Fuselage Assembly via Reinforcement Learning",
    "slug": "sapo-rl:-sequential-actuator-placement-optimization-for-fuselage-assembly-via-reinforcement-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Peng Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Precise assembly of composite fuselages is critical for aircraft assembly to meet the ultra-high precision requirements. Due to dimensional variations, there is a gap when two fuselage assemble. In practice, actuators are required to adjust fuselage dimensions by applying forces to specific points on fuselage edge through pulling or pushing force actions. The positioning and force settings of these actuators significantly influence the efficiency of the shape adjustments. The current literature usually predetermines the fixed number of actuators, which is not optimal in terms of overall quality and corresponding actuator costs. However, optimal placement of actuators in terms of both locations and number is challenging due to compliant structures, complex material properties, and dimensional variabilities of incoming fuselages. To address these challenges, this paper introduces a reinforcement learning (RL) framework that enables sequential decision-making for actuator placement selection and optimal force computation. Specifically, our methodology employs the Dueling Double Deep Q-Learning (D3QN) algorithm to refine the decision-making capabilities of sequential actuator placements. The environment is meticulously crafted to enable sequential and incremental selection of an actuator based on system states. We formulate the actuator selection problem as a submodular function optimization problem, where the sub-modularity properties can be adopted to efficiently achieve near-optimal solutions. The proposed methodology has been comprehensively evaluated through numerical studies and comparison studies, demonstrating its effectiveness and outstanding performance in enhancing assembly precision with limited actuator numbers.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17603",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.681950Z"
  },
  {
    "id": "04e1bfaf7a3eb80a7de4bdf302ec3809",
    "title": "Are EVs Cleaner Than We Think? Evaluating Consequential Greenhouse Gas Emissions from EV Charging",
    "slug": "are-evs-cleaner-than-we-think?-evaluating-consequential-greenhouse-gas-emissions-from-ev-charging",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Riti Bhandarkar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "While electrifying transportation eliminates tailpipe greenhouse gas (GHG) emissions, electric vehicle (EV) adoption can create additional electricity sector emissions. To quantify this emissions impact, prior work typically employs short-run marginal emissions or average emissions rates calculated from historical data or power systems models that do not consider changes in installed capacity. In this work, we use an electricity system capacity expansion model to consider the full consequential GHG emissions impact from large-scale EV adoption in the western United States, accounting for induced changes in generation and storage capacity. We find that the metrics described above do not accurately reflect the true emissions impact of EV adoption-average emissions rates can either under- or over-estimate emission impacts, and short-run marginal emissions rates can significantly underestimate emission reductions, especially when charging timing is flexible. Our results also show that using short-run marginal emission rates as signals to coordinate EV charging could increase emissions relative to price-based charging signals, indicating the need for alternative control strategies to minimize consequential emissions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17632",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.682154Z"
  },
  {
    "id": "fa82f4ee903f837af5b62f79d0f0ca35",
    "title": "Design and benchmarking of a two degree of freedom tendon driver unit for cable-driven wearable technologies",
    "slug": "design-and-benchmarking-of-a-two-degree-of-freedom-tendon-driver-unit-for-cable-driven-wearable-technologies",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Adrian Esser",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Exosuits have recently been developed as alternatives to rigid exoskeletons and are increasingly adopted for both upper and lower limb therapy and assistance in clinical and home environments. Many cable-driven exosuits have been developed but little has been published on their electromechanical designs and performance. Therefore, this paper presents a comprehensive design and performance analysis of a two degree of freedom tendon driver unit (TDU) for cable-driven wearable exosuits. Detailed methodologies are presented to benchmark the functionality of the TDU. A static torque output test compares the commanded and measured torques. A velocity control test evaluates the attenuation and phase shift across velocities. A noise test evaluates how loud the TDU is for the wearer under different speeds. A thermal stress test captures the cooling performance of the TDU to ensure safe operation at higher loads. Finally, a battery endurance test evaluates the runtime of the TDU under various loading conditions to inform the usable time. To demonstrate these tests, a modular TDU system for cable-driven applications is introduced, which allows components such as motors, pulleys, and sensors to be adapted based on the requirements of the intended application. By sharing detailed methodologies and performance results, this study aims to provide a TDU design that may be leveraged by others and resources for researchers and engineers to better document the capabilities of their TDU designs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17736",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.682353Z"
  },
  {
    "id": "6fd016890b4358ddb3ba47166ded96a7",
    "title": "Geometric Formulation of Unified Force-Impedance Control on SE(3) for Robotic Manipulators",
    "slug": "geometric-formulation-of-unified-force-impedance-control-on-se(3)-for-robotic-manipulators",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Joohwan Seo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we present an impedance control framework on the SE(3) manifold, which enables force tracking while guaranteeing passivity. Building upon the unified force-impedance control (UFIC) and our previous work on geometric impedance control (GIC), we develop the geometric unified force impedance control (GUFIC) to account for the SE(3) manifold structure in the controller formulation using a differential geometric perspective. As in the case of the UFIC, the GUFIC utilizes energy tank augmentation for both force-tracking and impedance control to guarantee the manipulator's passivity relative to external forces. This ensures that the end effector maintains safe contact interaction with uncertain environments and tracks a desired interaction force. Moreover, we resolve a non-causal implementation problem in the UFIC formulation by introducing velocity and force fields. Due to its formulation on SE(3), the proposed GUFIC inherits the desirable SE(3) invariance and equivariance properties of the GIC, which helps increase sample efficiency in machine learning applications where a learning algorithm is incorporated into the control law. The proposed control law is validated in a simulation environment under scenarios requiring tracking an SE(3) trajectory, incorporating both position and orientation, while exerting a force on a surface. The codes are available at this https URL.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17080",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:28.682572Z"
  },
  {
    "id": "64a6863e44ed8d6f8554f6285ac84bd5",
    "title": "Singular Arcs in Optimal Control: Closed-loop Implementations without Workarounds",
    "slug": "singular-arcs-in-optimal-control:-closed-loop-implementations-without-workarounds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Nikilesh Ramesh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Singular arcs emerge in the solutions of Optimal Control Problems (OCPs) when the optimal inputs on some finite time intervals cannot be directly obtained via the optimality conditions. Solving OCPs with singular arcs often requires tailored treatments, suitable for offline trajectory optimization. This approach can become increasingly impractical for online closed-loop implementations, especially for large-scale engineering problems. Recent development of Integrated Residual Methods (IRM) have indicated their suitability for handling singular arcs; the convergence of error measures in IRM automatically suppresses singular arc-induced fluctuations and leads to non-fluctuating solutions more suitable for practical problems. Through several examples, we demonstrate the advantages of solving OCPs with singular arcs using {IRM} under an economic model predictive control framework. In particular, the following observations are made: (i) IRM does not require special treatment for singular arcs, (ii) it solves the OCPs reliably with singular arc fluctuation suppressed, and (iii) the closed-loop results closely match the analytic optimal solutions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17093",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:28.682776Z"
  },
  {
    "id": "23de29e9d7f1f92636b07ac31a866ce1",
    "title": "Neural Contraction Metrics with Formal Guarantees for Discrete-Time Nonlinear Dynamical Systems",
    "slug": "neural-contraction-metrics-with-formal-guarantees-for-discrete-time-nonlinear-dynamical-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Haoyu Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Contraction metrics are crucial in control theory because they provide a powerful framework for analyzing stability, robustness, and convergence of various dynamical systems. However, identifying these metrics for complex nonlinear systems remains an open challenge due to the lack of scalable and effective tools. This paper explores the approach of learning verifiable contraction metrics parametrized as neural networks (NNs) for discrete-time nonlinear dynamical systems. While prior works on formal verification of contraction metrics for general nonlinear systems have focused on convex optimization methods (e.g. linear matrix inequalities, etc) under the assumption of continuously differentiable dynamics, the growing prevalence of NN-based controllers, often utilizing ReLU activations, introduces challenges due to the non-smooth nature of the resulting closed-loop dynamics. To bridge this gap, we establish a new sufficient condition for establishing formal neural contraction metrics for general discrete-time nonlinear systems assuming only the continuity of the dynamics. We show that from a computational perspective, our sufficient condition can be efficiently verified using the state-of-the-art neural network verifier $\\alpha,\\!\\beta$-CROWN, which scales up non-convex neural network verification via novel integration of symbolic linear bound propagation and branch-and-bound. Built upon our analysis tool, we further develop a learning method for synthesizing neural contraction metrics from sampled data. Finally, our approach is validated through the successful synthesis and verification of NN contraction metrics for various nonlinear examples.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17102",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:28.682981Z"
  },
  {
    "id": "e9a193be5f9f9316ec690845d0f94ba6",
    "title": "Subframework-based Bearing Rigidity Maintenance Control in Multirobot Networks",
    "slug": "subframework-based-bearing-rigidity-maintenance-control-in-multirobot-networks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "J. Francisco Presenza",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This work presents a novel approach for analyzing and controlling bearing rigidity in multi-robot networks with dynamic topology. By decomposing the system's framework into subframeworks, we express bearing rigidity, a global property, as a set of local properties, with rigidity eigenvalues serving as natural local rigidity metrics. We propose a decentralized, scalable, gradient-based controller that uses only bearing measurements to execute mission-specific commands. The controller preserves bearing rigidity by maintaining rigidity eigenvalues above a threshold, and also avoids inter-robot collisions. Simulations confirm the scheme's effectiveness, with information exchange confined to subframeworks, underscoring its scalability and practicality.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17103",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:28.683190Z"
  },
  {
    "id": "496c42522840eb42925c1e613000967f",
    "title": "Demonstration of an AI-driven workflow for dynamic x-ray spectroscopy",
    "slug": "demonstration-of-an-ai-driven-workflow-for-dynamic-x-ray-spectroscopy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Applied Physics (physics.app-ph)",
    "author": {
      "name": "Ming Du",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "X-ray absorption near edge structure (XANES) spectroscopy is a powerful technique for characterizing the chemical state and symmetry of individual elements within materials, but requires collecting data at many energy points which can be time-consuming. While adaptive sampling methods exist for efficiently collecting spectroscopic data, they often lack domain-specific knowledge about XANES spectra structure. Here we demonstrate a knowledge-injected Bayesian optimization approach for adaptive XANES data collection that incorporates understanding of spectral features like absorption edges and pre-edge peaks. We show this method accurately reconstructs the absorption edge of XANES spectra using only 15-20% of the measurement points typically needed for conventional sampling, while maintaining the ability to determine the x-ray energy of the sharp peak after absorption edge with errors less than 0.03 eV, the absorption edge with errors less than 0.1 eV; and overall root-mean-square errors less than 0.005 compared to compared to traditionally sampled spectra. Our experiments on battery materials and catalysts demonstrate the method's effectiveness for both static and dynamic XANES measurements, improving data collection efficiency and enabling better time resolution for tracking chemical changes. This approach advances the degree of automation in XANES experiments reducing the common errors of under- or over-sampling points in near the absorption edge and enabling dynamic experiments that require high temporal resolution or limited measurement time.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17124",
    "tags": [
      "Applied Physics (physics.app-ph)"
    ],
    "createdAt": "2025-04-25T15:49:28.683391Z"
  },
  {
    "id": "23250d3e259b598c5893300cc6a8ca00",
    "title": "Advancing Frontiers of Path Integral Theory for Stochastic Optimal Control",
    "slug": "advancing-frontiers-of-path-integral-theory-for-stochastic-optimal-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Apurva Patil",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Stochastic Optimal Control (SOC) problems arise in systems influenced by uncertainty, such as autonomous robots or financial models. Traditional methods like dynamic programming are often intractable for high-dimensional, nonlinear systems due to the curse of dimensionality. This dissertation explores the path integral control framework as a scalable, sampling-based alternative. By reformulating SOC problems as expectations over stochastic trajectories, it enables efficient policy synthesis via Monte Carlo sampling and supports real-time implementation through GPU parallelization.\nWe apply this framework to six classes of SOC problems: Chance-Constrained SOC, Stochastic Differential Games, Deceptive Control, Task Hierarchical Control, Risk Mitigation of Stealthy Attacks, and Discrete-Time LQR. A sample complexity analysis for the discrete-time case is also provided. These contributions establish a foundation for simulator-driven autonomy in complex, uncertain environments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17154",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:28.683578Z"
  },
  {
    "id": "6bb7e2b20ec63d318a36e46288e5bd44",
    "title": "Parameter Estimation in ODE Models with Certified Polynomial System Solving",
    "slug": "parameter-estimation-in-ode-models-with-certified-polynomial-system-solving",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Symbolic Computation (cs.SC)",
    "author": {
      "name": "Alexander Demin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider dynamical models given by rational ODE systems. Parameter estimation is an important and challenging task of recovering parameter values from observed data. Recently, a method based on differential algebra and rational interpolation was proposed to express parameter estimation in terms of polynomial system solving. Typically, polynomial system solving is a bottleneck, hence the choice of the polynomial solver is crucial. In this contribution, we compare two polynomial system solvers applied to parameter estimation: homotopy continuation solver from this http URL and our new implementation of a certified solver based on rational univariate representation (RUR) and real root isolation. We show how the new RUR solver can tackle examples that are out of reach for the homotopy methods and vice versa.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17268",
    "tags": [
      "Symbolic Computation (cs.SC)"
    ],
    "createdAt": "2025-04-25T15:49:28.683778Z"
  },
  {
    "id": "9f52750e06bb9fc21bebf3324bdb7807",
    "title": "Obtaining Structural Network Controllability with Higher-Order Local Dynamics",
    "slug": "obtaining-structural-network-controllability-with-higher-order-local-dynamics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Marco Peruzzo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider a network of identical, first-order linear systems, and investigate how replacing a subset of the systems composing the network with higher-order ones, either taken to be generic or specifically designed, may affect its controllability. After establishing a correspondence between state controllability in networks of first-order systems with output controllability in networks of higher-order systems, we show that adding higher-order dynamics may require significantly fewer subsystem modifications to achieve structural controllability, when compared to first-order heterogeneous subsystems. Furthermore, we characterize the topology of networks (which we call X-networks) in which the introduction of heterogeneous local dynamics is not necessary for structural output controllability, as the latter can be attained by suitable higher-order subsystems with homogeneous internal dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17417",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:28.684366Z"
  },
  {
    "id": "77c608305c805b4926914ad5be12a9fc",
    "title": "Flying through cluttered and dynamic environments with LiDAR",
    "slug": "flying-through-cluttered-and-dynamic-environments-with-lidar",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Huajie Wu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Navigating unmanned aerial vehicles (UAVs) through cluttered and dynamic environments remains a significant challenge, particularly when dealing with fast-moving or sudden-appearing obstacles. This paper introduces a complete LiDAR-based system designed to enable UAVs to avoid various moving obstacles in complex environments. Benefiting the high computational efficiency of perception and planning, the system can operate in real time using onboard computing resources with low latency. For dynamic environment perception, we have integrated our previous work, M-detector, into the system. M-detector ensures that moving objects of different sizes, colors, and types are reliably detected. For dynamic environment planning, we incorporate dynamic object predictions into the integrated planning and control (IPC) framework, namely DynIPC. This integration allows the UAV to utilize predictions about dynamic obstacles to effectively evade them. We validate our proposed system through both simulations and real-world experiments. In simulation tests, our system outperforms state-of-the-art baselines across several metrics, including success rate, time consumption, average flight time, and maximum velocity. In real-world trials, our system successfully navigates through forests, avoiding moving obstacles along its path.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17569",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:28.684613Z"
  },
  {
    "id": "3bd24fc66358c2c89f8f1f3aedb02f22",
    "title": "Unifying Complementarity Constraints and Control Barrier Functions for Safe Whole-Body Robot Control",
    "slug": "unifying-complementarity-constraints-and-control-barrier-functions-for-safe-whole-body-robot-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Rafael I. Cabral Muchacho",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Safety-critical whole-body robot control demands reactive methods that ensure collision avoidance in real-time. Complementarity constraints and control barrier functions (CBF) have emerged as core tools for ensuring such safety constraints, and each represents a well-developed field. Despite addressing similar problems, their connection remains largely unexplored. This paper bridges this gap by formally proving the equivalence between these two methodologies for sampled-data, first-order systems, considering both single and multiple constraint scenarios. By demonstrating this equivalence, we provide a unified perspective on these techniques. This unification has theoretical and practical implications, facilitating the cross-application of robustness guarantees and algorithmic improvements between complementarity and CBF frameworks. We discuss these synergistic benefits and motivate future work in the comparison of the methods in more general cases.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17647",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:28.684825Z"
  },
  {
    "id": "66079ca9bd0c0d8d30b09ab85114012c",
    "title": "Fault Diagnosis in New Wind Turbines using Knowledge from Existing Turbines by Generative Domain Adaptation",
    "slug": "fault-diagnosis-in-new-wind-turbines-using-knowledge-from-existing-turbines-by-generative-domain-adaptation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Stefan Jonas",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Intelligent condition monitoring of wind turbines is essential for reducing downtimes. Machine learning models trained on wind turbine operation data are commonly used to detect anomalies and, eventually, operation faults. However, data-driven normal behavior models (NBMs) require a substantial amount of training data, as NBMs trained with scarce data may result in unreliable fault diagnosis. To overcome this limitation, we present a novel generative deep learning approach to make SCADA samples from one wind turbine lacking training data resemble SCADA data from wind turbines with representative training data. Through CycleGAN-based domain mapping, our method enables the application of an NBM trained on an existing wind turbine to one with severely limited data. We demonstrate our approach on field data mapping SCADA samples across 7 substantially different WTs. Our findings show significantly improved fault diagnosis in wind turbines with scarce data. Our method achieves the most similar anomaly scores to an NBM trained with abundant data, outperforming NBMs trained on scarce training data with improvements of +10.3% in F1-score when 1 month of training data is available and +16.8% when 2 weeks are available. The domain mapping approach outperforms conventional fine-tuning at all considered degrees of data scarcity, ranging from 1 to 8 weeks of training data. The proposed technique enables earlier and more reliable fault diagnosis in newly installed wind farms, demonstrating a novel and promising research direction to improve anomaly detection when faced with training data scarcity.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17709",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:28.685022Z"
  },
  {
    "id": "add199977f6076aac066a0275c05fa64",
    "title": "Recursive feasibility for stochastic MPC and the rationale behind fixing flat tires",
    "slug": "recursive-feasibility-for-stochastic-mpc-and-the-rationale-behind-fixing-flat-tires",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Mirko Fiacchini",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we address the problem of designing stochastic model predictive control (SMPC) schemes for linear systems affected by unbounded disturbances. The contribution of the paper is rooted in a measured-state initialization strategy. First, due to the nonzero probability of violating chance-constraints in the case of unbounded noise, we introduce ellipsoidal-based probabilistic reachable sets and we include constraint relaxations to recover recursive feasibility conditioned to the measured state. Second, we prove that the solution of this novel SMPC scheme guarantees closed-loop chance constraints satisfaction under minimum relaxation. Last, we demonstrate that, in expectation, the need of relaxing the constraints vanishes over time, which leads the closed-loop trajectories steered towards the unconstrained LQR invariant region. This novel SMPC scheme is proven to satisfy the recursive feasibility conditioned to the state realization, and its superiority with respect to open-loop initialization schemes is shown through numerical examples.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17718",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:28.685221Z"
  },
  {
    "id": "afa446c433ea55072612ee1a31169cf2",
    "title": "Coriolis Factorizations and their Connections to Riemannian Geometry",
    "slug": "coriolis-factorizations-and-their-connections-to-riemannian-geometry",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Patrick M. Wensing",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many energy-based control strategies for mechanical systems require the choice of a Coriolis factorization satisfying a skew-symmetry property. This paper (a) explores if and when a control designer has flexibility in this choice, (b) develops a canonical choice related to the Christoffel symbols, and (c) describes how to efficiently perform control computations with it for constrained mechanical systems. We link the choice of a Coriolis factorization to the notion of an affine connection on the configuration manifold and show how properties of the connection relate with the associated factorization. In particular, the factorization based on the Christoffel symbols is linked with a torsion-free property that can limit the twisting of system trajectories during passivity-based control. We then develop a way to induce Coriolis factorizations for constrained mechanisms from unconstrained ones, which provides a pathway to use the theory for efficient control computations with high-dimensional systems such as humanoids and quadruped robots with open- and closed-chain mechanisms. A collection of algorithms is provided (and made available open source) to support the recursive computation of passivity-based control laws, adaptation laws, and regressor matrices in future applications.",
    "pdfUrl": "https://arxiv.org/pdf/2312.14425",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.685418Z"
  },
  {
    "id": "b1e0f4dd254a6fe295b8c05da8fe7454",
    "title": "Enhancing Industrial Flexibility and Market Participation in Cement Manufacturing Through Optimized Production Scheduling",
    "slug": "enhancing-industrial-flexibility-and-market-participation-in-cement-manufacturing-through-optimized-production-scheduling",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Sebastin Rojas-Innocenti",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The growing share of variable renewable energy (VRE) sources in power systems is increasing the need for short term operational flexibility, particularly from large industrial electricity consumers. This study proposes a practical, two stage optimization framework to unlock this flexibility in cement manufacturing and support participation in electricity balancing markets. In Stage 1, a mixed integer linear programming (MILP) model minimizes electricity procurement costs by optimally scheduling the raw milling subsystem. In Stage 2, a flexibility assessment model evaluates profitable deviations, targeting participation in Spain manual Frequency Restoration Reserve (mFRR) market. A real world case study in a Spanish cement plant (including PV and battery storage) shows that flexibility services can yield monthly revenues of up to 800 EUR and paybacks as short as six years. This framework offers a replicable pathway for industrial flexibility in energy intensive sectors.",
    "pdfUrl": "https://arxiv.org/pdf/2403.06573",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.685622Z"
  },
  {
    "id": "ac65bd17f00359ad5353c91ff1cf6d9d",
    "title": "RACH Traffic Prediction in Massive Machine Type Communications",
    "slug": "rach-traffic-prediction-in-massive-machine-type-communications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Hossein Mehri",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Traffic pattern prediction has emerged as a promising approach for efficiently managing and mitigating the impacts of event-driven bursty traffic in massive machine-type communication (mMTC) networks. However, achieving accurate predictions of bursty traffic remains a non-trivial task due to the inherent randomness of events, and these challenges intensify within live network environments. Consequently, there is a compelling imperative to design a lightweight and agile framework capable of assimilating continuously collected data from the network and accurately forecasting bursty traffic in mMTC networks. This paper addresses these challenges by presenting a machine learning-based framework tailored for forecasting bursty traffic in multi-channel slotted ALOHA networks. The proposed machine learning network comprises long-term short-term memory (LSTM) and a DenseNet with feed-forward neural network (FFNN) layers, where the residual connections enhance the training ability of the machine learning network in capturing complicated patterns. Furthermore, we develop a new low-complexity online prediction algorithm that updates the states of the LSTM network by leveraging frequently collected data from the mMTC network. Simulation results and complexity analysis demonstrate the superiority of our proposed algorithm in terms of both accuracy and complexity, making it well-suited for time-critical live scenarios. We evaluate the performance of the proposed framework in a network with a single base station and thousands of devices organized into groups with distinct traffic-generating characteristics. Comprehensive evaluations and simulations indicate that our proposed machine learning approach achieves a remarkable $52\\%$ higher accuracy in long-term predictions compared to traditional methods, without imposing additional processing load on the system.",
    "pdfUrl": "https://arxiv.org/pdf/2405.05235",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.685831Z"
  },
  {
    "id": "c2f6ad91ec06895c08bb00d213d71472",
    "title": "Robust Model Predictive Control Exploiting Monotonicity Properties",
    "slug": "robust-model-predictive-control-exploiting-monotonicity-properties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Moritz Heinlein",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Robust model predictive control algorithms are essential for addressing unavoidable errors due to the uncertainty in predicting real-world systems. However, the formulation of such algorithms typically results in a trade-off between conservatism and computational complexity. Monotone systems facilitate the efficient computation of reachable sets and thus the straightforward formulation of a robust model predictive control approach optimizing over open-loop predictions. We present an approach based on the division of reachable sets to incorporate feedback in the predictions, resulting in less conservative strategies. The concept of mixed-monotonicity enables an extension of our methodology to non-monotone systems. The potential of the proposed approaches is demonstrated through a nonlinear high-dimensional chemical tank reactor cascade case study.",
    "pdfUrl": "https://arxiv.org/pdf/2408.17348",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.686041Z"
  },
  {
    "id": "3e6e6a7dbe8a764493645dcb46b5493a",
    "title": "State Feedback System Level Synthesis in Continuous Time",
    "slug": "state-feedback-system-level-synthesis-in-continuous-time",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Yaozhi Du",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "System level synthesis (SLS) is a controller parameterization technique that facilitates synthesis of structured distributed controllers via convex optimization. Past results on SLS are primarily in the discrete-time setting; this paper extends SLS to the continuous-time setting. We translate the parametrization and associated constraints to continuous-time, and propose a controller design procedure consisting of two steps: (1) selection of poles and (2) optimization over closed-loop responses. We provide SLS parameterizations for continuous-time $\\H2$ and $\\Hinf$ control, and show that the proposed procedure allows us to design structured $\\H2$ and $\\Hinf$ controllers via convex optimization. Furthermore, the proposed procedure preserves the scalability and local-disturbance-rejection features of the original discrete-time SLS framework. We verify our findings in simulation -- on a grid of 9 nodes governed by linearized swing equations, our structured distributed controllers perform similarly to the optimal centralized controllers.",
    "pdfUrl": "https://arxiv.org/pdf/2410.08135",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.686238Z"
  },
  {
    "id": "7964ab47ce394f7625d138aaf054deb3",
    "title": "Automated Discovery of Operable Dynamics from Videos",
    "slug": "automated-discovery-of-operable-dynamics-from-videos",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Kuang Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Dynamical systems form the foundation of scientific discovery, traditionally modeled with predefined state variables such as the angle and angular velocity, and differential equations such as the equation of motion for a single pendulum. We introduce a framework that automatically discovers a low-dimensional and operable representation of system dynamics, including a set of compact state variables that preserve the smoothness of the system dynamics and a differentiable vector field, directly from video without requiring prior domain-specific knowledge. The prominence and effectiveness of the proposed approach are demonstrated through both quantitative and qualitative analyses of a range of dynamical systems, including the identification of stable equilibria, the prediction of natural frequencies, and the detection of of chaotic and limit cycle behaviors. The results highlight the potential of our data-driven approach to advance automated scientific discovery.",
    "pdfUrl": "https://arxiv.org/pdf/2410.11894",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.686430Z"
  },
  {
    "id": "5eefbffefc2d67667e2022be392e0235",
    "title": "A Quadratic Control Framework for Dynamic Systems",
    "slug": "a-quadratic-control-framework-for-dynamic-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Igor Ladnik",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This article presents a unified approach to quadratic optimal control for both linear and nonlinear discrete-time systems, with a focus on trajectory tracking. The control strategy is based on minimizing a quadratic cost function that penalizes deviations of system states and control inputs from their desired trajectories.\nFor linear systems, the classical Linear Quadratic Regulator (LQR) solution is derived using dynamic programming, resulting in recursive equations for feedback and feedforward terms. For nonlinear dynamics, the Iterative Linear Quadratic Regulator (iLQR) method is employed, which iteratively linearizes the system and solves a sequence of LQR problems to converge to an optimal policy.\nTo implement this approach, a software service was developed and tested on several canonical models, including: Rayleigh oscillator, inverted pendulum on a moving cart, two-link manipulator, and quadcopter. The results confirm that iLQR enables efficient and accurate trajectory tracking in the presence of nonlinearities.\nTo further enhance performance, it can be seamlessly integrated with Model Predictive Control (MPC), enabling online adaptation and improved robustness to constraints and system uncertainties.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15396",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.686624Z"
  },
  {
    "id": "7126b2b07f42372a2f6eceba9ea1025c",
    "title": "One-Point Sampling for Distributed Bandit Convex Optimization with Time-Varying Constraints",
    "slug": "one-point-sampling-for-distributed-bandit-convex-optimization-with-time-varying-constraints",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Kunpeng Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper considers the distributed bandit convex optimization problem with time-varying constraints. In this problem, the global loss function is the average of all the local convex loss functions, which are unknown beforehand. Each agent iteratively makes its own decision subject to time-varying inequality constraints which can be violated but are fulfilled in the long run. For a uniformly jointly strongly connected time-varying directed graph, a distributed bandit online primal-dual projection algorithm with one-point sampling is proposed. We show that sublinear dynamic network regret and network cumulative constraint violation are achieved if the path-length of the benchmark also increases in a sublinear manner. In addition, an $\\mathcal{O}({T^{3/4 + g}})$ static network regret bound and an $\\mathcal{O}( {{T^{1 - {g}/2}}} )$ network cumulative constraint violation bound are established, where $T$ is the total number of iterations and $g \\in ( {0,1/4} )$ is a trade-off parameter. Moreover, a reduced static network regret bound $\\mathcal{O}( {T^{2/3 + 4g /3}} )$ is established for strongly convex local loss functions. Finally, a numerical example is presented to validate the theoretical results.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16211",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:28.686846Z"
  },
  {
    "id": "7a3938513794aa157331b6827b6a8ca7",
    "title": "SE(3)-Equivariant Robot Learning and Control: A Tutorial Survey",
    "slug": "se(3)-equivariant-robot-learning-and-control:-a-tutorial-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Joohwan Seo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advances in deep learning and Transformers have driven major breakthroughs in robotics by employing techniques such as imitation learning, reinforcement learning, and LLM-based multimodal perception and decision-making. However, conventional deep learning and Transformer models often struggle to process data with inherent symmetries and invariances, typically relying on large datasets or extensive data augmentation. Equivariant neural networks overcome these limitations by explicitly integrating symmetry and invariance into their architectures, leading to improved efficiency and generalization. This tutorial survey reviews a wide range of equivariant deep learning and control methods for robotics, from classic to state-of-the-art, with a focus on SE(3)-equivariant models that leverage the natural 3D rotational and translational symmetries in visual robotic manipulation and control design. Using unified mathematical notation, we begin by reviewing key concepts from group theory, along with matrix Lie groups and Lie algebras. We then introduce foundational group-equivariant neural network design and show how the group-equivariance can be obtained through their structure. Next, we discuss the applications of SE(3)-equivariant neural networks in robotics in terms of imitation learning and reinforcement learning. The SE(3)-equivariant control design is also reviewed from the perspective of geometric control. Finally, we highlight the challenges and future directions of equivariant methods in developing more robust, sample-efficient, and multi-modal real-world robotic systems.",
    "pdfUrl": "https://arxiv.org/pdf/2503.09829",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:28.687071Z"
  },
  {
    "id": "9e0938a463a1e6b4620bbf0d7fdfeb04",
    "title": "A three-axis Nanopositioner based on Near-Field Acoustic Levitation and Electromagnetic Actuation",
    "slug": "a-three-axis-nanopositioner-based-on-near-field-acoustic-levitation-and-electromagnetic-actuation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Applied Physics (physics.app-ph)",
    "author": {
      "name": "K. S. Vikrant",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Near-field acoustic levitation (NFAL) enables nanometer-scale positioning resolution and bandwidth exceeding several hundred hertz specifically along the vertical (Z) direction, owing to its high acoustic stiffness and squeeze film damping. However, its application to horizontal (XY) positioning is limited by significantly lower acoustic stiffness and insufficient damping in horizontal directions, resulting in reduced resolution and bandwidth. Moreover, NFAL-based positioning systems typically lack multi-axis actuation capabilities due to challenges in generating multi-directional acoustic forces. This work presents a hybrid positioning approach that overcomes the mentioned limitations by integrating NFAL with electromagnetic actuation. A planar magnetic platform is acoustically levitated, while a coplanar current-carrying coil provides horizontal trapping stiffness more than three orders of magnitude higher than that achievable with acoustic forces alone. Additionally, the coil generates three-dimensional electromagnetic forces, enabling multi-axis positioning capability. Eddy currents induced in a thin copper sheet integrated with the coil enhance horizontal damping by 52 times. We experimentally demonstrate precise 3-axis linear motion with a root mean square (RMS) positioning resolution better than 20 nm along all axes. The system achieves an in-plane motion range of 1.42 mm with a bandwidth of 16 Hz and a Z-axis motion range of 40 micrometers with a positioning bandwidth of 171 Hz.",
    "pdfUrl": "https://arxiv.org/pdf/2503.19175",
    "tags": [
      "Applied Physics (physics.app-ph)"
    ],
    "createdAt": "2025-04-25T15:49:28.687267Z"
  },
  {
    "id": "0d2f5ee4439c5061ae0bdea3ea6b7c2e",
    "title": "Fast Online Adaptive Neural MPC via Meta-Learning",
    "slug": "fast-online-adaptive-neural-mpc-via-meta-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Robotics (cs.RO)",
    "author": {
      "name": "Yu Mei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Data-driven model predictive control (MPC) has demonstrated significant potential for improving robot control performance in the presence of model uncertainties. However, existing approaches often require extensive offline data collection and computationally intensive training, limiting their ability to adapt online. To address these challenges, this paper presents a fast online adaptive MPC framework that leverages neural networks integrated with Model-Agnostic Meta-Learning (MAML). Our approach focuses on few-shot adaptation of residual dynamics - capturing the discrepancy between nominal and true system behavior - using minimal online data and gradient steps. By embedding these meta-learned residual models into a computationally efficient L4CasADi-based MPC pipeline, the proposed method enables rapid model correction, enhances predictive accuracy, and improves real-time control performance. We validate the framework through simulation studies on a Van der Pol oscillator, a Cart-Pole system, and a 2D quadrotor. Results show significant gains in adaptation speed and prediction accuracy over both nominal MPC and nominal MPC augmented with a freshly initialized neural network, underscoring the effectiveness of our approach for real-time adaptive robot control.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16369",
    "tags": [
      "Robotics (cs.RO)"
    ],
    "createdAt": "2025-04-25T15:49:28.687469Z"
  },
  {
    "id": "336815390c4d08e2959be5e660e698d0",
    "title": "Algebraic properties of tensor product of modules over a field",
    "slug": "algebraic-properties-of-tensor-product-of-modules-over-a-field",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Commutative Algebra (math.AC)",
    "author": {
      "name": "Ahad Rahimi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $A$ and $B$ be commutative Noetherian algebras over an arbitrary field $\\Bbbk$ such that $A \\otimes_\\Bbbk B$ is Noetherian. We consider ideals $I$ and $J$ of $A$ and $B$, respectively, as well as nonzero finitely generated modules $L$ and $N$ over $A$ and $B$, respectively. In this paper, we investigate certain algebraic properties of the $A \\otimes_\\Bbbk B$-module $L\\otimes_{\\Bbbk} N$, which are often inherited from the properties of the $A$-module $L$ and the $B$-module $N$. Specifically, we provide characterizations for the Cohen-Macaulayness, generalized Cohen-Macaulayness, and sequentially Cohen-Macaulayness of $L\\otimes_{\\Bbbk} N$ with respect to the ideal $I \\otimes_\\Bbbk B + A \\otimes_\\Bbbk J$, in terms of the corresponding properties for $L$ and $N$ with respect to $I$ and $J$, respectively.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17217",
    "tags": [
      "Commutative Algebra (math.AC)"
    ],
    "createdAt": "2025-04-25T15:49:29.410091Z"
  },
  {
    "id": "cb099b90fa768c901ffb04b757400fd7",
    "title": "An Upper Bound on Generalized Cospectral Mates of Oriented Graphs Using Skew-Walk Matrices",
    "slug": "an-upper-bound-on-generalized-cospectral-mates-of-oriented-graphs-using-skew-walk-matrices",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Muhammad Raza",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $D$ be an oriented graph with skew adjacency matrix $S(D)$. Two oriented graphs $D$ and $C$ are said to share the same generalized skew spectrum if $S(D)$ and $S(C)$ have the same eigenvalues, and $J-S(D)$ and $J-S(C)$ also have the same eigenvalues, where $J$ is the all-ones matrix. Such graphs that are not isomorphic are generalized cospectral mates. We derive tight upper bounds on the number of non-isomorphic generalized cospectral mates an oriented graph can admit, based on arithmetic criteria involving the determinant of its skew-walk matrix. As a special case, we also provide a criterion for an oriented graph to be weakly determined by its generalized skew spectrum (WDGSS), that is, its only generalized cospectral mate is its transpose. These criteria relate directly to the controllability of graphs, a fundamental concept in the control of networked systems, thereby connecting spectral characterization of graphs to graph controllability.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17278",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:29.410306Z"
  },
  {
    "id": "0e6c3d2cc0abd3b6dee224aa31bf8e3c",
    "title": "A mixed characteristic analogue of the perfection of rings and its almost Cohen-Macaulay property",
    "slug": "a-mixed-characteristic-analogue-of-the-perfection-of-rings-and-its-almost-cohen-macaulay-property",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Commutative Algebra (math.AC)",
    "author": {
      "name": "Ryo Ishizuka",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Over a complete Noetherian local domain of mixed characteristic with perfect residue field, we construct a perfectoid ring which is similar to an explicit representation of a perfect closure in positive characteristic. Then we demonstrate that this perfectoid ring is almost Cohen-Macaulay in the sense of almost ring theory. The proof of this result uses Andr's flatness lemma along with Riemann's extension theorem. We stress that the idea partially originates from the \"perfectoidization\" in the theory of prismatic cohomology.",
    "pdfUrl": "https://arxiv.org/pdf/2303.13872",
    "tags": [
      "Commutative Algebra (math.AC)"
    ],
    "createdAt": "2025-04-25T15:49:29.410656Z"
  },
  {
    "id": "fc4eb2638ba5380842f8340224bf082d",
    "title": "Tensor products of $d$-fold matrix factorizations",
    "slug": "tensor-products-of-$d$-fold-matrix-factorizations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Commutative Algebra (math.AC)",
    "author": {
      "name": "Richie Sheng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Consider a pair of elements $f$ and $g$ in a commutative ring $Q$. Given a matrix factorization of $f$ and another of $g$, the tensor product of matrix factorizations, which was first introduced by Knrrer and later generalized by Yoshino, produces a matrix factorization of the sum $f+g$. We will study the tensor product of $d$-fold matrix factorizations, with a particular emphasis on understanding when the construction has a non-trivial direct sum decomposition. As an application of our results, we construct indecomposable maximal Cohen-Macaulay and Ulrich modules over hypersurface domains of a certain form.",
    "pdfUrl": "https://arxiv.org/pdf/2407.05072",
    "tags": [
      "Commutative Algebra (math.AC)"
    ],
    "createdAt": "2025-04-25T15:49:29.410921Z"
  },
  {
    "id": "cff28598a5031e98ab4495aa473f099d",
    "title": "$F$-pure threshold for the symmetric determinantal ring",
    "slug": "$f$-pure-threshold-for-the-symmetric-determinantal-ring",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Commutative Algebra (math.AC)",
    "author": {
      "name": "Justin Fong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We give a value for the $F$-pure threshold at the maximal homogeneous ideal $\\mathfrak{m}$ of the symmetric determinantal ring over a field of prime characteristic. The answer is characteristic independent, so we immediately get the log canonical threshold in characteristic zero as well.",
    "pdfUrl": "https://arxiv.org/pdf/2407.09978",
    "tags": [
      "Commutative Algebra (math.AC)"
    ],
    "createdAt": "2025-04-25T15:49:29.411119Z"
  },
  {
    "id": "6d8bc0a3d77f5d6c0a267d4c3648944a",
    "title": "Monomial ideals whose all matching powers are Cohen-Macaulay",
    "slug": "monomial-ideals-whose-all-matching-powers-are-cohen-macaulay",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Commutative Algebra (math.AC)",
    "author": {
      "name": "Antonino Ficarra",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the present paper, we aim to classify monomial ideals whose all matching powers are Cohen-Macaulay. We especially focus our attention on edge ideals. The Cohen-Macaulayness of the last matching power of an edge ideal is characterized, providing an algebraic analogue of the famous Tutte theorem regarding graphs having a perfect matching. For chordal graphs, very well-covered graphs and Cameron-Walker graphs, we completely solve our problem.",
    "pdfUrl": "https://arxiv.org/pdf/2410.01666",
    "tags": [
      "Commutative Algebra (math.AC)"
    ],
    "createdAt": "2025-04-25T15:49:29.411309Z"
  },
  {
    "id": "a41c763d04f0f214d39aee892f2dce5a",
    "title": "The $F$-pure threshold of a Schubert cycle",
    "slug": "the-$f$-pure-threshold-of-a-schubert-cycle",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Commutative Algebra (math.AC)",
    "author": {
      "name": "Justin Fong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The $F$-pure threshold is the characteristic $p$ counter part of the log canonical threshold in characteristic zero. It is a numerical invariant associated to the singularities of a variety, hence computing its value is important. We give a closed formula for the $F$-pure threshold of the irrelevant maximal ideal of Schubert cycles, which are the homogeneous coordinate rings of Schubert subvarieties of a Grassmannian. The main point of the computation is to give an explicit formula for the $a$-invariant of a Schubert cycle. The derivation of both formulas is made possible through the combinatorics of the underlying poset of these rings.",
    "pdfUrl": "https://arxiv.org/pdf/2502.09559",
    "tags": [
      "Commutative Algebra (math.AC)"
    ],
    "createdAt": "2025-04-25T15:49:29.411507Z"
  },
  {
    "id": "0e6f4c533799b4c1fc61dfce31b0e46a",
    "title": "Computing the $F$-pure Threshold of Flag Varieties",
    "slug": "computing-the-$f$-pure-threshold-of-flag-varieties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Justin Fong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We compute the $F$-pure threshold of the natural cone over flag varieties in characteristic $p>0$. Our calculations are mainly focused on flag varieties that are arithmetically Gorenstein, but we offer some results in the non-Gorenstein case. Our goal is to determine the $a$-invariant of the cone. As a result, the $F$-pure thresholds we find are independent of the characteristic $p$, hence one immediately gets the value of the log canonical threshold of flags in characteristic 0 as well.",
    "pdfUrl": "https://arxiv.org/pdf/2311.06908",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.411694Z"
  },
  {
    "id": "68fe541c4ee2f7851492c8d48e04ae45",
    "title": "Higher Koszul duality and $n$-affineness",
    "slug": "higher-koszul-duality-and-$n$-affineness",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "James Pascaleff",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study $\\mathbb{E}_n$-Koszul duality for pairs of algebras of the form $\\mathrm{C}_{\\bullet}(\\Omega^{n}_*X;\\Bbbk) \\leftrightarrow \\mathrm{C}^{\\bullet}(X;\\Bbbk)$, and the closely related question of $n$-affineness for Betti stacks. It was expected, but not known, that $\\mathbb{E}_n$-Koszul duality should induce a kind of Morita equivalence between categories of iterated modules. We establish this rigorously by proving that the $(\\infty,n)$-category of iterated modules over $\\mathrm{C}_{\\bullet}(\\Omega_*^{n+1}X;\\Bbbk)$ is equivalent to the $(\\infty,n)$-category of quasi-coherent sheaves of $(\\infty,n-1)$-categories on $\\mathrm{cSpec}(\\mathrm{C}^{\\bullet}(X;\\Bbbk))$, where $\\mathrm{cSpec}(\\mathrm{C}^{\\bullet}(X;\\Bbbk))$ is the cospectrum of $\\mathrm{C}^{\\bullet}(X;\\Bbbk)$. By the monodromy equivalence, these categories are also equivalent to the category of higher local systems on $X$, $n\\mathbf{LocSysCat}^{n-1}(X;\\Bbbk)$. Our result is new already in the classical case $n=1$, although it can be seen to recover well known formulations of $\\mathbb{E}_1$-Koszul duality as a Morita equivalence of module categories (up to appropriate completions of the $t$-structures). We also investigate (higher) affineness properties of Betti stacks. We give a complete characterization of $n$-affine Betti stacks, in terms of the $0$-affineness of their iterated loop space. As a consequence, we prove that $n$-truncated Betti stacks are $n$-affine; and that $\\pi_{n+1}(X)$ is an obstruction to $n$-affineness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16935",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.706319Z"
  },
  {
    "id": "a1986248cc44f0305c657d984e7ec31c",
    "title": "A bi-Lipschitz invariant for analytic function germs",
    "slug": "a-bi-lipschitz-invariant-for-analytic-function-germs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Nhan Nguyen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we introduce a new bi-Lipschitz invariant for analytic function germs in two variables, enhancing the Henry-Parusinski invariant.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17250",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.706526Z"
  },
  {
    "id": "0235611e97fab09fb365f2c9c6065306",
    "title": "Complexity one varieties are cluster type",
    "slug": "complexity-one-varieties-are-cluster-type",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Joshua Enwright",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The complexity of a pair $(X,B)$ is an invariant that relates the dimension of $X$, the rank of the group of divisors, and the coefficients of $B$. If the complexity is less than one, then $X$ is a toric variety. We prove that if the complexity is less than two, then $X$ is a Fano type variety. Furthermore, if the complexity is less than 3/2, then $X$ admits a Calabi--Yau structure $(X,B)$ of complexity one and index at most two, and it admits a finite cover $Y \\to X$ of degree at most 2, where $Y$ is a cluster type variety. In particular, if the complexity is one and the index is one, $(X,B)$ is cluster type. Finally, we establish a connection with the theory of $\\mathbb{T}$-varieties. We prove that a variety of $\\mathbb{T}$-complexity one admits a similar finite cover from a cluster type variety.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17369",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.706727Z"
  },
  {
    "id": "8277d38ee4bba3c94766a3307c83f5c5",
    "title": "Odd fake $\\mathbb{Q}$ -homology quadrics exist",
    "slug": "odd-fake-$\\mathbb{q}$--homology-quadrics-exist",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Fabrizio Catanese",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We show the existence of odd fake $\\mathbb{Q}$-homology quadrics, namely of minimal surfaces $S$ of general type which have the same $\\mathbb{Q}$-homology as a smooth quadric $Q \\cong (\\mathbb{P}^1(\\mathbb{C}))^2$, but have an odd intersection form on $ H^2(S, \\mathbb{Z})/Tors(S)$, where $Tors(S)$ is the Torsion subgroup.\nOur examples are provided by a special 1-dimensional family of surfaces isogenous to a product of unmixed type.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17475",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.706919Z"
  },
  {
    "id": "176d636a7bd4e957beec7e0b12ede20b",
    "title": "On unitary Shimura varieties at ramified primes",
    "slug": "on-unitary-shimura-varieties-at-ramified-primes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Yu Luo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider unitary Shimura varieties at places where the totally real field ramifies over $\\mbQ$. Our first result constructs comparison isomorphisms between absolute and relative local models in this context which relies on a reformulation of the Eisenstein condition of Rapoport--Zink and Rapoport--Smithling--Zhang. Our second result lifts this comparison to categories of $p$-divisible groups and, as a corollary, to various kinds of Rapoport--Zink spaces. This unifies multiple previously known results in this direction. Our third result and main application is to the arithmetic transfer conjecture of the third author. Using our statements about Rapoport--Zink spaces, we extend his previous proof from the unramified case to that of all $p$-adic local fields (for odd $p$). In general, our results have similar applications to other problems around the arithmetic of Shimura varieties as well, removing several ramification assumptions in the literature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17484",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.707110Z"
  },
  {
    "id": "b77c07ed4e0700e1041578e47b47915c",
    "title": "Desingularization of double covers of regular surfaces",
    "slug": "desingularization-of-double-covers-of-regular-surfaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Qing Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $Z$ be a noetherian integral excellent regular scheme of dimension $2$. Let $Y$ be an integral normal scheme endowed with a finite flat morphism $Y\\to Z$ of degree $2$. We give a description of Lipman's desingularization of $Y$ by explicit equations, leading to a desingularization algorithm for $Y$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16808",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:29.707299Z"
  },
  {
    "id": "393a31d16853f87dcc0fff93f365e22e",
    "title": "Insertion algorithms and pattern avoidance on trees arising in the Kapranov embedding of $\\overline{M}_{0,n+3}$",
    "slug": "insertion-algorithms-and-pattern-avoidance-on-trees-arising-in-the-kapranov-embedding-of-$\\overline{m}_{0,n+3}$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Andrew Reimer-Berg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We resolve a question of Gillespie, Griffin, and Levinson that asks for a combinatorial bijection between two classes of trivalent trees, tournament trees and slide trees, that both naturally arise in the intersection theory of the moduli space $\\overline{M}_{0,n+3}$ of stable genus zero curves with $n+3$ marked points. Each set of trees enumerates the same intersection product of certain pullbacks of $\\psi$ classes under forgetting maps.\nWe give an explicit combinatorial bijection between these two sets of trees using an insertion algorithm. We also classify the words that appear on the slide trees of caterpillar shape via pattern avoidance conditions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17098",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:29.707483Z"
  },
  {
    "id": "a23107e80d01199e56a792eb78373fed",
    "title": "Hochschild (Co)homology of D-modules on rigid analytic spaces II",
    "slug": "hochschild-(co)homology-of-d-modules-on-rigid-analytic-spaces-ii",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Fernando Pea Vzquez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $X$ be a smooth $p$-adic Stein space with free tangent sheaf. We use the notion of Hochschild cohomology for sheaves of Ind-Banach algebras developed in our previous work to study the Hochschild cohomology of the algebra of infinite order differential operators $\\mathcal{D}_X$-cap. In particular, we show that the Hochschild cohomology complex of $\\mathcal{D}_X$-cap is a strict complex of nuclear Frchet spaces which is quasi-isomorphic to the de Rham complex of $X$. We then use this to compare the first Hochschild cohomology group of $\\mathcal{D}_X$-cap with a wide array of Ext functors. Finally, we investigate the relation of the Hochschild cohomology of $\\mathcal{D}_X$-cap with the deformation theory of $\\mathcal{D}_X(X)$-cap. Assuming some finiteness conditions on the de Rham cohomology of $X$, we define explicit isomorphisms between the first Hochschild cohomology group of $\\mathcal{D}_X$-cap and the space of bounded outer derivations of $\\mathcal{D}_X(X)$-cap, and between the second Hochschild cohomology group of $\\mathcal{D}_X$-cap and the space of infinitesimal deformations of $\\mathcal{D}_X(X)$-cap.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17167",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:29.707680Z"
  },
  {
    "id": "46da9d3fa4cdcabaaabeacea33f02c73",
    "title": "Formal Manifold Structures on Positive Characteristic Varieties",
    "slug": "formal-manifold-structures-on-positive-characteristic-varieties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Runjie Hu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In his ICM report, Sullivan proposes the program of l-adic formalization of the concept of manifolds. In this program, he claims that smooth positive characteristic varieties should carry l-adic formal manifold structures. He also claims the existence of an abelianized Galois symmetry on l-adic formal manifold structures. This paper carries out this program, establishes the claims, and relates the abelianized Galois symmetry on l-adic formal manifold structures to the Galois symmetry of varieties. Meanwhile, we prove that simply-connected varieties are homotopically finite CW complexes in the l-adic sense.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17221",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:29.707874Z"
  },
  {
    "id": "ed0c21fe5c18c4a92f97285d512e12e1",
    "title": "Cyclic Nielsen realization for del Pezzo surfaces",
    "slug": "cyclic-nielsen-realization-for-del-pezzo-surfaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Seraphina Eun Bi Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The cyclic Nielsen realization problem for a closed, oriented manifold asks whether any mapping class of finite order can be represented by a homeomorphism of the same order. In this article, we resolve the smooth, metric, and complex cyclic Nielsen realization problem for certain \"irreducible\" mapping classes on the family of smooth 4-manifolds underlying del Pezzo surfaces. Both positive and negative examples of realizability are provided in various settings. Our techniques are varied, synthesizing results from reflection group theory and 4-manifold topology.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17235",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:29.708072Z"
  },
  {
    "id": "2bef3343311db9fb7e80142e6e23d79e",
    "title": "Stratifying quiver Schur algebras via ersatz parity sheaves",
    "slug": "stratifying-quiver-schur-algebras-via-ersatz-parity-sheaves",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Ruslan Maksimau",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose an extension of the theory of parity sheaves, which allows for non-locally constant sheaves along strata. Our definition is tailored for proving the existence of (proper, quasihereditary, etc) stratifications of $\\mathrm{Ext}$-algebras. We use this to study quiver Schur algebras $A(\\alpha)$ for the cyclic quiver of length $2$. We find a polynomial quasihereditary structure on $A(\\alpha)$ compatible with the categorified PBW basis of McNamara and Kleshchev-Muth, and sharpen their results to arbitrary characteristic. We also prove that semicuspidal algebras of $A(n\\delta)$ are polynomial quasihereditary covers of semicuspidal algebras of the corresponding KLR algebra $R(n\\delta)$, and compute them diagrammatically.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17430",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:29.708265Z"
  },
  {
    "id": "0e6f4c533799b4c1fc61dfce31b0e46a",
    "title": "Computing the $F$-pure Threshold of Flag Varieties",
    "slug": "computing-the-$f$-pure-threshold-of-flag-varieties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Justin Fong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We compute the $F$-pure threshold of the natural cone over flag varieties in characteristic $p>0$. Our calculations are mainly focused on flag varieties that are arithmetically Gorenstein, but we offer some results in the non-Gorenstein case. Our goal is to determine the $a$-invariant of the cone. As a result, the $F$-pure thresholds we find are independent of the characteristic $p$, hence one immediately gets the value of the log canonical threshold of flags in characteristic 0 as well.",
    "pdfUrl": "https://arxiv.org/pdf/2311.06908",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.708453Z"
  },
  {
    "id": "1ddc42e3ed34c851e81ac325e2552645",
    "title": "Moduli of finite flat torsors over nodal curves",
    "slug": "moduli-of-finite-flat-torsors-over-nodal-curves",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Sara Mehidi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We show that log flat torsors over a family $X/S$ of nodal curves under a finite flat commutative group scheme $G/S$ are classified by maps from the Cartier dual of $G$ to the log Jacobian of $X$. We deduce that fppf torsors on the smooth fibres of $X/S$ can be extended to global log flat torsors under some regularity hypotheses.",
    "pdfUrl": "https://arxiv.org/pdf/2407.10924",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.708653Z"
  },
  {
    "id": "8d8367b5cba14fad60b183ad77d74b71",
    "title": "The tempered disk and the tempered cohomology",
    "slug": "the-tempered-disk-and-the-tempered-cohomology",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Federico Bambozzi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Consider a non-archimedean valuation ring V (K its fraction field, in mixed characteristic): inspired by some views presented by Scholze, we introduce a new point of view on the non-archimedean analytic setting in terms of derived analytic geometry (then associating a \"spectrum\" to each ind-Banach algebra). We want to look at the behaviour of this spectrum from a differential point of view. In such a spectrum, for example, there exist open subsets having functions with log-growth as sections for the structural sheaf. In this framework, a transfer theorem for the log-growth of solutions of p-adic differential equations can be interpreted as a continuity theorem (analogue to the transfer theorem for their radii of convergence in the Berkovich spaces). As a dividend of such a theory, we define a new cohomology theory in terms of the Hodge-completed derived de Rham cohomology of the ind-Banach derived analytic space associated to a smooth k-scheme, X_k (k residual field of V), via the use of \"tempered tubes\".\nWe finally compare our tempered de Rham cohomology with crystalline cohomology.",
    "pdfUrl": "https://arxiv.org/pdf/2410.09473",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.708851Z"
  },
  {
    "id": "b4d3c1dca46eef5bd25381363c949375",
    "title": "Harmonic covers of skeleta",
    "slug": "harmonic-covers-of-skeleta",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Art Waeterschoot",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The geometry of a toroidal scheme over a DVR is encoded in a $\\mathbb{Z}$-PL space known as the dual polyhedral complex. Any such dual complex is a skeleton, i.e. a nonarchimedean analytic retract, and admits a combinatorial divisor theory via specialisation. These structures on the dual complex interact via a Poincar-Lelong slope formula, which interprets specialisations of divisors as Laplacians of PL functions. The main result presented here shows that finite covers of toroidal schemes give harmonic morphisms of dual complexes, i.e. morphisms that preserve the tropical Laplace equation. A crucial ingredient is a balancing condition which is a variant of the tropical multiplicity formula for dual complexes. We apply these results to obtain a Riemann-Hurwitz formula for covers of skeleta in any dimension: the Laplacian of the different function is the tropical relative canonical divisor.",
    "pdfUrl": "https://arxiv.org/pdf/2503.13875",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.709041Z"
  },
  {
    "id": "e6987a871eea54a545aeb00bfc4bd6f6",
    "title": "Completion of motivic sheaves",
    "slug": "completion-of-motivic-sheaves",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Denis-Charles Cisinski",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the process of $\\ell$-adic completion of motivic sheaves. We observe that, in equal characteristic, when restricted to constructible objets, it is compatible with the six operations. This implies that one can reconstruct $\\ell$-adic sheaves of geometric origin over a scheme of finite type over a field from $\\ell$-adic cohomology of smooth schemes. In the case of finite fields, this includes perverse $\\ell$-adic sheaves of geometric orgin. However, the analogous behaviour fails systematically in mixed characteristic: the reason is that it would imply strong independence of $\\ell$ results that can be proven to be too optimistic.",
    "pdfUrl": "https://arxiv.org/pdf/2503.24033",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:29.709230Z"
  },
  {
    "id": "0e6c3d2cc0abd3b6dee224aa31bf8e3c",
    "title": "A mixed characteristic analogue of the perfection of rings and its almost Cohen-Macaulay property",
    "slug": "a-mixed-characteristic-analogue-of-the-perfection-of-rings-and-its-almost-cohen-macaulay-property",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Commutative Algebra (math.AC)",
    "author": {
      "name": "Ryo Ishizuka",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Over a complete Noetherian local domain of mixed characteristic with perfect residue field, we construct a perfectoid ring which is similar to an explicit representation of a perfect closure in positive characteristic. Then we demonstrate that this perfectoid ring is almost Cohen-Macaulay in the sense of almost ring theory. The proof of this result uses Andr's flatness lemma along with Riemann's extension theorem. We stress that the idea partially originates from the \"perfectoidization\" in the theory of prismatic cohomology.",
    "pdfUrl": "https://arxiv.org/pdf/2303.13872",
    "tags": [
      "Commutative Algebra (math.AC)"
    ],
    "createdAt": "2025-04-25T15:49:29.709420Z"
  },
  {
    "id": "f40b95b6d5bd7da9a6cf6802ab7e0ff5",
    "title": "The prismatic realization functor for Shimura varieties of abelian type",
    "slug": "the-prismatic-realization-functor-for-shimura-varieties-of-abelian-type",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Naoki Imai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "For the integral canonical model $\\mathscr{S}_{\\mathsf{K}^p}$ of a Shimura variety $\\mathrm{Sh}_{\\mathsf{K}_0\\mathsf{K}^p}(\\mathbf{G},\\mathbf{X})$ of abelian type at hyperspecial level $K_0=\\mathcal{G}(\\mathbb{Z}_p)$, we construct a prismatic $F$-gauge model for the `universal' $\\mathcal{G}(\\mathbb{Z}_p)$-local system on $\\mathrm{Sh}_{\\mathsf{K}_0\\mathsf{K}^p}(\\mathbf{G},\\mathbf{X})$. We use this to obtain several new results about the $p$-adic geometry of Shimura varieties, notably an abelian-type analogue of the Serre--Tate deformation theorem (realizing an expectation of Drinfeld in the abelian-type case) and a prismatic characterization of these models at individual level.",
    "pdfUrl": "https://arxiv.org/pdf/2310.08472",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:29.709620Z"
  },
  {
    "id": "cb9749315ea6f6b6752111ab5a702882",
    "title": "Four dimensional almost complex torus manifolds",
    "slug": "four-dimensional-almost-complex-torus-manifolds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Differential Geometry (math.DG)",
    "author": {
      "name": "Donghoon Jang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In dimension 4, we extend the correspondence between compact nonsingular toric varieties and regular fans to a correspondence between almost complex torus manifolds and families of multi-fans in a geometric way, where an (almost) complex torus manifold is a $2n$-dimensional compact connected (almost) complex manifold equipped with an effective action of a real $n$-dimensional torus $T^n$ that has fixed points.\nLet $M$ be a 4-dimensional almost complex torus manifold. To $M$, we associate two equivalent combinatorial objects, a family $\\Delta$ of multi-fans and a graph $\\Gamma$, which encode the data on the fixed point set. We find a necessary and sufficient condition for each of $\\Delta$ and $\\Gamma$.\nMoreover, we provide a minimal model and operations for each of $\\Delta$ and $\\Gamma$. We introduce operations on a multi-fan and a graph that correspond to blow up and down of a manifold, and show that we can blow up and down $M$ to a minimal manifold $M'$ whose weights at the fixed points are unit vectors in $\\mathbb{Z}^2$, $\\Delta$ to a family of minimal multi-fans that has unit vectors only, and $\\Gamma$ to a minimal graph whose edges all have unit vectors as labels.\nAs an application, if $M$ is complex, $\\Delta$ is a fan and determines $M$, $\\Gamma$ encodes the equivariant cohomology of $M$, and $M'$ is $\\mathbb{CP}^1 \\times \\mathbb{CP}^1$. This implies that any two 4-dimensional complex torus manifolds are obtained from each other by equivariant blow up and down.",
    "pdfUrl": "https://arxiv.org/pdf/2310.11024",
    "tags": [
      "Differential Geometry (math.DG)"
    ],
    "createdAt": "2025-04-25T15:49:29.709835Z"
  },
  {
    "id": "7bcbfdb97c1a726758db25474e4b22cd",
    "title": "Bordism and resolution of singularities",
    "slug": "bordism-and-resolution-of-singularities",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Mohammed Abouzaid",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We adapt algorithms for resolving the singularities of complex algebraic varieties to prove that the natural map of homology theories from complex bordism to the bordism theory of complex derived orbifolds splits. In equivariant stable homotopy theory, our techniques yield a splitting of homology theories for the map from bordism to the equivariant bordism theory of a finite group $\\Gamma$, given by assigning to a manifold its product with $\\Gamma$. In symplectic topology, and using recent work of Abouzaid-McLean-Smith and Hirschi-Swaminathan, we conclude that one can define complex cobordism-valued Gromov-Witten invariant for arbitrary (closed) symplectic manifolds. We apply our results to constrain the topology of the space of Hamiltonian fibrations over $S^2$. The methods we develop apply to normally complex orbifolds, and will hence lead to applications in symplectic topology that rely on moduli spaces of holomorphic curves with Lagrangian boundary conditions.",
    "pdfUrl": "https://arxiv.org/pdf/2412.04451",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:29.710025Z"
  },
  {
    "id": "9ed3635dd4359baefcfbcfb6ecb3e343",
    "title": "Isolated points on modular curves",
    "slug": "isolated-points-on-modular-curves",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Kenji Terao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study isolated points on the modular curves $X_{H}$, for $H$ a subgroup of $\\operatorname{GL}_{2}(\\mathbb{Z}/n \\mathbb{Z})$ for some $n \\geq 1$. In particular, we prove a single-source theorem for such isolated points, which traces the existence of all such isolated points with the same $j$-invariant back to an isolated point on a single curve. Building on this result, we also present a uniform strategy for determining the isolated points on any family of modular curves. As an example, we use this strategy to classify the isolated points with rational $j$-invariant on all modular curves of level 7, as well as the modular curves $X_{0}(n)$, the latter assuming a conjecture on images of Galois representations of elliptic curves over $\\mathbb{Q}$.",
    "pdfUrl": "https://arxiv.org/pdf/2412.13108",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:29.710210Z"
  },
  {
    "id": "1c977c239079943072c844e92f4e0a5f",
    "title": "Global stability for compressible isentropic Navier-Stokes equations in 3D bounded domains with Navier-slip boundary conditions",
    "slug": "global-stability-for-compressible-isentropic-navier-stokes-equations-in-3d-bounded-domains-with-navier-slip-boundary-conditions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Yang Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the global stability of large solutions to the compressible isentropic Navier-Stokes equations in a three-dimensional (3D) bounded domain with Navier-slip boundary conditions. It is shown that the strong solutions converge to an equilibrium state exponentially in the $L^2$-norm provided the density is essentially uniform-in-time bounded from above. Moreover, we obtain that the density converges to its equilibrium state exponentially in the $L^\\infty$-norm if additionally the initial density is bounded away from zero. Furthermore, we derive that the vacuum states will not vanish for any time provided vacuum appears (even at a point) initially. This is the first result concerning the global stability for large strong solutions of compressible Navier-Stokes equations with vacuum in 3D general bounded domains.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17136",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.056121Z"
  },
  {
    "id": "ba61debda0da19737fa476552e731f5e",
    "title": "A Diffuse Domain Approximation with Transmission-Type Boundary Conditions II: Gamma--Convergence",
    "slug": "a-diffuse-domain-approximation-with-transmission-type-boundary-conditions-ii:-gamma--convergence",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Toai Luong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Diffuse domain methods (DDMs) have gained significant attention for solving partial differential equations (PDEs) on complex geometries. These methods approximate the domain by replacing sharp boundaries with a diffuse layer of thickness $\\varepsilon$, which scales with the minimum grid size. This reformulation extends the problem to a regular domain, incorporating boundary conditions via singular source terms. In this work, we analyze the convergence of a DDM approximation problem with transmission-type Neumann boundary conditions. We prove that the energy functional of the diffuse domain problem $\\Gamma$--converges to the energy functional of the original problem as $\\varepsilon \\to 0$. Additionally, we show that the solution of the diffuse domain problem strongly converges in $H^1(\\Omega)$, up to a subsequence, to the solution of the original problem, as $\\varepsilon \\to 0$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17148",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.056342Z"
  },
  {
    "id": "09c61747b326529472802036d5ecd7a4",
    "title": "The critical power of short pulse initial data on the global existence or blowup of smooth solutions to 3-D semilinear Klein-Gordon equations",
    "slug": "the-critical-power-of-short-pulse-initial-data-on-the-global-existence-or-blowup-of-smooth-solutions-to-3-d-semilinear-klein-gordon-equations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Jindou Shen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is well-known that there are global small data smooth solutions for the 3-D semilinear Klein-Gordon equations $\\square u + u = F(u,{\\partial u})$ with cubic nonlinearities. However, for the short pulse initial data $(u, \\partial_tu)(0, x)=({\\delta^{\\nu+1}}{u_0}({\\frac{x}{\\delta}}),{\\delta^\\nu }{u_1}({\\frac{x}{\\delta}}))$ with $\\nu\\in\\Bbb R$ and $(u_0, u_1)\\in C_0^{\\infty}(\\Bbb R)$, which are a class of large initial data, we establish that when $\\nu\\le -\\frac{1}{2}$, the solution $u$ can blow up in finite time for some suitable choices of $(u_0, u_1)$ and cubic nonlinearity $F(u,{\\partial u})$; when $\\nu>-\\frac{1}{2}$, the smooth solution $u$ exists globally. Therefore, $\\nu=-\\frac{1}{2}$ is just the critical power corresponding to the global existence or blowup of smooth\nshort pulse solutions for the cubic semilinear Klein-Gordon equations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17169",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.056701Z"
  },
  {
    "id": "415f5da299e84ccebc7e01700bbf61c7",
    "title": "Horizontally periodic generalized surface quasigeostrophic patches and layers",
    "slug": "horizontally-periodic-generalized-surface-quasigeostrophic-patches-and-layers",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "David M. Ambrose",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study solutions to the $\\alpha$-SQG equations, which interpolate between the incompressible Euler and surface quasi-geostrophic equations. We extend prior results on existence of bounded patches, proving propagation of $H^k$-regularity of the patch boundary, $k \\ge 3$, for finite time for patches that are periodic in one spatial dimension. Such periodic patches also encompass layers, or two-sided fronts. As the authors have treated the Euler case in prior work, we now primarily focus on the range of $\\alpha$ for which $\\alpha$-SQG lies strictly between the Euler and SQG equations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17199",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.057027Z"
  },
  {
    "id": "10c88fdd4858893954e6a4686ecc897a",
    "title": "Some remarks on Liouville type theorems for the 3D steady tropical climate model",
    "slug": "some-remarks-on-liouville-type-theorems-for-the-3d-steady-tropical-climate-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Yanyan Dong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Observing the special structure of the system and using the Poincar{}-Sobolev inequality, we establish Liouville type theorems for the 3D steady tropical climate model under certain conditions on $u$, $v$, $\\nabla \\theta$. Our results extend and improve a Liouville type result of Cho-In-Yang (arXiv:2312.17441).",
    "pdfUrl": "https://arxiv.org/pdf/2504.17285",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.057329Z"
  },
  {
    "id": "32feedbb141be20b67fe12ec8d452835",
    "title": "Incompressible and fast rotation limits for 3D compressible rotating Euler system with general initial data",
    "slug": "incompressible-and-fast-rotation-limits-for-3d-compressible-rotating-euler-system-with-general-initial-data",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Mikihiro Fujii",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper is concerned with the low Mach and Rossby number limits of $3$D compressible rotating Euler equations with ill-prepared initial data in the whole space. More precisely, the initial data is the sum of a $3$D part and a $2$D part. With the help of a suitable intermediate system, we perform this singular limit rigorously with the target system being a $2$D QG-type. This particularly gives an affirmative answer to the question raised by Ngo and Scrobogna [\\emph{Discrete Contin. Dyn. Syst.}, 38 (2018), pp. 749-789]. As a by-product, our proof gives a rigorous justification from the $2$D inviscid rotating shallow water equations to the $2$D QG equations in whole space.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17290",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.057636Z"
  },
  {
    "id": "68c1a695ca87e7b38b3cfe7a0d25beb1",
    "title": "Principal eigenvalues for the weighted p-Laplacian and antimaximum principle in $\\mathbb{R}^N$",
    "slug": "principal-eigenvalues-for-the-weighted-p-laplacian-and-antimaximum-principle-in-$\\mathbb{r}^n$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Anumol Joseph",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the existence of principal eigenvalues and principal eigenfunctions for weighted eigenvalue problems of the form: \\begin{equation*} - \\mbox{div} ( L (x) |\\nabla u|^{p-2} \\nabla u ) = \\lambda K(x) |u|^{p-2} u \\hspace{.1cm} \\mbox { in } \\hspace{.1cm} \\mathbb{R}^N , \\end{equation*} where $\\lambda \\in \\mathbb{R}$, $p>1$, $K : \\mathbb{R}^N \\rightarrow \\mathbb{R}$, $L : \\mathbb{R}^N \\rightarrow \\mathbb{R}^+$ are locally integrable functions. The weight function $K$ is allowed to change sign, provided it remains positive on a set of nonzero measure. We establish the existence, regularity, and asymptotic behavior of the principal eigenfunctions. We also prove local and global antimaximum principles for a perturbed version of the problem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17325",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.057948Z"
  },
  {
    "id": "615ee7d9265dfc0ff580481a92adbae0",
    "title": "A Rellich-type theorem for the Helmholtz equation in a junction of stratified media",
    "slug": "a-rellich-type-theorem-for-the-helmholtz-equation-in-a-junction-of-stratified-media",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Sarah Al Humaikani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove that there are no non-zero square-integrable solutions to a two-dimensional Helmholtz equation in some unbounded inhomogeneous domains which represent junctions of stratified media. More precisely, we consider domains that are unions of three half-planes, where each half-plane is stratified in the direction orthogonal to its boundary. As for the well-known Rellich uniqueness theorem for a homogeneous exterior domain, our result does not require any boundary condition. Our proof is based on half-plane representations of the solution which are derived through a generalization of the Fourier transform adapted to stratified media. A byproduct of our result is the absence of trapped modes at the junction of open waveguides as soon as the angles between branches are greater than $\\pi$/2.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17345",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.058255Z"
  },
  {
    "id": "ed272e74bc53bcee7c6d63eacda3ca41",
    "title": "Logarithmic continuity for the Nonlocal degenerate two-phase Stefan problem",
    "slug": "logarithmic-continuity-for-the-nonlocal-degenerate-two-phase-stefan-problem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Kyeongbae Kim",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish certain oscillation estimates for weak solutions to nonlinear, anomalous phase transitions modeled on the nonlocal two-phase Stefan problem. The problem is singular in time, is scaling deficient and influenced by far-off effects. We study the the problem in a geometry adapted to the solution and obtain oscillation estimates in intrinsically scaled cylinders. Furthermore, via certain uniform estimates, we construct a continuous weak solution to the corresponding initial boundary value problem with a quantitative modulus of continuity.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17383",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.058457Z"
  },
  {
    "id": "f2aeed9a70767ebd8e42a557f5383d0e",
    "title": "Periodic homogenization and harmonic measures",
    "slug": "periodic-homogenization-and-harmonic-measures",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Guy David",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Since the seminal work of Kenig and Pipher, the Dahlberg-Kenig-Pipher (DKP) condition on oscillations of the coefficient matrix became a standard threshold in the study of absolute continuity of the harmonic measure with respect to the Hausdorff measure on the boundary. It has been proved sufficient for absolute continuity in the domains with increasingly complex geometry, and known counterexamples show that in a certain sense it is necessary as well. In the present note, we introduce into the subject ideas from homogenization theory to exhibit a new class of operators for which the elliptic measure is well-behaved, featuring the coefficients violating the DKP condition, and on the contrary, oscillating so quickly, that the homogenization takes place.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17396",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.058656Z"
  },
  {
    "id": "c40f4694f2e8c3073b03ae13ad440b8e",
    "title": "An Inverse Source Problem for Semilinear Stochastic Hyperbolic Equations",
    "slug": "an-inverse-source-problem-for-semilinear-stochastic-hyperbolic-equations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Qi L",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper investigates an inverse source problem for general semilinear stochastic hyperbolic equations. Motivated by the challenges arising from both randomness and nonlinearity, we develop a globally convergent iterative regularization method that combines Carleman estimate with fixed-point iteration. Our approach enables the reconstruction of the unknown source function from partial lateral Cauchy data, without requiring a good initial guess. We establish a new Carleman estimate for stochastic hyperbolic equations and prove the convergence of the proposed method in weighted spaces. Furthermore, we design an efficient numerical algorithm that avoids solving backward stochastic partial differential equations and is robust to randomness in both the model and the data. Numerical experiments are provided to demonstrate the effectiveness of the method.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17398",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.058847Z"
  },
  {
    "id": "8f2fae1520cd7c03f4776d4d02d1227f",
    "title": "Stability of Stochastically Forced Solitons in the Korteweg-de Vries Equation",
    "slug": "stability-of-stochastically-forced-solitons-in-the-korteweg-de-vries-equation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Rik W.S. Westdorp",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the stability and dynamics of solitons in the Korteweg-de Vries (KdV) equation in the presence of noise and deterministic forcing. The noise is space-dependent and statistically translation-invariant. We show that, for small forcing, solitons remain close to the family of traveling waves in a weighted Sobolev norm, with high probability. We study the effective dynamics of the soliton amplitude and position via their variational phase, for which we derive explicit modulation equations. The stability result holds on a time scale where the deterministic forcing induces significant amplitude modulation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17407",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.059048Z"
  },
  {
    "id": "4e764b6307c36f13f9838dd3aa3b6896",
    "title": "Boundary observation and control for fractional heat and wave equations",
    "slug": "boundary-observation-and-control-for-fractional-heat-and-wave-equations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Umberto Biccari",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish boundary observability and control for the fractional heat equation over arbitrary time horizons $T > 0$, within the optimal range of fractional exponents $s \\in (1/2, 1)$. Our approach introduces a novel synthesis of techniques from fractional partial differential equations and control theory, combining several key ingredients in an original and effective manner:\n1. Boundary observability for low-frequency solutions of the fractional wave equation. We begin by analyzing the associated fractional wave equation. Using a fractional analogue of Pohozaev's identity, we establish a partial boundary observability result for the low-frequency solutions. The corresponding observability time horizon increases with the eigenmode frequency, reflecting the inherently slower propagation speed of the fractional waves.\n2. Transmutation to the parabolic setting. Using transmutation techniques, we transfer the observability results from the wave setting to the parabolic one. This yields a frequency-dependent observability inequality for the fractional heat equation, which - via duality - enables control of its low-frequency components.\n3. Frequency-wise iteration. Leveraging the dissipative nature of the fractional heat equation, we develop an iterative procedure to successively control the entire frequency spectrum of solutions. The condition $s \\in (1/2, 1)$ is crucial in this analysis, as it guarantees sufficient decay of high-frequency components, enabling the convergence of the iteration.\n4. Duality. By a duality argument, we derive boundary observability from the boundary controllability of the fractional heat equation. Remarkably, this type of boundary observability result is entirely new in the multi-dimensional setting and appears to be out of reach for existing methods. \\end{itemize}",
    "pdfUrl": "https://arxiv.org/pdf/2504.17413",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.059253Z"
  },
  {
    "id": "a70d243dd5d3e40903ff37e6498c16de",
    "title": "On soliton resolution to Cauchy problem of the spin-1 Gross-Pitaevskii equation",
    "slug": "on-soliton-resolution-to-cauchy-problem-of-the-spin-1-gross-pitaevskii-equation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Shou-Fu Tian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the Cauchy problem for the spin-1 Gross-Pitaevskii(GP) equation, which is a model instrumental in characterizing the soliton dynamics within spinor Bose-Einstein condensates. Recently, Geng $etal.$ (Commun. Math. Phys. 382, 585-611 (2021)) reported the long-time asymptotic result with error $\\mathcal{O}(\\frac{\\log t}t)$ for the spin-1 GP equation that only exists in the continuous spectrum. The main purpose of our work is to further generalize and improve Geng's work. Compared with the previous work, our asymptotic error accuracy has been improved from $\\mathcal{O}(\\frac{\\log t}t)$ to $\\mathcal{O}(t^{-3/4})$. More importantly, by establishing two matrix valued functions, we obtained effective asymptotic errors and successfully constructed asymptotic analysis of the spin-1 GP equation based on the characteristics of the spectral problem, including two cases: (i)coexistence of discrete and continuous spectrum; (ii)only continuous spectrum which considered by Geng's work with error $\\mathcal{O}(\\frac{\\log t}t)$. For the case (i), the corresponding asymptotic approximations can be characterized with an $N$-soliton as well as an interaction term between soliton solutions and the dispersion term with diverse residual error order $\\mathcal{O}(t^{-3/4})$. For the case (ii), the corresponding asymptotic approximations can be characterized with the leading term on the continuous spectrum and the residual error order $\\mathcal{O}(t^{-3/4})$. Finally, our results confirm the soliton resolution conjecture for the spin-1 GP equation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17465",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.059451Z"
  },
  {
    "id": "4b3a457bcb8746b447ad872bdb5580ec",
    "title": "Parabolic PDEs with Dynamic Data under a Bounded Slope Condition",
    "slug": "parabolic-pdes-with-dynamic-data-under-a-bounded-slope-condition",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Verena Bgelein",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish the existence of Lipschitz continuous solutions to the Cauchy Dirichlet problem for a class of evolutionary partial differential equations of the form $$ \\partial_tu-\\text{div}_x \\nabla_\\xi f(\\nabla u)=0 $$ in a space-time cylinder $\\Omega_T=\\Omega\\times (0,T)$, subject to time-dependent boundary data $g\\colon \\partial_{\\mathcal{P}}\\Omega_T\\to \\mathbf{R}$ prescribed on the parabolic boundary. The main novelty in our analysis is a time-dependent version of the classical bounded slope condition, imposed on the boundary data $g$ along the lateral boundary $\\partial\\Omega\\times (0,T)$. More precisely, we require that for each fixed $t\\in [0,T)$, the graph of $g(\\cdot ,t)$ over $\\partial\\Omega$ admits supporting hyperplanes with slopes that may vary in time but remain uniformly bounded. The key to handling time-dependent data lies in constructing more flexible upper and lower barriers.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17556",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.059655Z"
  },
  {
    "id": "03c5bd314b753bf8d00caf5b3325fc0d",
    "title": "$R$-boundedness of Poisson operators",
    "slug": "$r$-boundedness-of-poisson-operators",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Robert Denk",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the $R$-boundedness of parameter-dependent families of Poisson operators on the half-space $\\mathbb R^n_+$ in various scales of function spaces. Applications concern maximal $L_q$-regularity for boundary value problems with dynamic boundary conditions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17557",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.059856Z"
  },
  {
    "id": "a9c25f590b3f233436d3ecf98e9aab0c",
    "title": "Linear Test Approach to Global Controllability of Higher-Order Nonlinear Dispersive Equations with Finite-Dimensional Control",
    "slug": "linear-test-approach-to-global-controllability-of-higher-order-nonlinear-dispersive-equations-with-finite-dimensional-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Debanjit Mondal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate a class of higher-order nonlinear dispersive equations posed on the circle, subject to additive forcing by a finite-dimensional control. Our main objective is to establish approximate controllability by using the controllability of the inviscid Burgers system, linearized around a suitably constructed trajectory. In contrast to earlier approaches based on Lie algebraic techniques, our method offers a more concise proof and sheds new light on the structure of the control. Although the approach necessitates a higher-dimensional control space, both the structure and dimension of the control remain uniform with respect to the order of the dispersive equation and the control time.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17580",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.060053Z"
  },
  {
    "id": "68262906a3cfcfb7f9eea43e68d79ee6",
    "title": "Well-posed Questions for Ill-posed Inverse Problems: a Note in Memory of Pierre Sabatier",
    "slug": "well-posed-questions-for-ill-posed-inverse-problems:-a-note-in-memory-of-pierre-sabatier",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Gaoming Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Professor Pierre Sabatier contributed much to the study of inverse problems in theory and practice. Two of these contributions were a focus on theory that actually supports practice, and the identification of well-posed aspects of inverse problems that may quite ill-posed. This paper illustrates these two themes in the context of Electrical Impedance Tomography (EIT), which is both very ill-posed and very practical. We show that for a highly constrained version of this inverse problem, in which a small elliptical inclusion in a homogeneous background is to be identified, optimization of the experimental design (that is, electrode locations) vastly improves the stability of the solution.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17592",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.060249Z"
  },
  {
    "id": "14c40f544c10dd398a0320167d2786d7",
    "title": "Sharp Material Interface Limit of the Darcy-Boussinesq System",
    "slug": "sharp-material-interface-limit-of-the-darcy-boussinesq-system",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Hongjie Dong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the sharp material interface limit of the Darcy-Boussinesq model for convection in layered porous media with diffused material interfaces, which allow a gradual transition of material parameters between different layers. We demonstrate that as the thickness of these transition layers approaches zero, the conventional sharp interface model with interfacial boundary conditions, commonly adopted by the fluids community, is recovered under the assumption of constant porosity. Our results validate the widely used sharp interface model by bridging it with the more physically realistic case of diffused material interfaces. This limiting process is singular and involves a boundary layer in the velocity field. Our analysis requires del",
    "pdfUrl": "https://arxiv.org/pdf/2504.17661",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.060434Z"
  },
  {
    "id": "ddad0e7797e46b72a975ba287377c07d",
    "title": "Asymptotic attraction with algebraic rates toward fronts of dispersive-diffusive Burgers equations",
    "slug": "asymptotic-attraction-with-algebraic-rates-toward-fronts-of-dispersive-diffusive-burgers-equations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Milena Stanislavova",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Burgers equation is a classic model, which arises in numerous applications. At its very core it is a simple conservation law, which serves as a toy model for various dynamics phenomena. In particular, it supports explicit heteroclinic solutions, both fronts and backs. Their stability has been studied in details. There has been substantial interest in considering dispersive and/or diffusive modifications, which present novel dynamical paradigms in such simple setting. More specificaly, the KdV-Burgers model has been showed to support unique fronts (not all of them monotone!) with fixed values at $\\pm \\infty$. Many articles, among which \\cite{Pego}, \\cite{NS1}, \\cite{NS2}, have studied the question of stability of monotone (or close to monotone) fronts.\nIn a breakthrough paper, \\cite{BBHY}, the authors have extended these results in several different directions. They have considered a wider range of models. The fronts do not need to be monotone, but are subject of a spectral condition instead. Most importantly the method allows for large perturbations, as long as the heteroclinic conditions at $\\pm \\infty$ are met. That is, there is asymptotic attraction to the said fronts or equivalently the limit set consist of one point.\nThe purpose of this paper is to extend the results of \\cite{BBHY} by providing explicit algebraic rates of convergence as $t\\to \\infty$. We bootstrap these results from the results in \\cite{BBHY} using additional energy estimates for two important examples namely KdV-Burgers and the fractional Burgers problem. These rates are likely not optimal, but we conjecture that they are algebraic nonetheless.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17745",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.060625Z"
  },
  {
    "id": "2640a03c48f5b22dc46d593e8ec78d96",
    "title": "Small noise fluctuations and large deviations of conservative SPDEs with Dirichlet boundary conditions",
    "slug": "small-noise-fluctuations-and-large-deviations-of-conservative-spdes-with-dirichlet-boundary-conditions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Shyam Popat",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish a central limit theorem and large deviations principle that characterises small noise fluctuations of the generalised Dean--Kawasaki stochastic PDE. The fluctuations agree to first order with fluctuations of certain interacting particle systems, such as the zero range process, about their hydrodynamic limits. Our main contribution is that we are able to consider stochastic PDEs on general $C^2$ bounded domains with Dirichlet boundary conditions. On the level of particles, the boundary condition corresponds to absorption or injection of particles at the boundary.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17094",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:30.060813Z"
  },
  {
    "id": "06f067dca3fa6542009a2a8d1468ed50",
    "title": "On the local stability of the elapsed-time model in terms of the transmission delay and interconnection strength",
    "slug": "on-the-local-stability-of-the-elapsed-time-model-in-terms-of-the-transmission-delay-and-interconnection-strength",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Mara J. Cceres",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The elapsed-time model describes the behavior of interconnected neurons through the time since their last spike. It is an age-structured non-linear equation in which age corresponds to the elapsed time since the last discharge, and models many interesting dynamics depending on the type of interactions between neurons. We investigate the linearized stability of this equation by considering a discrete delay, which accounts for the possibility of a synaptic delay due to the time needed to transmit a nerve impulse from one neuron to the rest of the ensemble. We state a stability criterion that allows to determine if a steady state is linearly stable or unstable depending on the delay and the interaction between neurons. Our approach relies on the study of the asymptotic behavior of related Volterra-type integral equations in terms of theirs Laplace transforms. The analysis is complemented with numerical simulations illustrating the change of stability of a steady state in terms of the delay and the intensity of interconnections.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17358",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:30.061014Z"
  },
  {
    "id": "91b420ad56922e61de93b6b0c1671b0c",
    "title": "Microscopic derivation of the stationary Chern-Simons-Schrdinger equation for almost-bosonic anyons",
    "slug": "microscopic-derivation-of-the-stationary-chern-simons-schrdinger-equation-for-almost-bosonic-anyons",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Alireza Ataei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work we consider the $N$-body Hamiltonian describing the microscopic structure of a quantum gas of almost-bosonic anyons. This description includes both extended magnetic flux and spin-orbit/soft-disk interaction between the particles which are confined in a scalar trapping potential. We study a physically well-motivated ansatz for a sequence of trial states, consisting of Jastrow repulsive short-range correlations and a condensate, with sufficient variational freedom to approximate the ground state (and possibly also low-energy excited states) of the gas. In the limit $N \\to \\infty$, while taking the relative size of the anyons to zero and the total magnetic flux $2\\pi\\beta$ to remain finite, we rigorously derive the stationary Chern-Simons-Schrdinger/average-field-Pauli effective energy density functional for the condensate wave function. This includes a scalar self-interaction parameter $\\gamma$ which depends both on $\\beta$, the diluteness of the gas, and the spin-orbit coupling strength $g$, but becomes independent of these microscopic details for a particular value of the coupling $g=2$ in which supersymmetry is exhibited (on all scales, both microscopic and mesoscopic) with $\\gamma=2\\pi|\\beta|$. Our findings confirm and clarify the predictions we have found in the physics literature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17488",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:30.061216Z"
  },
  {
    "id": "d5c62a341432b036450d54dc092a962f",
    "title": "Long-time asymptotics of the Sawada-Kotera equation on the line",
    "slug": "long-time-asymptotics-of-the-sawada-kotera-equation-on-the-line",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Exactly Solvable and Integrable Systems (nlin.SI)",
    "author": {
      "name": "Deng-Shan Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Sawada-Kotera (SK) equation is an integrable system characterized by a third-order Lax operator and is related to the modified Sawada-Kotera (mSK) equation through a Miura transformation. This work formulates the Riemann-Hilbert problem associated with the SK and mSK equations by using direct and inverse scattering transforms. The long-time asymptotic behaviors of the solutions to these equations are then analyzed via the Deift-Zhou steepest descent method for Riemann-Hilbert problems. It is shown that the asymptotic solutions of the SK and mSK equations are categorized into four distinct regions: the decay region, the dispersive wave region, the Painlev region, and the rapid decay region. Notably, the Painlev region is governed by the F-XVIII equation in the Painlev classification of fourth-order ordinary differential equations, a fourth-order analogue of the Painlev transcendents. This connection is established through the Riemann-Hilbert formulation in this work. Similar to the KdV equation, the SK equation exhibits a transition region between the dispersive wave and Painlev regions, arising from the special values of the reflection coefficients at the origin. Finally, numerical comparisons demonstrate that the asymptotic solutions agree excellently with results from direct numerical simulations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17537",
    "tags": [
      "Exactly Solvable and Integrable Systems (nlin.SI)"
    ],
    "createdAt": "2025-04-25T15:49:30.061402Z"
  },
  {
    "id": "4692fd23e6590d8d298abec27535770e",
    "title": "Error estimates for the highly efficient and energy stable schemes for the 2D/3D two-phase MHD",
    "slug": "error-estimates-for-the-highly-efficient-and-energy-stable-schemes-for-the-2d/3d-two-phase-mhd",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Ke Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we mainly focus on the rigorous convergence analysis of two fully decoupled, unconditionally energy-stable methods for the diffuse interface two-phase magnetohydrodynamics (MHD) model. The two methods consist of the semi-implicit stabilization method and the invariant energy quadratization (IEQ) method, which are both applied to the phase field system. In addition, the pressure correction method is used for the saddle point system, and appropriate implicit-explicit treatments are employed for the nonlinear coupled terms. We prove the unconditional energy stability of the two schemes. In addition, we mainly establish the error estimates based on the bounds of $\\left\\|\\phi^{k}\\right\\|_{L^{\\infty}}$ and $\\left\\|\\textbf{b}^{k}\\right\\|_{L^{\\infty}}$. Several numerical examples are presented to test the accuracy and stability of the proposed methods.",
    "pdfUrl": "https://arxiv.org/pdf/2306.07025",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.061594Z"
  },
  {
    "id": "8c2e1ecc9b2e7f252c08533814caf939",
    "title": "Wave map null form estimates via Peter-Weyl theory",
    "slug": "wave-map-null-form-estimates-via-peter-weyl-theory",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Grigalius Taujanskas",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study spacetime estimates for the wave map null form $Q_0$ on $\\mathbb{R} \\times \\mathbb{S}^3$. By using the Lie group structure of $\\mathbb{S}^3$ and Peter-Weyl theory, combined with the time-periodicity of the conformal wave equation on $\\mathbb{R} \\times \\mathbb{S}^3$, we extend the classical ideas of Klainerman and Machedon to estimates on $\\mathbb{R} \\times \\mathbb{S}^3$, allowing for a range of powers of natural (Laplacian and wave) Fourier multiplier operators. A key difference in these curved space estimates as compared to the flat case is a loss of an arbitrarily small amount of differentiability, attributable to a lack of dispersion of linear waves on $\\mathbb{R} \\times \\mathbb{S}^3$. This arises in Fourier space from the product structure of irreducible representations of $\\mathrm{SU}(2)$. We further show that our estimates imply weighted estimates for the null form on Minkowski space.",
    "pdfUrl": "https://arxiv.org/pdf/2307.13052",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.061785Z"
  },
  {
    "id": "ff607863b83f7bc2d325f54ceaade7c5",
    "title": "Spectral Multipliers II: Elliptic and Parabolic Operators and Bochner-Riesz Means",
    "slug": "spectral-multipliers-ii:-elliptic-and-parabolic-operators-and-bochner-riesz-means",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Marius Beceanu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish estimates for the Poisson kernel, the heat kernel, and Bochner--Riesz means defined in terms of $H=-\\Delta+V$, where $V$ is a possibly large rough real-valued scalar potential and $H$ can have negative eigenvalues. All results are in three space dimensions.\nWe eliminate several unnecessary conditions on $V$, leaving just $V \\in \\mathcal K_0$, meaning that $V$ is locally integrable and $(-\\Delta)^{-1}|V|$ is bounded.\nFor the spectral multiplier bounds, we assume that $H$ has no zero or positive energy bound states. For $V \\in \\mathcal K_0$, we prove that $H$ has at most a finite number of negative bound states. If in addition $V \\in \\dot W^{-1/4, 4/3}$, then by [GoSc] and [KoTa] there are no positive energy bound states.",
    "pdfUrl": "https://arxiv.org/pdf/2308.09606",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.061982Z"
  },
  {
    "id": "3323de530215800b5d4dc736361ba64a",
    "title": "Longtime dynamics for the Landau Hamiltonian with a time dependent magnetic field",
    "slug": "longtime-dynamics-for-the-landau-hamiltonian-with-a-time-dependent-magnetic-field",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Dario Bambusi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider a modulated magnetic field, $B(t) = B_0 +\\varepsilon f(\\omega t)$, perpendicular to a fixed plane, where $B_0$ is constant, $\\varepsilon>0$ and $f$ a periodic function on the torus ${\\mathbb T}^n$. Our aim is to study classical and quantum dynamics for the corresponding Landau Hamiltonian. It turns out that the results depend strongly on the chosen gauge. For the Landau gauge the position observable is unbounded for \"almost all\" non resonant frequencies $\\omega$. On the contrary, for the symmetric gauge we obtain that, for \"almost all\" non resonant frequencies $\\omega$, the Landau Hamiltonian is reducible to a two dimensional harmonic oscillator and thus gives rise to bounded dynamics. The proofs use KAM algorithms for the classical dynamics. Quantum applications are given. In particular, the Floquet spectrum is absolutely continuous in the Landau gauge while it is discrete, of finite multiplicity, in symmetric gauge.",
    "pdfUrl": "https://arxiv.org/pdf/2402.00428",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.062246Z"
  },
  {
    "id": "9fde55d00e34967b812d34b74c280be9",
    "title": "On the semi-additivity of the $1/2$-symmetric caloric capacity in the plane",
    "slug": "on-the-semi-additivity-of-the-$1/2$-symmetric-caloric-capacity-in-the-plane",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Joan Hernndez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper we study properties of a variant of the $1/2$-caloric capacity, called $1/2$-symmetric caloric capacity. The latter is associated simultaneously with the $1/2$-fractional heat equation and its conjugate. We establish its semi-additivity in $\\mathbb{R}^2$ and, moreover, we compute explicitly the $1/2$-symmetric caloric capacity of rectangles, which illustrates its anisotropic behaviour.",
    "pdfUrl": "https://arxiv.org/pdf/2405.01195",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.062444Z"
  },
  {
    "id": "f0b1f232e3d8566a739ebf45981f65e8",
    "title": "Nonlinear Stability of First-Order Relativistic Viscous Hydrodynamics",
    "slug": "nonlinear-stability-of-first-order-relativistic-viscous-hydrodynamics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Heinrich Freistuhler",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper shows nonlinear stability of homogeneous states in second-order hyperbolic systems of partial differential equations that model the dynamics of dissipative relativistic fluids, by checking a dissipativity criterion formulated earlier by the authors and invoking a recent general result by the second author on long-time existence and time-asymptotic stability of small-data solutions to nonlinear hyperbolic systems.\nVersion 3 differs from version 2 by a trivial correction (minus signs in front of six coefficients).",
    "pdfUrl": "https://arxiv.org/pdf/2406.00673",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.062633Z"
  },
  {
    "id": "18af1967cf44520df35761644bd8cebd",
    "title": "A Priori Estimates for Singularities of the Lagrangian Mean Curvature Flow with Supercritical Phase",
    "slug": "a-priori-estimates-for-singularities-of-the-lagrangian-mean-curvature-flow-with-supercritical-phase",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Arunima Bhattacharya",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we prove interior a priori estimates for singularities of the Lagrangian mean curvature flow assuming the Lagrangian phase is supercritical. We prove a Jacobi inequality that holds good when the Lagrangian phase is critical and supercritical. We further extend our results to a broader class of Lagrangian mean curvature type equations.",
    "pdfUrl": "https://arxiv.org/pdf/2407.12756",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.062835Z"
  },
  {
    "id": "30c4e0c88a086d3a99cf48a9496ae3cd",
    "title": "A Diffuse Domain Approximation with Transmission-Type Boundary Conditions I: Asymptotic Analysis and Numerics",
    "slug": "a-diffuse-domain-approximation-with-transmission-type-boundary-conditions-i:-asymptotic-analysis-and-numerics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Toai Luong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Diffuse domain methods (DDMs) have garnered significant attention for approximating solutions to partial differential equations on complex geometries. These methods implicitly represent the geometry by replacing the sharp boundary interface with a diffuse layer of thickness $\\varepsilon$, which scales with the minimum grid size. This approach reformulates the original equations on an extended regular domain, incorporating boundary conditions through singular source terms. In this work, we conduct a matched asymptotic analysis of a DDM for a two-sided problem with transmission-type Robin boundary conditions. Our results show that, in the one dimensional space, the solution of the diffuse domain approximation asymptotically converges to the solution of the original problem, with exactly first-order accuracy in $\\varepsilon$. Furthermore, we provide numerical simulations that validate and illustrate the analytical result.",
    "pdfUrl": "https://arxiv.org/pdf/2412.07007",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.063033Z"
  },
  {
    "id": "869a871b4cd8b0a97892e15bffb9d343",
    "title": "The monopolist's free boundary problem in the plane",
    "slug": "the-monopolist's-free-boundary-problem-in-the-plane",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Robert J. McCann",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the Monopolist's problem with a focus on the free boundary separating bunched from unbunched consumers, especially in the plane, and give a full description of its solution for the family of square domains $\\{(a,a+1)^2\\}_{a \\ge 0}$. The Monopolist's problem is fundamental in economics, yet widely considered analytically intractable when both consumers and products have more than one degree of heterogeneity. Mathematically, the problem is to minimize a smooth, uniformly convex Lagrangian over the space of nonnegative convex functions. What results is a free boundary problem between the regions of strict and nonstrict convexity. Our work is divided into three parts: a study of the structure of the free boundary problem on convex domains in $\\mathbf{R}^n$ showing that the product allocation map remains Lipschitz up to most of the fixed boundary and that each bunch extends to this boundary; a proof in $\\mathbf{R}^2$ that the interior free boundary can only fail to be smooth in one of four specific ways (cusp, high frequency oscillations, stray bunch, nontranversal bunch); and, finally, the first complete solution to Rochet and Chon's example on the family of squares $\\Omega = (a,a+1)^2$, where we discover bifurcations first to targeted and then to blunt bunching as the distance $a \\ge 0$ to the origin is increased. We use techniques from the study of the Monge--Ampre equation, the obstacle problem, and localization for measures in convex-order.",
    "pdfUrl": "https://arxiv.org/pdf/2412.15505",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:30.063236Z"
  },
  {
    "id": "c83ae97bd3e0a928fb6ecec9531018c5",
    "title": "Construction of $p$-energy measures associated with strongly local $p$-energy forms",
    "slug": "construction-of-$p$-energy-measures-associated-with-strongly-local-$p$-energy-forms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Functional Analysis (math.FA)",
    "author": {
      "name": "Khei Sasaya",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We construct canonical $p$-energy measures associated with strongly local $p$-energy forms without any assumptions of self-similarity, where $p$-energy forms are $L^p$-versions of Dirichlet forms, which have recently been studied mainly on fractals. Furthermore, we prove that the measures satisfy the chain and Leibniz rules, and that such a \"good\" energy measures are unique. As an application, we also prove the $p$-energy version of Mosco's domination principle. Moreover, we show a Korevaar--Schoen-type $p$-energies defined by Alonso-Ruiz and Baudoin coincide with our energy measures.",
    "pdfUrl": "https://arxiv.org/pdf/2502.10369",
    "tags": [
      "Functional Analysis (math.FA)"
    ],
    "createdAt": "2025-04-25T15:49:30.063427Z"
  },
  {
    "id": "dbfa9070d02b4fe5f39a52b12ab839d5",
    "title": "Uniqueness of Parisi measures for enriched convex vector spin glass",
    "slug": "uniqueness-of-parisi-measures-for-enriched-convex-vector-spin-glass",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Hong-Bin Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the PDE approach to mean-field spin glasses, it has been observed that the free energy of convex spin glass models could be enriched by adding an extra parameter in its definition, and that the thermodynamic limit of the enriched free energy satisfies a partial differential equation. This parameter can be thought of as a matrix-valued path, and the usual free energy is recovered by setting this parameter to be the constant path taking only the value $0$. Furthermore, the enriched free energy can be expressed using a variational formula, which is a natural extension of the Parisi formula for the usual free energy. For models with scalar spins the Parisi formula can be expressed as an optimization problem over a convex set, and it was shown in [arXiv:1402.5132] that this problem has a unique optimizer thanks to a strict convexity property. For models with vector spins, the Parisi formula cannot easily be written as a convex optimization problem. In this paper, we generalize the uniqueness of Parisi measures proven in [arXiv:1402.5132] to the enriched free energy of models with vector spins when the extra parameter is a strictly increasing path. Our approach relies on a Gateaux differentiability property of the free energy and the envelope theorem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15818",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:30.063625Z"
  },
  {
    "id": "886ad60004ef81efed50171caeab15c3",
    "title": "Simplified Morse-Bott-Smale chain complex",
    "slug": "simplified-morse-bott-smale-chain-complex",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Ryuma Orita",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Banyaga and Hurtubise defined the Morse-Bott-Smale chain complex as a quotient of a large chain complex by introducing five degeneracy relations. In this paper, we unify the five conditions into only one degeneracy condition. This allows for a simpler definition of Morse-Bott homology and more computable examples. Moreover, we show that our chain complex for a Morse-Smale function is quasi-isomorphic to the Morse-Smale-Witten chain complex. As a result, we obtain another proof of the Morse Homology Theorem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16962",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:30.339579Z"
  },
  {
    "id": "46da9d3fa4cdcabaaabeacea33f02c73",
    "title": "Formal Manifold Structures on Positive Characteristic Varieties",
    "slug": "formal-manifold-structures-on-positive-characteristic-varieties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Runjie Hu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In his ICM report, Sullivan proposes the program of l-adic formalization of the concept of manifolds. In this program, he claims that smooth positive characteristic varieties should carry l-adic formal manifold structures. He also claims the existence of an abelianized Galois symmetry on l-adic formal manifold structures. This paper carries out this program, establishes the claims, and relates the abelianized Galois symmetry on l-adic formal manifold structures to the Galois symmetry of varieties. Meanwhile, we prove that simply-connected varieties are homotopically finite CW complexes in the l-adic sense.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17221",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:30.339801Z"
  },
  {
    "id": "68fe541c4ee2f7851492c8d48e04ae45",
    "title": "Higher Koszul duality and $n$-affineness",
    "slug": "higher-koszul-duality-and-$n$-affineness",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "James Pascaleff",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study $\\mathbb{E}_n$-Koszul duality for pairs of algebras of the form $\\mathrm{C}_{\\bullet}(\\Omega^{n}_*X;\\Bbbk) \\leftrightarrow \\mathrm{C}^{\\bullet}(X;\\Bbbk)$, and the closely related question of $n$-affineness for Betti stacks. It was expected, but not known, that $\\mathbb{E}_n$-Koszul duality should induce a kind of Morita equivalence between categories of iterated modules. We establish this rigorously by proving that the $(\\infty,n)$-category of iterated modules over $\\mathrm{C}_{\\bullet}(\\Omega_*^{n+1}X;\\Bbbk)$ is equivalent to the $(\\infty,n)$-category of quasi-coherent sheaves of $(\\infty,n-1)$-categories on $\\mathrm{cSpec}(\\mathrm{C}^{\\bullet}(X;\\Bbbk))$, where $\\mathrm{cSpec}(\\mathrm{C}^{\\bullet}(X;\\Bbbk))$ is the cospectrum of $\\mathrm{C}^{\\bullet}(X;\\Bbbk)$. By the monodromy equivalence, these categories are also equivalent to the category of higher local systems on $X$, $n\\mathbf{LocSysCat}^{n-1}(X;\\Bbbk)$. Our result is new already in the classical case $n=1$, although it can be seen to recover well known formulations of $\\mathbb{E}_1$-Koszul duality as a Morita equivalence of module categories (up to appropriate completions of the $t$-structures). We also investigate (higher) affineness properties of Betti stacks. We give a complete characterization of $n$-affine Betti stacks, in terms of the $0$-affineness of their iterated loop space. As a consequence, we prove that $n$-truncated Betti stacks are $n$-affine; and that $\\pi_{n+1}(X)$ is an obstruction to $n$-affineness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16935",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:30.340012Z"
  },
  {
    "id": "f2ddee4efb5fb45741e13c5e78f4fc6c",
    "title": "Mathematical Modeling of Protein Structures: A Cohomology-Based Approach to the Flagellar Motor",
    "slug": "mathematical-modeling-of-protein-structures:-a-cohomology-based-approach-to-the-flagellar-motor",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Biomolecules (q-bio.BM)",
    "author": {
      "name": "Zakaria Lamine",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This study presents a novel mathematical model derived from cohomology, leveraging the KEEL-proven theorem that establishes cohomology as tautological, generated by boundary classes of curves with fixed dual graphs. Simplicial complexes are constructed using skew-commutative graded algebra, and the structure theorem is applied to connect distinct homologies, enabling precise interpretations of the resulting geometric forms. The proposed model is utilized for protein structure analysis and prediction, with a specific application to the Flagellar Motor structure. This approach offers new insights into the geometric and algebraic foundations of biological macromolecular modeling, highlighting its potential for advancement in structural biology.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16941",
    "tags": [
      "Biomolecules (q-bio.BM)"
    ],
    "createdAt": "2025-04-25T15:49:30.340211Z"
  },
  {
    "id": "8e813f20c38b86594b25a3e657cb377e",
    "title": "Conley-Morse persistence barcode: a homological signature of a combinatorial bifurcation",
    "slug": "conley-morse-persistence-barcode:-a-homological-signature-of-a-combinatorial-bifurcation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Tamal K. Dey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Bifurcation is one of the major topics in the theory of dynamical systems. It characterizes the nature of qualitative changes in parametrized dynamical systems. In this work, we study combinatorial bifurcations within the framework of combinatorial multivector field theory--a young but already well-established theory providing a combinatorial model for continuous-time dynamical systems (or simply, flows). We introduce Conley-Morse persistence barcode, a compact algebraic descriptor of combinatorial bifurcations. The barcode captures structural changes in a dynamical system at the level of Morse decompositions and provides a characterization of the nature of observed transitions in terms of the Conley index. The construction of Conley-Morse persistence barcode builds upon ideas from topological data analysis (TDA). Specifically, we consider a persistence module obtained from a zigzag filtration of topological pairs (formed by index pairs defining the Conley index) over a poset. Using gentle algebras, we prove that this module decomposes into simple intervals (bars) and compute them with algorithms from TDA known for processing zigzag filtrations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17105",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:30.340415Z"
  },
  {
    "id": "8277d38ee4bba3c94766a3307c83f5c5",
    "title": "Odd fake $\\mathbb{Q}$ -homology quadrics exist",
    "slug": "odd-fake-$\\mathbb{q}$--homology-quadrics-exist",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Fabrizio Catanese",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We show the existence of odd fake $\\mathbb{Q}$-homology quadrics, namely of minimal surfaces $S$ of general type which have the same $\\mathbb{Q}$-homology as a smooth quadric $Q \\cong (\\mathbb{P}^1(\\mathbb{C}))^2$, but have an odd intersection form on $ H^2(S, \\mathbb{Z})/Tors(S)$, where $Tors(S)$ is the Torsion subgroup.\nOur examples are provided by a special 1-dimensional family of surfaces isogenous to a product of unmixed type.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17475",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:30.340616Z"
  },
  {
    "id": "2260e7e066ceaaaf7fb5c0459dd2df25",
    "title": "Applied Sheaf Theory For Multi-agent Artificial Intelligence (Reinforcement Learning) Systems: A Prospectus",
    "slug": "applied-sheaf-theory-for-multi-agent-artificial-intelligence-(reinforcement-learning)-systems:-a-prospectus",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Eric Schmid",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper provides a pedagogical introduction to classical sheaf theory and sheaf cohomology, followed by a research prospectus exploring potential applications to multi-agent artificial intelligence systems. The first section offers a comprehensive overview of fundamental sheaf-theoretic concepts-presheaves, sheaves, stalks, and cohomology-aimed at researchers in computer science and AI who may not have extensive background in algebraic topology. The second section presents a detailed research prospectus that outlines a roadmap for developing sheaf-theoretic approaches to model and analyze complex systems of interacting agents. We propose that sheaf theory's inherent local-to-global perspective may provide valuable mathematical tools for reasoning about how local agent behaviors collectively determine emergent system properties. The third section contains a literature review connecting sheaf theory with existing research in multi-agent systems, reinforcement learning, and economic modeling. This paper does not present a completed model but rather lays theoretical groundwork and identifies promising research directions that could bridge abstract mathematics with practical AI applications, potentially revealing new approaches to coordination and emergence in multi-agent systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17700",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:30.340819Z"
  },
  {
    "id": "57e018162c4a7c446df334cdab1fdd0d",
    "title": "Analysing Multiscale Clusterings with Persistent Homology",
    "slug": "analysing-multiscale-clusterings-with-persistent-homology",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Juni Schindler",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In data clustering, it is often desirable to find not just a single partition into clusters but a sequence of partitions that describes the data at different scales (or levels of coarseness). A natural problem then is to analyse and compare the (not necessarily hierarchical) sequences of partitions that underpin such multiscale descriptions. Here, we use tools from topological data analysis and introduce the Multiscale Clustering Filtration (MCF), a well-defined and stable filtration of abstract simplicial complexes that encodes arbitrary cluster assignments in a sequence of partitions across scales of increasing coarseness. We show that the zero-dimensional persistent homology of the MCF measures the degree of hierarchy of this sequence, and the higher-dimensional persistent homology tracks the emergence and resolution of conflicts between cluster assignments across the sequence of partitions. To broaden the theoretical foundations of the MCF, we provide an equivalent construction via a nerve complex filtration, and we show that, in the hierarchical case, the MCF reduces to a Vietoris-Rips filtration of an ultrametric space. Using synthetic data, we then illustrate how the persistence diagram of the MCF provides a feature map that can serve to characterise and classify multiscale clusterings.",
    "pdfUrl": "https://arxiv.org/pdf/2305.04281",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:30.341019Z"
  },
  {
    "id": "2b95831ba9fd5f3341b709364f0fb63f",
    "title": "On sequential versions of distributional topological complexity",
    "slug": "on-sequential-versions-of-distributional-topological-complexity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Ekansh Jauhari",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We define a (non-decreasing) sequence $\\{\\mathsf{dTC}_m(X)\\}_{m\\ge 2}$ of higher versions of distributional topological complexity ($\\mathsf{dTC}$) of a space $X$ introduced by Dranishnikov and Jauhari. This sequence generalizes $\\mathsf{dTC}(X)$ in the sense that $\\mathsf{dTC}_2(X) = \\mathsf{dTC}(X)$, and is a direct analog to the classical sequence $\\{\\mathsf{TC}_m(X)\\}_{m\\ge 2}$. We show that like $\\mathsf{TC}_m$ and $\\mathsf{dTC}$, the sequential versions $\\mathsf{dTC}_m$ are also homotopy invariants. Also, $\\mathsf{dTC}_m(X)$ relates with the distributional LS-category ($\\mathsf{dcat}$) of products of $X$ in the same way as $\\mathsf{TC}_m(X)$ relates with the classical LS-category ($\\mathsf{cat}$) of products of $X$. On one hand, we show that in general, $\\mathsf{dTC}_m$ is a different concept than $\\mathsf{TC}_m$ for each $m \\ge 2$. On the other hand, by finding sharp cohomological lower bounds to $\\mathsf{dTC}_m(X)$, we provide various examples of closed manifolds $X$ for which the sequences $\\{\\mathsf{TC}_m(X)\\}_{m\\ge 2}$ and $\\{\\mathsf{dTC}_m(X)\\}_{m\\ge 2}$ coincide.",
    "pdfUrl": "https://arxiv.org/pdf/2401.17218",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:30.341239Z"
  },
  {
    "id": "6b45a38765424b153df5e1673c9eb493",
    "title": "Intertwining category and complexity",
    "slug": "intertwining-category-and-complexity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Ekansh Jauhari",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We develop the theory of the intertwining distributional versions of the LS-category and the sequential topological complexities of a space $X$, denoted by $\\mathsf{icat}(X)$ and $\\mathsf{iTC}_m(X)$, respectively. We prove that they satisfy most of the nice properties as their respective distributional counterparts $\\mathsf{dcat}(X)$ and $\\mathsf{dTC}_m(X)$, and their classical counterparts $\\mathsf{cat}(X)$ and $\\mathsf{TC}_m(X)$, such as homotopy invariance and special behavior on topological groups. We show that the notions of $\\mathsf{iTC}_m$ and $\\mathsf{dTC}_m$ are different for each $m \\ge 2$ by proving that $\\mathsf{iTC}_m(\\mathcal{H})=1$ for all $m \\ge 2$ for Higman's group $\\mathcal{H}$. Using cohomological lower bounds, we also provide various examples of locally finite CW complexes $X$ for which $\\mathsf{icat}(X) > 1$, $\\mathsf{iTC}_m(X) > 1$, $\\mathsf{icat}(X) = \\mathsf{dcat}(X) = \\mathsf{cat}(X)$, and $\\mathsf{iTC}(X) = \\mathsf{dTC}(X) = \\mathsf{TC}(X)$.",
    "pdfUrl": "https://arxiv.org/pdf/2406.12265",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:30.341448Z"
  },
  {
    "id": "7e275fba7762d6d48019bda6d16a0b43",
    "title": "Unital k-Restricted Infinity-Operads",
    "slug": "unital-k-restricted-infinity-operads",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Amartya Shekhar Dubey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study unital $\\infty$-operads by their arity restrictions. Given $k \\geq 1$, we develop a model for unital $k$-restricted $\\infty$-operads, which are variants of $\\infty$-operads which has only $(\\leq k)$-arity morphisms, as complete Segal presheaves on closed $k$-dendroidal trees, which are closed trees build from corollas with valences $\\leq k$. Furthermore, we prove that the restriction functors from unital $\\infty$-operads to unital $k$-restricted $\\infty$-operads admit fully faithful left and right adjoints by showing that the left and right Kan extensions preserve complete Segal objects. Varying $k$, the left and right adjoints give a filtration and a co-filtration for any unital $\\infty$-operads by $k$-restricted $\\infty$-operads.",
    "pdfUrl": "https://arxiv.org/pdf/2407.17444",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:30.341649Z"
  },
  {
    "id": "079ae1ace1995f8c3f7c33199522207f",
    "title": "Good objects in the equivariant world",
    "slug": "good-objects-in-the-equivariant-world",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Surojit Ghosh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This article explores equivariant localization in the category of $G$-spaces, where $G$ is a compact Lie group. We establish a commutation rule for the localization functor and the equivariant loop functor. Additionally, we introduce and classify certain good objects in this category up to their Bredon cohomology with coefficients in the constant rational Mackey functor $\\underline{\\Q}$.",
    "pdfUrl": "https://arxiv.org/pdf/2411.02803",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:30.341850Z"
  },
  {
    "id": "7bcbfdb97c1a726758db25474e4b22cd",
    "title": "Bordism and resolution of singularities",
    "slug": "bordism-and-resolution-of-singularities",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Mohammed Abouzaid",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We adapt algorithms for resolving the singularities of complex algebraic varieties to prove that the natural map of homology theories from complex bordism to the bordism theory of complex derived orbifolds splits. In equivariant stable homotopy theory, our techniques yield a splitting of homology theories for the map from bordism to the equivariant bordism theory of a finite group $\\Gamma$, given by assigning to a manifold its product with $\\Gamma$. In symplectic topology, and using recent work of Abouzaid-McLean-Smith and Hirschi-Swaminathan, we conclude that one can define complex cobordism-valued Gromov-Witten invariant for arbitrary (closed) symplectic manifolds. We apply our results to constrain the topology of the space of Hamiltonian fibrations over $S^2$. The methods we develop apply to normally complex orbifolds, and will hence lead to applications in symplectic topology that rely on moduli spaces of holomorphic curves with Lagrangian boundary conditions.",
    "pdfUrl": "https://arxiv.org/pdf/2412.04451",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:30.342061Z"
  },
  {
    "id": "cb9749315ea6f6b6752111ab5a702882",
    "title": "Four dimensional almost complex torus manifolds",
    "slug": "four-dimensional-almost-complex-torus-manifolds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Differential Geometry (math.DG)",
    "author": {
      "name": "Donghoon Jang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In dimension 4, we extend the correspondence between compact nonsingular toric varieties and regular fans to a correspondence between almost complex torus manifolds and families of multi-fans in a geometric way, where an (almost) complex torus manifold is a $2n$-dimensional compact connected (almost) complex manifold equipped with an effective action of a real $n$-dimensional torus $T^n$ that has fixed points.\nLet $M$ be a 4-dimensional almost complex torus manifold. To $M$, we associate two equivalent combinatorial objects, a family $\\Delta$ of multi-fans and a graph $\\Gamma$, which encode the data on the fixed point set. We find a necessary and sufficient condition for each of $\\Delta$ and $\\Gamma$.\nMoreover, we provide a minimal model and operations for each of $\\Delta$ and $\\Gamma$. We introduce operations on a multi-fan and a graph that correspond to blow up and down of a manifold, and show that we can blow up and down $M$ to a minimal manifold $M'$ whose weights at the fixed points are unit vectors in $\\mathbb{Z}^2$, $\\Delta$ to a family of minimal multi-fans that has unit vectors only, and $\\Gamma$ to a minimal graph whose edges all have unit vectors as labels.\nAs an application, if $M$ is complex, $\\Delta$ is a fan and determines $M$, $\\Gamma$ encodes the equivariant cohomology of $M$, and $M'$ is $\\mathbb{CP}^1 \\times \\mathbb{CP}^1$. This implies that any two 4-dimensional complex torus manifolds are obtained from each other by equivariant blow up and down.",
    "pdfUrl": "https://arxiv.org/pdf/2310.11024",
    "tags": [
      "Differential Geometry (math.DG)"
    ],
    "createdAt": "2025-04-25T15:49:30.342259Z"
  },
  {
    "id": "2f03684c213ddafb5105368c535ae1f6",
    "title": "Coloring, list coloring, and fractional coloring in intersections of matroids",
    "slug": "coloring,-list-coloring,-and-fractional-coloring-in-intersections-of-matroids",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Ron Aharoni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is known that in matroids the difference between the chromatic number and the fractional chromatic number is smaller than 1, and that the list chromatic number is equal to the chromatic number. We investigate the gap within these pairs of parameters for hypergraphs that are the intersection of a given number k of matroids. We prove that in such hypergraphs the list chromatic number is at most k times the chromatic number and at most 2k-1 times the maximum chromatic number among the k matroids. We study the relationship between three polytopes associated with k-sets of matroids, and connect them to bounds on the fractional chromatic number of the intersection of the members of the k-set. This also connects to bounds on the matroidal matching and covering number of the intersection of the members of the k-set. The tools used are in part topological.",
    "pdfUrl": "https://arxiv.org/pdf/2407.08789",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.342472Z"
  },
  {
    "id": "6be177fa702765270169a5c0f89316da",
    "title": "Coloring the intersection of two matroids",
    "slug": "coloring-the-intersection-of-two-matroids",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Eli Berger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A result [The intersection of a matroid and a simplicial complex, Trans. Amer. Math. Soc. 358] from 2006 of Aharoni and the first author of this paper states that for any two positive integers $p,q$, where $p$ divides $q$, if a matroid $\\mathcal{M}$ is $p$-colorable and a matroid $\\mathcal{N}$ is $q$-colorable then $\\mathcal{M} \\cap \\mathcal{N}$ is $(p+q)$-colorable. In this paper we show that the assumption that $p$ divides $q$ is in fact redundant, and we also prove that $\\mathcal{M} \\cap \\mathcal{N}$ is even $p+q$ list-colorable.\nThe result uses topology and relies on a new parameter yielding a lower bound for the topological connectivity of the intersection of two matroids.",
    "pdfUrl": "https://arxiv.org/pdf/2407.09160",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.342670Z"
  },
  {
    "id": "6805f0c622dfcc8f71bf683f8afcd0cf",
    "title": "Distributional category of manifolds",
    "slug": "distributional-category-of-manifolds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Ekansh Jauhari",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, a new homotopy invariant of metric spaces, called the distributional LS-category, was defined, which provides a lower bound to the classical LS-category. In this paper, we obtain several sufficient conditions for the distributional LS-category (dcat) of a closed manifold to be maximum, i.e., equal to its classical LS-category (cat). These give us many new computations of dcat, especially for some essential manifolds and (generalized) connected sums. In the process, we also determine the cat of closed 3-manifolds having torsion-free fundamental groups and some closed geometrically decomposable 4-manifolds. Finally, we extend some of our results to closed Alexandrov spaces with curvature bounded below and discuss their cat and dcat in dimension 3.",
    "pdfUrl": "https://arxiv.org/pdf/2408.11036",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:30.342868Z"
  },
  {
    "id": "b3d1677c18b7633c9bbd2243dab5eee3",
    "title": "Fast Directed $q$-Analysis for Brain Graphs",
    "slug": "fast-directed-$q$-analysis-for-brain-graphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantitative Methods (q-bio.QM)",
    "author": {
      "name": "Felix Windisch",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent innovations in reconstructing large scale, full-precision, neuron-synapse-scale connectomes demand subsequent improvements to graph analysis methods to keep up with the growing complexity and size of the data. One such tool is the recently introduced directed $q$-analysis. We present numerous improvements, theoretical and applied, to this technique: on the theoretical side, we introduce modified definitions for key elements of directed $q$-analysis, which remedy a well-hidden and previously undetected bias. This also leads to new, beneficial perspectives to the associated computational challenges. Most importantly, we present a high-speed, publicly available, low-level implementation that provides speed-ups of several orders of magnitude on C. Elegans. Furthermore, the speed gains grow with the size of the considered graph. This is made possible due to the mathematical and algorithmic improvements as well as a carefully crafted implementation. These speed-ups enable, for the first time, the analysis of full-sized connectomes such as those obtained by recent reconstructive methods. Additionally, the speed-ups allow comparative analysis to corresponding null models, appropriately designed randomly structured artificial graphs that do not correspond to actual brains. This, in turn, allows for assessing the efficacy and usefulness of directed $q$-analysis for studying the brain. We report on the results in this paper.",
    "pdfUrl": "https://arxiv.org/pdf/2501.04596",
    "tags": [
      "Quantitative Methods (q-bio.QM)"
    ],
    "createdAt": "2025-04-25T15:49:30.343064Z"
  },
  {
    "id": "9335d68dd655d52a374c821c2fc06c74",
    "title": "Decoupling for surfaces with radial symmetry",
    "slug": "decoupling-for-surfaces-with-radial-symmetry",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Classical Analysis and ODEs (math.CA)",
    "author": {
      "name": "Jianhui Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We utilise the two principles of decoupling introduced in [arXiv:2407.16108] to prove decoupling for two types of surfaces exhibiting radial symmetry. The first type are surfaces of revolution in $\\mathbb R^n$ generated by smooth surfaces in $\\mathbb R^3$. The second type of surfaces are graphs of trivariate homogeneous smooth functions of nonzero degree.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17100",
    "tags": [
      "Classical Analysis and ODEs (math.CA)"
    ],
    "createdAt": "2025-04-25T15:49:30.577617Z"
  },
  {
    "id": "e877f99cb1be296f06c80e7f893f34e8",
    "title": "Uniform treatments of Bernoulli numbers, Stirling numbers, and their generating functions",
    "slug": "uniform-treatments-of-bernoulli-numbers,-stirling-numbers,-and-their-generating-functions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Feng Qi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, by virtue of a determinantal formula for derivatives of the ratio between two differentiable functions, in view of the Fa di Bruno formula, and with the help of several identities and closed-form formulas for the partial Bell polynomials $\\operatorname{B}_{n,k}$, the author establishes thirteen Maclaurin series expansions of the functions \\begin{align*} &\\ln\\frac{\\operatorname{e}^x+1}{2}, && \\ln\\frac{\\operatorname{e}^x-1}{x}, && \\ln\\cosh x, \\\\ &\\ln\\frac{\\sinh x}{x}, && \\biggl[\\frac{\\ln(1+x)}{x}\\biggr]^r, && \\biggl(\\frac{\\operatorname{e}^x-1}{x}\\biggr)^r \\end{align*} for $r=\\pm\\frac{1}{2}$ and $r\\in\\mathbb{R}$ in terms of the Dirichlet eta function $\\eta(1-2k)$, the Riemann zeta function $\\zeta(1-2k)$, and the Stirling numbers of the first and second kinds $s(n,k)$ and $S(n,k)$. presents four determinantal expressions and three recursive relations for the Bernoulli numbers $B_{2n}$.  finds out three closed-form formulas for the Bernoulli numbers $B_{2n}$ and the generalized Bernoulli numbers $B_n^{(r)}$ in terms of the Stirling numbers of the second kind $S(n,k)$, and deduce two combinatorial identities for the Stirling numbers of the second kind $S(n,k)$. acquires two combinatorial identities, which can be regarded as diagonal recursive relations, involving the Stirling numbers of the first and second kinds $s(n,k)$ and $S(n,k)$. recovers an integral representation and a closed-form formula, and establish an alternative explicit and closed-form formula, for the Bernoulli numbers of the second kind $b_n$ in terms of the Stirling numbers of the first kind $s(n,k)$. obtains three identities connecting the Stirling numbers of the first and second kinds $s(n,k)$ and $S(n,k)$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16965",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.577878Z"
  },
  {
    "id": "ae30cda558ccbbd47473162cb099bf3c",
    "title": "Period Function of Maass forms from Ramanujan's Lost Notebook",
    "slug": "period-function-of-maass-forms-from-ramanujan's-lost-notebook",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "YoungJu Choie",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Lost Notebook of Ramanujan contains a number of beautiful formulas, one of which can be found on its page 220. It involves an interesting function, which we denote as $\\mathcal{F}_1(x)$. In this paper, we show that $\\mathcal{F}_1(x)$ belongs to the category of period functions as it satisfies the period relations of Maass forms in the sense of Lewis and Zagier \\cite{lz}. Hence, we refer to $\\mathcal{F}_1(x)$ as the \\emph{Ramanujan period function}. Moreover, one of the salient aspects of the Ramanujan period function $\\mathcal{F}_1(x)$ that we found out is that it is a Hecke eigenfunction under the action of Hecke operators on the space of periods. We also establish that it naturally appears in a Kronecker limit formula of a certain zeta function, revealing its connections to various topics. Finally, we generalize $\\mathcal{F}_1(x)$ to include a parameter $s,$ connecting our work to the broader theory of period functions developed by Bettin and Conrey \\cite{bc} and Lewis and Zagier \\cite{lz}. We emphasize that Ramanujan was the first to study this function, marking the beginning of the study of period functions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17284",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:30.578100Z"
  },
  {
    "id": "56d376ea4eea90f377daf0c887fc717b",
    "title": "Widom factors in $\\mathbb C^n$",
    "slug": "widom-factors-in-$\\mathbb-c^n$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Complex Variables (math.CV)",
    "author": {
      "name": "Gkalp Alpan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We generalize the theory of Widom factors to the $\\mathbb C^n$ setting. We define Widom factors of compact subsets $K\\subset \\mathbb C^n$ associated with multivariate orthogonal polynomials and weighted Chebyshev polynomials. We show that on product subsets $K=K_1\\times\\cdots\\times K_n$ of $\\mathbb C^n$, where each $K_j$ is a non-polar compact subset of $\\mathbb C$, these quantities have universal lower bounds which directly extend one dimensional results. Under the additional assumption that each $K_j$ is a subset of the real line, we provide improved lower bounds for Widom factors for some weight functions $w$; in particular, for the case $w\\equiv 1$. Finally, we define the Mahler measure of a multivariate polynomial relative to $K\\subset \\mathbb C^n$ and obtain lower bounds for this quantity on product sets.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17727",
    "tags": [
      "Complex Variables (math.CV)"
    ],
    "createdAt": "2025-04-25T15:49:30.578324Z"
  },
  {
    "id": "2bf902a9acaba9b6166e6b344b4b1a97",
    "title": "No infinite spin for partial collisions converging to isolated central configurations on the plane",
    "slug": "no-infinite-spin-for-partial-collisions-converging-to-isolated-central-configurations-on-the-plane",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Anna Gierzkiewicz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the $n$-body problem, when a~cluster of bodies tends to a collision, then its normalized shape curve converges to the set of normalized central configurations, which has $SO(2)$ symmetry in the planar case. This leaves a possibility that the normalized shape curve tends to the circle obtained by rotation of some central configuration instead of a particular point on it. This is the \\emph{infinite spin problem} which concerns the rotational behavior of total collision orbits in the $n$-body problem. The question also makes sense for partial collision.\nWe show that the infinite spin is not possible if the limiting circle is isolated from other connected components of the set of normalized central configurations. Our approach extends the method from recent work for total collision by Moeckel and Montgomery, which was based on a combination of the center manifold theorem with ojasiewicz inequality. To that we add a shadowing result for pseudo-orbits near normally hyperbolic manifold and careful estimates on the influence of other bodies on the cluster of colliding bodies.",
    "pdfUrl": "https://arxiv.org/pdf/2408.16409",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:30.578543Z"
  },
  {
    "id": "e877f99cb1be296f06c80e7f893f34e8",
    "title": "Uniform treatments of Bernoulli numbers, Stirling numbers, and their generating functions",
    "slug": "uniform-treatments-of-bernoulli-numbers,-stirling-numbers,-and-their-generating-functions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Feng Qi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, by virtue of a determinantal formula for derivatives of the ratio between two differentiable functions, in view of the Fa di Bruno formula, and with the help of several identities and closed-form formulas for the partial Bell polynomials $\\operatorname{B}_{n,k}$, the author establishes thirteen Maclaurin series expansions of the functions \\begin{align*} &\\ln\\frac{\\operatorname{e}^x+1}{2}, && \\ln\\frac{\\operatorname{e}^x-1}{x}, && \\ln\\cosh x, \\\\ &\\ln\\frac{\\sinh x}{x}, && \\biggl[\\frac{\\ln(1+x)}{x}\\biggr]^r, && \\biggl(\\frac{\\operatorname{e}^x-1}{x}\\biggr)^r \\end{align*} for $r=\\pm\\frac{1}{2}$ and $r\\in\\mathbb{R}$ in terms of the Dirichlet eta function $\\eta(1-2k)$, the Riemann zeta function $\\zeta(1-2k)$, and the Stirling numbers of the first and second kinds $s(n,k)$ and $S(n,k)$. presents four determinantal expressions and three recursive relations for the Bernoulli numbers $B_{2n}$.  finds out three closed-form formulas for the Bernoulli numbers $B_{2n}$ and the generalized Bernoulli numbers $B_n^{(r)}$ in terms of the Stirling numbers of the second kind $S(n,k)$, and deduce two combinatorial identities for the Stirling numbers of the second kind $S(n,k)$. acquires two combinatorial identities, which can be regarded as diagonal recursive relations, involving the Stirling numbers of the first and second kinds $s(n,k)$ and $S(n,k)$. recovers an integral representation and a closed-form formula, and establish an alternative explicit and closed-form formula, for the Bernoulli numbers of the second kind $b_n$ in terms of the Stirling numbers of the first kind $s(n,k)$. obtains three identities connecting the Stirling numbers of the first and second kinds $s(n,k)$ and $S(n,k)$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16965",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.928729Z"
  },
  {
    "id": "26b6b5164258e3bea3b1cfe8b2527eaa",
    "title": "On the Turn number of the $G_{3\\times 3}$ in linear hypergraphs",
    "slug": "on-the-turn-number-of-the-$g_{3\\times-3}$-in-linear-hypergraphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Jozsef Solymosi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We show a construction for dense 3-uniform linear hypergraphs without $3\\times 3$ grids, improving the lower bound on its Turn number.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16973",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.928940Z"
  },
  {
    "id": "70363ac8437ac72064a4367d431fe6e6",
    "title": "The autotopism group of a family of commutative semifields",
    "slug": "the-autotopism-group-of-a-family-of-commutative-semifields",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Lukas Klsch",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We completely determine the autotopism group of the (as of now) largest family of commutative semifields found by Glolu and Klsch. Since this family of semifields generally does not have large nuclei, this process is considerably harder than for families considered in preceding work. Our results show that all autotopisms are semilinear over the degree 2 subfield and that the autotopism group is always solvable. Using known connections, our results also completely determine the automorphism groups of the associated rank-metric codes and the collineation groups of the associated translation planes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17057",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.929150Z"
  },
  {
    "id": "59361e35390ebd7937e71d6c1f087e94",
    "title": "On the number of drawings of a combinatorial triangulation",
    "slug": "on-the-number-of-drawings-of-a-combinatorial-triangulation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Beln Cruces",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In 1962, Tutte provided a formula for the number of combinatorial triangulations, that is, maximal planar graphs with a fixed triangular face and $n$ additional vertices. In this note, we study how many ways a combinatorial triangulation can be drawn as geometric triangulation, that is, with straight-line segments, on a given point set in the plane. Our central contribution is that there exists a combinatorial triangulation with n vertices that can be drawn in at least $\\Omega(1,31^n)$ ways on a set of n points as different geometric triangulations. We also show an upper bound on the number of drawings of a combinatorial triangulation on the so-called double chain point set.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17088",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.929347Z"
  },
  {
    "id": "393a31d16853f87dcc0fff93f365e22e",
    "title": "Insertion algorithms and pattern avoidance on trees arising in the Kapranov embedding of $\\overline{M}_{0,n+3}$",
    "slug": "insertion-algorithms-and-pattern-avoidance-on-trees-arising-in-the-kapranov-embedding-of-$\\overline{m}_{0,n+3}$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Andrew Reimer-Berg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We resolve a question of Gillespie, Griffin, and Levinson that asks for a combinatorial bijection between two classes of trivalent trees, tournament trees and slide trees, that both naturally arise in the intersection theory of the moduli space $\\overline{M}_{0,n+3}$ of stable genus zero curves with $n+3$ marked points. Each set of trees enumerates the same intersection product of certain pullbacks of $\\psi$ classes under forgetting maps.\nWe give an explicit combinatorial bijection between these two sets of trees using an insertion algorithm. We also classify the words that appear on the slide trees of caterpillar shape via pattern avoidance conditions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17098",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.929539Z"
  },
  {
    "id": "37ae5bad3d277c9ed369c54c2a30bdb1",
    "title": "On the Reflective Symmetry of the Mother Graph",
    "slug": "on-the-reflective-symmetry-of-the-mother-graph",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Benjamin V. Holt",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A permutiple is a natural number whose representation in some base is an integer multiple of a number whose representation has the same collection of digits. Previous efforts have made progress on finding such numbers using graph-theoretical and finite-state-machine constructions. These are the mother graph and the Hoey-Sloane machine (and its state graph). In this paper, we use the reflective symmetry of the mother graph as a starting point for understanding relationships between permutiple classes and how new classes can be determined from old. Such results are not only useful for finding new permutiples from old, they help us to see previous work through a new lens.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17158",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.929742Z"
  },
  {
    "id": "e8429d14cf3fd0a1da9bb371d9061a8d",
    "title": "On the existence and non-existence of spherical $m$-stiff configurations",
    "slug": "on-the-existence-and-non-existence-of-spherical-$m$-stiff-configurations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Eiichi Bannai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper investigates the existence of $m$-stiff configurations in the unit sphere $S^{d-1}$, which are spherical $(2m-1)$-designs that lie on $m$ parallel hyperplanes. We establish two non-existence results: (1) for each fixed integer $m > 5$, there exists no $m$-stiff configuration in $S^{d-1}$ for sufficiently large $d$; (2) for each fixed integer $d > 10$, there exists no $m$-stiff configuration in $S^{d-1}$ for sufficiently large $m$. Furthermore, we provide a complete classification of the dimensions where $m$-stiff configurations exist for $m=2,3,4,5$. We also determine the non-existence (and the existence) of $m$-stiff configurations in $S^{d-1}$ for small $d$ ($3 \\leq d \\leq 120$) with arbitrary $m$, and also for small $m$ ($6 \\leq m \\leq 10$) with arbitrary $d$. Finally, we conjecture that there is no $m$-stiff configuration in $S^{d-1}$ for $(d,m)$ with $d\\geq 3$ and $m\\geq 6$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17184",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.930101Z"
  },
  {
    "id": "764fd0bbe9bdf66fec7ad02af94dad8d",
    "title": "Sombor index and eigenvalues of weakly zero-divisor graph of commutative rings",
    "slug": "sombor-index-and-eigenvalues-of-weakly-zero-divisor-graph-of-commutative-rings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Mohd Shariq",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The weakly zero-divisor graph $W\\Gamma(R)$ of a commutative ring $R$ is the simple undirected graph whose vertices are nonzero zero-divisors of $R$ and two distinct vertices $x$, $y$ are adjacent if and only if there exist $w\\in {\\rm ann}(x)$ and $ z\\in {\\rm ann}(y)$ such that $wz =0$. In this paper, we determine the Sombor index for the weakly zero-divisor graph of the integers modulo ring $\\mathbb{Z}_n$. Furthermore, we investigate the Sombor spectrum and establish bounds for the Sombor energy of the weakly zero-divisor graph of $\\mathbb{Z}_n$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17265",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.930305Z"
  },
  {
    "id": "cb099b90fa768c901ffb04b757400fd7",
    "title": "An Upper Bound on Generalized Cospectral Mates of Oriented Graphs Using Skew-Walk Matrices",
    "slug": "an-upper-bound-on-generalized-cospectral-mates-of-oriented-graphs-using-skew-walk-matrices",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Muhammad Raza",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $D$ be an oriented graph with skew adjacency matrix $S(D)$. Two oriented graphs $D$ and $C$ are said to share the same generalized skew spectrum if $S(D)$ and $S(C)$ have the same eigenvalues, and $J-S(D)$ and $J-S(C)$ also have the same eigenvalues, where $J$ is the all-ones matrix. Such graphs that are not isomorphic are generalized cospectral mates. We derive tight upper bounds on the number of non-isomorphic generalized cospectral mates an oriented graph can admit, based on arithmetic criteria involving the determinant of its skew-walk matrix. As a special case, we also provide a criterion for an oriented graph to be weakly determined by its generalized skew spectrum (WDGSS), that is, its only generalized cospectral mate is its transpose. These criteria relate directly to the controllability of graphs, a fundamental concept in the control of networked systems, thereby connecting spectral characterization of graphs to graph controllability.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17278",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.930514Z"
  },
  {
    "id": "9d1916302c6568918e8e2cbeb2cf4371",
    "title": "Vertex evaluation of multiplex graphs using Forman Curvature",
    "slug": "vertex-evaluation-of-multiplex-graphs-using-forman-curvature",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Taiki Yamada",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Identifying vertices that play a central role is a fundamental problem in network analysis. Although traditional centrality measures have been widely used for this purpose, the growing complexity of contemporary networks necessitates more sophisticated indicators. Forman curvature has recently emerged as a promising approach. In this paper, we define Forman curvature for multilayer networks, a class of complex networks characterized by multiple types of connections or layers between nodes, which are increasingly used to model intricate real-world phenomena. We establish the key properties of Forman curvature in the context of multilayer networks and demonstrate its utility for identifying vertices that hold central positions within these networks. Furthermore, we show that Forman curvature can also serve as an effective tool for the structural classification of entire multilayer networks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17286",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.930708Z"
  },
  {
    "id": "a1a76afc6788543c92a0bfe01f0f63ad",
    "title": "Graph covers and semi-covers: Who is stronger?",
    "slug": "graph-covers-and-semi-covers:-who-is-stronger?",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Jan Kratochvil",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The notion of graph cover, also known as locally bijective homomorphism, is a discretization of covering spaces known from general topology. It is a pair of incidence-preserving vertex- and edge-mappings between two graphs, the edge-component being bijective on the edge-neighborhoods of every vertex and its image. In line with the current trends in topological graph theory and its applications in mathematical physics, graphs are considered in the most relaxed form and as such they may contain multiple edges, loops and semi-edges.\nNevertheless, simple graphs (binary structures without multiple edges, loops, or semi-edges) play an important role. It has been conjectured in [Bok et al.: List covering of regular multigraphs, Proceedings IWOCA 2022, LNCS 13270, pp. 228--242] that for every fixed graph $H$, deciding if a graph covers $H$ is either polynomial time solvable for arbitrary input graphs, or NP-complete for simple ones. A graph $A$ is called stronger than a graph $B$ if every simple graph that covers $A$ also covers $B$. This notion was defined and found useful for NP-hardness reductions for disconnected graphs in [Bok et al.: Computational complexity of covering disconnected multigraphs, Proceedings FCT 2022, LNCS 12867, pp. 85--99]. It was conjectured in [Kratochv\\'l: Towards strong dichotomy of graphs covers, GROW 2022 - Book of open problems, p. 10, {\\tt this https URL}] that if $A$ has no semi-edges, then $A$ is stronger than $B$ if and only if $A$ covers $B$. We prove this conjecture for cubic one-vertex graphs, and we also justify it for all cubic graphs $A$ with at most 4 vertices.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17387",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.930911Z"
  },
  {
    "id": "0fd89000077e3c606fa34434c1c88ed1",
    "title": "Boundedness and Separation in the Graph Covering Number Framework",
    "slug": "boundedness-and-separation-in-the-graph-covering-number-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Miriam Goetze",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "For a graph class $\\mathcal G$ and a graph $H$, the four $\\mathcal G$-covering numbers of $H$, namely global ${\\rm cn}_{g}^{\\mathcal{G}}(H)$, union ${\\rm cn}_{u}^{\\mathcal{G}}(H)$, local ${\\rm cn}_{l}^{\\mathcal{G}}(H)$, and folded ${\\rm cn}_{f}^{\\mathcal{G}}(H)$, each measure in a slightly different way how well $H$ can be covered with graphs from $\\mathcal G$. For every $\\mathcal G$ and $H$ it holds \\[\n{\\rm cn}_{g}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{u}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{l}^{\\mathcal{G}}(H) \\geq {\\rm cn}_{f}^{\\mathcal{G}}(H) \\] and in general each inequality can be arbitrarily far apart. We investigate structural properties of graph classes $\\mathcal G$ and $\\mathcal H$ such that for all graphs $H \\in \\mathcal{H}$, a larger $\\mathcal G$-covering number of $H$ can be bounded in terms of a smaller $\\mathcal G$-covering number of $H$. For example, we prove that if $\\mathcal G$ is hereditary and the chromatic number of graphs in $\\mathcal H$ is bounded, then there exists a function $f$ (called a binding function) such that for all $H \\in \\mathcal{H}$ it holds ${\\rm cn}_{u}^{\\mathcal{G}}(H) \\leq f({\\rm cn}_{g}^{\\mathcal{G}}(H))$.\nFor $\\mathcal G$ we consider graph classes that are component-closed, hereditary, monotone, sparse, or of bounded chromatic number. For $\\mathcal H$ we consider graph classes that are sparse, $M$-minor-free, of bounded chromatic number, or of bounded treewidth. For each combination and every pair of $\\mathcal G$-covering numbers, we either give a binding function $f$ or provide an example of such $\\mathcal{G},\\mathcal{H}$ for which no binding function exists.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17458",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.931109Z"
  },
  {
    "id": "63cd934315f5defddfa97b1631d0ae5e",
    "title": "Two gluing methods for string C-group representations of the symmetric groups",
    "slug": "two-gluing-methods-for-string-c-group-representations-of-the-symmetric-groups",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Dimitri Leemans",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The study of string C-group representations of rank at least $n/2$ for the symmetric group $S_n$ has gained a lot of attention in the last fifteen years. In a recent paper, Cameron et al. gave a list of permutation representation graphs of rank $r\\geq n/2$ for $S_n$, having a fracture graph and a non-perfect split. They conjecture that these graphs are permutation representation graphs of string C-groups. In trying to prove this conjecture, we discovered two new techniques to glue two CPR graphs for symmetric groups together. We discuss the cases in which they yield new CPR graphs. By doing so, we invalidate the conjecture of Cameron et al. We believe our gluing techniques will be useful in the study of string C-group representations of high ranks for the symmetric groups.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17535",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.931297Z"
  },
  {
    "id": "81813bde824cf316f8d4e165e4464542",
    "title": "Principal Minors of Hermitian Laplacian Matrix of Directed Graphs and Their Connection to Directed Graph Substructures",
    "slug": "principal-minors-of-hermitian-laplacian-matrix-of-directed-graphs-and-their-connection-to-directed-graph-substructures",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Silin Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper explores the algebraic characterization of directed graph substructures through principal minors of the Hermitian Laplacian matrix. By generalizing Bapat et al.'s nonsingular substructure theory and by defining substructures as vertex-edge pairs $(V',E')$ which allows edges to connect vertices outside $V'$, we establish a link between the principle minors and the topological properties of key substructures such as rootless trees and unicyclic graphs. Using the Cauchy-Binet formula, we decompose principal minors into sums of determinants of regular substructures. Specifically, we investigate how these algebraic invariants encode information about unicyclic substructures and their properties, contributing to the broader understanding of graph structures through the lens of Hermitian Laplacian matrix of algebraic graph theory.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17553",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.931479Z"
  },
  {
    "id": "43a960edba33691e460e9f87b1eed58a",
    "title": "Log-concavity of inverse Kazhdan-Lusztig polynomials of paving matroids",
    "slug": "log-concavity-of-inverse-kazhdan-lusztig-polynomials-of-paving-matroids",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Matthew H.Y. Xie",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Gao and Xie (2021) conjectured that the inverse Kazhdan-Lusztig polynomial of any matroid is log-concave. Although the inverse Kazhdan-Lusztig polynomial may not always have only real roots, we conjecture that the Hadamard product of an inverse Kazhdan-Lusztig polynomial of degree $n$ and $(1+t)^n$ has only real roots. Using interlacing polynomials and multiplier sequences, we confirm this conjecture for paving matroids. This result allows us to confirm the log-concavity conjecture for these matroids by applying Newton's inequalities.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17567",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.931669Z"
  },
  {
    "id": "dd8f5b155c1c7bcbcf02706371a8c0c3",
    "title": "Signed puzzles for Schubert coefficients",
    "slug": "signed-puzzles-for-schubert-coefficients",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Igor Pak",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We give a signed puzzle rule to compute Schubert coefficients. The rule is based on a careful analysis of Knutson's recurrence arXiv:math/0306304. We use the rule to prove polynomiality of the sums of Schubert coefficients with bounded number of inversions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17734",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.931870Z"
  },
  {
    "id": "4b7b1175b519d08787ce52d23237411e",
    "title": "Quasi-treeings are treeable: a streamlined proof",
    "slug": "quasi-treeings-are-treeable:-a-streamlined-proof",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic (math.LO)",
    "author": {
      "name": "Zhaoshen Zhai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present a streamlined exposition of a construction by R. Chen, A. Poulin, R. Tao, and A. Tserunyan, which proves the treeability of equivalence relations generated by any locally-finite Borel graph such that each component is a quasi-tree. More generally, we show that if each component of a locally-finite Borel graph admits a finitely-separating Borel family of cuts, then we may 'canonically' replace each component of the graph by a tree of special ultrafilter-like objects on cuts called orientations; moreover, if the cuts are dense towards ends, then the union of these trees is a Borel treeing.",
    "pdfUrl": "https://arxiv.org/pdf/2409.09843",
    "tags": [
      "Logic (math.LO)"
    ],
    "createdAt": "2025-04-25T15:49:30.932068Z"
  },
  {
    "id": "9ecda36eec5373fc55f5620571a41872",
    "title": "Burning some myths on privacy properties of social networks against active attacks",
    "slug": "burning-some-myths-on-privacy-properties-of-social-networks-against-active-attacks",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Social and Information Networks (cs.SI)",
    "author": {
      "name": "Serafino Cicerone",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This work focuses on showing some arguments addressed to dismantle the extended idea about that social networks completely lacks of privacy properties. We consider the so-called active attacks to the privacy of social networks and the counterpart $(k,\\ell)$-anonymity measure, which is used to quantify the privacy satisfied by a social network against active attacks. To this end, we make use of the graph theoretical concept of $k$-metric antidimensional graphs for which the case $k=1$ represents those graphs achieving the worst scenario in privacy whilst considering the $(k,\\ell)$-anonymity measure.\nAs a product of our investigation, we present a large number of computational results stating that social networks might not be as insecure as one often thinks. In particular, we develop a large number of experiments on random graphs which show that the number of $1$-metric antidimensional graphs is indeed ridiculously small with respect to the total number of graphs that can be considered. Moreover, we search on several real networks in order to check if they are $1$-metric antidimensional, and obtain that none of them are such. Along the way, we show some theoretical studies on the mathematical properties of the $k$-metric antidimensional graphs for any suitable $k\\ge 1$. In addition, we also describe some operations on graphs that are $1$-metric antidimensional so that they get embedded into another larger graphs that are not such, in order to obscure their privacy properties against active attacks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16944",
    "tags": [
      "Social and Information Networks (cs.SI)"
    ],
    "createdAt": "2025-04-25T15:49:30.932275Z"
  },
  {
    "id": "d548a994ee7cf333488027317d127a46",
    "title": "$C^*$- Colored graph algebras",
    "slug": "$c^*$--colored-graph-algebras",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Farrokh Razavinia",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Following our previous works on $C^*$-graph algebras and the associated Cuntz-Krieger graph families, in this paper we will try to have a look at the colored version of these structures and to see what a $C^*$-colored graph algebra might mean by employing some constructive examples very close to the toy example used in our previous works, and we also will try to study their graph theoretical properties as possible.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16963",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:30.932461Z"
  },
  {
    "id": "f4b7c071349e5c401ca75670d9f79f26",
    "title": "Lower Bound for Zeros in The Character Table of The Symmetric Group with an n-Core Index",
    "slug": "lower-bound-for-zeros-in-the-character-table-of-the-symmetric-group-with-an-n-core-index",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Jayanta Barman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "For any two partitions $\\lambda$ and $\\mu$ of a positive integer $N$, let $\\chi_{\\lambda}(\\mu)$ denote the value of the irreducible character of the symmetric group $S_{N}$ associated with $\\lambda$, evaluated at the conjugacy class of elements whose cycle type is determined by $\\mu$. The quantity $Z_{t}(N)$ is defined as $$ Z_{t}(N):= \\#\\{(\\lambda,\\mu): \\chi_{\\lambda}(\\mu) = 0 \\quad \\text{with $\\lambda$ a $t$-core}\\}. $$ We establish the bound $$ \\max\\limits_{1\\leq t \\leq N} Z_{t}(N) \\geq c_{t}(N)p(N-t)\\geq \\frac{2\\pi p(N)^{2}}{1.01e\\sqrt{6N}\\log N} \\biggl(1+O(N^{-\\frac{1}{2}}\\log N)\\biggr), $$ where $p(N)$ denotes the number of partitions of $N$. Also, we give lower bounds for $Z_{t}(N)$ in different ranges of $t$ and obtain a lower bound for the total number of zeros in the character table of $S_N$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17037",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:30.932660Z"
  },
  {
    "id": "c5b818d514795cc8215a861563f4dee6",
    "title": "Graph Quasirandomness for Hypothesis Testing of Stochastic Block Models",
    "slug": "graph-quasirandomness-for-hypothesis-testing-of-stochastic-block-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Kiril Bangachev",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The celebrated theorem of Chung, Graham, and Wilson on quasirandom graphs implies that if the 4-cycle and edge counts in a graph $G$ are both close to their typical number in $\\mathbb{G}(n,1/2),$ then this also holds for the counts of subgraphs isomorphic to $H$ for any $H$ of constant size. We aim to prove a similar statement where the notion of close is whether the given (signed) subgraph count can be used as a test between $\\mathbb{G}(n,1/2)$ and a stochastic block model $\\mathbb{SBM}.$\nQuantitatively, this is related to approximately maximizing $H \\longrightarrow |\\Phi(H)|^{\\frac{1}{|\\mathsf{V}(H)|}},$ where $\\Phi(H)$ is the Fourier coefficient of $\\mathbb{SBM}$, indexed by subgraph $H.$ This formulation turns out to be equivalent to approximately maximizing the partition function of a spin model over alphabet equal to the community labels in $\\mathbb{SBM}.$\nWe resolve the approximate maximization when $\\mathbb{SBM}$ satisfies one of four conditions: 1) the probability of an edge between any two vertices in different communities is exactly $1/2$; 2) the probability of an edge between two vertices from any two communities is at least $1/2$ (this case is also covered in a recent work of Yu, Zadik, and Zhang); 3) the probability of belonging to any given community is at least $c$ for some universal constant $c>0$; 4) $\\mathbb{SBM}$ has two communities. In each of these cases, we show that there is an approximate maximizer of $|\\Phi(H)|^{\\frac{1}{|\\mathsf{V}(H)|}}$ in the set $\\mathsf{A} = \\{\\text{stars, 4-cycle}\\}.$ This implies that if there exists a constant-degree polynomial test distinguishing $\\mathbb{G}(n,1/2)$ and $\\mathbb{SBM},$ then the two distributions can also be distinguished via the signed count of some graph in $\\mathsf{A}.$ We conjecture that the same holds true for distinguishing $\\mathbb{G}(n,1/2)$ and any graphon if we also add triangles to $\\mathsf{A}.$",
    "pdfUrl": "https://arxiv.org/pdf/2504.17202",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:30.932851Z"
  },
  {
    "id": "3a01db7984dea0e153110045becfdbfc",
    "title": "Service Rate Regions of MDS Codes & Fractional Matchings in Quasi-uniform Hypergraphs",
    "slug": "service-rate-regions-of-mds-codes-&-fractional-matchings-in-quasi-uniform-hypergraphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Hoang Ly",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The service rate region (SRR) has emerged as a critical performance metric for distributed systems that store data redundantly. It measures the system's ability to serve multiple users concurrently. Mathematically, the SRR is a polytope in R^k where each dimension corresponds to the service request rate of one of the k data objects. This paper focuses on systems employing a class of Maximum Distance Separable (MDS) codes. For each code in the class, we characterize the k axes intercept points of its SRR, and the smallest standard simplex that includes the SRR. We use these results to show that the SRR grows with the increasing number of systematic columns in the generator matrices. We establish a graph-theoretic framework associating this SRR problem with fractional matchings in quasi-uniform hypergraphs. Identifying the SRR polytope is equivalent to determining a particular image of the fractional-matching polytope. We introduce a notion of Greedy Matching and show that it is sufficient to focus on these matchings to characterize the SRR rather than the entire matching polytope. With these tools, we determine the SRR of a large subset of the considered class of codes. Our results generalize previous characterizations of systematic and non-systematic MDS-coded systems, offering a unified framework for analyzing service rate regions of codes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17244",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:30.933037Z"
  },
  {
    "id": "459afca5ca8a432ac31945b587c0c128",
    "title": "Quantum Corner VOA and the Super Macdonald Polynomials",
    "slug": "quantum-corner-voa-and-the-super-macdonald-polynomials",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "Panupong Cheewaphutthisakun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we establish a relation between the quantum corner VOA $q\\widetilde{Y}_{L,0,N}[\\Psi]$, which can be regarded as a generalization of quantum $W_N$ algebra, and Sergeev-Veselov super Macdonald polynomials. We demonstrate precisely that, under a specific map, the correlation functions of the currents of $q\\widetilde{Y}_{L,0,N}[\\Psi]$, coincide with the Sergeev-Veselov super Macdonald polynomials.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17326",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:30.933243Z"
  },
  {
    "id": "f5d5d64922ed38f8ec96931a8cbb94f1",
    "title": "Morphisms and BWT-run Sensitivity",
    "slug": "morphisms-and-bwt-run-sensitivity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Formal Languages and Automata Theory (cs.FL)",
    "author": {
      "name": "Gabriele Fici",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study how the application of injective morphisms affects the number $r$ of equal-letter runs in the Burrows-Wheeler Transform (BWT). This parameter has emerged as a key repetitiveness measure in compressed indexing. We focus on the notion of BWT-run sensitivity after application of an injective morphism. For binary alphabets, we characterize the class of morphisms that preserve the number of BWT-runs up to a bounded additive increase, by showing that it coincides with the known class of primitivity-preserving morphisms, which are those that map primitive words to primitive words. We further prove that deciding whether a given binary morphism has bounded BWT-run sensitivity is possible in polynomial time with respect to the total length of the images of the two letters. Additionally, we explore new structural and combinatorial properties of synchronizing and recognizable morphisms. These results establish new connections between BWT-based compressibility, code theory, and symbolic dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17443",
    "tags": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "createdAt": "2025-04-25T15:49:30.933446Z"
  },
  {
    "id": "496bf2bf27e62ee3524ab04c0a34eac8",
    "title": "Modularity of tadpole Nahm sums in ranks 4 and 5",
    "slug": "modularity-of-tadpole-nahm-sums-in-ranks-4-and-5",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Changsong Shi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Around 2016, Calinescu, Milas and Penn conjectured that the rank $r$ Nahm sum associated with the $r\\times r$ tadpole Cartan matrix is modular, and they provided a proof for $r=2$. The $r=3$ case was recently resolved by Milas and Wang. We prove this conjecture for the next cases $r=4,5$. We also prove the modularity of some companion Nahm sums by establishing the corresponding Rogers--Ramanujan type identities. A key new ingredient in our proofs is some rank reduction formulas which allow us to decompose higher rank tadpole Nahm sums to mixed products of some lower rank Nahm-type sums and theta functions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17737",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:30.933641Z"
  },
  {
    "id": "d562a7935cbef0bbe44abe0a66e94994",
    "title": "Dual Ramsey degrees of relational structures over finite languages",
    "slug": "dual-ramsey-degrees-of-relational-structures-over-finite-languages",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Aleksa Duklevski",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The main goal of this paper is to develop the dual Ramsey theory for finite relational structures with respect to natural structure-preserving maps. Tools of category theory prove to be instrumental in this endeavor, as they allow us to lift the dual Ramsey phenomena from the context of chains and rigid surjections (which capture the Finite Dual Ramsey Theorem of Graham, Leeb and Rothschild, and the Infinite Dual Ramsey Theorem of Carlson and Simpson) onto the context of structures and structure-preserving maps.",
    "pdfUrl": "https://arxiv.org/pdf/2407.04030",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.933829Z"
  },
  {
    "id": "2f03684c213ddafb5105368c535ae1f6",
    "title": "Coloring, list coloring, and fractional coloring in intersections of matroids",
    "slug": "coloring,-list-coloring,-and-fractional-coloring-in-intersections-of-matroids",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Ron Aharoni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is known that in matroids the difference between the chromatic number and the fractional chromatic number is smaller than 1, and that the list chromatic number is equal to the chromatic number. We investigate the gap within these pairs of parameters for hypergraphs that are the intersection of a given number k of matroids. We prove that in such hypergraphs the list chromatic number is at most k times the chromatic number and at most 2k-1 times the maximum chromatic number among the k matroids. We study the relationship between three polytopes associated with k-sets of matroids, and connect them to bounds on the fractional chromatic number of the intersection of the members of the k-set. This also connects to bounds on the matroidal matching and covering number of the intersection of the members of the k-set. The tools used are in part topological.",
    "pdfUrl": "https://arxiv.org/pdf/2407.08789",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.934032Z"
  },
  {
    "id": "6be177fa702765270169a5c0f89316da",
    "title": "Coloring the intersection of two matroids",
    "slug": "coloring-the-intersection-of-two-matroids",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Eli Berger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A result [The intersection of a matroid and a simplicial complex, Trans. Amer. Math. Soc. 358] from 2006 of Aharoni and the first author of this paper states that for any two positive integers $p,q$, where $p$ divides $q$, if a matroid $\\mathcal{M}$ is $p$-colorable and a matroid $\\mathcal{N}$ is $q$-colorable then $\\mathcal{M} \\cap \\mathcal{N}$ is $(p+q)$-colorable. In this paper we show that the assumption that $p$ divides $q$ is in fact redundant, and we also prove that $\\mathcal{M} \\cap \\mathcal{N}$ is even $p+q$ list-colorable.\nThe result uses topology and relies on a new parameter yielding a lower bound for the topological connectivity of the intersection of two matroids.",
    "pdfUrl": "https://arxiv.org/pdf/2407.09160",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.934233Z"
  },
  {
    "id": "98f76051f8cf6d49ea0a4293a6e0078a",
    "title": "Parabolic restrictions and double deformations of weight multiplicities",
    "slug": "parabolic-restrictions-and-double-deformations-of-weight-multiplicities",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Cdric Lecouvey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce some (p,q)-deformations of the weight multiplicities for the representations of any simple Lie algebra g over the complex numbers. This is done by associating the indeterminate q to the positive roots of a parabolic subsystem of g and the indeterminate p to the remaining positive roots. When p=q, we so recover the usual Lusztig analogues of weight multiplicities. We then study the positivity of the coefficients in these double deformations. In particular, the positivity holds when p=1 in which case the polynomials have a natural algebraic interpretation in terms of a parabolic Brylinski filtration. For the parabolic restriction from type C to type A, this positivity result was conjectured by Lee.",
    "pdfUrl": "https://arxiv.org/pdf/2412.10003",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.934420Z"
  },
  {
    "id": "60e6b881d7d47f188466ee7d41ad5ac6",
    "title": "Cyclic Sieving of Multisets with Bounded Multiplicity and the Frobenius Coin Problem",
    "slug": "cyclic-sieving-of-multisets-with-bounded-multiplicity-and-the-frobenius-coin-problem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Drew Armstrong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The two subjects in the title are related via the specialization of symmetric polynomials at roots of unity. Let $f(z_1,\\ldots,z_n)\\in\\mathbb{Z}[z_1,\\ldots,z_n]$ be a symmetric polynomial with integer coefficients and let $\\omega$ be a primitive $d$th root of unity. If $d|n$ or $d|(n-1)$ then we have $f(1,\\ldots,\\omega^{n-1})\\in\\mathbb{Z}$. If $d|n$ then of course we have $f(\\omega,\\ldots,\\omega^n)=f(1,\\ldots,\\omega^{n-1})\\in\\mathbb{Z}$, but when $d|(n+1)$ we also have $f(\\omega,\\ldots,\\omega^n)\\in\\mathbb{Z}$. We investigate these three families of integers in the case $f=h_k^{(b)}$, where $h_k^{(b)}$ is the coefficient of $t^k$ in the generating function $\\prod_{i=1}^n (1+z_it+\\cdots+(z_it)^{b-1})$. These polynomials were previously considered by several authors. They interpolate between the elementary symmetric polynomials ($b$=2) and the complete homogeneous symmetric polynomials ($b\\to\\infty$). When $\\gcd(b,d)=1$ with $d|n$ or $d|(n-1)$ we find that the integers $h_k^{(b)}=(1,\\omega,\\ldots,\\omega^{n-1})$ are related to cyclic sieving of multisets with multiplicities bounded above by $b$, generalizing the well know cyclic sieving results for sets ($b=2$) and multisets ($b\\to \\infty$). When $\\gcd(b,d)=1$ and $d|(n+1)$ we find that the integers $h_k^{(b)}(\\omega,\\omega^2,\\ldots,\\omega^n)$ are related to the Frobenius coin problem with two coins. The case $\\gcd(b,d)\\neq 1$ is more complicated. At the end of the paper we combine these results with the expansion of $h_k^{(b)}$ in various bases of the ring of symmetric polynomials.",
    "pdfUrl": "https://arxiv.org/pdf/2502.00378",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.934610Z"
  },
  {
    "id": "f2c873ba5feac43f639fa2ec63a9b899",
    "title": "A short proof of Tuza's conjecture for weak saturation in hypergraphs",
    "slug": "a-short-proof-of-tuza's-conjecture-for-weak-saturation-in-hypergraphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Nikolai Terekhov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Given an $r$-uniform hypergraph $H$ and a positive integer $n$, the weak saturation number $\\mathrm{wsat}(n,H)$ is the minimum number of edges in an $r$-uniform hypergraph $F$ on $n$ vertices such that the missing edges in $F$ can be added, one at a time, so that each added edge creates a copy of $H$. Shapira and Tyomkyn (Proceedings of the American Mathematical Society, 2023) proved Tuza's conjecture on asymptotic behaviour of $\\mathrm{wsat}(n, H)$. In this paper we provide a significantly shorter proof of the conjecture.",
    "pdfUrl": "https://arxiv.org/pdf/2504.03816",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.934794Z"
  },
  {
    "id": "f54a318e725c81549ca1bfeda9fb589f",
    "title": "A Recursive Block Pillar Structure in the Kolakoski Sequence K(1,3)",
    "slug": "a-recursive-block-pillar-structure-in-the-kolakoski-sequence-k(1,3)",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "William Cook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Kolakoski sequence K(1,3) over {1, 3} is known to be structured, unlike K(1,2), with symbol frequency d approx. 0.397 linked to the Pisot number alpha (real root of x^3 - 2x^2 - 1 = 0). We reveal an explicit nested recursion defining block sequences B(n) and pillar sequences P(n) via B(n+1) = B(n) P(n) B(n) and P(n+1) = G(R(P(n)), 3), where G generates runs from vector R(P(n)). We prove B(n) are prefixes of K(1,3) converging to it, and B(n+1) = G(R(B(n)), 1), directly reflecting the Kolakoski self-encoding property. We derive recurrences for lengths |B(n)|, |P(n)| and symbol counts, confirming growth governed by alpha (limit |B(n+1)|/|B(n)| = alpha as n -> infinity). If block/pillar densities converge, they must equal d. This constructive framework provides an alternative perspective on K(1,3)'s regularity, consistent with known results from substitution dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13433",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.934984Z"
  },
  {
    "id": "9597913d7c68a51e7a3bc6f7d90d587d",
    "title": "Hypertrees and their host trees: a survey",
    "slug": "hypertrees-and-their-host-trees:-a-survey",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Pablo De Caria Di Fonzo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A hypergraph $\\mathcal{H}=(V,\\mathcal{E})$ is a hypertree if it admits a tree $T$ with vertex set $V$ such that every edge of $\\mathcal{H}$ induces a subtree of $T$. A tree like that is called a host tree. Several characterizations and properties of hypertrees have been discovered over the years. However, the interest in the structure of their host trees was weaker and restricted to particular scenarios where they arise, like the clique tree of chordal graphs. In that special case, the proofs of most characteristics of clique trees that exist in the literature rely significantly on the structural properties of chordal graphs. The purpose of this work is the study of the properties of the host trees of hypertrees in a more general context and have them described in a single place, giving simpler proofs for known facts, generalizing others and introducing some new concepts that the author considers that are relevant for the study of the topic. Particularly, we will determine what edges can be found in some host tree of a hypertree, and how these edges must be combined to form a host tree, with an emphasis in tools like the basis and the completion of a hypergraph, and the concept of equivalent hypergraphs.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15570",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:30.935172Z"
  },
  {
    "id": "afa3e7c4e2db4e77e05c78be70f89f9b",
    "title": "Pseudorandomness of the Sticky Random Walk",
    "slug": "pseudorandomness-of-the-sticky-random-walk",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Emile Anand",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We extend the pseudorandomness of random walks on expander graphs using the sticky random walk. Building on prior works, it was recently shown that expander random walks can fool all symmetric functions in total variation distance (TVD) upto an $O(\\lambda(\\frac{p}{\\min f})^{O(p)})$ error, where $\\lambda$ is the second largest eigenvalue of the expander, $p$ is the size of the arbitrary alphabet used to label the vertices, and $\\min f = \\min_{b\\in[p]} f_b$, where $f_b$ is the fraction of vertices labeled $b$ in the graph. Golowich and Vadhan conjecture that the dependency on the $(\\frac{p}{\\min f})^{O(p)}$ term is not tight. In this paper, we resolve the conjecture in the affirmative for a family of expanders. We present a generalization of the sticky random walk for which Golowich and Vadhan predict a TVD upper bound of $O(\\lambda p^{O(p)})$ using a Fourier-analytic approach. For this family of graphs, we use a combinatorial approach involving the Krawtchouk functions to derive a strengthened TVD of $O(\\lambda)$. Furthermore, we present equivalencies between the generalized sticky random walk, and, using linear-algebraic techniques, show that the generalized sticky random walk parameterizes an infinite family of expander graphs.",
    "pdfUrl": "https://arxiv.org/pdf/2307.11104",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:30.935364Z"
  },
  {
    "id": "b3ef80e117c8a72fab4243655c24f214",
    "title": "Catalan percolation",
    "slug": "catalan-percolation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Eleanor Archer",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In Catalan percolation, all nearest-neighbor edges $\\{i,i+1\\}$ along $\\mathbb Z$ are initially occupied, and all other edges are open independently with probability $p$. Open edges $\\{i,j\\}$ are occupied if some pair of edges $\\{i,k\\}$ and $\\{k,j\\}$, with $i<k<j$, become occupied. This model was introduced by Gravner and the third author, in the context of polluted graph bootstrap percolation.\nWe prove that the critical $p_{\\mathrm c}$ is strictly between that of oriented site percolation on $\\mathbb Z^2$ and the Catalan growth rate $1/4$. Our main result shows that an enhanced oriented percolation model, with non-decaying infinite-range dependency, has a strictly smaller critical parameter than the classical model. This is reminiscent of the work of Duminil-Copin, Hilrio, Kozma and Sidoravicius on brochette percolation. Our proof differs, however, in that we do not use Aizenman--Grimmett enhancements or differential inequalities. Two key ingredients are the work of Hilrio, S, Sanchis and Teixeira on stretched lattices, and the Russo--Seymour--Welsh result for oriented percolation by Duminil-Copin, Tassion and Teixeira.",
    "pdfUrl": "https://arxiv.org/pdf/2404.19583",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:30.935577Z"
  },
  {
    "id": "1c6e6c388642c2129ca843b31a477159",
    "title": "Two-row Delta Springer varieties",
    "slug": "two-row-delta-springer-varieties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Abel Lacabanne",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the geometry and topology of $\\Delta$-Springer varieties associated with two-row partitions. These varieties were introduced in recent work by Griffin-Levinson-Woo to give a geometric realization of a symmetric function appearing in the Delta conjecture by Haglund-Remmel-Wilson. We provide an explicit and combinatorial description of the irreducible components of the two-row $\\Delta$-Springer variety and compare it to the ordinary two-row Springer fiber as well as Kato's exotic Springer fiber corresponding to a one-row bipartition. In addition to that, we extend the action of the symmetric group on the homology of the two-row $\\Delta$-Springer variety to an action of a degenerate affine Hecke algebra and relate this action to a $\\mathfrak{gl}_{2}$-tensor space.",
    "pdfUrl": "https://arxiv.org/pdf/2407.10792",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:30.935771Z"
  },
  {
    "id": "d1b9a337e52fef816f9fa67aa2d19d23",
    "title": "A Graph-Theoretic Framework for Free-Parafermion Solvability",
    "slug": "a-graph-theoretic-framework-for-free-parafermion-solvability",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Ryan L. Mann",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present a graph-theoretic characterisation of when a quantum spin model admits an exact solution via a mapping to free parafermions. Our characterisation is based on the concept of a frustration graph, which represents the commutation relations between Weyl operators of a Hamiltonian. We show that a quantum spin system has an exact free-parafermion solution if its frustration graph is an oriented indifference graph. Further, we show that if the frustration graph of a model can be dipath oriented via switching operations, then the model is integrable in the sense that there is a family of commuting independent set charges. Additionally, we establish an efficient algorithm for deciding whether this is possible. Our characterisation extends that given for free-fermion solvability. Finally, we apply our results to solve three qudit spin models.",
    "pdfUrl": "https://arxiv.org/pdf/2408.09684",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:30.935974Z"
  },
  {
    "id": "6d8bc0a3d77f5d6c0a267d4c3648944a",
    "title": "Monomial ideals whose all matching powers are Cohen-Macaulay",
    "slug": "monomial-ideals-whose-all-matching-powers-are-cohen-macaulay",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Commutative Algebra (math.AC)",
    "author": {
      "name": "Antonino Ficarra",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the present paper, we aim to classify monomial ideals whose all matching powers are Cohen-Macaulay. We especially focus our attention on edge ideals. The Cohen-Macaulayness of the last matching power of an edge ideal is characterized, providing an algebraic analogue of the famous Tutte theorem regarding graphs having a perfect matching. For chordal graphs, very well-covered graphs and Cameron-Walker graphs, we completely solve our problem.",
    "pdfUrl": "https://arxiv.org/pdf/2410.01666",
    "tags": [
      "Commutative Algebra (math.AC)"
    ],
    "createdAt": "2025-04-25T15:49:30.936160Z"
  },
  {
    "id": "e8b3b6577ad7bc68b5e32047b880c59f",
    "title": "Fermions and Zeta Function on the Graph",
    "slug": "fermions-and-zeta-function-on-the-graph",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "So Matsuura",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a novel fermionic model on the graphs. The Dirac operator of the model consists of deformed incidence matrices on the graph and the partition function is given by the inverse of the graph zeta function. We find that the coefficients of the inverse of the graph zeta function, which is a polynomial of finite degree in the coupling constant, count the number of fermionic cycles on the graph. We also construct the model on grid graphs by using the concept of the covering graph and the Artin-Ihara $L$-function. In connection with this, we show that the fermion doubling is absent, and the overlap fermions can be constructed on a general graph. Furthermore, we relate our model to statistical models by introducing the winding number around cycles, where the distribution of the poles of the graph zeta function (the zeros of the partition function) plays a crucial role. Finally, we formulate gauge theory including fermions on the graph from the viewpoint of the covering graph derived from the gauge group in a unified way.",
    "pdfUrl": "https://arxiv.org/pdf/2501.08803",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:30.936353Z"
  },
  {
    "id": "68fe541c4ee2f7851492c8d48e04ae45",
    "title": "Higher Koszul duality and $n$-affineness",
    "slug": "higher-koszul-duality-and-$n$-affineness",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "James Pascaleff",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study $\\mathbb{E}_n$-Koszul duality for pairs of algebras of the form $\\mathrm{C}_{\\bullet}(\\Omega^{n}_*X;\\Bbbk) \\leftrightarrow \\mathrm{C}^{\\bullet}(X;\\Bbbk)$, and the closely related question of $n$-affineness for Betti stacks. It was expected, but not known, that $\\mathbb{E}_n$-Koszul duality should induce a kind of Morita equivalence between categories of iterated modules. We establish this rigorously by proving that the $(\\infty,n)$-category of iterated modules over $\\mathrm{C}_{\\bullet}(\\Omega_*^{n+1}X;\\Bbbk)$ is equivalent to the $(\\infty,n)$-category of quasi-coherent sheaves of $(\\infty,n-1)$-categories on $\\mathrm{cSpec}(\\mathrm{C}^{\\bullet}(X;\\Bbbk))$, where $\\mathrm{cSpec}(\\mathrm{C}^{\\bullet}(X;\\Bbbk))$ is the cospectrum of $\\mathrm{C}^{\\bullet}(X;\\Bbbk)$. By the monodromy equivalence, these categories are also equivalent to the category of higher local systems on $X$, $n\\mathbf{LocSysCat}^{n-1}(X;\\Bbbk)$. Our result is new already in the classical case $n=1$, although it can be seen to recover well known formulations of $\\mathbb{E}_1$-Koszul duality as a Morita equivalence of module categories (up to appropriate completions of the $t$-structures). We also investigate (higher) affineness properties of Betti stacks. We give a complete characterization of $n$-affine Betti stacks, in terms of the $0$-affineness of their iterated loop space. As a consequence, we prove that $n$-truncated Betti stacks are $n$-affine; and that $\\pi_{n+1}(X)$ is an obstruction to $n$-affineness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16935",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:31.157214Z"
  },
  {
    "id": "9cd2f077306c051a40cdb384bdb365ca",
    "title": "Many-valued aspects of tense an related operators",
    "slug": "many-valued-aspects-of-tense-an-related-operators",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic (math.LO)",
    "author": {
      "name": "Michal Botur",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Our research builds upon Halmos's foundational work on functional monadic Boolean algebras and our previous work on tense operators to develop three essential constructions, including the important concepts of fuzzy sets and powerset operators. These constructions have widespread applications across contemporary mathematical disciplines, including algebra, logic, and topology. The framework we present generates four covariant and two contravariant functors, establishing three adjoint situations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17654",
    "tags": [
      "Logic (math.LO)"
    ],
    "createdAt": "2025-04-25T15:49:31.157428Z"
  },
  {
    "id": "f5941b15a632184834374432848a5a9d",
    "title": "Orbifolds, higher dagger structures, and idempotents",
    "slug": "orbifolds,-higher-dagger-structures,-and-idempotents",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Algebra (math.QA)",
    "author": {
      "name": "Nils Carqueville",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The orbifold/condensation completion procedure of defect topological quantum field theories can be seen as carrying out a lattice or state sum model construction internal to an ambient theory. In this paper, we propose a conceptual algebraic description of orbifolds/condensations for arbitrary tangential structures in terms of higher dagger structures and higher idempotents. In particular, we obtain (oriented) orbifold completion from (framed) condensation completion by using a general strictification procedure for higher dagger structures which we describe explicitly in low dimensions; we also discuss the spin and unoriented case. We provide several examples of higher dagger categories, such as those associated to state sum models, (orbifolds of) Landau--Ginzburg models, and truncated affine Rozansky--Witten models. We also explain how their higher dagger structures are naturally induced from rigid symmetric monoidal structures, recontextualizing and extending results from the literature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17764",
    "tags": [
      "Quantum Algebra (math.QA)"
    ],
    "createdAt": "2025-04-25T15:49:31.157633Z"
  },
  {
    "id": "7e275fba7762d6d48019bda6d16a0b43",
    "title": "Unital k-Restricted Infinity-Operads",
    "slug": "unital-k-restricted-infinity-operads",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Amartya Shekhar Dubey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study unital $\\infty$-operads by their arity restrictions. Given $k \\geq 1$, we develop a model for unital $k$-restricted $\\infty$-operads, which are variants of $\\infty$-operads which has only $(\\leq k)$-arity morphisms, as complete Segal presheaves on closed $k$-dendroidal trees, which are closed trees build from corollas with valences $\\leq k$. Furthermore, we prove that the restriction functors from unital $\\infty$-operads to unital $k$-restricted $\\infty$-operads admit fully faithful left and right adjoints by showing that the left and right Kan extensions preserve complete Segal objects. Varying $k$, the left and right adjoints give a filtration and a co-filtration for any unital $\\infty$-operads by $k$-restricted $\\infty$-operads.",
    "pdfUrl": "https://arxiv.org/pdf/2407.17444",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:31.157832Z"
  },
  {
    "id": "d3ef8db3f5ae1d2a4f906c12359561ff",
    "title": "A hypercomplex method for solving piecewise continuous biharmonic problem in domains with corner points",
    "slug": "a-hypercomplex-method-for-solving-piecewise-continuous-biharmonic-problem-in-domains-with-corner-points",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Complex Variables (math.CV)",
    "author": {
      "name": "S.V. Gryshchuk",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A piecewise continuous biharmonic problem in domains with corner points and a corresponding Schwarz type boundary value problem for monogenic functions in a commutative biharmonic algebra are considered. A method for reducing the problems to a system of integral equations is developed.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17351",
    "tags": [
      "Complex Variables (math.CV)"
    ],
    "createdAt": "2025-04-25T15:49:31.400637Z"
  },
  {
    "id": "97bd0f6d6d641332f1b552ce897a84d6",
    "title": "Minimal Surfaces via Complex Quaternions",
    "slug": "minimal-surfaces-via-complex-quaternions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Complex Variables (math.CV)",
    "author": {
      "name": "Amedeo Altavilla",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Minimal surfaces play a fundamental role in differential geometry, with applications spanning physics, material science, and geometric design. In this paper, we explore a novel quaternionic representation of minimal surfaces, drawing an analogy with the well-established theory of Pythagorean Hodograph (PH) curves. By exploiting the algebraic structure of complex quaternions, we introduce a new approach to generating minimal surfaces via quaternionic transformations. This method extends classical Weierstra-Enneper representations and provides insights into the interplay between quaternionic analysis, PH curves, and minimal surface geometry. Additionally, we discuss the role of the Sylvester equation in this framework and demonstrate practical examples, including the construction of Enneper surface patches. The findings open new avenues in computational geometry and geometric modeling, bridging abstract algebraic structures with practical applications in CAD and computer graphics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17377",
    "tags": [
      "Complex Variables (math.CV)"
    ],
    "createdAt": "2025-04-25T15:49:31.400850Z"
  },
  {
    "id": "edd46b5a081408d984c6e414544dc9db",
    "title": "The Cauchy--Szeg Projection for domains in $\\mathbb C^n$ with minimal smoothness: weighted theory",
    "slug": "the-cauchy--szeg-projection-for-domains-in-$\\mathbb-c^n$-with-minimal-smoothness:-weighted-theory",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Complex Variables (math.CV)",
    "author": {
      "name": "Xuan Thinh Duong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $D\\subset\\mathbb C^n$ be a bounded, strongly pseudoconvex domain whose boundary $bD$ satisfies the minimal regularity condition of class $C^2$. A 2017 result of Lanzani \\& Stein states that the Cauchy--Szeg projection $S_\\omega$ defined with respect to a bounded, positive continuous multiple $\\omega$ of induced Lebesgue measure, {maps $L^p(bD, \\omega)$ to $L^p(bD, \\omega)$ continuously} for any $1<p<\\infty$. Here we show that $S_\\omega$ satisfies explicit quantitative bounds in $L^p(bD, \\Omega)$, for any $1<p<\\infty$ and for any $\\Omega$ in the maximal class of \\textit{$A_p$}-measures, that is for $\\Omega_p = \\psi_p\\sigma$ where $\\psi_p$ is a Muckenhoupt $A_p$-weight and $\\sigma$ is the induced Lebesgue measure (with $\\omega$'s as above being a sub-class). Earlier results rely upon an asymptotic expansion and subsequent pointwise estimates of the Cauchy--Szeg kernel, but these are unavailable in our setting of minimal regularity {of $bD$}; at the same time, more recent techniques that allow to handle domains with minimal regularity (Lanzani--Stein 2017) are not applicable to $A_p$-measures. It turns out that the method of {quantitative} extrapolation is an appropriate replacement for the missing tools. To finish, we identify a class of holomorphic Hardy spaces defined with respect to $A_p$-measures for which a meaningful notion of Cauchy--Szeg projection can be defined when $p=2$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17608",
    "tags": [
      "Complex Variables (math.CV)"
    ],
    "createdAt": "2025-04-25T15:49:31.401064Z"
  },
  {
    "id": "26d9f9c74eb45fa7724d433195ddaf96",
    "title": "Non-quadratic solutions to the Monge-Ampre equation",
    "slug": "non-quadratic-solutions-to-the-monge-ampre-equation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Complex Variables (math.CV)",
    "author": {
      "name": "Yifei Pan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We construct ample smooth strictly plurisubharmonic non-quadratic solutions to the Monge-Ampre equation on either cylindrical type domains or the whole complex Euclidean space $\\mathbb C^2$. Among these, the entire solutions defined on $\\mathbb C^2$ induce flat Kahler metrics, as expected by a question of Calabi. In contrast, those on cylindrical domains produce a family of nowhere flat Kahler metrics. Beyond these smooth solutions, we also classify solutions that are radially symmetric in one variable, which exhibit various types of singularities. Finally, we explore analogous solutions to Donaldson's equation motivated by a result of He.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17625",
    "tags": [
      "Complex Variables (math.CV)"
    ],
    "createdAt": "2025-04-25T15:49:31.401270Z"
  },
  {
    "id": "56d376ea4eea90f377daf0c887fc717b",
    "title": "Widom factors in $\\mathbb C^n$",
    "slug": "widom-factors-in-$\\mathbb-c^n$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Complex Variables (math.CV)",
    "author": {
      "name": "Gkalp Alpan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We generalize the theory of Widom factors to the $\\mathbb C^n$ setting. We define Widom factors of compact subsets $K\\subset \\mathbb C^n$ associated with multivariate orthogonal polynomials and weighted Chebyshev polynomials. We show that on product subsets $K=K_1\\times\\cdots\\times K_n$ of $\\mathbb C^n$, where each $K_j$ is a non-polar compact subset of $\\mathbb C$, these quantities have universal lower bounds which directly extend one dimensional results. Under the additional assumption that each $K_j$ is a subset of the real line, we provide improved lower bounds for Widom factors for some weight functions $w$; in particular, for the case $w\\equiv 1$. Finally, we define the Mahler measure of a multivariate polynomial relative to $K\\subset \\mathbb C^n$ and obtain lower bounds for this quantity on product sets.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17727",
    "tags": [
      "Complex Variables (math.CV)"
    ],
    "createdAt": "2025-04-25T15:49:31.401463Z"
  },
  {
    "id": "609aedfdf2b1ca7ddba9bcebcad8cfce",
    "title": "The $q^{\\mathrm{Volume}}$ lozenge tiling model via non-Hermitian orthogonal polynomials",
    "slug": "the-$q^{\\mathrm{volume}}$-lozenge-tiling-model-via-non-hermitian-orthogonal-polynomials",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Ahmad Barhoumi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider the $q^\\text{Volume}$ lozenge tiling model on a large, finite hexagon. It is well-known that random lozenge tilings of the hexagon correspond to a two-dimensional determinantal point process via a bijection with ensembles of non-intersecting paths. The starting point of our analysis is a formula for the correlation kernel due to Duits and Kuijlaars which involves the Christoffel-Darboux kernel of a particular family of non-Hermitian orthogonal polynomials. Our main results are split into two parts: the first part concerns the family of orthogonal polynomials, and the second concerns the behavior of the boundary of the so-called arctic curve. In the first half, we identify the orthogonal polynomials as a non-standard instance of little $q$-Jacobi polynomials and compute their large degree asymptotics in the $q \\to 1$ regime. A consequence of this analysis is a proof that the zeros of the orthogonal polynomials accumulate on an arc of a circle and an asymptotic formula for the Christoffel-Darboux kernel. In the second half, we use these asymptotics to show that the boundary of the liquid region converges to the Airy process, in the sense of finite dimensional distributions, away from the boundary of the hexagon. At inflection points of the arctic curve, we show that we do not need to subtract/add a parabola to the Airy line ensemble, and this effect persists at distances which are $o(N^{-2/9})$ in the tangent direction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17042",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:31.401650Z"
  },
  {
    "id": "ab14a6c0c33b7ee52d0a38397fe7badd",
    "title": "On Hopf hypersurfaces of the complex quadric with constant principal curvatures",
    "slug": "on-hopf-hypersurfaces-of-the-complex-quadric-with-constant-principal-curvatures",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Differential Geometry (math.DG)",
    "author": {
      "name": "Haizhong Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we classify the Hopf hypersurfaces of the complex quadric $Q^m=SO_{m+2}/(SO_2SO_m)$ ($m\\geq3$) with at most five distinct constant principal curvatures. We also classify the Hopf hypersurfaces of $Q^m$ ($m=3,4,5$) with constant principal curvatures. All these real hypersurfaces are open parts of homogeneous examples.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17689",
    "tags": [
      "Differential Geometry (math.DG)"
    ],
    "createdAt": "2025-04-25T15:49:31.686318Z"
  },
  {
    "id": "32b7fc58d16c28afb509b37858b3454b",
    "title": "On the creation of conjugate points for thermostats",
    "slug": "on-the-creation-of-conjugate-points-for-thermostats",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Javier Echevarra Cuesta",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $(M, g)$ be a closed oriented Riemannian surface, and let $SM$ be its unit tangent bundle. We show that the interior in the $\\mathcal{C}^2$ topology of the set of smooth functions $\\lambda:SM\\to \\mathbb{R}$ for which the thermostat $(M, g, \\lambda)$ has no conjugate points is a subset of those functions for which the thermostat is projectively Anosov. Moreover, we prove that if a reversible thermostat is projectively Anosov, then its non-wandering set contains no conjugate points.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17153",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.686520Z"
  },
  {
    "id": "d175ee3f82653a651b1b69acbacc32c4",
    "title": "Defects in unidimensional structures",
    "slug": "defects-in-unidimensional-structures",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Mewen Crespo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In a previous work of the first authors, a non-holonomic model, generalising the micromorphic models and allowing for curvature (disclinations) to arise from the kinematic values, was presented. In the present paper, a generalisation of the classical models of Euler-Bernoulli and Timoshenko bending beams based on the mentioned work is proposed. The former is still composed of only one unidimensional scalar field, while the later introduces a third unidimensional scalar field, correcting the second order terms. The generalised Euler-Bernoulli beam is then shown to exhibit curvature (i.e. disclinations) linked to a third order derivative of the displacement, but no torsion (dislocations). Parallelly, the generalised Timoshenko beam is shown to exhibit both curvature and torsion, where the former is linked to the non-holonomy introduced in the generalisation. Lastly, using variational calculus, asymptotic values for the value taken by the curvature in static equilibrium are obtained when the second order contribution becomes negligible; along with an equation for the torsion in the generalised Timoshenko beam.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17340",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:31.686732Z"
  },
  {
    "id": "731b3839093ad39d9fd6cd8abb0445dd",
    "title": "A representation of range decreasing group homomorphisms",
    "slug": "a-representation-of-range-decreasing-group-homomorphisms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Ning Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The method of range decreasing group homomorphisms can be applied to study various maps between mapping spaces, includin holomorphic maps, group homomorphisms, linear maps, semigroup homomorphisms, Lie algebra homomorphisms and algebra homomorphisms [Z1, Z2]. Previous studies on range decreasing group homomorphisms have primarily focused on specific subsets of mapping groups. In this paper, we provide a characterization of a general range decreasing group homomorphism applicable to the entire mapping group. As applications, we compute a particular class of homomorphisms between mapping groups and identify all range decreasing group homomorphisms defined on specific mapping groups.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17459",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:31.686929Z"
  },
  {
    "id": "2a7eddbc91c581f880cf62326d81505e",
    "title": "Geodesic causality in Kerr spacetimes with $|a|\\geq M$",
    "slug": "geodesic-causality-in-kerr-spacetimes-with-$|a|\\geq-m$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "General Relativity and Quantum Cosmology (gr-qc)",
    "author": {
      "name": "Giulio Sanzeni",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The analytic extension of the Kerr spacetimes into the negative radial region contains closed causal curves for any non-zero rotation parameter $a$ and mass parameter $M$. Furthermore, the spacetimes become totally vicious when $|a|>M$, meaning that through every point there exists a closed timelike curve. Despite this, we prove that the Kerr spacetimes do not admit any closed null geodesics when $|a|\\geq M$. This result generalises recent findings by one of the authors, which showed the nonexistence of closed causal geodesics in the case $|a|<M$. Combining these results, we establish the absence of closed null geodesics in Kerr spacetimes for any non-zero $a$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17763",
    "tags": [
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "createdAt": "2025-04-25T15:49:31.687124Z"
  },
  {
    "id": "cb9749315ea6f6b6752111ab5a702882",
    "title": "Four dimensional almost complex torus manifolds",
    "slug": "four-dimensional-almost-complex-torus-manifolds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Differential Geometry (math.DG)",
    "author": {
      "name": "Donghoon Jang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In dimension 4, we extend the correspondence between compact nonsingular toric varieties and regular fans to a correspondence between almost complex torus manifolds and families of multi-fans in a geometric way, where an (almost) complex torus manifold is a $2n$-dimensional compact connected (almost) complex manifold equipped with an effective action of a real $n$-dimensional torus $T^n$ that has fixed points.\nLet $M$ be a 4-dimensional almost complex torus manifold. To $M$, we associate two equivalent combinatorial objects, a family $\\Delta$ of multi-fans and a graph $\\Gamma$, which encode the data on the fixed point set. We find a necessary and sufficient condition for each of $\\Delta$ and $\\Gamma$.\nMoreover, we provide a minimal model and operations for each of $\\Delta$ and $\\Gamma$. We introduce operations on a multi-fan and a graph that correspond to blow up and down of a manifold, and show that we can blow up and down $M$ to a minimal manifold $M'$ whose weights at the fixed points are unit vectors in $\\mathbb{Z}^2$, $\\Delta$ to a family of minimal multi-fans that has unit vectors only, and $\\Gamma$ to a minimal graph whose edges all have unit vectors as labels.\nAs an application, if $M$ is complex, $\\Delta$ is a fan and determines $M$, $\\Gamma$ encodes the equivariant cohomology of $M$, and $M'$ is $\\mathbb{CP}^1 \\times \\mathbb{CP}^1$. This implies that any two 4-dimensional complex torus manifolds are obtained from each other by equivariant blow up and down.",
    "pdfUrl": "https://arxiv.org/pdf/2310.11024",
    "tags": [
      "Differential Geometry (math.DG)"
    ],
    "createdAt": "2025-04-25T15:49:31.687314Z"
  },
  {
    "id": "91d21841702b9e3bbf1c54972f2a3c16",
    "title": "Rigidity results for non-Khler Calabi-Yau geometries on threefolds",
    "slug": "rigidity-results-for-non-khler-calabi-yau-geometries-on-threefolds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Differential Geometry (math.DG)",
    "author": {
      "name": "Vestislav Apostolov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We derive a canonical symmetry reduction associated to a compact non-Khler Bismut-Hermitian-Einstein manifold. In real dimension $6$, the transverse geometry is conformally Khler, and we give a complete description in terms of a single scalar PDE for the underlying Khler structure. In the case when the soliton potential is constant, we show that that the Bott-Chern number $h^{1,1}_{BC} \\geq 2$, and that equality holds if and only if the metric is Bismut-flat, and hence a quotient of either $\\SU(2) \\times \\mathbb R \\times \\mathbb C$ or $\\SU(2) \\times \\SU(2)$.",
    "pdfUrl": "https://arxiv.org/pdf/2408.09648",
    "tags": [
      "Differential Geometry (math.DG)"
    ],
    "createdAt": "2025-04-25T15:49:31.687546Z"
  },
  {
    "id": "f697802e2541a82c8bc52ceea678c421",
    "title": "Partial AHS-Structures, their Cartan description and partial BGG sequences",
    "slug": "partial-ahs-structures,-their-cartan-description-and-partial-bgg-sequences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Differential Geometry (math.DG)",
    "author": {
      "name": "Andreas Cap",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "G-structures and Cartan geometries are two major approaches to the description of geometric structures (in the sense of differential geometry) on manifolds of some fixed dimension $n$. We show that both descriptions naturally extend to the setting of manifolds of dimension $\\geq n$ which are endowed with a distinguished involutive distribution $F$ of rank $n$. The resulting ``partial'' structures are most naturally interpreted as smooth families of standard G-structures or Cartan geometries on the leaves of the foliation defined by $F$.\nWe prove that for the special class of AHS-structures (also known as $|1|$-graded parabolic geometries) the construction of a canonical Cartan geometry associated to a G-structure extends to this general setting. As an application, we prove that for partial AHS-structures there is an analog of the machinery of BGG sequences. This constructs sequences of differential operators of arbitrarily high order intrinsic to the structures. Under appropriate flatness conditions, these sequence are fine resolutions of sheaves which locally can be realized as pullbacks of sheaves on local leaf spaces for the foliation defined by $F$.",
    "pdfUrl": "https://arxiv.org/pdf/2410.10410",
    "tags": [
      "Differential Geometry (math.DG)"
    ],
    "createdAt": "2025-04-25T15:49:31.687745Z"
  },
  {
    "id": "965f65fc0cfd891022ac6c3b3e97e305",
    "title": "Type II Singularities of Lagrangian Mean Curvature Flow with Zero Maslov Class",
    "slug": "type-ii-singularities-of-lagrangian-mean-curvature-flow-with-zero-maslov-class",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Differential Geometry (math.DG)",
    "author": {
      "name": "Xiang Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we will prove some rigidity theorems for blow up limits to Type II singularities of Lagrangian mean curvature flow with zero Maslov class or almost calibrated Lagrangian mean curvature flows, especially for Lagrangian translating solitons in any dimension. These theorems generalized previous corresponding results from two dimensional case to arbitrarily dimensional case.",
    "pdfUrl": "https://arxiv.org/pdf/2412.15880",
    "tags": [
      "Differential Geometry (math.DG)"
    ],
    "createdAt": "2025-04-25T15:49:31.687947Z"
  },
  {
    "id": "823e1172c99440ed439bf1f12742e272",
    "title": "The Geometry of Loop Spaces IV: Closed Sasakian Manifolds",
    "slug": "the-geometry-of-loop-spaces-iv:-closed-sasakian-manifolds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Differential Geometry (math.DG)",
    "author": {
      "name": "Yoshiaki Maeda",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove that a closed regular $(4k+1)$-Sasakian manifold $(M,h_0)$ admits a family of non-isometric metrics $h_\\rho, \\rho\\geq 0,$ such that $\\pi_1({\\rm Isom}(M, h_\\rho))$, the fundamental group of the isometry group, is infinite for $\\rho>0.$ For $M= S^{4k+1}$, this result holds for all $\\rho>0$, but fails at $\\rho=0.$",
    "pdfUrl": "https://arxiv.org/pdf/2412.16743",
    "tags": [
      "Differential Geometry (math.DG)"
    ],
    "createdAt": "2025-04-25T15:49:31.688131Z"
  },
  {
    "id": "18af1967cf44520df35761644bd8cebd",
    "title": "A Priori Estimates for Singularities of the Lagrangian Mean Curvature Flow with Supercritical Phase",
    "slug": "a-priori-estimates-for-singularities-of-the-lagrangian-mean-curvature-flow-with-supercritical-phase",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Arunima Bhattacharya",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we prove interior a priori estimates for singularities of the Lagrangian mean curvature flow assuming the Lagrangian phase is supercritical. We prove a Jacobi inequality that holds good when the Lagrangian phase is critical and supercritical. We further extend our results to a broader class of Lagrangian mean curvature type equations.",
    "pdfUrl": "https://arxiv.org/pdf/2407.12756",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:31.688537Z"
  },
  {
    "id": "e43be991bf5d519e6767de59207b2ff3",
    "title": "Contact homology of contact manifolds and its applications",
    "slug": "contact-homology-of-contact-manifolds-and-its-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Symplectic Geometry (math.SG)",
    "author": {
      "name": "Frdric Bourgeois",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This is a survey of contact homology and its applications to the study of contact manifolds. It is a small tribute to Yasha Eliashberg's huge generosity with his countless explanations of his deep mathematical insights all along his career. It is also the author's wishful thinking that this text could be useful to students and young mathematicians for learning about some of the holomorphic curves based invariants in contact geometry.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16540",
    "tags": [
      "Symplectic Geometry (math.SG)"
    ],
    "createdAt": "2025-04-25T15:49:31.688840Z"
  },
  {
    "id": "01864c83041f1325b60283e9972aa0ce",
    "title": "An Exact SIR Series Solution and an Exploration of the Related Parameter Space",
    "slug": "an-exact-sir-series-solution-and-an-exploration-of-the-related-parameter-space",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Daniel P Hobbs",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A convergent power series solution is obtained for the SIR model, using an asymptotically motivated gauge function. For certain choices of model parameter values, the series converges over the full physical domain (i.e., for all positive time). Furthermore, the radius of convergence as a function of nondimensionalized initial susceptible and infected populations is obtained via a numerical root test.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17026",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.990777Z"
  },
  {
    "id": "1ab87242b19f8cee5cc5affa731e3a7f",
    "title": "Port-Hamiltonian modeling of rigid multibody systems",
    "slug": "port-hamiltonian-modeling-of-rigid-multibody-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Thomas Berger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We employ a port-Hamiltonian approach to model nonlinear rigid multibody systems subject to both position and velocity constraints. Our formulation accommodates Cartesian and redundant coordinates, respectively, and captures kinematic as well as gyroscopic effects. The resulting equations take the form of nonlinear differential-algebraic equations that inherently preserve an energy balance. We show that the proposed class is closed under interconnection, and we provide several examples to illustrate the theory.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17063",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.990990Z"
  },
  {
    "id": "8e813f20c38b86594b25a3e657cb377e",
    "title": "Conley-Morse persistence barcode: a homological signature of a combinatorial bifurcation",
    "slug": "conley-morse-persistence-barcode:-a-homological-signature-of-a-combinatorial-bifurcation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Tamal K. Dey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Bifurcation is one of the major topics in the theory of dynamical systems. It characterizes the nature of qualitative changes in parametrized dynamical systems. In this work, we study combinatorial bifurcations within the framework of combinatorial multivector field theory--a young but already well-established theory providing a combinatorial model for continuous-time dynamical systems (or simply, flows). We introduce Conley-Morse persistence barcode, a compact algebraic descriptor of combinatorial bifurcations. The barcode captures structural changes in a dynamical system at the level of Morse decompositions and provides a characterization of the nature of observed transitions in terms of the Conley index. The construction of Conley-Morse persistence barcode builds upon ideas from topological data analysis (TDA). Specifically, we consider a persistence module obtained from a zigzag filtration of topological pairs (formed by index pairs defining the Conley index) over a poset. Using gentle algebras, we prove that this module decomposes into simple intervals (bars) and compute them with algorithms from TDA known for processing zigzag filtrations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17105",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.991415Z"
  },
  {
    "id": "32b7fc58d16c28afb509b37858b3454b",
    "title": "On the creation of conjugate points for thermostats",
    "slug": "on-the-creation-of-conjugate-points-for-thermostats",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Javier Echevarra Cuesta",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $(M, g)$ be a closed oriented Riemannian surface, and let $SM$ be its unit tangent bundle. We show that the interior in the $\\mathcal{C}^2$ topology of the set of smooth functions $\\lambda:SM\\to \\mathbb{R}$ for which the thermostat $(M, g, \\lambda)$ has no conjugate points is a subset of those functions for which the thermostat is projectively Anosov. Moreover, we prove that if a reversible thermostat is projectively Anosov, then its non-wandering set contains no conjugate points.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17153",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.991718Z"
  },
  {
    "id": "06f067dca3fa6542009a2a8d1468ed50",
    "title": "On the local stability of the elapsed-time model in terms of the transmission delay and interconnection strength",
    "slug": "on-the-local-stability-of-the-elapsed-time-model-in-terms-of-the-transmission-delay-and-interconnection-strength",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Mara J. Cceres",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The elapsed-time model describes the behavior of interconnected neurons through the time since their last spike. It is an age-structured non-linear equation in which age corresponds to the elapsed time since the last discharge, and models many interesting dynamics depending on the type of interactions between neurons. We investigate the linearized stability of this equation by considering a discrete delay, which accounts for the possibility of a synaptic delay due to the time needed to transmit a nerve impulse from one neuron to the rest of the ensemble. We state a stability criterion that allows to determine if a steady state is linearly stable or unstable depending on the delay and the interaction between neurons. Our approach relies on the study of the asymptotic behavior of related Volterra-type integral equations in terms of theirs Laplace transforms. The analysis is complemented with numerical simulations illustrating the change of stability of a steady state in terms of the delay and the intensity of interconnections.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17358",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.992028Z"
  },
  {
    "id": "bbfd542bc4d3c6379fb8abaf552517b2",
    "title": "Hausdorff dimension of shrinking targets on Przytycki-Urbaski fractals",
    "slug": "hausdorff-dimension-of-shrinking-targets-on-przytycki-urbaski-fractals",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Thomas Jordan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Shrinking target problems in the context of iterated function systems have received an increasing amount of interest in the past few years. The classical shrinking target problem concerns points returning infinitely many times to a sequence of shrinking balls. In the iterated function system context, the shrinking balls problem is only well tractable in the case of similarity maps, but the case of affine maps is more elusive due to many geometric-dynamical complications.\nIn the current work, we push through these complications and compute the Hausdorff dimension of a set recurring to a shrinking target of geometric balls in some affine iterated function systems. For these results, we have pinpointed a representative class of affine iterated function systems, consisting of a pair of diagonal affine maps, that was introduced by Przytycki and Urbaski. The analysis splits into many sub-cases according to the type of the centre point of the targets, and the relative sizes of the targets and the contractions of the maps, illustrating the array of challenges of going beyond affine maps with nice projections. The proofs require heavy machinery from, and expand, the theory of Bernoulli convolutions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17498",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.992357Z"
  },
  {
    "id": "dccdd5745c2d69dd4b51f4736543936f",
    "title": "On systems disjoint from all minimal systems",
    "slug": "on-systems-disjoint-from-all-minimal-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Wen Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, Grska, Lemaczyk, and de la Rue characterized the class of automorphisms disjoint from all ergodic automorphisms. Inspired by their work, we provide several characterizations of systems that are disjoint from all minimal systems.\nFor a topological dynamical system $(X,T)$, it is disjoint from all minimal systems if and only if there exist minimal subsets $(M_i)_{i\\in\\mathbb{N}}$ of $X$ whose union is dense in $X$ and each of them is disjoint from $X$ (we also provide a measure-theoretical analogy of the result). For a semi-simple system $(X,T)$, it is disjoint from all minimal systems if and only if there exists a dense $G_{\\delta}$ set $\\Omega$ in $X \\times X$ such that for every pair $(x_1,x_2) \\in \\Omega$, the subsystems $\\overline{\\mathcal{O}}(x_1,T)$ and $\\overline{\\mathcal{O}}(x_2,T)$ are disjoint. Furthermore, for a general system a characterization similar to the ergodic case is obtained.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17504",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.992580Z"
  },
  {
    "id": "d35305561643314e4b1befd8faeb3b01",
    "title": "Auerbach bases, projection constants, and the joint spectral radius of principal submatrices",
    "slug": "auerbach-bases,-projection-constants,-and-the-joint-spectral-radius-of-principal-submatrices",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Jeremias Epperlein",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is shown that compact sets of complex matrices can always be brought, via similarity transformation, into a form where all matrix entries are bounded in absolute value by the joint spectral radius (JSR). The key tool for this is that every extremal norm of a matrix set admits an Auerbach basis; any such basis gives rise to a desired coordinate system. An immediate implication is that all diagonal entries - equivalently, all one-dimensional principal submatrices - are uniformly bounded above by the JSR. It is shown that the corresponding bounding property does not hold for higher dimensional principal submatrices. More precisely, we construct finite matrix sets for which, across the entire similarity orbit, the JSRs of all higher-dimensional principal submatrices exceed that of the original set. This shows that the bounding result does not extend to submatrices of dimension greater than one. The constructions rely on tools from the geometry of finite-dimensional Banach spaces, with projection constants of norms playing a key role. Additional bounds of the JSR of principal submatrices are obtained using John's ellipsoidal approximation and known estimates for projection constants.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17505",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.992778Z"
  },
  {
    "id": "b51676e9388d6e87e86e6b624810be48",
    "title": "Coexistence of mixing and rigid behaviors in ergodic theory",
    "slug": "coexistence-of-mixing-and-rigid-behaviors-in-ergodic-theory",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Rigoberto Zelada",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper we introduce and explore the notion of rigidity group, associated with a collection of finitely many sequences, and show that this concept has many, somewhat surprising characterizations of algebraic, spectral, and unitary nature. Furthermore, we demonstrate that these characterizations can be employed to obtain various results in the theory of generic Lebesgue-preserving automorphisms of $[0,1]$, IP-ergodic theory, multiple recurrence, additive combinatorics, and spectral theory. As a consequence of one of our results we show that given $(b_1,...b_\\ell)\\in\\mathbb N^\\ell$, there is no orthogonal vector $(a_1,\\dots,a_\\ell)\\in\\mathbb Z^\\ell$ with some $|a_j|=1$ if and only if there is an increasing sequence of natural numbers $(n_k)_{k\\in\\mathbb N}$ with the property that for each $F\\subseteq \\{1,...,\\ell\\}$ there is a $\\mu$-preserving transformation $T_F:[0,1]\\rightarrow[0,1]$ ($\\mu$ denotes the Lebesgue measure) such that for any measurable $A,B\\subseteq [0,1]$, $$\\lim_{k\\rightarrow\\infty}\\mu(A\\cap T_F^{-b_jn_k}B)=\\begin{cases} \\mu(A\\cap B),\\,\\text{ if }j\\in F,\\\\ \\mu(A)\\mu(B),\\,\\text{ if }j\\not\\in F. \\end{cases}$$ We remark that this result has a natural extension to a wide class of families of sequences.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17555",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.992971Z"
  },
  {
    "id": "2dd150d01a864c1484379b646fbd28ca",
    "title": "Bounded diagonal orbits in homogeneous spaces over function fields",
    "slug": "bounded-diagonal-orbits-in-homogeneous-spaces-over-function-fields",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Qianlin Huang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper is about topological rigidity of diagonal group actions on the homogeneous $\\SL_4\\big(\\F(\\!(t^{-1})\\!)\\big)/\\SL_4(\\F[t])$ where $\\F$ is a finite field of characteristic $3$. We show that there is a non-closed relatively compact orbit of the diagonal group.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17644",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.993158Z"
  },
  {
    "id": "23125538ed057fa91846ac2d8c9daa13",
    "title": "A common first integral from three-body secular theory and Kepler billiards",
    "slug": "a-common-first-integral-from-three-body-secular-theory-and-kepler-billiards",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Gabriella Pinzari",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We observe that a particular first integral of the partially-averaged system in the secular theory of the three-body problem appears also as an important conserved quantity of integrable Kepler billiards. In this note we illustrate their common roots with the projective dynamics of the two-center problem. We then combine these two aspects to define a class of integrable billiard systems on surfaces of constant curvature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17645",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.993353Z"
  },
  {
    "id": "886ad60004ef81efed50171caeab15c3",
    "title": "Simplified Morse-Bott-Smale chain complex",
    "slug": "simplified-morse-bott-smale-chain-complex",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Ryuma Orita",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Banyaga and Hurtubise defined the Morse-Bott-Smale chain complex as a quotient of a large chain complex by introducing five degeneracy relations. In this paper, we unify the five conditions into only one degeneracy condition. This allows for a simpler definition of Morse-Bott homology and more computable examples. Moreover, we show that our chain complex for a Morse-Smale function is quasi-isomorphic to the Morse-Smale-Witten chain complex. As a result, we obtain another proof of the Morse Homology Theorem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16962",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:31.993552Z"
  },
  {
    "id": "6bb7e2b20ec63d318a36e46288e5bd44",
    "title": "Parameter Estimation in ODE Models with Certified Polynomial System Solving",
    "slug": "parameter-estimation-in-ode-models-with-certified-polynomial-system-solving",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Symbolic Computation (cs.SC)",
    "author": {
      "name": "Alexander Demin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider dynamical models given by rational ODE systems. Parameter estimation is an important and challenging task of recovering parameter values from observed data. Recently, a method based on differential algebra and rational interpolation was proposed to express parameter estimation in terms of polynomial system solving. Typically, polynomial system solving is a bottleneck, hence the choice of the polynomial solver is crucial. In this contribution, we compare two polynomial system solvers applied to parameter estimation: homotopy continuation solver from this http URL and our new implementation of a certified solver based on rational univariate representation (RUR) and real root isolation. We show how the new RUR solver can tackle examples that are out of reach for the homotopy methods and vice versa.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17268",
    "tags": [
      "Symbolic Computation (cs.SC)"
    ],
    "createdAt": "2025-04-25T15:49:31.993751Z"
  },
  {
    "id": "2bf902a9acaba9b6166e6b344b4b1a97",
    "title": "No infinite spin for partial collisions converging to isolated central configurations on the plane",
    "slug": "no-infinite-spin-for-partial-collisions-converging-to-isolated-central-configurations-on-the-plane",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Anna Gierzkiewicz",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the $n$-body problem, when a~cluster of bodies tends to a collision, then its normalized shape curve converges to the set of normalized central configurations, which has $SO(2)$ symmetry in the planar case. This leaves a possibility that the normalized shape curve tends to the circle obtained by rotation of some central configuration instead of a particular point on it. This is the \\emph{infinite spin problem} which concerns the rotational behavior of total collision orbits in the $n$-body problem. The question also makes sense for partial collision.\nWe show that the infinite spin is not possible if the limiting circle is isolated from other connected components of the set of normalized central configurations. Our approach extends the method from recent work for total collision by Moeckel and Montgomery, which was based on a combination of the center manifold theorem with ojasiewicz inequality. To that we add a shadowing result for pseudo-orbits near normally hyperbolic manifold and careful estimates on the influence of other bodies on the cluster of colliding bodies.",
    "pdfUrl": "https://arxiv.org/pdf/2408.16409",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.993950Z"
  },
  {
    "id": "08832ea3a51c6b130febe38e09a6c790",
    "title": "Entropy for compact operators and results on entropy and specification",
    "slug": "entropy-for-compact-operators-and-results-on-entropy-and-specification",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Paulo Lupatini",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the topological entropy of operators. More precisely, in the Banach space setting, we show that compact operators have finite entropy, which depends solely on their point spectrum. Moreover, for operators on \\(F\\)-spaces, we explore the relationship between the specification property and entropy. In particular, we show that the specification property implies infinite topological entropy, while the operator specification property implies positive entropy. We also show that the invariance principle fails for the class of compact operators.",
    "pdfUrl": "https://arxiv.org/pdf/2409.10844",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:31.994146Z"
  },
  {
    "id": "0c9bd9e191a6b795c894f36b02a5125f",
    "title": "Stability of travelling wave solutions to reaction-diffusion equations driven by additive noise with Hlder continuous paths",
    "slug": "stability-of-travelling-wave-solutions-to-reaction-diffusion-equations-driven-by-additive-noise-with-hlder-continuous-paths",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Amjad Saef",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper we investigate stability of travelling wave solutions to a class of reaction-diffusion equations perturbed by infinite-dimensional additive noise with Hlder continuous paths, covering in particular fractional Brownian motion with general Hurst index. We obtain long- and short time asymptotic error bounds on the maximal distance from the solution of the stochastic reaction-diffusion equation to the orbit of travelling wave fronts. These bounds, in terms of Hurst index and Hlder exponent, apply to a large class of infinite-dimensional self-similar drivers with Hlder continuous paths, such as linear fractional stable motion. We find that for short times, higher Hurst indices imply higher stability, while for large times, the difference of Hurst index to Hlder exponent influences the size of scaling exponents of the noise amplitude that are sufficient to ensure stability.",
    "pdfUrl": "https://arxiv.org/pdf/2501.12944",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:31.994351Z"
  },
  {
    "id": "f54a318e725c81549ca1bfeda9fb589f",
    "title": "A Recursive Block Pillar Structure in the Kolakoski Sequence K(1,3)",
    "slug": "a-recursive-block-pillar-structure-in-the-kolakoski-sequence-k(1,3)",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "William Cook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Kolakoski sequence K(1,3) over {1, 3} is known to be structured, unlike K(1,2), with symbol frequency d approx. 0.397 linked to the Pisot number alpha (real root of x^3 - 2x^2 - 1 = 0). We reveal an explicit nested recursion defining block sequences B(n) and pillar sequences P(n) via B(n+1) = B(n) P(n) B(n) and P(n+1) = G(R(P(n)), 3), where G generates runs from vector R(P(n)). We prove B(n) are prefixes of K(1,3) converging to it, and B(n+1) = G(R(B(n)), 1), directly reflecting the Kolakoski self-encoding property. We derive recurrences for lengths |B(n)|, |P(n)| and symbol counts, confirming growth governed by alpha (limit |B(n+1)|/|B(n)| = alpha as n -> infinity). If block/pillar densities converge, they must equal d. This constructive framework provides an alternative perspective on K(1,3)'s regularity, consistent with known results from substitution dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.13433",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:31.994557Z"
  },
  {
    "id": "26fb453eff0d0100722a703489b84ecc",
    "title": "On the Boundedness of Generalized Fractional Integral Operators in Morrey Spaces and Camapanato Spaces associated with the Dunkl Operator on the Real line",
    "slug": "on-the-boundedness-of-generalized-fractional-integral-operators-in-morrey-spaces-and-camapanato-spaces-associated-with-the-dunkl-operator-on-the-real-line",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Functional Analysis (math.FA)",
    "author": {
      "name": "Sumit Parashar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is known that the Dunkl-type fractional integral operator $I_\\beta$ $(0 < \\beta < 2\\alpha + 2 =d_\\alpha)$ is bounded from $L^p(\\R,d\\mu_\\alpha)$ to $L^q (\\R, d\\mu_\\alpha)$ when $1 < p < \\frac{d_\\alpha}{\\beta}$ and $\\frac{1}{p} - \\frac{1}{q} = \\frac{\\beta}{d_\\alpha}$. In \\cite{spsa} , the authors introduced the generalized Dunkl-type fractional integral operator $T_\\rho^\\alpha$ and it's modified version $\\tilde{T}_\\rho^\\alpha$ and extended the above boundedness results to the generalized Dunkl-type Morrey spaces and Dunkl-type $BMO_\\phi$ spaces. In this paper we investigate the boundedness of generalized Dunkl-type fractional integral operators and it's modified version mainly on the Dunkl-type Campanato space.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17241",
    "tags": [
      "Functional Analysis (math.FA)"
    ],
    "createdAt": "2025-04-25T15:49:32.257123Z"
  },
  {
    "id": "9050d0c66159f105889705c62ed0ad8d",
    "title": "Band-dominated and Fourier-band-dominated operators on locally compact abelian groups",
    "slug": "band-dominated-and-fourier-band-dominated-operators-on-locally-compact-abelian-groups",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Functional Analysis (math.FA)",
    "author": {
      "name": "Robert Fulsche",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "By relating notions from quantum harmonic analysis and band-dominated operator theory, we prove that over any locally compact abelian group $G$, the operator algebra $\\mathcal C_1$ from quantum harmonic analysis agrees with the intersection of band-dominated operators and Fourier band-dominated operators. As an application, we characterize the compactness of operators acting on $L^2(G)$ and compare it with previous results in the discrete case. In particular, our results can be seen as a generalization of the limit operator concept to the non-discrete world. Moreover, we briefly discuss property $A'$ for arbitrary locally compact abelian groups.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17442",
    "tags": [
      "Functional Analysis (math.FA)"
    ],
    "createdAt": "2025-04-25T15:49:32.257336Z"
  },
  {
    "id": "fb63d27f26beca3125a01f02afa246b5",
    "title": "Density of irreducible operators in the trace-class norm",
    "slug": "density-of-irreducible-operators-in-the-trace-class-norm",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Junsheng Fang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In 1968, Paul Halmos initiated the research on density of the set of irreducible operators on a separable Hilbert space. Through the research, a long-standing unsolved problem inquires: is the set of irreducible operators dense in $B(H)$ with respect to the trace-class norm topology? Precisely, for each operator $T $ in $B(H)$ and every $\\varepsilon >0$, is there a trace-class operator $K$ such that $T+K$ is irreducible and $\\Vert K \\Vert_1 < \\varepsilon$?\nFor $p>1$, to prove the $\\Vert \\cdot \\Vert_p$-norm density of irreducible operators in $B(H)$, a type of Weyl-von Neumann theorem effects as a key technique. But the traditional method fails for the case $p=1$, where by $\\Vert \\cdot \\Vert_p$-norm we denote the Schatten $p$-norm.\nIn the current paper, for a large family of operators in $B(H)$, we give the above long-term problem an affirmative answer. The result is derived from a combination of techniques in both operator theory and operator algebras. Moreover, we discover that there is a strong connection between the problem and another related operator-theoretical problem related to type $\\mathrm{II}_1$ von Neumann algebras.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17190",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:32.257557Z"
  },
  {
    "id": "b49fecec128505b364553e18f0db2088",
    "title": "On the equivalence of a Hessian-free inequality and Lipschitz continuous Hessian",
    "slug": "on-the-equivalence-of-a-hessian-free-inequality-and-lipschitz-continuous-hessian",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Radu I. Bo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is known that if a twice differentiable function has a Lipschitz continuous Hessian, then its gradients satisfy a Jensen-type inequality. In particular, this inequality is Hessian-free in the sense that the Hessian does not actually appear in the inequality. In this paper, we show that the converse holds in a generalized setting: if a continuos function from a Hilbert space to a reflexive Banach space satisfies such an inequality, then it is Frchet differentiable and its derivative is Lipschitz continuous. Our proof relies on the Baillon-Haddad theorem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17193",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:32.257772Z"
  },
  {
    "id": "d35305561643314e4b1befd8faeb3b01",
    "title": "Auerbach bases, projection constants, and the joint spectral radius of principal submatrices",
    "slug": "auerbach-bases,-projection-constants,-and-the-joint-spectral-radius-of-principal-submatrices",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Jeremias Epperlein",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is shown that compact sets of complex matrices can always be brought, via similarity transformation, into a form where all matrix entries are bounded in absolute value by the joint spectral radius (JSR). The key tool for this is that every extremal norm of a matrix set admits an Auerbach basis; any such basis gives rise to a desired coordinate system. An immediate implication is that all diagonal entries - equivalently, all one-dimensional principal submatrices - are uniformly bounded above by the JSR. It is shown that the corresponding bounding property does not hold for higher dimensional principal submatrices. More precisely, we construct finite matrix sets for which, across the entire similarity orbit, the JSRs of all higher-dimensional principal submatrices exceed that of the original set. This shows that the bounding result does not extend to submatrices of dimension greater than one. The constructions rely on tools from the geometry of finite-dimensional Banach spaces, with projection constants of norms playing a key role. Additional bounds of the JSR of principal submatrices are obtained using John's ellipsoidal approximation and known estimates for projection constants.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17505",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:32.257974Z"
  },
  {
    "id": "7bf506db409e6b6e15bf1c632e8e1870",
    "title": "On the weak-fragmentability index of some Lipschitz-free spaces",
    "slug": "on-the-weak-fragmentability-index-of-some-lipschitz-free-spaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Functional Analysis (math.FA)",
    "author": {
      "name": "Estelle Basset",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We show the existence of Lipschitz-free spaces verifying the Point of Continuity Property with arbitrarily high weak-fragmentability index. For this purpose, we use a generalized construction of the countably branching diamond graphs. As a consequence, we deduce that to be Lipschitz-universal for countable complete metric spaces, a separable complete metric space cannot be purely 1-unrectifiable. Another corollary is the existence of an uncountable family of pairwise non-isomorphic Lipschitz-free spaces over purely 1-unrectifiable metric spaces. Some results on compact reduction are also obtained.",
    "pdfUrl": "https://arxiv.org/pdf/2404.00174",
    "tags": [
      "Functional Analysis (math.FA)"
    ],
    "createdAt": "2025-04-25T15:49:32.258164Z"
  },
  {
    "id": "50645519cb1cfdaca96e580e81d31c05",
    "title": "The linear targeting problem",
    "slug": "the-linear-targeting-problem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Functional Analysis (math.FA)",
    "author": {
      "name": "Kyle Bierly",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "For given real or complex $m \\times n$ data matrices $X$, $Y$, we investigate when there is a matrix $A$ such that $AX = Y$, and $A$ is invertible, Hermitian, positive (semi)definite, unitary, an orthogonal projection, a reflection, complex symmetric, or normal.",
    "pdfUrl": "https://arxiv.org/pdf/2408.10036",
    "tags": [
      "Functional Analysis (math.FA)"
    ],
    "createdAt": "2025-04-25T15:49:32.258360Z"
  },
  {
    "id": "216830d49250094f7379c7cba4e95536",
    "title": "Composition Operators on the Little Lipschitz space of a rooted tree",
    "slug": "composition-operators-on-the-little-lipschitz-space-of-a-rooted-tree",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Functional Analysis (math.FA)",
    "author": {
      "name": "Flavia Colonna",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, we study the composition operators on the little Lipschitz space ${\\mathcal L}_0$ of a rooted tree $T$, defined as the subspace of the Lipschitz space ${\\mathcal L}$ consisting of the complex-valued functions $f$ on $T$ such that $$\\lim_{|v|\\to\\infty}|f(v)-f(v^-)|=0,$$ where $v^-$ is the vertex adjacent to the vertex $v$ in the path from the root to $v$ and $|v|$ denotes the number of edges from the root to $v$. Specifically, we give a complete characterization of the self-maps $\\phi$ of $T$ for which the composition operator $C_\\phi$ is bounded and we estimate its operator norm. In addition, we study the spectrum of $C_\\phi$ and the hypercyclicity of the operators $\\lambda C_\\phi$ for $\\lambda \\in {\\mathbb C}$.",
    "pdfUrl": "https://arxiv.org/pdf/2410.14714",
    "tags": [
      "Functional Analysis (math.FA)"
    ],
    "createdAt": "2025-04-25T15:49:32.258550Z"
  },
  {
    "id": "c83ae97bd3e0a928fb6ecec9531018c5",
    "title": "Construction of $p$-energy measures associated with strongly local $p$-energy forms",
    "slug": "construction-of-$p$-energy-measures-associated-with-strongly-local-$p$-energy-forms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Functional Analysis (math.FA)",
    "author": {
      "name": "Khei Sasaya",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We construct canonical $p$-energy measures associated with strongly local $p$-energy forms without any assumptions of self-similarity, where $p$-energy forms are $L^p$-versions of Dirichlet forms, which have recently been studied mainly on fractals. Furthermore, we prove that the measures satisfy the chain and Leibniz rules, and that such a \"good\" energy measures are unique. As an application, we also prove the $p$-energy version of Mosco's domination principle. Moreover, we show a Korevaar--Schoen-type $p$-energies defined by Alonso-Ruiz and Baudoin coincide with our energy measures.",
    "pdfUrl": "https://arxiv.org/pdf/2502.10369",
    "tags": [
      "Functional Analysis (math.FA)"
    ],
    "createdAt": "2025-04-25T15:49:32.258738Z"
  },
  {
    "id": "5afd0b128eb2da832a544b4f6f68f993",
    "title": "Semigroups of self-similar actions and higher rank Baumslag-Solitar semigroups",
    "slug": "semigroups-of-self-similar-actions-and-higher-rank-baumslag-solitar-semigroups",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Robert Valente",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we initiate the study of higher rank Baumslag-Solitar semigroups and their related C*-algebras. We focus on two extreme, but interesting, classes - one is related to products of odometers and the other is related to Furstenberg's $\\times p,, \\times q$ conjecture. For the former class, whose C*-algebras are studied by H. Li and the second author, we here characterize the factoriality of the associated von Neumann algebras and further determine their types; for the latter, we obtain their canonical Cartan subalgebras. In the rank 1 case, we study a more general setting which encompasses (single-vertex) generalized Baumslag-Solitar semigroups. One of our main tools is from self-similar higher rank graphs and their C*-algebras.",
    "pdfUrl": "https://arxiv.org/pdf/2405.07062",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:32.258929Z"
  },
  {
    "id": "8d8367b5cba14fad60b183ad77d74b71",
    "title": "The tempered disk and the tempered cohomology",
    "slug": "the-tempered-disk-and-the-tempered-cohomology",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Federico Bambozzi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Consider a non-archimedean valuation ring V (K its fraction field, in mixed characteristic): inspired by some views presented by Scholze, we introduce a new point of view on the non-archimedean analytic setting in terms of derived analytic geometry (then associating a \"spectrum\" to each ind-Banach algebra). We want to look at the behaviour of this spectrum from a differential point of view. In such a spectrum, for example, there exist open subsets having functions with log-growth as sections for the structural sheaf. In this framework, a transfer theorem for the log-growth of solutions of p-adic differential equations can be interpreted as a continuity theorem (analogue to the transfer theorem for their radii of convergence in the Berkovich spaces). As a dividend of such a theory, we define a new cohomology theory in terms of the Hodge-completed derived de Rham cohomology of the ind-Banach derived analytic space associated to a smooth k-scheme, X_k (k residual field of V), via the use of \"tempered tubes\".\nWe finally compare our tempered de Rham cohomology with crystalline cohomology.",
    "pdfUrl": "https://arxiv.org/pdf/2410.09473",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:32.259127Z"
  },
  {
    "id": "d8d4bd6a8d9604f0bddbd2252bbbe2ba",
    "title": "Absolutely dilatable bimodule maps",
    "slug": "absolutely-dilatable-bimodule-maps",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Alexandros Chatzinikolaou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We characterise absolutely dilatable completely positive maps on the space of all bounded operators on a Hilbert space that are also bimodular over a given von Neumann algebra as rotations by a suitable unitary on a larger Hilbert space followed by slicing along the trace of an additional ancilla. We define the local, quantum and approximately quantum types of absolutely dilatable maps, according to the type of the admissible ancilla. We show that the local absolutely dilatable maps admit an exact factorisation through an abelian ancilla and show that they are limits in the point weak* topology of conjugations by unitaries in the commutant of the given von Neumann algebra. We show that the Connes Embedding Problem is equivalent to deciding if all absolutely dilatable maps are approximately quantum.",
    "pdfUrl": "https://arxiv.org/pdf/2411.08086",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:32.259323Z"
  },
  {
    "id": "6e851a058b8fa6a87fce55f46e6f3262",
    "title": "Higher order error estimates for regularization of inverse problems under non-additive noise",
    "slug": "higher-order-error-estimates-for-regularization-of-inverse-problems-under-non-additive-noise",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Diana-Elena Mirciu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work we derive higher order error estimates for inverse problems distorted by non-additive noise, in terms of Bregman distances. The results are obtained by means of a novel source condition, inspired by the dual problem. Specifically, we focus on variational regularization having the Kullback-Leibler divergence as data-fidelity, and a convex penalty term. In this framework, we provide an interpretation of the new source condition, and present error estimates also when a variational formulation of the source condition is employed. We show that this approach can be extended to variational regularization that incorporates more general convex data fidelities.",
    "pdfUrl": "https://arxiv.org/pdf/2411.19736",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:32.259508Z"
  },
  {
    "id": "af28c133a4eae83ed1684811dcbe4e16",
    "title": "A note on Arveson's hyperrigidity and non-degenerate C*-correspondences",
    "slug": "a-note-on-arveson's-hyperrigidity-and-non-degenerate-c*-correspondences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Joseph A. Dessi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We revisit the results of Kim, and of Katsoulis and Ramsey concerning hyperrigidity for non-degenerate C*-correspondences. We show that the tensor algebra is hyperrigid, if and only if Katsura's ideal acts non-degenerately, if and only if Katsura's ideal acts non-degenerately under any representation. This gives a positive answer to the question of Katsoulis and Ramsey, showing that their necessary condition and their sufficient condition for hyperrigidity of the tensor algebra are equivalent. Non-degeneracy of the left action of Katsura's ideal was also shown by Kim to be equivalent to hyperrigidity for the selfadjoint operator space associated with the C*-correspondence, and our approach provides a simplified proof of this result as well. In the process we revisit Arveson's criterion connecting maximality with the unique extension property and hyperrigidity, in conjunction with the work of Salomon on generating sets.",
    "pdfUrl": "https://arxiv.org/pdf/2503.16618",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:32.259702Z"
  },
  {
    "id": "2e4004912c129e2bb7ef5a5ea986d196",
    "title": "Quasitubal Tensor Algebra Over Separable Hilbert Spaces",
    "slug": "quasitubal-tensor-algebra-over-separable-hilbert-spaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Uria Mor",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The tubal tensor framework provides a clean and effective algebraic setting for tensor computations, supporting matrix-mimetic features like Singular Value Decomposition and Eckart-Young-like optimality results. Underlying the tubal tensor framework is a view of a tensor as a matrix of finite sized tubes. In this work, we lay the mathematical and computational foundations for working with tensors with infinite size tubes: matrices whose elements are elements from a separable Hilbert space. A key challenge is that existence of important desired matrix-mimetic features of tubal tensors rely on the existence of a unit element in the ring of tubes. Such unit element cannot exist for tubes which are elements of an infinite-dimensional Hilbert space. We sidestep this issue by embedding the tubal space in a commutative unital C*-algebra of bounded operators. The resulting quasitubal algebra recovers the structural properties needed for decomposition and low-rank approximation. In addition to laying the theoretical groundwork for working with tubal tensors with infinite dimensional tubes, we discuss computational aspects of our construction, and provide a numerical illustration where we compute a finite dimensional approximation to a infinitely-sized synthetic tensor using our theory. We believe our theory opens new exciting avenues for applying matrix mimetic tensor framework in the context of inherently infinite dimensional problems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16231",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:32.259895Z"
  },
  {
    "id": "0dddd9bb7129c76ca2f01d188f53ca5c",
    "title": "The Intermediate Value Theorem for Linear Transformations",
    "slug": "the-intermediate-value-theorem-for-linear-transformations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "General Mathematics (math.GM)",
    "author": {
      "name": "Ruben A. Martinez-Avendao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "If a real-valued function is continuous on a real interval and it takes on two different values, then it will also take any value in between those two, by the Intermediate Value Theorem. It is not immediately clear what would be a natural generalization for functions whose domain and range are in higher-dimensional Euclidean spaces. In this article, we analyze this problem, by first arriving at what we think is the appropriate question to ask, and then restricting to linear transformations. It turns out that the matrices that will satisfy an appropriate version of the Intermediate Value Theorem are the so called {\\em monotone} and {\\em weakly monotone} matrices, which have applications in numerical approximation of the solutions to systems of linear equations.",
    "pdfUrl": "https://arxiv.org/pdf/2411.03323",
    "tags": [
      "General Mathematics (math.GM)"
    ],
    "createdAt": "2025-04-25T15:49:32.508303Z"
  },
  {
    "id": "8545e1f8f9b122ed2f31ebe604f90198",
    "title": "Polynomial sequences related to Chebyshev polynomials and the minimal polynomial of $2\\cos (2/n)$",
    "slug": "polynomial-sequences-related-to-chebyshev-polynomials-and-the-minimal-polynomial-of-$2\\cos-(2/n)$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "General Mathematics (math.GM)",
    "author": {
      "name": "Mamoru Doi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper we consider the minimal polynomial $\\psi_n(x)$ of $2\\cos (2\\pi /n)$. We introduce some polynomial sequences with the same recurrence relation as the rescaled Chebyshev polynomials $t_n(x)=2\\, T_n(x/2)$ of the first kind, which turn out to be related to those of various kinds, all coming from those of the second kind. We see that $t_n(x)\\pm 2=2(T_n(x/2)\\pm 1)$ are divisible by the square of either of these polynomials. Then by appropriately removing unnecessary factors from these polynomials, we can easily calculate $\\psi_n(x)$ without recursion, which improves Barnes' result in 1977. As an appendix, we give a compact table of the minimal polynomials $\\psi_n(x)$ of $2\\cos (2\\pi /n)$ for $n\\leqslant 120$.",
    "pdfUrl": "https://arxiv.org/pdf/2501.16478",
    "tags": [
      "General Mathematics (math.GM)"
    ],
    "createdAt": "2025-04-25T15:49:32.508513Z"
  },
  {
    "id": "7f71d5f90b4c07e239db1aec49baeeb0",
    "title": "On the structure of modal and tense operators on a boolean algebra",
    "slug": "on-the-structure-of-modal-and-tense-operators-on-a-boolean-algebra",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic (math.LO)",
    "author": {
      "name": "Guram Bezhanishvili",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the poset NO(B) of necessity operators on a boolean algebra B. We show that NO(B) is a meet-semilattice that need not be distributive. However, when B is complete, NO(B) is necessarily a frame, which is spatial iff B is atomic. In that case, NO(B) is a locally Stone frame. Dual results hold for the poset PO(B) of possibility operators. We also obtain similar results for the posets TNO(B) and TPO(B) of tense necessity and possibility operators on B. Our main tool is Jonsson-Tarski duality, by which such operators correspond to continuous and interior relations on the Stone space of B.",
    "pdfUrl": "https://arxiv.org/pdf/2308.08664",
    "tags": [
      "Logic (math.LO)"
    ],
    "createdAt": "2025-04-25T15:49:32.712861Z"
  },
  {
    "id": "da057448299a55c44a433fa825309930",
    "title": "The Fields of Values of the Isaacs' Head Characters",
    "slug": "the-fields-of-values-of-the-isaacs'-head-characters",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Gabriel Navarro",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We determine the fields of values of the Isaacs' head characters of a finite solvable group.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17301",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.004132Z"
  },
  {
    "id": "c69618e8cf5e3f9fd1ec8d3b1c80ac27",
    "title": "$(2B, 3A, 5A)$-subalgebras of the Griess algebra with alternating Miyamoto group",
    "slug": "$(2b,-3a,-5a)$-subalgebras-of-the-griess-algebra-with-alternating-miyamoto-group",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Clara Franchi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We use Majorana representations to study the subalgebras of the Griess algebra that have shape $(2B,3A,5A)$ and whose associated Miyamoto groups are isomorphic to $A_n$. We prove that these subalgebras exist only if $n\\in \\{5,6,8\\}$. The case $n=5$ was already treated by Ivanov, Seress, McInroy, and Shpectorov. In case $n=6$ we prove that these algebras are all isomorphic and provide their precise description. In case $n=8$ we prove that these algebras do not arise from standard Majorana representations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17446",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.004341Z"
  },
  {
    "id": "731b3839093ad39d9fd6cd8abb0445dd",
    "title": "A representation of range decreasing group homomorphisms",
    "slug": "a-representation-of-range-decreasing-group-homomorphisms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Ning Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The method of range decreasing group homomorphisms can be applied to study various maps between mapping spaces, includin holomorphic maps, group homomorphisms, linear maps, semigroup homomorphisms, Lie algebra homomorphisms and algebra homomorphisms [Z1, Z2]. Previous studies on range decreasing group homomorphisms have primarily focused on specific subsets of mapping groups. In this paper, we provide a characterization of a general range decreasing group homomorphism applicable to the entire mapping group. As applications, we compute a particular class of homomorphisms between mapping groups and identify all range decreasing group homomorphisms defined on specific mapping groups.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17459",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.004542Z"
  },
  {
    "id": "53cc8edcfc617b34c3280f98df6d7bc1",
    "title": "Uncountably many $2$-spherical groups of Kac-Moody type of rank $3$ over $\\mathbb{F}_2$",
    "slug": "uncountably-many-$2$-spherical-groups-of-kac-moody-type-of-rank-$3$-over-$\\mathbb{f}_2$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Sebastian Bischof",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper we show that Weyl-invariant commutator blueprints of type $(4, 4, 4)$ are faithful. As a consequence we answer a question of Tits from the late $1980$s about twin buildings. Moreover, we obtain the first example of a $2$-spherical Kac-Moody group over a finite field which is not finitely presented.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17513",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.004912Z"
  },
  {
    "id": "457563cd90a978cc5f27d9f596fdc442",
    "title": "Asymptotically CAT(0) metrics, Z-structures, and the Farrell-Jones Conjecture",
    "slug": "asymptotically-cat(0)-metrics,-z-structures,-and-the-farrell-jones-conjecture",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Matthew Gentry Durham",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We show that colorable hierarchically hyperbolic groups (HHGs) admit asymptotically CAT(0) metrics, that is, roughly, metrics where the CAT(0) inequality holds up to sublinear error in the size of the triangle.\nWe use the asymptotically CAT(0) metrics to construct contractible simplicial complexes and compactifications that provide $\\mathcal{Z}$-structures in the sense of Bestvina and Dranishnikov. It was previously unknown that mapping class groups are asymptotically CAT(0) and admit $\\mathcal{Z}$-structures. As an application, we prove that many HHGs satisfy the Farrell--Jones Conjecture, including extra large-type Artin groups.\nTo construct asymptotically CAT(0) metrics, we show that hulls of finitely many points in a colorable HHGs can be approximated by CAT(0) cube complexes in a way that adding a point to the finite set corresponds, up to finitely many hyperplanes deletions, to a convex embedding.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17048",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.005219Z"
  },
  {
    "id": "2db535dab7f7a4b99959939e62fb4c44",
    "title": "Group Downsampling with Equivariant Anti-aliasing",
    "slug": "group-downsampling-with-equivariant-anti-aliasing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Md Ashiqur Rahman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Downsampling layers are crucial building blocks in CNN architectures, which help to increase the receptive field for learning high-level features and reduce the amount of memory/computation in the model. In this work, we study the generalization of the uniform downsampling layer for group equivariant architectures, e.g., G-CNNs. That is, we aim to downsample signals (feature maps) on general finite groups with anti-aliasing. This involves the following: (a) Given a finite group and a downsampling rate, we present an algorithm to form a suitable choice of subgroup. (b) Given a group and a subgroup, we study the notion of bandlimited-ness and propose how to perform anti-aliasing. Notably, our method generalizes the notion of downsampling based on classical sampling theory. When the signal is on a cyclic group, i.e., periodic, our method recovers the standard downsampling of an ideal low-pass filter followed by a subsampling operation. Finally, we conducted experiments on image classification tasks demonstrating that the proposed downsampling operation improves accuracy, better preserves equivariance, and reduces model size when incorporated into G-equivariant networks",
    "pdfUrl": "https://arxiv.org/pdf/2504.17258",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:33.005419Z"
  },
  {
    "id": "63cd934315f5defddfa97b1631d0ae5e",
    "title": "Two gluing methods for string C-group representations of the symmetric groups",
    "slug": "two-gluing-methods-for-string-c-group-representations-of-the-symmetric-groups",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Dimitri Leemans",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The study of string C-group representations of rank at least $n/2$ for the symmetric group $S_n$ has gained a lot of attention in the last fifteen years. In a recent paper, Cameron et al. gave a list of permutation representation graphs of rank $r\\geq n/2$ for $S_n$, having a fracture graph and a non-perfect split. They conjecture that these graphs are permutation representation graphs of string C-groups. In trying to prove this conjecture, we discovered two new techniques to glue two CPR graphs for symmetric groups together. We discuss the cases in which they yield new CPR graphs. By doing so, we invalidate the conjecture of Cameron et al. We believe our gluing techniques will be useful in the study of string C-group representations of high ranks for the symmetric groups.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17535",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:33.005609Z"
  },
  {
    "id": "ad176dfa6201ace458b3de4a6bd8190c",
    "title": "Measure equivalence rigidity of $\\mathrm{Out}(F_N)$",
    "slug": "measure-equivalence-rigidity-of-$\\mathrm{out}(f_n)$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Vincent Guirardel",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove that for every $N\\ge 3$, the group $\\mathrm{Out}(F_N)$ of outer automorphisms of a free group of rank $N$ is superrigid from the point of view of measure equivalence: any countable group that is measure equivalent to $\\mathrm{Out}(F_N)$, is in fact virtually isomorphic to $\\mathrm{Out}(F_N)$.\nWe introduce three new constructions of canonical splittings associated to a subgroup of $\\mathrm{Out}(F_N)$ of independent interest. They encode respectively the collection of invariant free splittings, invariant cyclic splittings, and maximal invariant free factor systems. Our proof also relies on the following improvement of an amenability result by Bestvina and the authors: given a free factor system $\\mathcal{F}$ of $F_N$, the action of $\\mathrm{Out}(F_N,\\mathcal{F})$ (the subgroup of $\\mathrm{Out}(F_N)$ that preserves $\\mathcal{F}$) on the space of relatively arational trees with amenable stabilizer is a Borel amenable action.",
    "pdfUrl": "https://arxiv.org/pdf/2103.03696",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.005803Z"
  },
  {
    "id": "4adcfe746f9ffab9f23cb1a4776b6ceb",
    "title": "Restricted Hausdorff spectra of $q$-adic automorphisms",
    "slug": "restricted-hausdorff-spectra-of-$q$-adic-automorphisms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Jorge Faria-Asategui",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Firstly, we completely determine the self-similar Hausdorff spectrum of the group of $q$-adic automorphisms where $q$ is a prime power, answering a question of Grigorchuk. Indeed, we take a further step and completely determine its Hausdorff spectra restricted to the most important subclasses of self-similar groups, providing examples differing drastically from the previously known ones in the literature. Our proof relies on a new explicit formula for the computation of the Hausdorff dimension of closed self-similar groups and a generalization of iterated permutational wreath products.\nSecondly, we provide for every prime $p$ the first examples of just infinite branch pro-$p$ groups with zero Hausdorff dimension in $\\Gamma_p$, giving strong evidence against a well-known conjecture of Boston.",
    "pdfUrl": "https://arxiv.org/pdf/2308.16508",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.005994Z"
  },
  {
    "id": "56fe232a3d8d5108fa9cd909debb338e",
    "title": "Product separability for special cube complexes",
    "slug": "product-separability-for-special-cube-complexes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Sam Shepherd",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove that if a group $G$ admits a virtually special action on a CAT(0) cube complex, then any product of convex-cocompact subgroups of $G$ is separable. Previously, this was only known for products of three subgroups, or in the case where $G$ is hyperbolic, or in some other more technical cases with additional assumptions on the subgroups (plus these previous results assume that the action of $G$ is cocompact). We also provide an application to the action of a virtually special cubulated group on its contact graph (and to some other actions of cubulated groups on graphs).",
    "pdfUrl": "https://arxiv.org/pdf/2412.08248",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.006186Z"
  },
  {
    "id": "0cc783003ab2a7af2c9c90709a25f8d0",
    "title": "The $m$-partite digraphical representations of valency 3 of finite groups generated by two elements",
    "slug": "the-$m$-partite-digraphical-representations-of-valency-3-of-finite-groups-generated-by-two-elements",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Songnian Xu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "\\ \\ Let $G$ be a finite group and $m \\geq 2$ an integer. An $m$-partite digraphical representation ($m$-PDR) of a group $G$ is a digraph $\\Gamma = (V, E)$ satisfying the following properties:\n\\item $\\Gamma$ is regular;\n\\item The automorphism group $\\mathrm{Aut}(\\Gamma)$ is isomorphic to $G$;\n\\item $\\mathrm{Aut}(\\Gamma)$ acts semiregularly on the vertex set $V$;\n\\item The action of $\\mathrm{Aut}(\\Gamma)$ partitions $V$ into exactly $m$ orbits, with each induced subgraph on an orbit being edgeless. This paper advances the classification program for $m$-PDRs with prescribed valency. Building on Du et al.'s complete classification of unrestricted $m$-PDRs \\cite{du4} (2021), we focus on the unresolved valency-specific cases. For digraphs, the minimal nontrivial valencies are $k=2$ (even) and $k=3$ (odd), since a connected digraph of valency one is just a directed cycle. While Du et al. \\cite{du3} recently classified valency 2 $m$-POSRs for groups generated by at most two elements - where $m$-POSRs are necessarily $m$-PDRs by definition - the valency 3 case remains open. Since all finite simple groups are two-generated, we investigate $m$-PDRs of valency 3 for groups generated by at most two elements, and establish a complete classification of nontrivial finite simple groups admitting $m$-PDRs of valency 3.",
    "pdfUrl": "https://arxiv.org/pdf/2503.22980",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.006382Z"
  },
  {
    "id": "4b40517c71a174ec8f470f90b18fecbc",
    "title": "An addendum on the Mathieu Conjecture for $SU(N)$, $Sp(N)$ and $G_2$",
    "slug": "an-addendum-on-the-mathieu-conjecture-for-$su(n)$,-$sp(n)$-and-$g_2$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Kevin Zwart",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we sharpen results obtained by the author in 2023. The new results reduce the Mathieu Conjecture on $SU(N)$ (formulated for all compact connected Lie groups by O. Mathieu in 1997) to a conjecture involving only functions on $\\mathbb{R}^n\\times (S^1)^m$ with $n,m$ non-negative integers instead of involving functions on $\\mathbb{R}^n\\times (S^1\\setminus\\{1\\})^m$. The proofs rely on a more recent work of the author (2024) and a specific $KAK$ decomposition. Finally, with these results we can also improve the results on the groups $Sp(N)$ and $G_2$ in the latter paper, since they relied on the construction introduced in the 2023 paper.",
    "pdfUrl": "https://arxiv.org/pdf/2504.01516",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.006569Z"
  },
  {
    "id": "457563cd90a978cc5f27d9f596fdc442",
    "title": "Asymptotically CAT(0) metrics, Z-structures, and the Farrell-Jones Conjecture",
    "slug": "asymptotically-cat(0)-metrics,-z-structures,-and-the-farrell-jones-conjecture",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Matthew Gentry Durham",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We show that colorable hierarchically hyperbolic groups (HHGs) admit asymptotically CAT(0) metrics, that is, roughly, metrics where the CAT(0) inequality holds up to sublinear error in the size of the triangle.\nWe use the asymptotically CAT(0) metrics to construct contractible simplicial complexes and compactifications that provide $\\mathcal{Z}$-structures in the sense of Bestvina and Dranishnikov. It was previously unknown that mapping class groups are asymptotically CAT(0) and admit $\\mathcal{Z}$-structures. As an application, we prove that many HHGs satisfy the Farrell--Jones Conjecture, including extra large-type Artin groups.\nTo construct asymptotically CAT(0) metrics, we show that hulls of finitely many points in a colorable HHGs can be approximated by CAT(0) cube complexes in a way that adding a point to the finite set corresponds, up to finitely many hyperplanes deletions, to a convex embedding.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17048",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.301374Z"
  },
  {
    "id": "ed0c21fe5c18c4a92f97285d512e12e1",
    "title": "Cyclic Nielsen realization for del Pezzo surfaces",
    "slug": "cyclic-nielsen-realization-for-del-pezzo-surfaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Seraphina Eun Bi Lee",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The cyclic Nielsen realization problem for a closed, oriented manifold asks whether any mapping class of finite order can be represented by a homeomorphism of the same order. In this article, we resolve the smooth, metric, and complex cyclic Nielsen realization problem for certain \"irreducible\" mapping classes on the family of smooth 4-manifolds underlying del Pezzo surfaces. Both positive and negative examples of realizability are provided in various settings. Our techniques are varied, synthesizing results from reflection group theory and 4-manifold topology.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17235",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.301593Z"
  },
  {
    "id": "4c2d33685a7d8033e284733d77c2e606",
    "title": "Small genus, small index critical points of the systole function",
    "slug": "small-genus,-small-index-critical-points-of-the-systole-function",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Ni An",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper the index of a family of critical points of the systole function on Teichmller space is calculated. The members of this family are interesting in that their existence implies the existence of strata in the Thurston spine for which the systoles do not determine a basis for the homology of the surface. Previously, index calculations of critical points with this pathological feature were impossible, because the only known examples were in surfaces with huge genus.\nA related concept is that of a ``minimal filling subset'' of the systoles at the critical point. Such minimal filling sets are studied, as they relate to the dimension of the Thurston spine near the critical point. We find an example of a minimal filling set of simple closed geodesics in genus 5 with cardinality 8, that are presumably realised as systoles. More generally, we determine the smallest and largest cardinality of a minimal filling set related to a tesselation of a hyperbolic surface by regular, right-angled $m$-gons for $m \\in \\{ 5, 6, 7 \\}$. For this, we use integer linear programming together with a hand-tailored symmetry breaking technique.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17316",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.301806Z"
  },
  {
    "id": "aeba88cbe69204cb7a6e0aee37c05778",
    "title": "On spaces of Euclidean triangles and triangulated Euclidean surfaces",
    "slug": "on-spaces-of-euclidean-triangles-and-triangulated-euclidean-surfaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Ismail Saglam",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we introduce an asymmetric metric on the space of marked Euclidean triangles, and we prove several properties of this metric, including two equivalent definitions of this metric, one of them comparing ratios of functions of the edges, and the other one in terms of best Lipschitz maps. We give a description of the geodesics of this metric. We show that this metric is Finsler, and give a formula for its infinitesimal Finsler structure. We then generalise this study to the case of convex Euclidean polygons in the Euclidean plane and to surfaces equipped with singular Euclidean structures with an underlying fixed triangulation. After developing some elements of the theory of completeness and completion of asymmetric metrics which is adapted to our setting, we study the completeness of the metrics we introduce in this paper. These problems and the results obtained are motivated by Thurston's work developed in his paper Minimal stretch maps between hyperbolic surfaces. We provide an analogue of Thurston's theory in a Euclidean setting.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17328",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.301998Z"
  },
  {
    "id": "963412bf7ccc008eb061259ab98eac9e",
    "title": "On the negative band number",
    "slug": "on-the-negative-band-number",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Michele Capovilla-Searle",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the negative band number of braids, knots, and links using Birman, Ko, and Lee's left-canonical form of a braid. As applications, we characterize up to conjugacy strongly quasipositive braids and almost strongly quasipositive braids.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17637",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.302198Z"
  },
  {
    "id": "2289140bdfa0e82af95af3595581529e",
    "title": "Hamiltonian quantization of complex Chern-Simons theory at level-$k$",
    "slug": "hamiltonian-quantization-of-complex-chern-simons-theory-at-level-$k$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "Muxin Han",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper develops a framework for the Hamiltonian quantization of complex Chern-Simons theory with gauge group $\\mathrm{SL}(2,\\mathbb{C})$ at an even level $k\\in\\mathbb{Z}_+$. Our approach follows the procedure of combinatorial quantization to construct the operator algebras of quantum holonomies on 2-surfaces and develop the representation theory. The $*$-representation of the operator algebra is carried by the infinite dimensional Hilbert space $\\mathcal{H}_{\\vec{\\lambda}}$ and closely connects to the infinite-dimensional $*$-representation of the quantum deformed Lorentz group $\\mathscr{U}_{\\mathbf{q}}(sl_2)\\otimes \\mathscr{U}_{\\widetilde{\\mathbf{q}}}(sl_2)$, where $\\mathbf{q}=\\exp[\\frac{2\\pi i}{k}(1+b^2)]$ and $\\widetilde{\\mathbf{q}}=\\exp[\\frac{2\\pi i}{k}(1+b^{-2})]$ with $|b|=1$. The quantum group $\\mathscr{U}_{\\mathbf{q}}(sl_2)\\otimes \\mathscr{U}_{\\widetilde{\\mathbf{q}}}(sl_2)$ also emerges from the quantum gauge transformations of the complex Chern-Simons theory. Focusing on a $m$-holed sphere $\\Sigma_{0,m}$, the physical Hilbert space $\\mathcal{H}_{phys}$ is identified by imposing the gauge invariance and the flatness constraint. The states in $\\mathcal{H}_{phys}$ are the $\\mathscr{U}_{\\mathbf{q}}(sl_2)\\otimes \\mathscr{U}_{\\widetilde{\\mathbf{q}}}(sl_2)$-invariant linear functionals on a dense domain in $\\mathcal{H}_{\\vec{\\lambda}}$. Finally, we demonstrate that the physical Hilbert space carries a Fenchel-Nielsen representation, where a set of Wilson loop operators associated with a pants decomposition of $\\Sigma_{0,m}$ are diagonalized.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16367",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:33.302403Z"
  },
  {
    "id": "886ad60004ef81efed50171caeab15c3",
    "title": "Simplified Morse-Bott-Smale chain complex",
    "slug": "simplified-morse-bott-smale-chain-complex",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Ryuma Orita",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Banyaga and Hurtubise defined the Morse-Bott-Smale chain complex as a quotient of a large chain complex by introducing five degeneracy relations. In this paper, we unify the five conditions into only one degeneracy condition. This allows for a simpler definition of Morse-Bott homology and more computable examples. Moreover, we show that our chain complex for a Morse-Smale function is quasi-isomorphic to the Morse-Smale-Witten chain complex. As a result, we obtain another proof of the Morse Homology Theorem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16962",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:33.302595Z"
  },
  {
    "id": "46da9d3fa4cdcabaaabeacea33f02c73",
    "title": "Formal Manifold Structures on Positive Characteristic Varieties",
    "slug": "formal-manifold-structures-on-positive-characteristic-varieties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Runjie Hu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In his ICM report, Sullivan proposes the program of l-adic formalization of the concept of manifolds. In this program, he claims that smooth positive characteristic varieties should carry l-adic formal manifold structures. He also claims the existence of an abelianized Galois symmetry on l-adic formal manifold structures. This paper carries out this program, establishes the claims, and relates the abelianized Galois symmetry on l-adic formal manifold structures to the Galois symmetry of varieties. Meanwhile, we prove that simply-connected varieties are homotopically finite CW complexes in the l-adic sense.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17221",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:33.302789Z"
  },
  {
    "id": "a3dd6ba91da6f870e47f6066a189362f",
    "title": "On chain link surgeries bounding rational homology balls and $$-slice 3-braid closures",
    "slug": "on-chain-link-surgeries-bounding-rational-homology-balls-and-$$-slice-3-braid-closures",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Vitalijs Brejevs",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We determine which integral surgeries on a large class of circular chain links bound rational homology balls. Our key tool is the lattice-theoretic cubiquity obstruction recently developed by Greene and Owens. We discuss a practical method of computing it, and, as an application, prove that a generalisation of the slice--ribbon conjecture holds for all but one infinite family of quasi-alternating 3-braid links. This extends previous results of Lisca concerning the conjecture for 3-braid knots.",
    "pdfUrl": "https://arxiv.org/pdf/2301.06573",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.302990Z"
  },
  {
    "id": "1cffe2bd7b4df0f5f51f06d77527cb53",
    "title": "A saturated 1-system of curves on the surface of genus 3",
    "slug": "a-saturated-1-system-of-curves-on-the-surface-of-genus-3",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Zhaoshen Zhai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We construct a system of 33 essential simple closed curves that are pairwise non-homotopic and intersect at most once on the oriented, closed surface of genus 3. Moreover, we show that our construction is saturated, in the sense that it is not properly contained in any other such system of curves.",
    "pdfUrl": "https://arxiv.org/pdf/2310.10814",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.303180Z"
  },
  {
    "id": "87b69bb5b8f751a648e2c5536eaad1c8",
    "title": "Twisted Alexander vanishing order of knots",
    "slug": "twisted-alexander-vanishing-order-of-knots",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Katsumi Ishikawa",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Based on a vanishing theorem for non-fibered knots due to Friedl and Vidussi, we define the twisted Alexander vanishing order of a knot to be the order of the smallest finite group such that the corresponding twisted Alexander polynomial is zero. In this paper, we show its basic properties, and provide several explicit values for knots with $10$ or fewer crossings. Moreover, we characterize a finite group admitting the zero-twisted Alexander polynomial.",
    "pdfUrl": "https://arxiv.org/pdf/2310.10936",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.303381Z"
  },
  {
    "id": "6805f0c622dfcc8f71bf683f8afcd0cf",
    "title": "Distributional category of manifolds",
    "slug": "distributional-category-of-manifolds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Ekansh Jauhari",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, a new homotopy invariant of metric spaces, called the distributional LS-category, was defined, which provides a lower bound to the classical LS-category. In this paper, we obtain several sufficient conditions for the distributional LS-category (dcat) of a closed manifold to be maximum, i.e., equal to its classical LS-category (cat). These give us many new computations of dcat, especially for some essential manifolds and (generalized) connected sums. In the process, we also determine the cat of closed 3-manifolds having torsion-free fundamental groups and some closed geometrically decomposable 4-manifolds. Finally, we extend some of our results to closed Alexandrov spaces with curvature bounded below and discuss their cat and dcat in dimension 3.",
    "pdfUrl": "https://arxiv.org/pdf/2408.11036",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.303578Z"
  },
  {
    "id": "6508cc0e1e7b1696e168745b98f79b8f",
    "title": "An exploration of low crossing and chiral cosmetic bands with grid diagrams",
    "slug": "an-exploration-of-low-crossing-and-chiral-cosmetic-bands-with-grid-diagrams",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Agnese Barbensi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We computationally explore non-coherent band attachments between low crossing number knots, using grid diagrams. We significantly improve the current H(2)-distance table. In particular, we find two new distance one pairs with fewer than seven crossings: one between $3_1\\#3_1$ and $7_4m$, and a chirally cosmetic one for $7_3$. We further determine a total of 33 previously unknown $H(2)$-distance one pairs for knots with up to $8$ crossings. The appendix by Kazuhiro Ichihara, In Dae Jong and Masakazu Teragaito contains a construction explaining the existence of chirally cosmetic bands for an infinite family of knots, including $5_1,\\, 7_3$ and $8_8$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.09749",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:33.303884Z"
  },
  {
    "id": "ad176dfa6201ace458b3de4a6bd8190c",
    "title": "Measure equivalence rigidity of $\\mathrm{Out}(F_N)$",
    "slug": "measure-equivalence-rigidity-of-$\\mathrm{out}(f_n)$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Vincent Guirardel",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove that for every $N\\ge 3$, the group $\\mathrm{Out}(F_N)$ of outer automorphisms of a free group of rank $N$ is superrigid from the point of view of measure equivalence: any countable group that is measure equivalent to $\\mathrm{Out}(F_N)$, is in fact virtually isomorphic to $\\mathrm{Out}(F_N)$.\nWe introduce three new constructions of canonical splittings associated to a subgroup of $\\mathrm{Out}(F_N)$ of independent interest. They encode respectively the collection of invariant free splittings, invariant cyclic splittings, and maximal invariant free factor systems. Our proof also relies on the following improvement of an amenability result by Bestvina and the authors: given a free factor system $\\mathcal{F}$ of $F_N$, the action of $\\mathrm{Out}(F_N,\\mathcal{F})$ (the subgroup of $\\mathrm{Out}(F_N)$ that preserves $\\mathcal{F}$) on the space of relatively arational trees with amenable stabilizer is a Borel amenable action.",
    "pdfUrl": "https://arxiv.org/pdf/2103.03696",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:33.304375Z"
  },
  {
    "id": "cb9749315ea6f6b6752111ab5a702882",
    "title": "Four dimensional almost complex torus manifolds",
    "slug": "four-dimensional-almost-complex-torus-manifolds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Differential Geometry (math.DG)",
    "author": {
      "name": "Donghoon Jang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In dimension 4, we extend the correspondence between compact nonsingular toric varieties and regular fans to a correspondence between almost complex torus manifolds and families of multi-fans in a geometric way, where an (almost) complex torus manifold is a $2n$-dimensional compact connected (almost) complex manifold equipped with an effective action of a real $n$-dimensional torus $T^n$ that has fixed points.\nLet $M$ be a 4-dimensional almost complex torus manifold. To $M$, we associate two equivalent combinatorial objects, a family $\\Delta$ of multi-fans and a graph $\\Gamma$, which encode the data on the fixed point set. We find a necessary and sufficient condition for each of $\\Delta$ and $\\Gamma$.\nMoreover, we provide a minimal model and operations for each of $\\Delta$ and $\\Gamma$. We introduce operations on a multi-fan and a graph that correspond to blow up and down of a manifold, and show that we can blow up and down $M$ to a minimal manifold $M'$ whose weights at the fixed points are unit vectors in $\\mathbb{Z}^2$, $\\Delta$ to a family of minimal multi-fans that has unit vectors only, and $\\Gamma$ to a minimal graph whose edges all have unit vectors as labels.\nAs an application, if $M$ is complex, $\\Delta$ is a fan and determines $M$, $\\Gamma$ encodes the equivariant cohomology of $M$, and $M'$ is $\\mathbb{CP}^1 \\times \\mathbb{CP}^1$. This implies that any two 4-dimensional complex torus manifolds are obtained from each other by equivariant blow up and down.",
    "pdfUrl": "https://arxiv.org/pdf/2310.11024",
    "tags": [
      "Differential Geometry (math.DG)"
    ],
    "createdAt": "2025-04-25T15:49:33.304722Z"
  },
  {
    "id": "2b95831ba9fd5f3341b709364f0fb63f",
    "title": "On sequential versions of distributional topological complexity",
    "slug": "on-sequential-versions-of-distributional-topological-complexity",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Ekansh Jauhari",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We define a (non-decreasing) sequence $\\{\\mathsf{dTC}_m(X)\\}_{m\\ge 2}$ of higher versions of distributional topological complexity ($\\mathsf{dTC}$) of a space $X$ introduced by Dranishnikov and Jauhari. This sequence generalizes $\\mathsf{dTC}(X)$ in the sense that $\\mathsf{dTC}_2(X) = \\mathsf{dTC}(X)$, and is a direct analog to the classical sequence $\\{\\mathsf{TC}_m(X)\\}_{m\\ge 2}$. We show that like $\\mathsf{TC}_m$ and $\\mathsf{dTC}$, the sequential versions $\\mathsf{dTC}_m$ are also homotopy invariants. Also, $\\mathsf{dTC}_m(X)$ relates with the distributional LS-category ($\\mathsf{dcat}$) of products of $X$ in the same way as $\\mathsf{TC}_m(X)$ relates with the classical LS-category ($\\mathsf{cat}$) of products of $X$. On one hand, we show that in general, $\\mathsf{dTC}_m$ is a different concept than $\\mathsf{TC}_m$ for each $m \\ge 2$. On the other hand, by finding sharp cohomological lower bounds to $\\mathsf{dTC}_m(X)$, we provide various examples of closed manifolds $X$ for which the sequences $\\{\\mathsf{TC}_m(X)\\}_{m\\ge 2}$ and $\\{\\mathsf{dTC}_m(X)\\}_{m\\ge 2}$ coincide.",
    "pdfUrl": "https://arxiv.org/pdf/2401.17218",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:33.305046Z"
  },
  {
    "id": "e43be991bf5d519e6767de59207b2ff3",
    "title": "Contact homology of contact manifolds and its applications",
    "slug": "contact-homology-of-contact-manifolds-and-its-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Symplectic Geometry (math.SG)",
    "author": {
      "name": "Frdric Bourgeois",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This is a survey of contact homology and its applications to the study of contact manifolds. It is a small tribute to Yasha Eliashberg's huge generosity with his countless explanations of his deep mathematical insights all along his career. It is also the author's wishful thinking that this text could be useful to students and young mathematicians for learning about some of the holomorphic curves based invariants in contact geometry.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16540",
    "tags": [
      "Symplectic Geometry (math.SG)"
    ],
    "createdAt": "2025-04-25T15:49:33.305352Z"
  },
  {
    "id": "c1bdeaca899e0bbd7708fa0d6c6b05a6",
    "title": "Towards a Critical Pragmatic Philosophy of Sustainable Mathematics Education",
    "slug": "towards-a-critical-pragmatic-philosophy-of-sustainable-mathematics-education",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "History and Overview (math.HO)",
    "author": {
      "name": "Dennis Mller",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper proposes critical pragmatism as a philosophy of sustainable mathematics education to bridge the gap between critical theory and the existing patchwork implementations. Combining existential sustainability as a holistic concept with pragmatic frameworks from the ethics in mathematics education literature creates a foundation enabling critical reflection and pragmatic implementation. We outline how their synthesis naturally leads to a three-stage implementation strategy: cultivating an ethical classroom culture, engaging with ethnomathematics, and tackling complex sustainability problems. Our critical pragmatic approach attempts to build a new philosophical perspective to equip teachers and students with the mathematical competencies, critical perspectives, and ethical grounding necessary to navigate and contribute to a sustainable future and to provide new analytic pathways.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17149",
    "tags": [
      "History and Overview (math.HO)"
    ],
    "createdAt": "2025-04-25T15:49:33.514914Z"
  },
  {
    "id": "ab0bc8aacfcd4f0282d95a1723a92046",
    "title": "Proofs for Folklore Theorems on the Radon-Nikodym Derivative",
    "slug": "proofs-for-folklore-theorems-on-the-radon-nikodym-derivative",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yaiza Bermudez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, rigorous statements and formal proofs are presented for both foundational and advanced folklore theorems on the Radon-Nikodym derivative. The cases of conditional and marginal probability measures are carefully considered, which leads to an identity involving the sum of mutual and lautum information suggesting a new interpretation for such a sum.",
    "pdfUrl": "https://arxiv.org/pdf/2501.18374",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.515139Z"
  },
  {
    "id": "f8c77fcd00b23ebd282ff343a55d74f1",
    "title": "A Coding-Enhanced Jamming Approach for Secure Semantic Communication over Wiretap Channels",
    "slug": "a-coding-enhanced-jamming-approach-for-secure-semantic-communication-over-wiretap-channels",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Weixuan Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As semantic communication (SemCom) gains increasing attention as a novel communication paradigm, ensuring the security of transmitted semantic information over open wireless channels becomes crucial. Existing secure SemCom solutions often lack explicit control over security. To address this, we propose a coding-enhanced jamming approach for secure SemCom over wiretap channels. This approach integrates deep joint source and channel coding (DeepJSCC) with neural network-based digital modulation, enabling controlled jamming through two-layer superposition coding. The outer constellation sequence encodes the source image, while the inner constellation sequence, derived from a secret image, acts as the jamming signal. By minimizing the mutual information between the outer and inner constellation sequences, the jamming effect is enhanced. The jamming signal is superposed on the outer constellation sequence, preventing the eavesdropper from recovering the source image. The power allocation coefficient (PAC) in the superposition coding can be adjusted to control system security. Experiments show that our approach matches existing methods in security while significantly improving reconstruction performance across varying channel signal-to-noise ratios (SNRs) and compression ratios.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16960",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.839797Z"
  },
  {
    "id": "ff63d15f2d54f0c03143bcfe3b4c3557",
    "title": "Relationship between Hlder Divergence and Functional Density Power Divergence: Intersection and Generalization",
    "slug": "relationship-between-hlder-divergence-and-functional-density-power-divergence:-intersection-and-generalization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Masahiro Kobayashi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this study, we discuss the relationship between two families of density-power-based divergences with functional degrees of freedom -- the Hlder divergence and the functional density power divergence (FDPD) -- based on their intersection and generalization. These divergence families include the density power divergence and the $\\gamma$-divergence as special cases. First, we prove that the intersection of the Hlder divergence and the FDPD is limited to a general divergence family introduced by Jones et al. (Biometrika, 2001). Subsequently, motivated by the fact that Hlder's inequality is used in the proofs of nonnegativity for both the Hlder divergence and the FDPD, we define a generalized divergence family, referred to as the $\\xi$-Hlder divergence. The nonnegativity of the $\\xi$-Hlder divergence is established through a combination of the inequalities used to prove the nonnegativity of the Hlder divergence and the FDPD. Furthermore, we derive an inequality between the composite scoring rules corresponding to different FDPDs based on the $\\xi$-Hlder divergence. Finally, we prove that imposing the mathematical structure of the Hlder score on a composite scoring rule results in the $\\xi$-Hlder divergence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17008",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.840022Z"
  },
  {
    "id": "21aa4775b86dbfd8c071027aea3fe59c",
    "title": "Rate-Distortion-Perception Theory for the Quadratic Wasserstein Space",
    "slug": "rate-distortion-perception-theory-for-the-quadratic-wasserstein-space",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Xiqiang Qu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish a single-letter characterization of the fundamental distortion-rate-perception tradeoff with limited common randomness under the squared error distortion measure and the squared Wasserstein-2 perception measure. Moreover, it is shown that this single-letter characterization can be explicitly evaluated for the Gaussian source. Various notions of universal representation are also clarified.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17236",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.840229Z"
  },
  {
    "id": "3a01db7984dea0e153110045becfdbfc",
    "title": "Service Rate Regions of MDS Codes & Fractional Matchings in Quasi-uniform Hypergraphs",
    "slug": "service-rate-regions-of-mds-codes-&-fractional-matchings-in-quasi-uniform-hypergraphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Hoang Ly",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The service rate region (SRR) has emerged as a critical performance metric for distributed systems that store data redundantly. It measures the system's ability to serve multiple users concurrently. Mathematically, the SRR is a polytope in R^k where each dimension corresponds to the service request rate of one of the k data objects. This paper focuses on systems employing a class of Maximum Distance Separable (MDS) codes. For each code in the class, we characterize the k axes intercept points of its SRR, and the smallest standard simplex that includes the SRR. We use these results to show that the SRR grows with the increasing number of systematic columns in the generator matrices. We establish a graph-theoretic framework associating this SRR problem with fractional matchings in quasi-uniform hypergraphs. Identifying the SRR polytope is equivalent to determining a particular image of the fractional-matching polytope. We introduce a notion of Greedy Matching and show that it is sufficient to focus on these matchings to characterize the SRR rather than the entire matching polytope. With these tools, we determine the SRR of a large subset of the considered class of codes. Our results generalize previous characterizations of systematic and non-systematic MDS-coded systems, offering a unified framework for analyzing service rate regions of codes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17244",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.840427Z"
  },
  {
    "id": "eef167e4f57a9dbaae65e7d1714ddae0",
    "title": "Error Exponents for DNA Storage Codes with a Variable Number of Reads",
    "slug": "error-exponents-for-dna-storage-codes-with-a-variable-number-of-reads",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yan Hao Ling",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we study error exponents for a concatataned coding based class of DNA storage codes in which the number of reads performed can be variable. That is, the decoder can sequentially perform reads and choose whether to output the final decision or take more reads, and we are interested in minimizing the average number of reads performed rather than a fixed pre-specified value. We show that this flexibility leads to a considerable reduction in the error probability compared to a fixed number of reads, not only in terms of constants in the error exponent but also in the scaling laws. This is shown via an achievability result for a suitably-designed protocol, and in certain parameter regimes we additionally establish a matching converse that holds for all protocols within a broader concatenated coding based class.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17337",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.840628Z"
  },
  {
    "id": "bf9d6eea488a3170041476743f20680a",
    "title": "Subcode Ensemble Decoding of Polar Codes",
    "slug": "subcode-ensemble-decoding-of-polar-codes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Henning Lulei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the short block length regime, pre-transformed polar codes together with successive cancellation list (SCL) decoding possess excellent error correction capabilities. However, in practice, the list size is limited due to the suboptimal scaling of the required area in hardware implementations. Automorphism ensemble decoding (AED) can improve performance for a fixed list size by running multiple parallel SCL decodings on permuted received words, yielding a list of estimates from which the final estimate is selected. Yet, AED is limited to appropriately designed polar codes. Subcode ensemble decoding (ScED) was recently proposed for low-density parity-check codes and does not impose such design constraints. It uses multiple decodings in different subcodes, ensuring that the selected subcodes jointly cover the original code. We extend ScED to polar codes by expressing polar subcodes through suitable pre-transformations (PTs). To this end, we describe a framework classifying pre-transformations for pre-transformed polar codes based on their role in encoding and decoding. Within this framework, we propose a new type of PT enabling ScED for polar codes, analyze its properties, and discuss how to construct an efficient ensemble.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17511",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.840844Z"
  },
  {
    "id": "ee1bb852438cf978aec272c7a44ee5b6",
    "title": "Secure Network Function Computation for Linear Functions, Part II: Target-Function Security",
    "slug": "secure-network-function-computation-for-linear-functions,-part-ii:-target-function-security",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yang Bai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this Part II of a two-part paper, we put forward secure network function computation, where in a directed acyclic network, a sink node is required to compute a target function of which the inputs are generated as source messages at multiple source nodes, while a wiretapper, who can access any one but not more than one wiretap set in a given collection of wiretap sets, is not allowed to obtain any information about a security function of the source messages. In Part I of the two-part paper, we have investigated securely computing linear functions with the wiretapper who can eavesdrop any edge subset up to a certain size r, referred to as the security level, where the security function is the identity function. The notion of this security is called source security. In the current paper, we consider another interesting model which is the same as the above one except that the security function is identical to the target function, i.e., we need to protect the information on the target function from being leaked to the wiretapper. The notion of this security is called target-function security. We first prove a non-trivial upper bound on the secure computing capacity, which is applicable to arbitrary network topologies and arbitrary security levels. In particular, when the security level r is equal to 0, the upper bound reduces to the computing capacity without security consideration. Further, from an algebraic point of view, we prove two equivalent conditions for target-function security and source security for the existence of the corresponding linear function-computing secure network codes. With them, for any linear function over a given finite field, we develop a code construction of linear secure network codes for target-function security and thus obtain a lower bound on the secure computing capacity; and also generalize the code construction developed in Part I for source security.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17514",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.841089Z"
  },
  {
    "id": "c35026bcdb9b28e432dbd48734d42909",
    "title": "MacWilliams Theory over Zk and nu-functions over Lattices",
    "slug": "macwilliams-theory-over-zk-and-nu-functions-over-lattices",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Zhiyong Zheng",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Continuing previous works on MacWilliams theory over codes and lattices, a generalization of the MacWilliams theory over $\\mathbb{Z}_k$ for $m$ codes is established, and the complete weight enumerator MacWilliams identity also holds for codes over the finitely generated rings $\\mathbb{Z}_k[\\xi]$. In the context of lattices, the analogy of the MacWilliams identity associated with nu-function was conjectured by Sol in 1995, and we present a new formula for nu-function over the lattices associated with a ternary code, which is rather different from the original conjecture. Furthermore, we provide many counterexamples to show that the Sol conjecture never holds in the general case, except for the lattices associated with a binary code.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17589",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.841306Z"
  },
  {
    "id": "e2fac3b8d105bf5b0ed7a0c2cdc46096",
    "title": "Integrated Sensing and Communications for Unsourced Random Access: A Spectrum Sharing Compressive Sensing Approach",
    "slug": "integrated-sensing-and-communications-for-unsourced-random-access:-a-spectrum-sharing-compressive-sensing-approach",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Zhentian Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper addresses the unsourced/uncoordinated random access problem in an integrated sensing and communications (ISAC) system, with a focus on uplink multiple access code design. Recent theoretical advancements highlight that an ISAC system will be overwhelmed by the increasing number of active devices, driven by the growth of massive machine-type communication (mMTC). To meet the demands of future mMTC network, fundamental solutions are required that ensure robust capacity while maintaining favorable energy and spectral efficiency. One promising approach to support emerging massive connectivity is the development of systems based on the unsourced ISAC (UNISAC) framework. This paper proposes a spectrum-sharing compressive sensing-based UNISAC (SSCS-UNISAC) and offers insights into the practical design of UNISAC multiple access codes. In this framework, both communication signals (data transmission) and sensing signals (e.g., radar echoes) overlap within finite channel uses and are transmitted via the proposed UNISAC protocol. The proposed decoder exhibits robust performance, providing 20-30 dB capacity gains compared to conventional protocols such as TDMA and ALOHA. Numerical results validate the promising performance of the proposed scheme.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17629",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.841517Z"
  },
  {
    "id": "b30ead38b35b4c32c709e0b41813f34a",
    "title": "Sparsity-Exploiting Channel Estimation For Unsourced Random Access With Fluid Antenna",
    "slug": "sparsity-exploiting-channel-estimation-for-unsourced-random-access-with-fluid-antenna",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Keru Zhou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This work explores the channel estimation (CE) problem in uplink transmission for unsourced random access (URA) with a fluid antenna receiver. The additional spatial diversity in a fluid antenna system (FAS) addresses the needs of URA design in multiple-input and multiple-output (MIMO) systems. We present two CE strategies based on the activation of different FAS ports, namely alternate ports and partial ports CE. Both strategies facilitate the estimation of channel coefficients and angles of arrival (AoAs). Additionally, we discuss how to refine channel estimation by leveraging the sparsity of finite scatterers. Specifically, the proposed partial ports CE strategy is implemented using a regularized estimator, and we optimize the estimator's parameter to achieve the desired AoA precision and refinement. Extensive numerical results demonstrate the feasibility of the proposed strategies, and a comparison with a conventional receiver using half-wavelength antennas highlights the promising future of integrating URA and FAS.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17634",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.841726Z"
  },
  {
    "id": "61dcd45c8304750fbf68362fdbbb1495",
    "title": "DTECM: Digital Twin Enabled Channel Measurement and Modeling in Terahertz Urban Macrocell",
    "slug": "dtecm:-digital-twin-enabled-channel-measurement-and-modeling-in-terahertz-urban-macrocell",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yuanbo Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, in the THz UMa, extensive channel measurements are conducted and an accurate channel model is developed by combining ray-tracing, computer vision (CV), and statistical methods. Specifically, substantial channel measurement campaigns with distances up to 410~m are conducted at 220~GHz, with nanosecond-level absolute time synchronization. Based on the measurement results, the propagation phenomena are analyzed in detail and the channel characteristics are calculated and statistically modeled. Furthermore, a digital twin enabled channel model (DTECM) is proposed, which generates THz channel responses in a hybrid manner. Specifically, the dominant paths are generated deterministically by using the ray-tracing technique and CV methods. Apart from the path gains determined by ray-tracing, the additional foliage loss is accurately modeled based on foliage information extracted from panoramic pictures. To maintain a low computational complexity for the DTECM, non-dominant paths are then generated statistically. Numeric results reveal that compared to the traditional statistical channel models, the DTECM reduces the path loss modeling error from 14~dB to 4~dB, showing its great superiority. Furthermore, a preliminary link performance evaluation using the DTECM indicates that THz UMa is feasible, though requiring high antenna gains and coverage extension techniques to achieve high spectral efficiencies and wide coverage.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17673",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.841927Z"
  },
  {
    "id": "cda84ffc834a46dd30383d2b06d0a6a3",
    "title": "Path Integral Methods for Synthesizing and Preventing Stealthy Attacks in Nonlinear Cyber-Physical Systems",
    "slug": "path-integral-methods-for-synthesizing-and-preventing-stealthy-attacks-in-nonlinear-cyber-physical-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Apurva Patil",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper studies the synthesis and mitigation of stealthy attacks in nonlinear cyber-physical systems (CPS). To quantify stealthiness, we employ the Kullback-Leibler (KL) divergence, a measure rooted in hypothesis testing and detection theory, which captures the trade-off between an attacker's desire to remain stealthy and her goal of degrading system performance. First, we synthesize the worst-case stealthy attack in nonlinear CPS using the path integral approach. Second, we consider how a controller can mitigate the impact of such stealthy attacks by formulating a minimax KL control problem, yielding a zero-sum game between the attacker and the controller. Again, we leverage a path integral-based solution that computes saddle-point policies for both players through Monte Carlo simulations. We validate our approach using unicycle navigation and cruise control problems, demonstrating how an attacker can covertly drive the system into unsafe regions, and how the controller can adapt her policy to combat the worst-case attacks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17118",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:33.842125Z"
  },
  {
    "id": "1f9ebbb86ef1e33f04f57e352ddacb2a",
    "title": "P$_\\ell$-Kyber: Packing $\\ell$ Plaintexts and Lattice Coding for Kyber",
    "slug": "p$_\\ell$-kyber:-packing-$\\ell$-plaintexts-and-lattice-coding-for-kyber",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Cryptography and Security (cs.CR)",
    "author": {
      "name": "Shuiyin Liu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, we propose a joint design of encoding and encryption processes for KEMs like Kyber, without assuming the independence of the decoding noise entries. Our design features two techniques: ciphertext packing and lattice packing. First, we extend the Peikert-Vaikuntanathan-Waters (PVW) method to the Kyber: $\\ell$ plaintexts are packed into a single ciphertext. This scheme is referred to as P$_\\ell$-Kyber. We prove that the P$_\\ell$-Kyber is IND-CCA secure under the M-LWE hardness assumption. We show that the decryption decoding noise entries across the $\\ell$ plaintexts (also known as layers) are mutually independent. Second, we propose a cross-layer lattice encoding scheme for the P$_\\ell$-Kyber, where every $\\ell$ cross-layer information symbols are encoded to a lattice point. This way we obtain a \\emph{coded} P$_\\ell$-Kyber, where the decoding noise entries for each lattice point are mutually independent. Therefore, the decryption failure rate (DFR) analysis does not require the assumption of independence among the decryption decoding noise entries. Both DFR and communication cost (CER) are greatly decreased thanks to ciphertext packing and lattice packing. Finally, we demonstrate that with $\\ell=24$ and Leech lattice encoder, the proposed coded P$_\\ell$-KYBER1024 achieves DFR $<2^{-281}$ and CER $ = 4.6$, i.e., a decrease of CER by $90\\%$ compared to KYBER1024.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17185",
    "tags": [
      "Cryptography and Security (cs.CR)"
    ],
    "createdAt": "2025-04-25T15:49:33.842322Z"
  },
  {
    "id": "997c769ca5664fc178fb75196e12bc56",
    "title": "Quantum-Enhanced Change Detection and Joint Communication-Detection",
    "slug": "quantum-enhanced-change-detection-and-joint-communication-detection",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Zihao Gong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Quick detection of transmittance changes in optical channel is crucial for secure communication. We demonstrate that pre-shared entanglement using two-mode squeezed vacuum states significantly reduces detection latency compared to classical and entanglement-augmented coherent-state probes. The change detection latency is inversely proportional to the quantum relative entropy (QRE), which goes to infinity in the absence of thermal noise, suggesting idealized instantaneous detection. However, in realistic scenarios, we show that QRE scales logarithmically with the inverse of the thermal noise mean photon number. We propose a receiver that achieves this scaling and quantify its performance gains over existing methods. Additionally, we explore the fundamental trade-off between communication capacity and change detection latency, highlighting how pre-shared entanglement enhances both.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17237",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:33.842522Z"
  },
  {
    "id": "6a2e639759a35dd90c4596d572ba6d49",
    "title": "Coding for Computation: Efficient Compression of Neural Networks for Reconfigurable Hardware",
    "slug": "coding-for-computation:-efficient-compression-of-neural-networks-for-reconfigurable-hardware",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Hans Rosenberger",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As state of the art neural networks (NNs) continue to grow in size, their resource-efficient implementation becomes ever more important. In this paper, we introduce a compression scheme that reduces the number of computations required for NN inference on reconfigurable hardware such as FPGAs. This is achieved by combining pruning via regularized training, weight sharing and linear computation coding (LCC). Contrary to common NN compression techniques, where the objective is to reduce the memory used for storing the weights of the NNs, our approach is optimized to reduce the number of additions required for inference in a hardware-friendly manner. The proposed scheme achieves competitive performance for simple multilayer perceptrons, as well as for large scale deep NNs such as ResNet-34.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17403",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:33.842731Z"
  },
  {
    "id": "563113a1e9a36deb603f7461d6ef5e52",
    "title": "UNILoc: Unified Localization Combining Model-Based Geometry and Unsupervised Learning",
    "slug": "uniloc:-unified-localization-combining-model-based-geometry-and-unsupervised-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Signal Processing (eess.SP)",
    "author": {
      "name": "Yuhao Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Accurate mobile device localization is critical for emerging 5G/6G applications such as autonomous vehicles and augmented reality. In this paper, we propose a unified localization method that integrates model-based and machine learning (ML)-based methods to reap their respective advantages by exploiting available map information. In order to avoid supervised learning, we generate training labels automatically via optimal transport (OT) by fusing geometric estimates with building layouts. Ray-tracing based simulations are carried out to demonstrate that the proposed method significantly improves positioning accuracy for both line-of-sight (LoS) users (compared to ML-based methods) and non-line-of-sight (NLoS) users (compared to model-based methods). Remarkably, the unified method is able to achieve competitive overall performance with the fully-supervised fingerprinting, while eliminating the need for cumbersome labeled data measurement and collection.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17676",
    "tags": [
      "Signal Processing (eess.SP)"
    ],
    "createdAt": "2025-04-25T15:49:33.842951Z"
  },
  {
    "id": "e484eff1a9c72a5e96075af419aebda1",
    "title": "Quantum Error Correction with Girth-16 Non-Binary LDPC Codes via Affine Permutation Construction",
    "slug": "quantum-error-correction-with-girth-16-non-binary-ldpc-codes-via-affine-permutation-construction",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Kenta Kasai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a method for constructing quantum error-correcting codes based on non-binary low-density parity-check codes with girth 16. In conventional constructions using circulant permutation matrices, the girth is upper-bounded by 12, which limits the suppression of harmful short cycles. Our construction employs affine permutation matrices and a randomized sequential selection procedure designed to eliminate short cycles, which are known to limit decoding performance.\nJoint belief propagation decoding is applied over depolarizing channels. Numerical experiments confirm that the proposed codes reduce the number of low-weight codewords in $C_X \\setminus C_Z^\\perp$ and $C_Z \\setminus C_X^\\perp$, and thus have the potential to suppress error floors. In addition, we obtain a significantly improved upper bound on the minimum distance, which we conjecture to be tight.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17790",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:33.843136Z"
  },
  {
    "id": "ca4cf1b11fc9dfd9c4556565d16b3ab0",
    "title": "QoS-based Beamforming and Compression Design for Cooperative Cellular Networks via Lagrangian Duality",
    "slug": "qos-based-beamforming-and-compression-design-for-cooperative-cellular-networks-via-lagrangian-duality",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Xilai Fan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper considers the quality-of-service (QoS)-based joint beamforming and compression design problem in the downlink cooperative cellular network, where multiple relay-like base stations (BSs), connected to the central processor via rate-limited fronthaul links, cooperatively transmit messages to the users. The problem of interest is formulated as the minimization of the total transmit power of the BSs, subject to all users' signal-to-interference-plus-noise ratio (SINR) constraints and all BSs' fronthaul rate constraints. In this paper, we first show that there is no duality gap between the considered joint optimization problem and its Lagrangian dual by showing the tightness of its semidefinite relaxation (SDR). Then, we propose an efficient algorithm based on the above duality result for solving the considered problem. The proposed algorithm judiciously exploits the special structure of an enhanced Karush-Kuhn-Tucker (KKT) conditions of the considered problem and finds the solution that satisfies the enhanced KKT conditions via two fixed point iterations. Two key features of the proposed algorithm are: (1) it is able to detect whether the considered problem is feasible or not and find its globally optimal solution when it is feasible; (2) it is highly efficient because both of the fixed point iterations in the proposed algorithm are linearly convergent and evaluating the functions in the fixed point iterations are computationally cheap. Numerical results show the global optimality and efficiency of the proposed algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2306.13962",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.843335Z"
  },
  {
    "id": "7b1787bbba88dad7ca44ab0c98e3404c",
    "title": "Revisit the Arimoto-Blahut algorithm: New Analysis with Approximation",
    "slug": "revisit-the-arimoto-blahut-algorithm:-new-analysis-with-approximation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Michail Fasoulakis",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "By the seminal paper of Claude Shannon \\cite{Shannon48}, the computation of the capacity of a discrete memoryless channel has been considered as one of the most important and fundamental problems in Information Theory. Nearly 50 years ago, Arimoto and Blahut independently proposed identical algorithms to solve this problem in their seminal papers \\cite{Arimoto1972AnAF, Blahut1972ComputationOC}. The Arimoto-Blahut algorithm was proven to converge to the capacity of the channel as $t \\to \\infty$ with the convergence rate upper bounded by $O\\left(\\log(m)/t\\right)$, where $m$ is the size of the input distribution, and being inverse exponential when there is a unique solution in the interior of the input probability simplex \\cite{Arimoto1972AnAF}. Recently it was proved, in \\cite{Nakagawa2020AnalysisOT}, that the convergence rate is at worst inverse linear $O(1/t)$ in some specific cases.\nIn this paper, we revisit this fundamental algorithm looking at the rate of convergence to the capacity and the time complexity, given $m,n$, where $n$ is size of the output of the channel, focusing on the approximation of the capacity. We prove that the rate of convergence to an $\\varepsilon$-optimal solution, for any sufficiently small constant $\\varepsilon > 0$, is inverse exponential $O\\left(\\log(m)/c^t\\right)$, for a constant $c > 1$ and $O\\left(\\log \\left(\\log (m)/\\varepsilon\\right)\\right)$ at most iterations, implying $O\\left(m n\\log \\left(\\log (m)/\\varepsilon\\right)\\right)$ total complexity of the algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2407.06013",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.843529Z"
  },
  {
    "id": "19076c3e1454701902a8562288b3446d",
    "title": "Capacity of Hierarchical Secure Coded Gradient Aggregation with Straggling Communication Links",
    "slug": "capacity-of-hierarchical-secure-coded-gradient-aggregation-with-straggling-communication-links",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Qinyi Lu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The growing privacy concerns in distributed learning have led to the widespread adoption of secure aggregation techniques in distributed machine learning systems, such as federated learning. Motivated by a coded gradient aggregation problem in a user-helper-master hierarchical network setting with straggling communication links, we formulate a new secure hierarchical coded gradient aggregation problem. In our setting, \\( K \\) users communicate with the master through an intermediate layer of \\( N \\) helpers, who can communicate with each other. With a resiliency threshold of \\( N_r \\) for straggling communication links, and at most \\( T \\) colluding helpers and any number of colluding users, the master aims to recover the sum of all users' gradients while remaining unaware of any individual gradient that exceeds the expected sum. In addition, helpers cannot infer more about users' gradients than what is already known by the colluding users. We propose an achievable scheme where users' upload messages are based on a globally known Vandermonde matrix, and helper communication is facilitated using an extended Vandermonde matrix with special structural properties. A matching converse bound is also derived, establishing the optimal result for this hierarchical coded gradient aggregation problem.",
    "pdfUrl": "https://arxiv.org/pdf/2412.11496",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.843733Z"
  },
  {
    "id": "e5d264b49b96b448f2b3b98315d73ef8",
    "title": "On Achievable Rates Over Noisy Nanopore Channels",
    "slug": "on-achievable-rates-over-noisy-nanopore-channels",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "V. Arvind Rameshwar",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we consider a recent channel model of a nanopore sequencer proposed by McBain, Viterbo, and Saunderson (2024), termed the noisy nanopore channel (NNC). In essence, an NNC is a duplication channel with structured, Markov inputs, that is corrupted by memoryless noise. We first discuss a (tight) lower bound on the capacity of the NNC in the absence of random noise. Next, we present lower and upper bounds on the channel capacity of general noisy nanopore channels. We then consider two interesting regimes of operation of an NNC: first, where the memory of the input process is large and the random noise introduces erasures, and second, where the rate of measurements of the electric current (also called the sampling rate) is high. For these regimes, we show that it is possible to achieve information rates close to the noise-free capacity, using low-complexity encoding and decoding schemes. In particular, our decoder for the regime of high sampling rates makes use of a change-point detection procedure -- a subroutine of immediate relevance for practitioners.",
    "pdfUrl": "https://arxiv.org/pdf/2501.02917",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.843926Z"
  },
  {
    "id": "ab0bc8aacfcd4f0282d95a1723a92046",
    "title": "Proofs for Folklore Theorems on the Radon-Nikodym Derivative",
    "slug": "proofs-for-folklore-theorems-on-the-radon-nikodym-derivative",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yaiza Bermudez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, rigorous statements and formal proofs are presented for both foundational and advanced folklore theorems on the Radon-Nikodym derivative. The cases of conditional and marginal probability measures are carefully considered, which leads to an identity involving the sum of mutual and lautum information suggesting a new interpretation for such a sum.",
    "pdfUrl": "https://arxiv.org/pdf/2501.18374",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.844131Z"
  },
  {
    "id": "4a6ee53af0ec6159715db2f605a3c355",
    "title": "Function-Correcting Codes for Locally Bounded Functions",
    "slug": "function-correcting-codes-for-locally-bounded-functions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Charul Rajput",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we introduce a class of functions that assume only a limited number $\\lambda$ of values within a given Hamming $\\rho$-ball and call them locally $(\\rho, \\lambda)$-bounded functions. We develop function-correcting codes (FCCs) for these functions and propose an upper bound on the redundancy of FCCs. The bound is based on the minimum length of an error-correcting code with a given number of codewords and a minimum distance. Furthermore, we provide a sufficient optimality condition for FCCs when $\\lambda =4$. We also demonstrate that any function can be represented as a locally $(\\rho, \\lambda)$-bounded function, illustrating this with a representation of Hamming weight distribution functions. Furthermore, we present another construction of function-correcting codes for Hamming weight distribution functions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.07804",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.844329Z"
  },
  {
    "id": "da6f10832b9d7dede024e0345e4866f7",
    "title": "Passive Channel Charting: Locating Passive Targets using Wi-Fi Channel State Information",
    "slug": "passive-channel-charting:-locating-passive-targets-using-wi-fi-channel-state-information",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Florian Euchner",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose passive channel charting, an extension of channel charting to passive target localization. As in conventional channel charting, we follow a dimensionality reduction approach to reconstruct a physically interpretable map of target positions from similarities in high-dimensional channel state information. We show that algorithms and neural network architectures developed in the context of channel charting with active mobile transmitters can be straightforwardly applied to the passive case, where we assume a scenario with static transmitters and receivers and a mobile target. We evaluate our method on a channel state information dataset collected indoors with a distributed setup of ESPARGOS Wi-Fi sensing antenna arrays. This scenario can be interpreted as either a multi-static or passive radar system. We demonstrate that passive channel charting outperforms a baseline based on classical triangulation in terms of localization accuracy. We discuss our results and highlight some unsolved issues related to the proposed concept.",
    "pdfUrl": "https://arxiv.org/pdf/2504.09924",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:33.844524Z"
  },
  {
    "id": "7ae3d874b9548121c1da8d36057a314b",
    "title": "Exponentially Consistent Nonparametric Linkage-Based Clustering of Data Sequences",
    "slug": "exponentially-consistent-nonparametric-linkage-based-clustering-of-data-sequences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Bhupender Singh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we consider nonparametric clustering of $M$ independent and identically distributed (i.i.d.) data sequences generated from {\\em unknown} distributions. The distributions of the $M$ data sequences belong to $K$ underlying distribution clusters. Existing results on exponentially consistent nonparametric clustering algorithms, like single linkage-based (SLINK) clustering and $k$-medoids distribution clustering, assume that the maximum intra-cluster distance ($d_L$) is smaller than the minimum inter-cluster distance ($d_H$). First, in the fixed sample size (FSS) setting, we show that exponential consistency can be achieved for SLINK clustering under a less strict assumption, $d_I < d_H$, where $d_I$ is the maximum distance between any two sub-clusters of a cluster that partition the cluster. Note that $d_I < d_L$ in general. Thus, our results show that SLINK is exponentially consistent for a larger class of problems than previously known. In our simulations, we also identify examples where $k$-medoids clustering is unable to find the true clusters, but SLINK is exponentially consistent. Then, we propose a sequential clustering algorithm, named SLINK-SEQ, based on SLINK and prove that it is also exponentially consistent. Simulation results show that the SLINK-SEQ algorithm requires fewer expected number of samples than the FSS SLINK algorithm for the same probability of error.",
    "pdfUrl": "https://arxiv.org/pdf/2411.13922",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:33.844715Z"
  },
  {
    "id": "14e6add221fb65478fcb949b1238950f",
    "title": "ROMA: ROtary and Movable Antenna",
    "slug": "roma:-rotary-and-movable-antenna",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Signal Processing (eess.SP)",
    "author": {
      "name": "Jiayi Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The rotary and movable antenna (ROMA) architecture represents a next-generation multi-antenna technology that enables flexible adjustment of antenna position and array rotation angles of the transceiver. In this letter, we propose a ROMA-aided multi-user MIMO communication system to fully enhance the efficiency and reliability of system transmissions. By deploying ROMA panels at both the transmitter and receiver sides, and jointly optimizing the three-dimensional (3D) rotation angles of each ROMA panel and the relative positions of antenna elements based on the spatial distribution of users and channel state information (CSI), we can achieve the objective of maximizing the average spectral efficiency (SE). Subsequently, we conduct a detailed analysis of the average SE performance of the system under the consideration of maximum ratio (MR) precoding. Due to the non-convexity of the optimization problem in the ROMA multi-user MIMO system, we propose an efficient solution based on an alternating optimization (AO) algorithm. Finally, simulation results demonstrate that the AO-based ROMA architecture can significantly improve the average SE. Furthermore, the performance improvement becomes more pronounced as the size of the movable region and the transmission power increase.",
    "pdfUrl": "https://arxiv.org/pdf/2501.13403",
    "tags": [
      "Signal Processing (eess.SP)"
    ],
    "createdAt": "2025-04-25T15:49:33.844923Z"
  },
  {
    "id": "68fe541c4ee2f7851492c8d48e04ae45",
    "title": "Higher Koszul duality and $n$-affineness",
    "slug": "higher-koszul-duality-and-$n$-affineness",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "James Pascaleff",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study $\\mathbb{E}_n$-Koszul duality for pairs of algebras of the form $\\mathrm{C}_{\\bullet}(\\Omega^{n}_*X;\\Bbbk) \\leftrightarrow \\mathrm{C}^{\\bullet}(X;\\Bbbk)$, and the closely related question of $n$-affineness for Betti stacks. It was expected, but not known, that $\\mathbb{E}_n$-Koszul duality should induce a kind of Morita equivalence between categories of iterated modules. We establish this rigorously by proving that the $(\\infty,n)$-category of iterated modules over $\\mathrm{C}_{\\bullet}(\\Omega_*^{n+1}X;\\Bbbk)$ is equivalent to the $(\\infty,n)$-category of quasi-coherent sheaves of $(\\infty,n-1)$-categories on $\\mathrm{cSpec}(\\mathrm{C}^{\\bullet}(X;\\Bbbk))$, where $\\mathrm{cSpec}(\\mathrm{C}^{\\bullet}(X;\\Bbbk))$ is the cospectrum of $\\mathrm{C}^{\\bullet}(X;\\Bbbk)$. By the monodromy equivalence, these categories are also equivalent to the category of higher local systems on $X$, $n\\mathbf{LocSysCat}^{n-1}(X;\\Bbbk)$. Our result is new already in the classical case $n=1$, although it can be seen to recover well known formulations of $\\mathbb{E}_1$-Koszul duality as a Morita equivalence of module categories (up to appropriate completions of the $t$-structures). We also investigate (higher) affineness properties of Betti stacks. We give a complete characterization of $n$-affine Betti stacks, in terms of the $0$-affineness of their iterated loop space. As a consequence, we prove that $n$-truncated Betti stacks are $n$-affine; and that $\\pi_{n+1}(X)$ is an obstruction to $n$-affineness.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16935",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:34.157084Z"
  },
  {
    "id": "e6987a871eea54a545aeb00bfc4bd6f6",
    "title": "Completion of motivic sheaves",
    "slug": "completion-of-motivic-sheaves",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Denis-Charles Cisinski",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the process of $\\ell$-adic completion of motivic sheaves. We observe that, in equal characteristic, when restricted to constructible objets, it is compatible with the six operations. This implies that one can reconstruct $\\ell$-adic sheaves of geometric origin over a scheme of finite type over a field from $\\ell$-adic cohomology of smooth schemes. In the case of finite fields, this includes perverse $\\ell$-adic sheaves of geometric orgin. However, the analogous behaviour fails systematically in mixed characteristic: the reason is that it would imply strong independence of $\\ell$ results that can be proven to be too optimistic.",
    "pdfUrl": "https://arxiv.org/pdf/2503.24033",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:34.157291Z"
  },
  {
    "id": "144ab76aed3c7a488bf80f811d46923e",
    "title": "Feasibility of Primality in Bounded Arithmetic",
    "slug": "feasibility-of-primality-in-bounded-arithmetic",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic (math.LO)",
    "author": {
      "name": "Raheleh Jalali",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove the correctness of the AKS algorithm \\cite{AKS} within the bounded arithmetic theory $T^{count}_2$ or, equivalently, the first-order consequence of the theory $VTC^0$ expanded by the smash function, which we denote by $VTC^0_2$. Our approach initially demonstrates the correctness within the theory $S^1_2 + iWPHP$ augmented by two algebraic axioms and then show that they are provable in $VTC^0_2$. The two axioms are: a generalized version of Fermat's Little Theorem and an axiom adding a new function symbol which injectively maps roots of polynomials over a definable finite field to numbers bounded by the degree of the given polynomial. To obtain our main result, we also give new formalizations of parts of number theory and algebra:\n$\\bullet$ In $PV_1$: We formalize Legendre's Formula on the prime factorization of $n!$, key properties of the Combinatorial Number System and the existence of cyclotomic polynomials over the finite fields $Z/p$.\n$\\bullet$ In $S^1_2$: We prove the inequality $lcm(1,\\dots, 2n) \\geq 2^n$.\n$\\bullet$ In $VTC^0$: We verify the correctness of the Kung--Sieveking algorithm for polynomial division.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17041",
    "tags": [
      "Logic (math.LO)"
    ],
    "createdAt": "2025-04-25T15:49:34.475890Z"
  },
  {
    "id": "9cd2f077306c051a40cdb384bdb365ca",
    "title": "Many-valued aspects of tense an related operators",
    "slug": "many-valued-aspects-of-tense-an-related-operators",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic (math.LO)",
    "author": {
      "name": "Michal Botur",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Our research builds upon Halmos's foundational work on functional monadic Boolean algebras and our previous work on tense operators to develop three essential constructions, including the important concepts of fuzzy sets and powerset operators. These constructions have widespread applications across contemporary mathematical disciplines, including algebra, logic, and topology. The framework we present generates four covariant and two contravariant functors, establishing three adjoint situations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17654",
    "tags": [
      "Logic (math.LO)"
    ],
    "createdAt": "2025-04-25T15:49:34.476100Z"
  },
  {
    "id": "7f71d5f90b4c07e239db1aec49baeeb0",
    "title": "On the structure of modal and tense operators on a boolean algebra",
    "slug": "on-the-structure-of-modal-and-tense-operators-on-a-boolean-algebra",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic (math.LO)",
    "author": {
      "name": "Guram Bezhanishvili",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the poset NO(B) of necessity operators on a boolean algebra B. We show that NO(B) is a meet-semilattice that need not be distributive. However, when B is complete, NO(B) is necessarily a frame, which is spatial iff B is atomic. In that case, NO(B) is a locally Stone frame. Dual results hold for the poset PO(B) of possibility operators. We also obtain similar results for the posets TNO(B) and TPO(B) of tense necessity and possibility operators on B. Our main tool is Jonsson-Tarski duality, by which such operators correspond to continuous and interior relations on the Stone space of B.",
    "pdfUrl": "https://arxiv.org/pdf/2308.08664",
    "tags": [
      "Logic (math.LO)"
    ],
    "createdAt": "2025-04-25T15:49:34.476302Z"
  },
  {
    "id": "9af753f60fb8287686530037d817be30",
    "title": "Outward compactness",
    "slug": "outward-compactness",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Logic (math.LO)",
    "author": {
      "name": "Peter Holy",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce and study a new type of compactness principle for strong logics that, roughly speaking, infers the consistency of a theory from the consistency of its small fragments in certain outer models of the set-theoretic universe. We refer to this type of compactness property as outward compactness, and we show that instances of this type of principle for second-order logic can be used to characterize various large cardinal notions between measurability and extendibility, directly generalizing a classical result of Magidor that characterizes extendible cardinals as the strong compactness cardinals of second-order logic. In addition, we generalize a result of Makowsky that shows that Vopnka's Principle is equivalent to the existence of compactness cardinals for all abstract logics by characterizing the principle \"Ord is Woodin\" through outward compactness properties of abstract logics.",
    "pdfUrl": "https://arxiv.org/pdf/2402.15788",
    "tags": [
      "Logic (math.LO)"
    ],
    "createdAt": "2025-04-25T15:49:34.476494Z"
  },
  {
    "id": "9224fac5bec3bce8ea212ddd9cc14efc",
    "title": "Hollow polytopes with many vertices",
    "slug": "hollow-polytopes-with-many-vertices",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Metric Geometry (math.MG)",
    "author": {
      "name": "Srinivas Arun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Given a set $S \\subseteq \\mathbb{R}^d$, a hollow polytope has vertices in $S$ but contains no other point of $S$ in its interior. We prove upper and lower bounds on the maximum number of vertices of hollow polytopes whose facets are simplices or whose vertices are in general position. We also obtain relatively tight asymptotic bounds for polytopes which do not contain lattice segments of large length.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17530",
    "tags": [
      "Metric Geometry (math.MG)"
    ],
    "createdAt": "2025-04-25T15:49:34.712902Z"
  },
  {
    "id": "457563cd90a978cc5f27d9f596fdc442",
    "title": "Asymptotically CAT(0) metrics, Z-structures, and the Farrell-Jones Conjecture",
    "slug": "asymptotically-cat(0)-metrics,-z-structures,-and-the-farrell-jones-conjecture",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Matthew Gentry Durham",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We show that colorable hierarchically hyperbolic groups (HHGs) admit asymptotically CAT(0) metrics, that is, roughly, metrics where the CAT(0) inequality holds up to sublinear error in the size of the triangle.\nWe use the asymptotically CAT(0) metrics to construct contractible simplicial complexes and compactifications that provide $\\mathcal{Z}$-structures in the sense of Bestvina and Dranishnikov. It was previously unknown that mapping class groups are asymptotically CAT(0) and admit $\\mathcal{Z}$-structures. As an application, we prove that many HHGs satisfy the Farrell--Jones Conjecture, including extra large-type Artin groups.\nTo construct asymptotically CAT(0) metrics, we show that hulls of finitely many points in a colorable HHGs can be approximated by CAT(0) cube complexes in a way that adding a point to the finite set corresponds, up to finitely many hyperplanes deletions, to a convex embedding.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17048",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:34.713142Z"
  },
  {
    "id": "4c2d33685a7d8033e284733d77c2e606",
    "title": "Small genus, small index critical points of the systole function",
    "slug": "small-genus,-small-index-critical-points-of-the-systole-function",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Geometric Topology (math.GT)",
    "author": {
      "name": "Ni An",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper the index of a family of critical points of the systole function on Teichmller space is calculated. The members of this family are interesting in that their existence implies the existence of strata in the Thurston spine for which the systoles do not determine a basis for the homology of the surface. Previously, index calculations of critical points with this pathological feature were impossible, because the only known examples were in surfaces with huge genus.\nA related concept is that of a ``minimal filling subset'' of the systoles at the critical point. Such minimal filling sets are studied, as they relate to the dimension of the Thurston spine near the critical point. We find an example of a minimal filling set of simple closed geodesics in genus 5 with cardinality 8, that are presumably realised as systoles. More generally, we determine the smallest and largest cardinality of a minimal filling set related to a tesselation of a hyperbolic surface by regular, right-angled $m$-gons for $m \\in \\{ 5, 6, 7 \\}$. For this, we use integer linear programming together with a hand-tailored symmetry breaking technique.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17316",
    "tags": [
      "Geometric Topology (math.GT)"
    ],
    "createdAt": "2025-04-25T15:49:34.713347Z"
  },
  {
    "id": "609aedfdf2b1ca7ddba9bcebcad8cfce",
    "title": "The $q^{\\mathrm{Volume}}$ lozenge tiling model via non-Hermitian orthogonal polynomials",
    "slug": "the-$q^{\\mathrm{volume}}$-lozenge-tiling-model-via-non-hermitian-orthogonal-polynomials",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Ahmad Barhoumi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider the $q^\\text{Volume}$ lozenge tiling model on a large, finite hexagon. It is well-known that random lozenge tilings of the hexagon correspond to a two-dimensional determinantal point process via a bijection with ensembles of non-intersecting paths. The starting point of our analysis is a formula for the correlation kernel due to Duits and Kuijlaars which involves the Christoffel-Darboux kernel of a particular family of non-Hermitian orthogonal polynomials. Our main results are split into two parts: the first part concerns the family of orthogonal polynomials, and the second concerns the behavior of the boundary of the so-called arctic curve. In the first half, we identify the orthogonal polynomials as a non-standard instance of little $q$-Jacobi polynomials and compute their large degree asymptotics in the $q \\to 1$ regime. A consequence of this analysis is a proof that the zeros of the orthogonal polynomials accumulate on an arc of a circle and an asymptotic formula for the Christoffel-Darboux kernel. In the second half, we use these asymptotics to show that the boundary of the liquid region converges to the Airy process, in the sense of finite dimensional distributions, away from the boundary of the hexagon. At inflection points of the arctic curve, we show that we do not need to subtract/add a parabola to the Airy line ensemble, and this effect persists at distances which are $o(N^{-2/9})$ in the tangent direction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17042",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.010608Z"
  },
  {
    "id": "d175ee3f82653a651b1b69acbacc32c4",
    "title": "Defects in unidimensional structures",
    "slug": "defects-in-unidimensional-structures",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Mewen Crespo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In a previous work of the first authors, a non-holonomic model, generalising the micromorphic models and allowing for curvature (disclinations) to arise from the kinematic values, was presented. In the present paper, a generalisation of the classical models of Euler-Bernoulli and Timoshenko bending beams based on the mentioned work is proposed. The former is still composed of only one unidimensional scalar field, while the later introduces a third unidimensional scalar field, correcting the second order terms. The generalised Euler-Bernoulli beam is then shown to exhibit curvature (i.e. disclinations) linked to a third order derivative of the displacement, but no torsion (dislocations). Parallelly, the generalised Timoshenko beam is shown to exhibit both curvature and torsion, where the former is linked to the non-holonomy introduced in the generalisation. Lastly, using variational calculus, asymptotic values for the value taken by the curvature in static equilibrium are obtained when the second order contribution becomes negligible; along with an equation for the torsion in the generalised Timoshenko beam.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17340",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.010829Z"
  },
  {
    "id": "97397f0f5138d79ebcbdefe004ed6ebc",
    "title": "The KP equation of plane elastodynamics",
    "slug": "the-kp-equation-of-plane-elastodynamics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Harold Berjamin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The propagation of nonlinear and dispersive waves in various materials can be described by the well-known Kadomtsev-Petviashvili (KP) equation, which is a (2+1)-dimensional partial differential equation. In this paper, we show that the KP equation can be used to describe the in-plane motion of compressible elastic solids with dispersion. Furthermore, a modified KP equation with cubic nonlinearity is obtained in the case of incompressible solids with dispersion. Then, several solutions of these partial differential equations are discussed and computed using a Fourier spectral method. In particular, both equations admit solitary wave solutions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17411",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.011025Z"
  },
  {
    "id": "7f66d47aa9c6176bd1edeffe42af2506",
    "title": "Baryogenesis in Conformally Flat Spacetimes",
    "slug": "baryogenesis-in-conformally-flat-spacetimes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Felix Finster",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Based on a baryogenesis mechanism originating from the theory of causal fermion systems, we analyze its main geometric and analytic features in conformally flat spacetimes. An explicit formula is derived for the rate of baryogenesis in these spacetimes, which depends on the mass $m$ of the particles, the conformal factor $\\Omega$ and a future directed timelike vector field $u$ (dubbed the regularizing vector field). Our analysis covers Friedmann-Lema{}tre-Robertson-Walker, Milne and Milne-like spacetimes. It sets the ground for concrete, quantitative predictions for specific cosmological spacetimes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17434",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.011224Z"
  },
  {
    "id": "91b420ad56922e61de93b6b0c1671b0c",
    "title": "Microscopic derivation of the stationary Chern-Simons-Schrdinger equation for almost-bosonic anyons",
    "slug": "microscopic-derivation-of-the-stationary-chern-simons-schrdinger-equation-for-almost-bosonic-anyons",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Alireza Ataei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work we consider the $N$-body Hamiltonian describing the microscopic structure of a quantum gas of almost-bosonic anyons. This description includes both extended magnetic flux and spin-orbit/soft-disk interaction between the particles which are confined in a scalar trapping potential. We study a physically well-motivated ansatz for a sequence of trial states, consisting of Jastrow repulsive short-range correlations and a condensate, with sufficient variational freedom to approximate the ground state (and possibly also low-energy excited states) of the gas. In the limit $N \\to \\infty$, while taking the relative size of the anyons to zero and the total magnetic flux $2\\pi\\beta$ to remain finite, we rigorously derive the stationary Chern-Simons-Schrdinger/average-field-Pauli effective energy density functional for the condensate wave function. This includes a scalar self-interaction parameter $\\gamma$ which depends both on $\\beta$, the diluteness of the gas, and the spin-orbit coupling strength $g$, but becomes independent of these microscopic details for a particular value of the coupling $g=2$ in which supersymmetry is exhibited (on all scales, both microscopic and mesoscopic) with $\\gamma=2\\pi|\\beta|$. Our findings confirm and clarify the predictions we have found in the physics literature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17488",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.011427Z"
  },
  {
    "id": "7d872640b1a7a21742c0bceeb917d9fa",
    "title": "One-dimensional $q$-state modified Potts model and its thermodynamic functions",
    "slug": "one-dimensional-$q$-state-modified-potts-model-and-its-thermodynamic-functions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Hasan Akin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Since its introduction, the Potts model has gained widespread popularity across various fields due to its diverse applications. Even minor advancements in this model continue to captivate scientists worldwide, and small modifications often intrigue researchers from different disciplines. This paper investigates a one-dimensional \\(q\\)-state modified Potts model influenced by an external magnetic field. By leveraging the transfer matrix method, exact expressions are derived for key thermodynamic quantities, including free energy, entropy, magnetization, susceptibility, and specific heat capacity. Numerical analyses explore how these thermodynamic functions vary with relevant parameters, offering insights into the system's behavior. Additionally, the asymptotic properties of these quantities are examined in the limiting cases \\(T \\to 0\\) and \\(T \\to \\infty\\). The findings contribute to a deeper understanding of the model's thermodynamic characteristics and highlight its potential applications across various disciplines.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17616",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.011617Z"
  },
  {
    "id": "a24d94fb6156ac705465b52669dbf9de",
    "title": "Three-local Charge Conservation Implies Quantum Integrability",
    "slug": "three-local-charge-conservation-implies-quantum-integrability",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Zhao Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is shown that the existence of a local conserved charge supported by three neighboring sites, or its local version, Reshetikhin's condition, suffices to guarantee the existence of all higher conserved charges and hence the integrability of a quantum spin chain. This explains the ``coincidence'' that no counterexample is known to Grabowski and Mathieu's long-standing conjecture despite the folklore that the conservation of local charges of order higher than 4 imposes additional constraints not implied by the conservation of the three-local charge.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17773",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.011797Z"
  },
  {
    "id": "01864c83041f1325b60283e9972aa0ce",
    "title": "An Exact SIR Series Solution and an Exploration of the Related Parameter Space",
    "slug": "an-exact-sir-series-solution-and-an-exploration-of-the-related-parameter-space",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Dynamical Systems (math.DS)",
    "author": {
      "name": "Daniel P Hobbs",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A convergent power series solution is obtained for the SIR model, using an asymptotically motivated gauge function. For certain choices of model parameter values, the series converges over the full physical domain (i.e., for all positive time). Furthermore, the radius of convergence as a function of nondimensionalized initial susceptible and infected populations is obtained via a numerical root test.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17026",
    "tags": [
      "Dynamical Systems (math.DS)"
    ],
    "createdAt": "2025-04-25T15:49:35.011991Z"
  },
  {
    "id": "7d02359e1bc2d76d2778ca269eed5d0c",
    "title": "Higher-Spin Currents and Flows in Auxiliary Field Sigma Models",
    "slug": "higher-spin-currents-and-flows-in-auxiliary-field-sigma-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "Daniele Bielli",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study local, higher-spin conserved currents in integrable $2d$ sigma models that have been deformed via coupling to auxiliary fields. These currents generate integrability-preserving flows introduced by Smirnov and Zamolodchikov. For auxiliary field (AF) deformations of a free boson, we prove that local spin-$n$ currents exist for all $n$ and give recursion relations that characterize Smirnov-Zamolodchikov (SZ) flows driven by these currents. We then show how to construct spin-$2n$ currents in a unified class of auxiliary field sigma models with common structure -- including AF theories based on the principal chiral model (PCM), its non-Abelian T-dual, (bi-)Yang-Baxter deformations of the PCM, and symmetric space models -- for interaction functions of one variable, and describe SZ flows driven by any function of the stress tensor in these cases. Finally, we give perturbative solutions for spin-$3$ SZ flows in any member of our unified class of AF models with underlying $\\mathfrak{su}(3)$ algebra. Part of our analysis shows that the class of AF deformations can be extended by allowing the interaction function to depend on a larger set of variables than has previously been considered.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17294",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:35.012196Z"
  },
  {
    "id": "459afca5ca8a432ac31945b587c0c128",
    "title": "Quantum Corner VOA and the Super Macdonald Polynomials",
    "slug": "quantum-corner-voa-and-the-super-macdonald-polynomials",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "Panupong Cheewaphutthisakun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we establish a relation between the quantum corner VOA $q\\widetilde{Y}_{L,0,N}[\\Psi]$, which can be regarded as a generalization of quantum $W_N$ algebra, and Sergeev-Veselov super Macdonald polynomials. We demonstrate precisely that, under a specific map, the correlation functions of the currents of $q\\widetilde{Y}_{L,0,N}[\\Psi]$, coincide with the Sergeev-Veselov super Macdonald polynomials.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17326",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:35.012395Z"
  },
  {
    "id": "33f5c6d536c7050aab8f44d0238945de",
    "title": "Classical Estimation of the Free Energy and Quantum Gibbs Sampling from the Markov Entropy Decomposition",
    "slug": "classical-estimation-of-the-free-energy-and-quantum-gibbs-sampling-from-the-markov-entropy-decomposition",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Physics (quant-ph)",
    "author": {
      "name": "Samuel O. Scalet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We revisit the Markov Entropy Decomposition, a classical convex relaxation algorithm introduced by Poulin and Hastings to approximate the free energy in quantum spin lattices. We identify a sufficient condition for its convergence, namely the decay of the effective interaction. We prove that this condition is satisfied for systems in 1D at any temperature as well as in the high-temperature regime under a certain commutativity condition on the Hamiltonian. This yields polynomial and quasi-polynomial time approximation algorithms in these settings, respectively. Furthermore, the decay of the effective interaction implies the decay of the conditional mutual information for the Gibbs state of the system. We then use this fact to devise a rounding scheme that maps the solution of the convex relaxation to a global state and show that the scheme can be efficiently implemented on a quantum computer, thus proving efficiency of quantum Gibbs sampling under our assumption of decay of the effective interaction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17405",
    "tags": [
      "Quantum Physics (quant-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.012603Z"
  },
  {
    "id": "46077ce1f11b9ba9e7c9463e8172b68f",
    "title": "Lectures on measurement in quantum field theory",
    "slug": "lectures-on-measurement-in-quantum-field-theory",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "General Relativity and Quantum Cosmology (gr-qc)",
    "author": {
      "name": "Christopher J. Fewster",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "These lectures present a brief introduction to measurement theory for QFT in possibly curved spacetimes introduced by the author and R. Verch [Comm. Math. Phys. 378 (2020) 851-889]. Topics include: a brief introduction to algebraic QFT, measurement schemes in QFT, state updates, multiple measurements and the resolution of Sorkin's \"impossible measurement\" problem. Examples using suitable theories based on Green hyperbolic operators are given, and the interpretational significance of the framework is briefly considered. The basic style is to give details relating to QFT while taking for granted various facts from the theory of globally hyperbolic spacetimes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17437",
    "tags": [
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "createdAt": "2025-04-25T15:49:35.012790Z"
  },
  {
    "id": "a70d243dd5d3e40903ff37e6498c16de",
    "title": "On soliton resolution to Cauchy problem of the spin-1 Gross-Pitaevskii equation",
    "slug": "on-soliton-resolution-to-cauchy-problem-of-the-spin-1-gross-pitaevskii-equation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Shou-Fu Tian",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the Cauchy problem for the spin-1 Gross-Pitaevskii(GP) equation, which is a model instrumental in characterizing the soliton dynamics within spinor Bose-Einstein condensates. Recently, Geng $etal.$ (Commun. Math. Phys. 382, 585-611 (2021)) reported the long-time asymptotic result with error $\\mathcal{O}(\\frac{\\log t}t)$ for the spin-1 GP equation that only exists in the continuous spectrum. The main purpose of our work is to further generalize and improve Geng's work. Compared with the previous work, our asymptotic error accuracy has been improved from $\\mathcal{O}(\\frac{\\log t}t)$ to $\\mathcal{O}(t^{-3/4})$. More importantly, by establishing two matrix valued functions, we obtained effective asymptotic errors and successfully constructed asymptotic analysis of the spin-1 GP equation based on the characteristics of the spectral problem, including two cases: (i)coexistence of discrete and continuous spectrum; (ii)only continuous spectrum which considered by Geng's work with error $\\mathcal{O}(\\frac{\\log t}t)$. For the case (i), the corresponding asymptotic approximations can be characterized with an $N$-soliton as well as an interaction term between soliton solutions and the dispersion term with diverse residual error order $\\mathcal{O}(t^{-3/4})$. For the case (ii), the corresponding asymptotic approximations can be characterized with the leading term on the continuous spectrum and the residual error order $\\mathcal{O}(t^{-3/4})$. Finally, our results confirm the soliton resolution conjecture for the spin-1 GP equation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17465",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:35.012986Z"
  },
  {
    "id": "56e41438f621dda40edb75368eb04ccb",
    "title": "Free field realization of the quantum toroidal algebra of $\\mathfrak{gl}_1$ with general levels",
    "slug": "free-field-realization-of-the-quantum-toroidal-algebra-of-$\\mathfrak{gl}_1$-with-general-levels",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "Zitao Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present a unified free field realization of representations for the quantum toroidal algebra of $\\mathfrak{gl}_1$ with arbitrary levels, constructed using six free boson fields. This realization arises from a specialized factorization of the structure function within the defining relations of the quantum toroidal algebra of $\\mathfrak{gl}_1$. Utilizing this free field realization, we further develop intertwining operators for the algebra of $\\mathfrak{gl}_1$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17508",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:35.013186Z"
  },
  {
    "id": "f5941b15a632184834374432848a5a9d",
    "title": "Orbifolds, higher dagger structures, and idempotents",
    "slug": "orbifolds,-higher-dagger-structures,-and-idempotents",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Algebra (math.QA)",
    "author": {
      "name": "Nils Carqueville",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The orbifold/condensation completion procedure of defect topological quantum field theories can be seen as carrying out a lattice or state sum model construction internal to an ambient theory. In this paper, we propose a conceptual algebraic description of orbifolds/condensations for arbitrary tangential structures in terms of higher dagger structures and higher idempotents. In particular, we obtain (oriented) orbifold completion from (framed) condensation completion by using a general strictification procedure for higher dagger structures which we describe explicitly in low dimensions; we also discuss the spin and unoriented case. We provide several examples of higher dagger categories, such as those associated to state sum models, (orbifolds of) Landau--Ginzburg models, and truncated affine Rozansky--Witten models. We also explain how their higher dagger structures are naturally induced from rigid symmetric monoidal structures, recontextualizing and extending results from the literature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17764",
    "tags": [
      "Quantum Algebra (math.QA)"
    ],
    "createdAt": "2025-04-25T15:49:35.013378Z"
  },
  {
    "id": "9858c0055adb0ca8990c644b5c63be78",
    "title": "Extended Scalar Particle Solutions in Black String Spacetimes with Anisotropic Quintessence",
    "slug": "extended-scalar-particle-solutions-in-black-string-spacetimes-with-anisotropic-quintessence",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "General Relativity and Quantum Cosmology (gr-qc)",
    "author": {
      "name": "M.L. Deglmann",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present new solutions to the Klein-Gordon equation for a scalar particle in a black string spacetime immersed in an anisotropic quintessence fluid surrounded by a cloud of strings, extending the analysis presented in our previous work. These novel solutions are dependent on the quintessence state parameter, $\\alpha_{Q}$, and are now valid for a much larger domain of the radial coordinate. We investigate the cases when $\\alpha_{Q} = 0,\\,1/2,\\,1$, encompassing both black hole and horizonless scenarios. We express the resulting radial wave functions using the confluent and biconfluent Heun functions, with special cases represented by Bessel functions. We derive restrictions on the allowed quantum energy levels by imposing constraints on the Heun parameters to ensure polynomial solutions. Furthermore, we investigate the emergence of \"dark phases\" associated with the radial wave function, focusing on the interesting case of $\\alpha_{Q} = 1$. Our findings provide insights into the dynamics of scalar particles in this complex spacetime and the potential impact of dark energy on quantum systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17765",
    "tags": [
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "createdAt": "2025-04-25T15:49:35.013578Z"
  },
  {
    "id": "1251a42f75a9d0f9464a3119e524cf83",
    "title": "Cyclic Representations of $U_q(\\hat{\\mathfrak{sl}}_2)$ and its Borel Subalgebras at Roots of Unity and Q-operators",
    "slug": "cyclic-representations-of-$u_q(\\hat{\\mathfrak{sl}}_2)$-and-its-borel-subalgebras-at-roots-of-unity-and-q-operators",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Robert Weston",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider the cyclic representations $\\Omega_{rs}$ of $ U_q(\\widehat{\\mathfrak{sl}}_2)$ at $q^N=1$ that depend upon two points $r,s$ in the chiral Potts algebraic curve. We show how $\\Omega_{rs}$ is related to the tensor product $\\rho_r\\otimes \\bar{\\rho}_s$ of two representations of the upper Borel subalgebra of $U_q(\\widehat{\\mathfrak{sl}}_2)$. This result is analogous to the factorization property of the Verma module of $U_q(\\widehat{\\mathfrak{sl}}_2)$ at generic-$q$ in terms of two q-oscillator representation of the Borel subalgebra - a key step in the construction of the Q-operator. We construct short exact sequences of the different representations and use the results to construct Q operators that satisfy TQ relations for $q^N=1$ for both the 6-vertex and $\\tau_2$ models.",
    "pdfUrl": "https://arxiv.org/pdf/2412.14811",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.013794Z"
  },
  {
    "id": "7c6ae689e2e55fa1203df832a97df620",
    "title": "Split Two-Periodic Aztec Diamond",
    "slug": "split-two-periodic-aztec-diamond",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Meredith Shea",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recent advancements have been made to understand the statistics of the Aztec diamond dimer model under general periodic weights. In this work we define a model that breaks periodicity in one direction by combining two different two-periodic weightings. We compute the correlation kernel for this Aztec diamond dimer model by extending the methods developed by Berggren and Duits (2019), which utilize the Eynard-Mehta theorem and a Wiener-Hopf factorization. From a form of the correlation kernel that is suitable for asymptotics, we compute the local asymptotics of the model in the different macroscopic regions present. We prove that the local asymptotics of the model agree with the typical two-periodic model in the highest order, however the sub-leading order terms are affected.",
    "pdfUrl": "https://arxiv.org/pdf/2502.18349",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.013987Z"
  },
  {
    "id": "def713f09d0515967d30d0f7d2cf9ddc",
    "title": "Noetherian Conservation Laws for Photons",
    "slug": "noetherian-conservation-laws-for-photons",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Michael K.-H. Kiessling",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We review the formulation of a Lorentz-covariant bispinorial wave function and wave equation for a single photon on a flat background. We show the existence of a 10-dimensional set of conservation laws for this equation, and prove that 8 of these can be used to obtain global, gauge-invariant, ADM-like quantities that together define a covariantly constant self-dual bispinor.",
    "pdfUrl": "https://arxiv.org/pdf/2503.03271",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.014179Z"
  },
  {
    "id": "1be3345d3807dfe852be3ef33cc77e8a",
    "title": "On the generalized Langevin equation and the Mori projection operator technique",
    "slug": "on-the-generalized-langevin-equation-and-the-mori-projection-operator-technique",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Christoph Widder",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In statistical physics, the Mori-Zwanzig projection operator formalism (also called Nakajima-Zwanzig projection operator formalism) is used to derive a linear integro-differential equation for observables in Hilbert space, the generalized Langevin equation (GLE). This technique relies on the splitting of the dynamics into a projected and an orthogonal part. We prove that the GLE together with the second fluctuation dissipation theorem (2FDT) uniquely define the fluctuating forces as well as the memory kernel. The GLE and 2FDT are an immediate consequence of the existence and uniqueness of solutions of linear Volterra equations. They neither rely on the Dyson identity nor on the concept of orthogonal dynamics. This holds true for autonomous as well as non-autonomous systems. Further results are obtained for the Mori projection for autonomous systems, for which the fluctuating forces are orthogonal to the observable of interest. In particular, we prove that the orthogonal dynamics is a strongly continuous semigroup generated by $\\overline{\\mathcal{QL}}Q$, where $\\mathcal{L}$ is the generator of the time evolution operator, and $\\mathcal{P}=1-\\mathcal{Q}$ is the Mori projection operator. As a consequence, the corresponding orbit maps (e.g. the fluctuating forces) are the unique mild solutions of the associated abstract Cauchy problem. Furthermore, we show that the orthogonal dynamics is a unitary group, if $\\mathcal{L}$ is skew-adjoint. In this case, the fluctuating forces are stationary. In addition, we present a proof of the GLE by means of semigroup theory, and we retrieve the commonly used definitions for the fluctuating forces, memory kernel, and orthogonal dynamics. Our results apply to general autonomous dynamical systems, whose time evolution is given by a strongly continuous semigroup. This includes large classes of systems in classical statistical mechanics.",
    "pdfUrl": "https://arxiv.org/pdf/2503.20457",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.014372Z"
  },
  {
    "id": "0b05b29c965c5d64ed38a5e1c2c3b09f",
    "title": "Surface-Polyconvex Models for Soft Elastic Solids",
    "slug": "surface-polyconvex-models-for-soft-elastic-solids",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Martin Hork",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Soft solids with surface energy exhibit complex mechanical behavior, necessitating advanced constitutive models to capture the interplay between bulk and surface mechanics. This interplay has profound implications for material design and emerging technologies. In this work, we set up variational models for bulk-surface elasticity and explore a novel class of surface-polyconvex constitutive models that account for surface energy while ensuring the existence of minimizers. These models are implemented within a finite element framework and validated through benchmark problems and applications, including, e.g., the liquid bridge problem and the Rayleigh-Plateau instability, for which the surface energy plays the dominant role. The results demonstrate the ability of surface-polyconvex models to accurately capture surface-driven phenomena, establishing them as a powerful tool for advancing the mechanics of soft materials in both engineering and biological applications.",
    "pdfUrl": "https://arxiv.org/pdf/2503.24294",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.014562Z"
  },
  {
    "id": "3323de530215800b5d4dc736361ba64a",
    "title": "Longtime dynamics for the Landau Hamiltonian with a time dependent magnetic field",
    "slug": "longtime-dynamics-for-the-landau-hamiltonian-with-a-time-dependent-magnetic-field",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Dario Bambusi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider a modulated magnetic field, $B(t) = B_0 +\\varepsilon f(\\omega t)$, perpendicular to a fixed plane, where $B_0$ is constant, $\\varepsilon>0$ and $f$ a periodic function on the torus ${\\mathbb T}^n$. Our aim is to study classical and quantum dynamics for the corresponding Landau Hamiltonian. It turns out that the results depend strongly on the chosen gauge. For the Landau gauge the position observable is unbounded for \"almost all\" non resonant frequencies $\\omega$. On the contrary, for the symmetric gauge we obtain that, for \"almost all\" non resonant frequencies $\\omega$, the Landau Hamiltonian is reducible to a two dimensional harmonic oscillator and thus gives rise to bounded dynamics. The proofs use KAM algorithms for the classical dynamics. Quantum applications are given. In particular, the Floquet spectrum is absolutely continuous in the Landau gauge while it is discrete, of finite multiplicity, in symmetric gauge.",
    "pdfUrl": "https://arxiv.org/pdf/2402.00428",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:35.014770Z"
  },
  {
    "id": "e54ab6402a83ab4e5095e28761eef435",
    "title": "The relativistic rotated harmonic oscillator",
    "slug": "the-relativistic-rotated-harmonic-oscillator",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Spectral Theory (math.SP)",
    "author": {
      "name": "A. Balmaseda",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a relativistic version of the non-self-adjoint operator obtained by a dilation analytic transformation of the quantum harmonic oscillator. While the spectrum is real and discrete, we show that the eigenfunctions do not form a basis and that the pseudospectra are highly non-trivial.",
    "pdfUrl": "https://arxiv.org/pdf/2411.16494",
    "tags": [
      "Spectral Theory (math.SP)"
    ],
    "createdAt": "2025-04-25T15:49:35.014967Z"
  },
  {
    "id": "bd5240ae9c313e2c1995ee888a35e40b",
    "title": "Transport theory in moderately anisotropic plasmas: I, Collisionless aspects of axisymmetric velocity space",
    "slug": "transport-theory-in-moderately-anisotropic-plasmas:-i,-collisionless-aspects-of-axisymmetric-velocity-space",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Plasma Physics (physics.plasm-ph)",
    "author": {
      "name": "Yanpeng Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A novel transport theory, based on the finitely distinguishable independent features (FDIF) hypothesis, is presented for scenarios when velocity space exhibits axisymmetry. In this theory, the transport equations are derived from the 1D-2V Vlasov equation, employing the spherical harmonics expansions (SHE) together with the King function expansion (KFE) in velocity space. The characteristic parameter equations (CPEs) are provided based on the general King mixture model (GKMM), serving as the constraint equations of the transport equations. It is a nature process to present the closure relations of transport equations based on SHE and KFE, successfully providing a kinetic moment-closed model (KMCM). This model is typically a nonlinear system, effective for moderately anisotropic non-equilibrium plasmas.",
    "pdfUrl": "https://arxiv.org/pdf/2501.08634",
    "tags": [
      "Plasma Physics (physics.plasm-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.015152Z"
  },
  {
    "id": "b1292a6001a27bdb5368c9e845d1f495",
    "title": "Universal Methods for Nonlinear Spectral Problems",
    "slug": "universal-methods-for-nonlinear-spectral-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Matthew J. Colbrook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Nonlinear spectral problems arise across a range of fields, including mechanical vibrations, fluid-solid interactions, and photonic crystals. Discretizing infinite-dimensional nonlinear spectral problems often introduces significant computational challenges, particularly spectral pollution and invisibility, which can distort or obscure the true underlying spectrum. We present the first general, convergent computational method for computing the spectra and pseudospectra of nonlinear spectral problems. Our approach uses new results on nonlinear injection moduli and requires only minimal continuity assumptions: specifically, continuity with respect to the gap metric on operator graphs, making it applicable to a broad class of problems. We use the Solvability Complexity Index (SCI) hierarchy, which has recently been used to resolve the classical linear problem, to systematically classify the computational complexity of nonlinear spectral problems. Our results establish the optimality of the method and reveal that Hermiticity does not necessarily simplify the computational complexity of these nonlinear problems. Comprehensive examples -- including nonlinear shifts, Klein--Gordon equations, wave equations with acoustic boundary conditions, time-fractional beam equations, and biologically inspired delay differential equations -- demonstrate the robustness, accuracy, and broad applicability of our methodology.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17012",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.298022Z"
  },
  {
    "id": "021c0af10ace6d6481216d5e66ab4321",
    "title": "An Adaptive Finite Element DtN Method for the Acoustic-Elastic Interaction Problem in Periodic Structures",
    "slug": "an-adaptive-finite-element-dtn-method-for-the-acoustic-elastic-interaction-problem-in-periodic-structures",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Lei Lin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Consider a time-harmonic acoustic plane wave incident onto an elastic body with an unbounded periodic surface. The medium above the surface is supposed to be filled with a homogeneous compressible inviscid air/fluid of constant mass density, while the elastic body is assumed to be isotropic and linear. By introducing the Dirichlet-to-Neumann (DtN) operators for acoustic and elastic waves simultaneously, the model is formulated as an acoustic-elastic interaction problem in periodic structures. Based on a duality argument, an a posteriori error estimate is derived for the associated truncated finite element approximation. The a posteriori error estimate consists of the finite element approximation error and the truncation error of two different DtN operators, where the latter decays exponentially with respect to the truncation parameter. Based on the a posteriori error, an adaptive finite element algorithm is proposed for solving the acoustic-elastic interaction problem in periodic structures. Numerical experiments are presented to demonstrate the effectiveness of the proposed algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17233",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.298236Z"
  },
  {
    "id": "fbd4f494e7cdb21b07eeb4cf4af943c4",
    "title": "On Runge-Kutta methods of order 10",
    "slug": "on-runge-kutta-methods-of-order-10",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Misha Stepanov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A family of explicit 15-stage Runge-Kutta methods of order 10 is derived.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17329",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.298439Z"
  },
  {
    "id": "0f99a0ef3a8fecec27e97a45b7d18a88",
    "title": "On Josephy-Halley method for generalized equations",
    "slug": "on-josephy-halley-method-for-generalized-equations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Tom Roubal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We extend the classical third-order Halley iteration to the setting of generalized equations of the form \\[ 0 \\in f(x) + F(x), \\] where \\(f\\colon X\\longrightarrow Y\\) is twice continuously Frchet-differentiable on Banach spaces and \\(F\\colon X\\tto Y\\) is a set-valued mapping with closed graph. Building on predictor-corrector framework, our scheme first solves a partially linearized inclusion to produce a predictor \\(u_{k+1}\\), then incorporates second-order information in a Halley-type corrector step to obtain \\(x_{k+1}\\). Under metric regularity of the linearization at a reference solution and Hlder continuity of \\(f''\\), we prove that the iterates converge locally with order \\(2+p\\) (cubically when \\(p=1\\)). Moreover, by constructing a suitable scalar majorant function we derive semilocal Kantorovich-type conditions guaranteeing well-definedness and R-cubic convergence from an explicit neighbourhood of the initial guess. Numerical experiments-including one- and two-dimensional test problems confirm the theoretical convergence rates and illustrate the efficiency of the Josephy-Halley method compared to its Josephy-Newton counterpart.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17649",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.298642Z"
  },
  {
    "id": "3d5f6c0e1b8158fc903eaeae747e9906",
    "title": "Fully-Mixed Virtual Element Method for the Biot Problem",
    "slug": "fully-mixed-virtual-element-method-for-the-biot-problem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Michele Botti",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Poroelasticity describes the interaction of deformation and fluid flow in saturated porous media. A fully-mixed formulation of Biot's poroelasticity problem has the advantage of producing a better approximation of the Darcy velocity and stress field, as well as satisfying local mass and momentum conservation. In this work, we focus on a novel four-fields Virtual Element discretization of Biot's equations. The stress symmetry is strongly imposed in the definition of the discrete space, thus avoiding the use of an additional Lagrange multiplier. A complete a priori analysis is performed, showing the robustness of the proposed numerical method with respect to limiting material properties. The first order convergence of the lowest-order fully-discrete numerical method, which is obtained by coupling the spatial approximation with the backward Euler time-advancing scheme, is confirmed by a complete 3D numerical validation. A well known poroelasticity benchmark is also considered to assess the robustness properties and computational performance.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17729",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.298841Z"
  },
  {
    "id": "40711ba97c4025a7f41de20ddb1fd368",
    "title": "Physics-informed features in supervised machine learning",
    "slug": "physics-informed-features-in-supervised-machine-learning",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Margherita Lampani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Supervised machine learning involves approximating an unknown functional relationship from a limited dataset of features and corresponding labels. The classical approach to feature-based machine learning typically relies on applying linear regression to standardized features, without considering their physical meaning. This may limit model explainability, particularly in scientific applications. This study proposes a physics-informed approach to feature-based machine learning that constructs non-linear feature maps informed by physical laws and dimensional analysis. These maps enhance model interpretability and, when physical laws are unknown, allow for the identification of relevant mechanisms through feature ranking. The method aims to improve both predictive performance in regression tasks and classification skill scores by integrating domain knowledge into the learning process, while also enabling the potential discovery of new physical equations within the context of explainable machine learning.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17112",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:35.299042Z"
  },
  {
    "id": "f7b9f15dca4273c7dd9001b9856525b8",
    "title": "Rescaling and unconstrained minimisation of convex quadratic maps",
    "slug": "rescaling-and-unconstrained-minimisation-of-convex-quadratic-maps",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Alexandra Zverovich",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the properties of a class of piecewise-fractional maps arising from the introduction of an invariance under rescaling into convex quadratic maps. The subsequent maps are quasiconvex, and pseudoconvex on specific convex cones; they can be optimised via exact line search along admissible directions, and the iterates then inherit a bidimensional optimality property. We study the minimisation of such relaxed maps via coordinate descents with gradient-based rules, placing a special emphasis on coordinate directions verifying a maximum-alignment property in the reproducing kernel Hilbert spaces related to the underlying positive-semidefinite matrices. In this setting, we illustrate that accounting for the optimal rescaling of the iterates can in certain situations substantially accelerate the unconstrained minimisation of convex quadratic maps.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17596",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:35.299247Z"
  },
  {
    "id": "fc025c08596d526d8fec7ffd34c017d8",
    "title": "Convolution Quadrature for the quasilinear subdiffusion equation",
    "slug": "convolution-quadrature-for-the-quasilinear-subdiffusion-equation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Maria Lpez-Fernndez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We construct a Convolution Quadrature (CQ) scheme for the quasilinear subdiffusion equation of order $\\alpha$ and supply it with the fast and oblivious implementation. In particular, we find a condition for the CQ to be admissible and discretize the spatial part of the equation with the Finite Element Method. We prove the unconditional stability and convergence of the scheme and find a bound on the error. Our estimates are globally optimal for all $0<\\alpha<1$ and pointwise for $\\alpha\\geq 1/2$ in the sense that they reduce to the well-known results for the linear equation. For the semilinear case, our estimates are optimal both globally and locally. As a passing result, we also obtain a discrete Grnwall inequality for the CQ, which is a crucial ingredient in our convergence proof based on the energy method. The paper is concluded with numerical examples verifying convergence and computation time reduction when using fast and oblivious quadrature.",
    "pdfUrl": "https://arxiv.org/pdf/2311.00081",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.299437Z"
  },
  {
    "id": "bb22d8c020c6be3032a545a2ca34b7f5",
    "title": "Analysis and improvement of a semi-Lagrangian exponential scheme for the shallow-water equations on the rotating sphere",
    "slug": "analysis-and-improvement-of-a-semi-lagrangian-exponential-scheme-for-the-shallow-water-equations-on-the-rotating-sphere",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Joo Guilherme Caldas Steinstraesser",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, we study and extend a class of semi-Lagrangian exponential methods, which combine exponential time integration techniques, suitable for integrating stiff linear terms, with a semi-Lagrangian treatment of nonlinear advection terms. Partial differential equations involving both processes arise for instance in atmospheric circulation models. Through a truncation error analysis, we show that previously formulated semi-Lagrangian exponential schemes are limited to first-order accuracy due to the approximation of the integration factor acting on the discretization of the linear term; we then formulate a new discretization leading to second-order accuracy. Also, a detailed stability study is conducted to compare several Eulerian and semi-Lagrangian exponential schemes, as well as a well-established semi-Lagrangian semi-implicit method, which is used in operational atmospheric models. Numerical simulations of the shallow-water equations on the rotating sphere are performed to assess the orders of convergence, stability properties, and computational cost of each method. The proposed second-order semi-Lagrangian exponential method was shown to be more stable and accurate than the previously formulated schemes of the same class at the expense of larger wall-clock times; however, the method is more stable and has a similar cost compared to the well-established semi-Lagrangian semi-implicit method; therefore, it is a competitive candidate for potential operational applications in atmospheric circulation modeling.",
    "pdfUrl": "https://arxiv.org/pdf/2405.02237",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.299636Z"
  },
  {
    "id": "d9ce02f0ffaeea3c37217a3f7fc6700c",
    "title": "A Random Integration Algorithm for High-dimensional Function Spaces",
    "slug": "a-random-integration-algorithm-for-high-dimensional-function-spaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Liang Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a novel random integration algorithm that boasts both high convergence order and polynomial tractability for functions characterized by sparse frequencies or rapidly decaying Fourier coefficients. Specifically, for integration in periodic isotropic Sobolev space and the isotropic Sobolev space with compact support, our approach attains a nearly optimal root mean square error (RMSE) bound. In contrast to previous nearly optimal algorithms, our method exhibits polynomial tractability, ensuring that the number of samples does not scale exponentially with increasing dimensions. Our integration algorithm also enjoys nearly optimal bound for weighted Korobov space. Furthermore, the algorithm can be applied without the need for prior knowledge of weights, distinguishing it from the component-by-component algorithm. For integration in the Wiener algebra, the sample complexity of our algorithm is independent of the decay rate of Fourier coefficients. The effectiveness of the integration is confirmed through numerical experiments.",
    "pdfUrl": "https://arxiv.org/pdf/2406.16627",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.299827Z"
  },
  {
    "id": "58163cc9677633570016cb43734f9baf",
    "title": "Superlinear Convergence of GMRES for clustered eigenvalues and its application to least squares problems",
    "slug": "superlinear-convergence-of-gmres-for-clustered-eigenvalues-and-its-application-to-least-squares-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Zeyu Liao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The objective of this paper is to understand the superlinear convergence behavior of the GMRES method when the coefficient matrix has clustered eigenvalues. In order to understand the phenomenon, we analyze the convergence using the Vandermonde matrix which is defined using the eigenvalues of the coefficient matrix. Although eigenvalues alone cannot explain the convergence, they may provide an upper bound of the residual, together with the right hand side vector and the eigenvectors of the coefficient matrix. We show that when the coefficient matrix is diagonalizable, if the eigenvalues of the coefficient matrix are clustered, the upper bound of the convergence curve shows superlinear convergence, when the norm of the matrix obtained by decomposing the right hand side vector into the eigenvector components is not so large. We apply the analysis to explain the convergence of inner-iteration preconditioned GMRES for least squares problems.",
    "pdfUrl": "https://arxiv.org/pdf/2408.00693",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.300042Z"
  },
  {
    "id": "6e851a058b8fa6a87fce55f46e6f3262",
    "title": "Higher order error estimates for regularization of inverse problems under non-additive noise",
    "slug": "higher-order-error-estimates-for-regularization-of-inverse-problems-under-non-additive-noise",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Diana-Elena Mirciu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work we derive higher order error estimates for inverse problems distorted by non-additive noise, in terms of Bregman distances. The results are obtained by means of a novel source condition, inspired by the dual problem. Specifically, we focus on variational regularization having the Kullback-Leibler divergence as data-fidelity, and a convex penalty term. In this framework, we provide an interpretation of the new source condition, and present error estimates also when a variational formulation of the source condition is employed. We show that this approach can be extended to variational regularization that incorporates more general convex data fidelities.",
    "pdfUrl": "https://arxiv.org/pdf/2411.19736",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.300229Z"
  },
  {
    "id": "cd82e49693cf660d6eb28c74a5ab5568",
    "title": "Deep Univariate Polynomial and Conformal Approximation",
    "slug": "deep-univariate-polynomial-and-conformal-approximation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Kingsley Yeon",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A deep approximation is an approximating function defined by composing more than one layer of simple functions. We study deep approximations of functions of one variable using layers consisting of low-degree polynomials or simple conformal transformations. We show that deep approximations to $|x|$ on $[-1,1]$ achieve exponential convergence with respect to the degrees of freedom. Computational experiments suggest that a composite of two and three polynomial layers can give more accurate approximations than a single polynomial with the same number of coefficients. We also study the related problem of reducing the Runge phenomenon by composing polynomials with conformal transformations.",
    "pdfUrl": "https://arxiv.org/pdf/2503.00698",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.300409Z"
  },
  {
    "id": "722d30dfe9f4c6ce4390e02481b7618c",
    "title": "The Resonance Bias Framework: Resonance, Structure, and Arithmetic in Quadrature Error",
    "slug": "the-resonance-bias-framework:-resonance,-structure,-and-arithmetic-in-quadrature-error",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "William Cook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the trapezoidal rule for periodic functions on uniform grids and show that the quadrature error exhibits a rich deterministic structure, beyond traditional asymptotic or statistical interpretations. Focusing on the prototype function f(x) = sin^2(2 pi k x), we derive an analytical expression for the error governed by a resonance function chi_P(y), closely related to the Dirichlet kernel, roots of unity, and discrete Fourier analysis on the group Z/PZ. This function acts as a spectral filter, connecting the integration error to arithmetic properties such as k/P and geometric phase cancellation, visualized as vector averaging on the unit circle. We introduce the Resonance Bias Framework (RBF), a generalization to arbitrary smooth periodic functions, leading to the error representation B_P[f] = sum_{k != 0} c_k chi_P(k/P). Although this is mathematically equivalent to the classical aliasing sum, it reveals a deeper mechanism: the quadrature error arises from structured resonance rather than random aliasing noise. The RBF thus provides an interpretable framework for understanding integration errors at finite resolution, grounded in number theory and geometry.",
    "pdfUrl": "https://arxiv.org/pdf/2503.12117",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.300594Z"
  },
  {
    "id": "2e4004912c129e2bb7ef5a5ea986d196",
    "title": "Quasitubal Tensor Algebra Over Separable Hilbert Spaces",
    "slug": "quasitubal-tensor-algebra-over-separable-hilbert-spaces",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Uria Mor",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The tubal tensor framework provides a clean and effective algebraic setting for tensor computations, supporting matrix-mimetic features like Singular Value Decomposition and Eckart-Young-like optimality results. Underlying the tubal tensor framework is a view of a tensor as a matrix of finite sized tubes. In this work, we lay the mathematical and computational foundations for working with tensors with infinite size tubes: matrices whose elements are elements from a separable Hilbert space. A key challenge is that existence of important desired matrix-mimetic features of tubal tensors rely on the existence of a unit element in the ring of tubes. Such unit element cannot exist for tubes which are elements of an infinite-dimensional Hilbert space. We sidestep this issue by embedding the tubal space in a commutative unital C*-algebra of bounded operators. The resulting quasitubal algebra recovers the structural properties needed for decomposition and low-rank approximation. In addition to laying the theoretical groundwork for working with tubal tensors with infinite dimensional tubes, we discuss computational aspects of our construction, and provide a numerical illustration where we compute a finite dimensional approximation to a infinitely-sized synthetic tensor using our theory. We believe our theory opens new exciting avenues for applying matrix mimetic tensor framework in the context of inherently infinite dimensional problems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16231",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.300784Z"
  },
  {
    "id": "11a5d12fecf239c495a10b65edd6bed1",
    "title": "Exponential speed up in Monte Carlo sampling through Radial Updates",
    "slug": "exponential-speed-up-in-monte-carlo-sampling-through-radial-updates",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Physics (physics.comp-ph)",
    "author": {
      "name": "Johann Ostmeyer",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Recently, it has been shown that the hybrid Monte Carlo (HMC) algorithm is guaranteed to converge exponentially to a given target probability distribution $p(x)\\propto e^{-V(x)}$ on non-compact spaces if augmented by an appropriate radial update. In this work we present a simple way to derive efficient radial updates meeting the necessary requirements for any potential $V$. We reduce the problem to finding a substitution for the radial direction $||x||=f(z)$ so that the effective potential $V(f(z))$ grows exponentially with $z\\rightarrow\\pm\\infty$. Any additive update of $z$ then leads to the desired convergence. We show that choosing this update from a normal distribution with standard deviation $\\sigma\\approx 1/\\sqrt{d}$ in $d$ dimensions yields very good results. We further generalise the previous results on radial updates to a wide class of Markov chain Monte Carlo (MCMC) algorithms beyond the HMC and we quantify the convergence behaviour of MCMC algorithms with badly chosen radial update. Finally, we apply the radial update to the sampling of heavy-tailed distributions and achieve a speed up of many orders of magnitude.",
    "pdfUrl": "https://arxiv.org/pdf/2411.18218",
    "tags": [
      "Computational Physics (physics.comp-ph)"
    ],
    "createdAt": "2025-04-25T15:49:35.300970Z"
  },
  {
    "id": "30c4e0c88a086d3a99cf48a9496ae3cd",
    "title": "A Diffuse Domain Approximation with Transmission-Type Boundary Conditions I: Asymptotic Analysis and Numerics",
    "slug": "a-diffuse-domain-approximation-with-transmission-type-boundary-conditions-i:-asymptotic-analysis-and-numerics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Toai Luong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Diffuse domain methods (DDMs) have garnered significant attention for approximating solutions to partial differential equations on complex geometries. These methods implicitly represent the geometry by replacing the sharp boundary interface with a diffuse layer of thickness $\\varepsilon$, which scales with the minimum grid size. This approach reformulates the original equations on an extended regular domain, incorporating boundary conditions through singular source terms. In this work, we conduct a matched asymptotic analysis of a DDM for a two-sided problem with transmission-type Robin boundary conditions. Our results show that, in the one dimensional space, the solution of the diffuse domain approximation asymptotically converges to the solution of the original problem, with exactly first-order accuracy in $\\varepsilon$. Furthermore, we provide numerical simulations that validate and illustrate the analytical result.",
    "pdfUrl": "https://arxiv.org/pdf/2412.07007",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:35.301164Z"
  },
  {
    "id": "6d85aefa62e5488082ac715d54550f72",
    "title": "A Robust Model-Based Approach for Continuous-Time Policy Evaluation with Unknown Lvy Process Dynamics",
    "slug": "a-robust-model-based-approach-for-continuous-time-policy-evaluation-with-unknown-lvy-process-dynamics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Qihao Ye",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper develops a model-based framework for continuous-time policy evaluation (CTPE) in reinforcement learning, incorporating both Brownian and Lvy noise to model stochastic dynamics influenced by rare and extreme events. Our approach formulates the policy evaluation problem as solving a partial integro-differential equation (PIDE) for the value function with unknown coefficients. A key challenge in this setting is accurately recovering the unknown coefficients in the stochastic dynamics, particularly when driven by Lvy processes with heavy tail effects. To address this, we propose a robust numerical approach that effectively handles both unbiased and censored trajectory datasets. This method combines maximum likelihood estimation with an iterative tail correction mechanism, improving the stability and accuracy of coefficient recovery. Additionally, we establish a theoretical bound for the policy evaluation error based on coefficient recovery error. Through numerical experiments, we demonstrate the effectiveness and robustness of our method in recovering heavy-tailed Lvy dynamics and verify the theoretical error analysis in policy evaluation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.01482",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:35.301369Z"
  },
  {
    "id": "d3e1ca951839f9565b2f2c2ee90cd87b",
    "title": "Omega Results for The Divisor and Circle Problems Using The Resonance Method",
    "slug": "omega-results-for-the-divisor-and-circle-problems-using-the-resonance-method",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Kamalakshya Mahatab",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We apply the resonance method to obtain large values of general exponential sums with positive coefficients. As applications, we show improved $\\Omega$-bounds for Dirichlet and Piltz divisor problems, Gauss circle Problem, and error term for the mean square of the Riemann zeta function and the Dirichlet $L$-function.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17032",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.643685Z"
  },
  {
    "id": "f4b7c071349e5c401ca75670d9f79f26",
    "title": "Lower Bound for Zeros in The Character Table of The Symmetric Group with an n-Core Index",
    "slug": "lower-bound-for-zeros-in-the-character-table-of-the-symmetric-group-with-an-n-core-index",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Jayanta Barman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "For any two partitions $\\lambda$ and $\\mu$ of a positive integer $N$, let $\\chi_{\\lambda}(\\mu)$ denote the value of the irreducible character of the symmetric group $S_{N}$ associated with $\\lambda$, evaluated at the conjugacy class of elements whose cycle type is determined by $\\mu$. The quantity $Z_{t}(N)$ is defined as $$ Z_{t}(N):= \\#\\{(\\lambda,\\mu): \\chi_{\\lambda}(\\mu) = 0 \\quad \\text{with $\\lambda$ a $t$-core}\\}. $$ We establish the bound $$ \\max\\limits_{1\\leq t \\leq N} Z_{t}(N) \\geq c_{t}(N)p(N-t)\\geq \\frac{2\\pi p(N)^{2}}{1.01e\\sqrt{6N}\\log N} \\biggl(1+O(N^{-\\frac{1}{2}}\\log N)\\biggr), $$ where $p(N)$ denotes the number of partitions of $N$. Also, we give lower bounds for $Z_{t}(N)$ in different ranges of $t$ and obtain a lower bound for the total number of zeros in the character table of $S_N$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17037",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.643904Z"
  },
  {
    "id": "a23107e80d01199e56a792eb78373fed",
    "title": "Hochschild (Co)homology of D-modules on rigid analytic spaces II",
    "slug": "hochschild-(co)homology-of-d-modules-on-rigid-analytic-spaces-ii",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Fernando Pea Vzquez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $X$ be a smooth $p$-adic Stein space with free tangent sheaf. We use the notion of Hochschild cohomology for sheaves of Ind-Banach algebras developed in our previous work to study the Hochschild cohomology of the algebra of infinite order differential operators $\\mathcal{D}_X$-cap. In particular, we show that the Hochschild cohomology complex of $\\mathcal{D}_X$-cap is a strict complex of nuclear Frchet spaces which is quasi-isomorphic to the de Rham complex of $X$. We then use this to compare the first Hochschild cohomology group of $\\mathcal{D}_X$-cap with a wide array of Ext functors. Finally, we investigate the relation of the Hochschild cohomology of $\\mathcal{D}_X$-cap with the deformation theory of $\\mathcal{D}_X(X)$-cap. Assuming some finiteness conditions on the de Rham cohomology of $X$, we define explicit isomorphisms between the first Hochschild cohomology group of $\\mathcal{D}_X$-cap and the space of bounded outer derivations of $\\mathcal{D}_X(X)$-cap, and between the second Hochschild cohomology group of $\\mathcal{D}_X$-cap and the space of infinitesimal deformations of $\\mathcal{D}_X(X)$-cap.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17167",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.644102Z"
  },
  {
    "id": "61918ca4be5e54b505f5a0341bce33a4",
    "title": "Recursion formulas for the Fourier coefficients of Siegel Eisenstein series of an odd prime level",
    "slug": "recursion-formulas-for-the-fourier-coefficients-of-siegel-eisenstein-series-of-an-odd-prime-level",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Keiichi Gunji",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper we treat the Fourier coefficients of Siegel Eisenstein series of level $p$ with trivial or quadratic character, for an odd prime $p$. The Euler $p$-factor of the Fourier coefficient is called the ramified Siegel series. First we show that the ramified Siegel series attached to each cusp can be decomposed to $U(p)$-eigenfunctions explicitly, next we give recursion formulas of such $U(p)$-characteristic ramified Siegel series.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17245",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.644295Z"
  },
  {
    "id": "ae30cda558ccbbd47473162cb099bf3c",
    "title": "Period Function of Maass forms from Ramanujan's Lost Notebook",
    "slug": "period-function-of-maass-forms-from-ramanujan's-lost-notebook",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "YoungJu Choie",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Lost Notebook of Ramanujan contains a number of beautiful formulas, one of which can be found on its page 220. It involves an interesting function, which we denote as $\\mathcal{F}_1(x)$. In this paper, we show that $\\mathcal{F}_1(x)$ belongs to the category of period functions as it satisfies the period relations of Maass forms in the sense of Lewis and Zagier \\cite{lz}. Hence, we refer to $\\mathcal{F}_1(x)$ as the \\emph{Ramanujan period function}. Moreover, one of the salient aspects of the Ramanujan period function $\\mathcal{F}_1(x)$ that we found out is that it is a Hecke eigenfunction under the action of Hecke operators on the space of periods. We also establish that it naturally appears in a Kronecker limit formula of a certain zeta function, revealing its connections to various topics. Finally, we generalize $\\mathcal{F}_1(x)$ to include a parameter $s,$ connecting our work to the broader theory of period functions developed by Bettin and Conrey \\cite{bc} and Lewis and Zagier \\cite{lz}. We emphasize that Ramanujan was the first to study this function, marking the beginning of the study of period functions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17284",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.644494Z"
  },
  {
    "id": "068ee608d817facc3639d5fccedc1f28",
    "title": "Doubling modulo odd integers, generalizations, and unexpected occurrences",
    "slug": "doubling-modulo-odd-integers,-generalizations,-and-unexpected-occurrences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Jean-Paul Allouche",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The starting point of this work is an equality between two quantities $A$ and $B$ found in the literature, which involve the {\\em doubling-modulo-an-odd-integer} map, i.e., $x\\in {\\mathbb N} \\mapsto 2x \\bmod{(2n+1)}$ for some positive integer $n$. More precisely, this doubling map defines a permutation $\\sigma_{2,n}$ and each of $A$ and $B$ counts the number $C_2(n)$ of cycles of $\\sigma_{2,n}$, hence $A=B$. In the first part of this note, we give a direct proof of this last equality. To do so, we consider and study a generalized $(k,n)$-perfect shuffle permutation $\\sigma_{k,n}$, where we multiply by an integer $k\\ge 2$ instead of $2$, and its number $C_k(n)$ of cycles. The second part of this note lists some of the many occurrences and applications of the doubling map and its generalizations in the literature: in mathematics (combinatorics of words, dynamical systems, number theory, correcting algorithms), but also in card-shuffling, juggling, bell-ringing, poetry, and music composition.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17564",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.644696Z"
  },
  {
    "id": "ab3cd7e4ae44c57c34a3cd3e71315a07",
    "title": "A modular framework for generalized Hurwitz class numbers III",
    "slug": "a-modular-framework-for-generalized-hurwitz-class-numbers-iii",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Andreas Mono",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In $2003$, Pei and Wang introduced higher level analogs of the classical Cohen--Eisenstein series. In recent joint work with Beckwith, we found a weight $\\frac{1}{2}$ sesquiharmonic preimage of their weight $\\frac{3}{2}$ Eisenstein series under $\\xi_{\\frac{1}{2}}$ utilizing a construction from seminal work by Duke, Imamoglu and Tth. In further joint work with Beckwith, when restricting to prime level, we realized our preimage as a regularized Siegel theta lift and evaluated its (regularized) Fourier coefficients explicitly. This relied crucially on work by Bruinier, Funke and Imamoglu. In this paper, we extend both works to higher weights. That is, we provide a harmonic preimage of Pei and Wang's generalized Cohen--Eisenstein series under $\\xi_{\\frac{3}{2}-k}$, where $k > 1$. Furthermore, when restricting to prime level, we realize them as outputs of a regularized Shintani theta lift of a higher level holomorphic Eisenstein series, which builds on recent work by Alfes and Schwagenscheidt. Lastly, we evaluate the regularized Millson theta lift of a higher level Maass--Eisenstein series, which is known to be connected to the Shintani theta lift by a differential equation by earlier work of Alfes and Schwagenscheidt.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17640",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.644884Z"
  },
  {
    "id": "f22baccf69813473d90e2b39be41dbdb",
    "title": "On the locally analytic $\\text{Ext}^1$-conjecture in the $\\text{GL}_2(L)$ case",
    "slug": "on-the-locally-analytic-$\\text{ext}^1$-conjecture-in-the-$\\text{gl}_2(l)$-case",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Benchao Su",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $L$ be a finite extension of $\\mathbb{Q}_p$. We calculate the dimension of $\\text{Ext}^1$-groups of certain locally analytic representations of $\\text{GL}_2(L)$ defined using coherent cohomology of Drinfeld curves. Furthermore, let $\\rho_p$ be a $2$-dimensional continuous representation of $\\text{Gal}(\\bar L/L)$, which is de Rham with parallel Hodge-Tate weights $0,1$ and whose underlying Weil-Deligne representation is irreducible. We prove Breuil's locally analytic $\\text{Ext}^1$ conjecture for such $\\rho_p$. As an application, we show that the isomorphism class of the multiplicity space $\\Pi^{\\text{an}}_{\\text{geo}}(\\rho_p)$ of $\\rho_p$ in the pro-tale cohomology of Drinfeld curves uniquely determines the isomorphism class of $\\rho_p$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17683",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.645073Z"
  },
  {
    "id": "ea404600b8ec1de96c2fca3b924ebe9b",
    "title": "The Igusa Zeta function of restricted power series over $\\mathbb{Q}_p$",
    "slug": "the-igusa-zeta-function-of-restricted-power-series-over-$\\mathbb{q}_p$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Leonie Dausy",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this article, we ask whether the Igusa zeta function of a restricted power series over $\\mathbb{Q}_p$ can be determined solely from the terms of degree at most $D$. That is, we ask whether the truncated polynomial $f_D$, consisting of all terms of f of degree $\\leq D$, yields the same Igusa zeta function as $f$ for sufficiently large $D$. Our main results include a counterexample already in the one-variable case, but also a positive result under the condition that $f$ is sufficiently non-degenerate with respect to its Newton polyhedron $\\Gamma(f)$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17687",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.645254Z"
  },
  {
    "id": "496bf2bf27e62ee3524ab04c0a34eac8",
    "title": "Modularity of tadpole Nahm sums in ranks 4 and 5",
    "slug": "modularity-of-tadpole-nahm-sums-in-ranks-4-and-5",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Changsong Shi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Around 2016, Calinescu, Milas and Penn conjectured that the rank $r$ Nahm sum associated with the $r\\times r$ tadpole Cartan matrix is modular, and they provided a proof for $r=2$. The $r=3$ case was recently resolved by Milas and Wang. We prove this conjecture for the next cases $r=4,5$. We also prove the modularity of some companion Nahm sums by establishing the corresponding Rogers--Ramanujan type identities. A key new ingredient in our proofs is some rank reduction formulas which allow us to decompose higher rank tadpole Nahm sums to mixed products of some lower rank Nahm-type sums and theta functions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17737",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.645444Z"
  },
  {
    "id": "37ae5bad3d277c9ed369c54c2a30bdb1",
    "title": "On the Reflective Symmetry of the Mother Graph",
    "slug": "on-the-reflective-symmetry-of-the-mother-graph",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Benjamin V. Holt",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A permutiple is a natural number whose representation in some base is an integer multiple of a number whose representation has the same collection of digits. Previous efforts have made progress on finding such numbers using graph-theoretical and finite-state-machine constructions. These are the mother graph and the Hoey-Sloane machine (and its state graph). In this paper, we use the reflective symmetry of the mother graph as a starting point for understanding relationships between permutiple classes and how new classes can be determined from old. Such results are not only useful for finding new permutiples from old, they help us to see previous work through a new lens.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17158",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:35.645634Z"
  },
  {
    "id": "9d088ef953d51fa964ac6ab0d5d47ba0",
    "title": "Parametrization of supercuspidal representations of depth zero for some simple adjoint groups",
    "slug": "parametrization-of-supercuspidal-representations-of-depth-zero-for-some-simple-adjoint-groups",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Amoru Fujii",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We construct a surjective map from the set of conjugacy classes of depth-zero cuspidal enhanced L-parameters to that of isomorphism classes of depth-zero supercuspidal representations for simple adjoint groups, and check the bijectivity in various cases. We also prove that the Hiraga--Ichino--Ikeda conjecture on the formal degree of essentially square-integrable irreducible representations holds for this parametrization if it is bijective.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17225",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:35.645816Z"
  },
  {
    "id": "176d636a7bd4e957beec7e0b12ede20b",
    "title": "On unitary Shimura varieties at ramified primes",
    "slug": "on-unitary-shimura-varieties-at-ramified-primes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Yu Luo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider unitary Shimura varieties at places where the totally real field ramifies over $\\mbQ$. Our first result constructs comparison isomorphisms between absolute and relative local models in this context which relies on a reformulation of the Eisenstein condition of Rapoport--Zink and Rapoport--Smithling--Zhang. Our second result lifts this comparison to categories of $p$-divisible groups and, as a corollary, to various kinds of Rapoport--Zink spaces. This unifies multiple previously known results in this direction. Our third result and main application is to the arithmetic transfer conjecture of the third author. Using our statements about Rapoport--Zink spaces, we extend his previous proof from the unramified case to that of all $p$-adic local fields (for odd $p$). In general, our results have similar applications to other problems around the arithmetic of Shimura varieties as well, removing several ramification assumptions in the literature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17484",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:35.646015Z"
  },
  {
    "id": "46e5de09e1c26204b3e2f587da6aaaef",
    "title": "On the Pseudonullity of Fine Selmer groups over function fields",
    "slug": "on-the-pseudonullity-of-fine-selmer-groups-over-function-fields",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Sohan Ghosh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The $p^\\infty$-fine Selmer group of an elliptic curve $E$ over a global field is a subgroup of the classical $p^\\infty$-Selmer group. Coates and Sujatha discovered that the structure of the fine Selmer group of $E$ over certain $p$-adic Lie extensions of a number field is intricately related to some deep questions in classical Iwasawa theory. Inspired by a conjecture of Greenberg, they made prediction about the structure of the fine Selmer group over certain $p$-adic Lie extensions of a number field, which they called Conjecture B. In this article, we discuss some new cases of Conjecture B and its analogues over some $p$-adic Lie extensions of function fields of characteristic $p$.",
    "pdfUrl": "https://arxiv.org/pdf/2304.00499",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.646209Z"
  },
  {
    "id": "f40b95b6d5bd7da9a6cf6802ab7e0ff5",
    "title": "The prismatic realization functor for Shimura varieties of abelian type",
    "slug": "the-prismatic-realization-functor-for-shimura-varieties-of-abelian-type",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Naoki Imai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "For the integral canonical model $\\mathscr{S}_{\\mathsf{K}^p}$ of a Shimura variety $\\mathrm{Sh}_{\\mathsf{K}_0\\mathsf{K}^p}(\\mathbf{G},\\mathbf{X})$ of abelian type at hyperspecial level $K_0=\\mathcal{G}(\\mathbb{Z}_p)$, we construct a prismatic $F$-gauge model for the `universal' $\\mathcal{G}(\\mathbb{Z}_p)$-local system on $\\mathrm{Sh}_{\\mathsf{K}_0\\mathsf{K}^p}(\\mathbf{G},\\mathbf{X})$. We use this to obtain several new results about the $p$-adic geometry of Shimura varieties, notably an abelian-type analogue of the Serre--Tate deformation theorem (realizing an expectation of Drinfeld in the abelian-type case) and a prismatic characterization of these models at individual level.",
    "pdfUrl": "https://arxiv.org/pdf/2310.08472",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.646413Z"
  },
  {
    "id": "b063ef9a9a9dd94cd18bfd2ed4314f08",
    "title": "Irreducibility criteria for pairs of polynomials whose resultant is a prime number",
    "slug": "irreducibility-criteria-for-pairs-of-polynomials-whose-resultant-is-a-prime-number",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Nicolae Ciprian Bonciocat",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We obtain various irreducibility criteria for pairs of polynomials $(f(X),g(X))$ with integer coefficients whose resultant $Res(f,g)$ is a prime number, or is divisible by a sufficiently large prime number, and also for some of their linear combinations $Mf(X)+Ng(X)$ with integer scalars $M$ and $N$. In particular, we find irreducibility conditions for polynomials with coefficients obtained by representing primes by certain quadratic forms. The irreducibility criteria will appear as corollaries of more general results providing upper bounds for the number of irreducible factors of each one of $f$ and $g$, counting multiplicities, that depend on the prime factorization of $Res(f,g)$, and on the distances between the roots of $f$ and those of $g$. Similar results will be also obtained for pairs of bivariate polynomials $(f(X,Y),g(X,Y))$ over an arbitrary field $K$, using information on the canonical decomposition of their resultant $Res_Y(f,g)$, and on the location of their roots in an algebraic closure of $K(X)$, studied in a non-Archimedean setting.",
    "pdfUrl": "https://arxiv.org/pdf/2311.18568",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.646604Z"
  },
  {
    "id": "e816ab040fb7c957e0c0b14866183f0e",
    "title": "Companion points and locally analytic socle conjecture for Steinberg case",
    "slug": "companion-points-and-locally-analytic-socle-conjecture-for-steinberg-case",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Yiqin He",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we will modify the Breuil-Hellmann-Schraen's (more generally, resp., Breuil-Ding's) local model for the trianguline variety (resp., Bernstein paraboline variety) to certain semistable (resp., potentially semistable) non-crystalline point with regular Hodge-Tate this http URL we deduce several local-global compatibility results, including a classicality result, and the existence of expected companion points on the (definite) eigenvariety and locally analytic socle conjecture for such semistable non-crystalline Galois representations, under certain hypothesis on trianguline variety and the usual Taylor-Wiles assumptions. Moreover, we also discuss slightly the coherent sheaves obtained by patching argument and the coherent sheaves which are constructed from local models and Bezrukavnikov functor, under the route of the recently work of Hellmann-Hernandez-Schraen.",
    "pdfUrl": "https://arxiv.org/pdf/2401.13242",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.646801Z"
  },
  {
    "id": "9ed3635dd4359baefcfbcfb6ecb3e343",
    "title": "Isolated points on modular curves",
    "slug": "isolated-points-on-modular-curves",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Kenji Terao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study isolated points on the modular curves $X_{H}$, for $H$ a subgroup of $\\operatorname{GL}_{2}(\\mathbb{Z}/n \\mathbb{Z})$ for some $n \\geq 1$. In particular, we prove a single-source theorem for such isolated points, which traces the existence of all such isolated points with the same $j$-invariant back to an isolated point on a single curve. Building on this result, we also present a uniform strategy for determining the isolated points on any family of modular curves. As an example, we use this strategy to classify the isolated points with rational $j$-invariant on all modular curves of level 7, as well as the modular curves $X_{0}(n)$, the latter assuming a conjecture on images of Galois representations of elliptic curves over $\\mathbb{Q}$.",
    "pdfUrl": "https://arxiv.org/pdf/2412.13108",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.646986Z"
  },
  {
    "id": "b5bf2f73966c61fb1644e1bf50a81109",
    "title": "On the distribution of $\\operatorname{SL}(2,{\\mathbb N})$-saturated Farey fractions",
    "slug": "on-the-distribution-of-$\\operatorname{sl}(2,{\\mathbb-n})$-saturated-farey-fractions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Jack Anderson",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider the ordered set ${\\mathscr S}_Q$ of Farey fractions $d/b$ of order $Q$ with the property that there exists a matrix $\\left( \\begin{smallmatrix} a & b \\\\ c & d \\end{smallmatrix} \\right) \\in \\operatorname{SL}(2,{\\mathbb Z})$ of trace at most $Q$, with positive entries and $a\\ge \\max\\{ b,c\\}$. For every $Q\\ge 3$, the set ${\\mathscr S}_Q \\cup \\{ 0\\}$ defines a unimodular partition of the interval $[0,1]$. We prove that the elements of ${\\mathscr S}_Q$ are asymptotically distributed with respect to the probability measure with density $ (1/(1+x) -1/(2+x) )/\\log (4/3) $ and that the sequence of sets $({\\mathscr S}_Q)_Q$ has a limiting gap distribution as $Q\\rightarrow \\infty$.",
    "pdfUrl": "https://arxiv.org/pdf/2502.03243",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.647184Z"
  },
  {
    "id": "f29af3afd4dd23c677988b6d30a54706",
    "title": "The first moment of central value of primitive quartic $L$-functions with fixed genus",
    "slug": "the-first-moment-of-central-value-of-primitive-quartic-$l$-functions-with-fixed-genus",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Ziwei Hong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the mean value of the first moment of primitive quartic $L$-functions over $\\mathbb{F}_q(T)$ in the non-Kummer setting. Specifically, we study the sum\n\\begin{equation*}\n\\sum_{\\substack{\\chi\\ primitive\\ quartic\\\\ \\chi^2 primitive\\\\ genus(\\chi)=g}}L_q(\\frac{1}{2}, \\chi),\n\\end{equation*} where $L_q(s,\\chi)$ denotes the $L$-function associated with primitive quartic character $\\chi$. Using double Dirichlet series, we derive an error term of size $q^{(\\frac{3}{5}+\\varepsilon)g}$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14291",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:35.647373Z"
  },
  {
    "id": "0e6c3d2cc0abd3b6dee224aa31bf8e3c",
    "title": "A mixed characteristic analogue of the perfection of rings and its almost Cohen-Macaulay property",
    "slug": "a-mixed-characteristic-analogue-of-the-perfection-of-rings-and-its-almost-cohen-macaulay-property",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Commutative Algebra (math.AC)",
    "author": {
      "name": "Ryo Ishizuka",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Over a complete Noetherian local domain of mixed characteristic with perfect residue field, we construct a perfectoid ring which is similar to an explicit representation of a perfect closure in positive characteristic. Then we demonstrate that this perfectoid ring is almost Cohen-Macaulay in the sense of almost ring theory. The proof of this result uses Andr's flatness lemma along with Riemann's extension theorem. We stress that the idea partially originates from the \"perfectoidization\" in the theory of prismatic cohomology.",
    "pdfUrl": "https://arxiv.org/pdf/2303.13872",
    "tags": [
      "Commutative Algebra (math.AC)"
    ],
    "createdAt": "2025-04-25T15:49:35.647567Z"
  },
  {
    "id": "8d8367b5cba14fad60b183ad77d74b71",
    "title": "The tempered disk and the tempered cohomology",
    "slug": "the-tempered-disk-and-the-tempered-cohomology",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Federico Bambozzi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Consider a non-archimedean valuation ring V (K its fraction field, in mixed characteristic): inspired by some views presented by Scholze, we introduce a new point of view on the non-archimedean analytic setting in terms of derived analytic geometry (then associating a \"spectrum\" to each ind-Banach algebra). We want to look at the behaviour of this spectrum from a differential point of view. In such a spectrum, for example, there exist open subsets having functions with log-growth as sections for the structural sheaf. In this framework, a transfer theorem for the log-growth of solutions of p-adic differential equations can be interpreted as a continuity theorem (analogue to the transfer theorem for their radii of convergence in the Berkovich spaces). As a dividend of such a theory, we define a new cohomology theory in terms of the Hodge-completed derived de Rham cohomology of the ind-Banach derived analytic space associated to a smooth k-scheme, X_k (k residual field of V), via the use of \"tempered tubes\".\nWe finally compare our tempered de Rham cohomology with crystalline cohomology.",
    "pdfUrl": "https://arxiv.org/pdf/2410.09473",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:35.647763Z"
  },
  {
    "id": "722d30dfe9f4c6ce4390e02481b7618c",
    "title": "The Resonance Bias Framework: Resonance, Structure, and Arithmetic in Quadrature Error",
    "slug": "the-resonance-bias-framework:-resonance,-structure,-and-arithmetic-in-quadrature-error",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "William Cook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the trapezoidal rule for periodic functions on uniform grids and show that the quadrature error exhibits a rich deterministic structure, beyond traditional asymptotic or statistical interpretations. Focusing on the prototype function f(x) = sin^2(2 pi k x), we derive an analytical expression for the error governed by a resonance function chi_P(y), closely related to the Dirichlet kernel, roots of unity, and discrete Fourier analysis on the group Z/PZ. This function acts as a spectral filter, connecting the integration error to arithmetic properties such as k/P and geometric phase cancellation, visualized as vector averaging on the unit circle. We introduce the Resonance Bias Framework (RBF), a generalization to arbitrary smooth periodic functions, leading to the error representation B_P[f] = sum_{k != 0} c_k chi_P(k/P). Although this is mathematically equivalent to the classical aliasing sum, it reveals a deeper mechanism: the quadrature error arises from structured resonance rather than random aliasing noise. The RBF thus provides an interpretable framework for understanding integration errors at finite resolution, grounded in number theory and geometry.",
    "pdfUrl": "https://arxiv.org/pdf/2503.12117",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:35.647949Z"
  },
  {
    "id": "e6987a871eea54a545aeb00bfc4bd6f6",
    "title": "Completion of motivic sheaves",
    "slug": "completion-of-motivic-sheaves",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Geometry (math.AG)",
    "author": {
      "name": "Denis-Charles Cisinski",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the process of $\\ell$-adic completion of motivic sheaves. We observe that, in equal characteristic, when restricted to constructible objets, it is compatible with the six operations. This implies that one can reconstruct $\\ell$-adic sheaves of geometric origin over a scheme of finite type over a field from $\\ell$-adic cohomology of smooth schemes. In the case of finite fields, this includes perverse $\\ell$-adic sheaves of geometric orgin. However, the analogous behaviour fails systematically in mixed characteristic: the reason is that it would imply strong independence of $\\ell$ results that can be proven to be too optimistic.",
    "pdfUrl": "https://arxiv.org/pdf/2503.24033",
    "tags": [
      "Algebraic Geometry (math.AG)"
    ],
    "createdAt": "2025-04-25T15:49:35.648135Z"
  },
  {
    "id": "d548a994ee7cf333488027317d127a46",
    "title": "$C^*$- Colored graph algebras",
    "slug": "$c^*$--colored-graph-algebras",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Farrokh Razavinia",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Following our previous works on $C^*$-graph algebras and the associated Cuntz-Krieger graph families, in this paper we will try to have a look at the colored version of these structures and to see what a $C^*$-colored graph algebra might mean by employing some constructive examples very close to the toy example used in our previous works, and we also will try to study their graph theoretical properties as possible.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16963",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:35.923132Z"
  },
  {
    "id": "fb63d27f26beca3125a01f02afa246b5",
    "title": "Density of irreducible operators in the trace-class norm",
    "slug": "density-of-irreducible-operators-in-the-trace-class-norm",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Junsheng Fang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In 1968, Paul Halmos initiated the research on density of the set of irreducible operators on a separable Hilbert space. Through the research, a long-standing unsolved problem inquires: is the set of irreducible operators dense in $B(H)$ with respect to the trace-class norm topology? Precisely, for each operator $T $ in $B(H)$ and every $\\varepsilon >0$, is there a trace-class operator $K$ such that $T+K$ is irreducible and $\\Vert K \\Vert_1 < \\varepsilon$?\nFor $p>1$, to prove the $\\Vert \\cdot \\Vert_p$-norm density of irreducible operators in $B(H)$, a type of Weyl-von Neumann theorem effects as a key technique. But the traditional method fails for the case $p=1$, where by $\\Vert \\cdot \\Vert_p$-norm we denote the Schatten $p$-norm.\nIn the current paper, for a large family of operators in $B(H)$, we give the above long-term problem an affirmative answer. The result is derived from a combination of techniques in both operator theory and operator algebras. Moreover, we discover that there is a strong connection between the problem and another related operator-theoretical problem related to type $\\mathrm{II}_1$ von Neumann algebras.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17190",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:35.923468Z"
  },
  {
    "id": "db5d9ff238c618f1096c719d01083366",
    "title": "The inverse-closed subalgebra of $C^{*}(G,A)$",
    "slug": "the-inverse-closed-subalgebra-of-$c^{*}(g,a)$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Jianjun Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper studies the inverse-closed subalgebras of the Roe algebra with coefficients of the type \\(l^2(G, A)\\). The coefficient \\(A\\) is chosen to be a non-commutative \\(C^*\\)-algebra, and the object of study is \\(C^*(G, A)\\) generated by the countable discrete group \\(G\\). By referring to the Sobolev-type algebra, the intersection of a family of Banach algebras is taken. It is proved that the intersection \\(W_a^{\\infty}(G, A)\\) of Banach spaces is a spectrally invariant dense subalgebra of \\(C^*(G, A)\\), and a sufficient condition for this is that the group action of \\(G\\) has polynomial growth.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17495",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:35.923730Z"
  },
  {
    "id": "9050d0c66159f105889705c62ed0ad8d",
    "title": "Band-dominated and Fourier-band-dominated operators on locally compact abelian groups",
    "slug": "band-dominated-and-fourier-band-dominated-operators-on-locally-compact-abelian-groups",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Functional Analysis (math.FA)",
    "author": {
      "name": "Robert Fulsche",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "By relating notions from quantum harmonic analysis and band-dominated operator theory, we prove that over any locally compact abelian group $G$, the operator algebra $\\mathcal C_1$ from quantum harmonic analysis agrees with the intersection of band-dominated operators and Fourier band-dominated operators. As an application, we characterize the compactness of operators acting on $L^2(G)$ and compare it with previous results in the discrete case. In particular, our results can be seen as a generalization of the limit operator concept to the non-discrete world. Moreover, we briefly discuss property $A'$ for arbitrary locally compact abelian groups.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17442",
    "tags": [
      "Functional Analysis (math.FA)"
    ],
    "createdAt": "2025-04-25T15:49:35.923973Z"
  },
  {
    "id": "b0d434241e86527121cad695f10377a3",
    "title": "On coproducts of operator $\\mathcal{A}$-systems",
    "slug": "on-coproducts-of-operator-$\\mathcal{a}$-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Alexandros Chatzinikolaou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Given a unital $\\boldsymbol{C}^{*}$-algebra $\\mathcal{A}$, we prove the existence of the coproduct of two faithful operator $\\mathcal{A}$-systems. We show that we can either consider it as a subsystem of an amalgamated free product of $\\boldsymbol{C}^{*}$-algebras, or as a quotient by an operator system kernel. We introduce a universal $\\boldsymbol{C}^{*}$-algebra for operator $\\mathcal{A}$-systems and prove that in the case of the coproduct of two operator $\\mathcal{A}$-systems, it is isomorphic to the amalgamated over $\\mathcal{A}$, free product of their respective universal $\\boldsymbol{C}^{*}$-algebras. Also, under the assumptions of hyperrigidity for operator systems, we can identify the $\\boldsymbol{C}^{*}$-envelope of the coproduct with the amalgamated free product of the $\\boldsymbol{C}^{*}$-envelopes. We consider graph operator systems as examples of operator $\\mathcal{A}$-systems and prove that there exist graph operator systems whose coproduct is not a graph operator system, it is however a dual operator $\\mathcal{A}$-system. More generally, the coproduct of dual operator $\\mathcal{A}$-systems is always a dual operator $\\mathcal{A}$-system. We show that the coproducts behave well with respect to inductive limits of operator systems.",
    "pdfUrl": "https://arxiv.org/pdf/2208.02687",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:35.924179Z"
  },
  {
    "id": "5afd0b128eb2da832a544b4f6f68f993",
    "title": "Semigroups of self-similar actions and higher rank Baumslag-Solitar semigroups",
    "slug": "semigroups-of-self-similar-actions-and-higher-rank-baumslag-solitar-semigroups",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Robert Valente",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we initiate the study of higher rank Baumslag-Solitar semigroups and their related C*-algebras. We focus on two extreme, but interesting, classes - one is related to products of odometers and the other is related to Furstenberg's $\\times p,, \\times q$ conjecture. For the former class, whose C*-algebras are studied by H. Li and the second author, we here characterize the factoriality of the associated von Neumann algebras and further determine their types; for the latter, we obtain their canonical Cartan subalgebras. In the rank 1 case, we study a more general setting which encompasses (single-vertex) generalized Baumslag-Solitar semigroups. One of our main tools is from self-similar higher rank graphs and their C*-algebras.",
    "pdfUrl": "https://arxiv.org/pdf/2405.07062",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:35.924382Z"
  },
  {
    "id": "131d06d113ffa267060649f93ee01837",
    "title": "Cartan semigroups and twisted groupoid C*-algebras",
    "slug": "cartan-semigroups-and-twisted-groupoid-c*-algebras",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Tristan Bice",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove that twisted groupoid C*-algebras are characterised, up to isomorphism, by having Cartan semigroups, a natural generalisation of normaliser semigroups of Cartan subalgebras. This extends the classic Kumjian-Renault theory to general twisted tale groupoid C*-algebras, even non-reduced C*-algebras of non-effective groupoids.",
    "pdfUrl": "https://arxiv.org/pdf/2407.05024",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:35.924597Z"
  },
  {
    "id": "d8d4bd6a8d9604f0bddbd2252bbbe2ba",
    "title": "Absolutely dilatable bimodule maps",
    "slug": "absolutely-dilatable-bimodule-maps",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Alexandros Chatzinikolaou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We characterise absolutely dilatable completely positive maps on the space of all bounded operators on a Hilbert space that are also bimodular over a given von Neumann algebra as rotations by a suitable unitary on a larger Hilbert space followed by slicing along the trace of an additional ancilla. We define the local, quantum and approximately quantum types of absolutely dilatable maps, according to the type of the admissible ancilla. We show that the local absolutely dilatable maps admit an exact factorisation through an abelian ancilla and show that they are limits in the point weak* topology of conjugations by unitaries in the commutant of the given von Neumann algebra. We show that the Connes Embedding Problem is equivalent to deciding if all absolutely dilatable maps are approximately quantum.",
    "pdfUrl": "https://arxiv.org/pdf/2411.08086",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:35.924812Z"
  },
  {
    "id": "ddb168138bf2a59c718ff4f639d95cc7",
    "title": "The Motzkin subproduct system",
    "slug": "the-motzkin-subproduct-system",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Valeriano Aiello",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a subproduct system of finite-dimensional Hilbert spaces using the Motzkin planar algebra and its Jones-Wenzl idempotents, which generalizes the Temperley-Lieb subproduct system of Habbestad and Neshveyev. We provide a description of the corresponding Toeplitz and Cuntz-Pimsner C$^*$-algebras as universal C$^*$-algebras, defined in terms of generators and relations, and we highlight properties of their representation theory.",
    "pdfUrl": "https://arxiv.org/pdf/2502.14057",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:35.925059Z"
  },
  {
    "id": "af28c133a4eae83ed1684811dcbe4e16",
    "title": "A note on Arveson's hyperrigidity and non-degenerate C*-correspondences",
    "slug": "a-note-on-arveson's-hyperrigidity-and-non-degenerate-c*-correspondences",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Joseph A. Dessi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We revisit the results of Kim, and of Katsoulis and Ramsey concerning hyperrigidity for non-degenerate C*-correspondences. We show that the tensor algebra is hyperrigid, if and only if Katsura's ideal acts non-degenerately, if and only if Katsura's ideal acts non-degenerately under any representation. This gives a positive answer to the question of Katsoulis and Ramsey, showing that their necessary condition and their sufficient condition for hyperrigidity of the tensor algebra are equivalent. Non-degeneracy of the left action of Katsura's ideal was also shown by Kim to be equivalent to hyperrigidity for the selfadjoint operator space associated with the C*-correspondence, and our approach provides a simplified proof of this result as well. In the process we revisit Arveson's criterion connecting maximality with the unique extension property and hyperrigidity, in conjunction with the work of Salomon on generating sets.",
    "pdfUrl": "https://arxiv.org/pdf/2503.16618",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:35.925299Z"
  },
  {
    "id": "ad176dfa6201ace458b3de4a6bd8190c",
    "title": "Measure equivalence rigidity of $\\mathrm{Out}(F_N)$",
    "slug": "measure-equivalence-rigidity-of-$\\mathrm{out}(f_n)$",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Vincent Guirardel",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove that for every $N\\ge 3$, the group $\\mathrm{Out}(F_N)$ of outer automorphisms of a free group of rank $N$ is superrigid from the point of view of measure equivalence: any countable group that is measure equivalent to $\\mathrm{Out}(F_N)$, is in fact virtually isomorphic to $\\mathrm{Out}(F_N)$.\nWe introduce three new constructions of canonical splittings associated to a subgroup of $\\mathrm{Out}(F_N)$ of independent interest. They encode respectively the collection of invariant free splittings, invariant cyclic splittings, and maximal invariant free factor systems. Our proof also relies on the following improvement of an amenability result by Bestvina and the authors: given a free factor system $\\mathcal{F}$ of $F_N$, the action of $\\mathrm{Out}(F_N,\\mathcal{F})$ (the subgroup of $\\mathrm{Out}(F_N)$ that preserves $\\mathcal{F}$) on the space of relatively arational trees with amenable stabilizer is a Borel amenable action.",
    "pdfUrl": "https://arxiv.org/pdf/2103.03696",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:35.925523Z"
  },
  {
    "id": "ec4678e76d6dcd4eaab6709b78fe178d",
    "title": "Robustifying networks for flow problems against edge failure",
    "slug": "robustifying-networks-for-flow-problems-against-edge-failure",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Artyom Klyuchikov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider the robust version of a multi-commodity network flow problem. The robustness is defined with respect to the deletion, or failure, of edges. While the flow problem itself is a polynomially-sized linear program, its robust version is a saddle-point problem with discrete variables. We present two approaches for the solution of the robust network flow problem. One way is to formulate the problem as a bigger linear program. The other is to solve a multi-level optimization problem, where the linear programs appearing at the lower level can be solved by the dual simplex method with a warm start. We then consider the problem of robustifying the network. This is accomplished by optimally using a fixed budget for strengthening certain edges, i.e., increasing their capacity. This problem is solved by a sequence of linear programs at the upper level, while at the lower levels the mentioned dual simplex algorithm is employed.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17031",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.363682Z"
  },
  {
    "id": "64a6863e44ed8d6f8554f6285ac84bd5",
    "title": "Singular Arcs in Optimal Control: Closed-loop Implementations without Workarounds",
    "slug": "singular-arcs-in-optimal-control:-closed-loop-implementations-without-workarounds",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Nikilesh Ramesh",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Singular arcs emerge in the solutions of Optimal Control Problems (OCPs) when the optimal inputs on some finite time intervals cannot be directly obtained via the optimality conditions. Solving OCPs with singular arcs often requires tailored treatments, suitable for offline trajectory optimization. This approach can become increasingly impractical for online closed-loop implementations, especially for large-scale engineering problems. Recent development of Integrated Residual Methods (IRM) have indicated their suitability for handling singular arcs; the convergence of error measures in IRM automatically suppresses singular arc-induced fluctuations and leads to non-fluctuating solutions more suitable for practical problems. Through several examples, we demonstrate the advantages of solving OCPs with singular arcs using {IRM} under an economic model predictive control framework. In particular, the following observations are made: (i) IRM does not require special treatment for singular arcs, (ii) it solves the OCPs reliably with singular arc fluctuation suppressed, and (iii) the closed-loop results closely match the analytic optimal solutions.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17093",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.363907Z"
  },
  {
    "id": "23de29e9d7f1f92636b07ac31a866ce1",
    "title": "Neural Contraction Metrics with Formal Guarantees for Discrete-Time Nonlinear Dynamical Systems",
    "slug": "neural-contraction-metrics-with-formal-guarantees-for-discrete-time-nonlinear-dynamical-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Haoyu Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Contraction metrics are crucial in control theory because they provide a powerful framework for analyzing stability, robustness, and convergence of various dynamical systems. However, identifying these metrics for complex nonlinear systems remains an open challenge due to the lack of scalable and effective tools. This paper explores the approach of learning verifiable contraction metrics parametrized as neural networks (NNs) for discrete-time nonlinear dynamical systems. While prior works on formal verification of contraction metrics for general nonlinear systems have focused on convex optimization methods (e.g. linear matrix inequalities, etc) under the assumption of continuously differentiable dynamics, the growing prevalence of NN-based controllers, often utilizing ReLU activations, introduces challenges due to the non-smooth nature of the resulting closed-loop dynamics. To bridge this gap, we establish a new sufficient condition for establishing formal neural contraction metrics for general discrete-time nonlinear systems assuming only the continuity of the dynamics. We show that from a computational perspective, our sufficient condition can be efficiently verified using the state-of-the-art neural network verifier $\\alpha,\\!\\beta$-CROWN, which scales up non-convex neural network verification via novel integration of symbolic linear bound propagation and branch-and-bound. Built upon our analysis tool, we further develop a learning method for synthesizing neural contraction metrics from sampled data. Finally, our approach is validated through the successful synthesis and verification of NN contraction metrics for various nonlinear examples.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17102",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.364117Z"
  },
  {
    "id": "23250d3e259b598c5893300cc6a8ca00",
    "title": "Advancing Frontiers of Path Integral Theory for Stochastic Optimal Control",
    "slug": "advancing-frontiers-of-path-integral-theory-for-stochastic-optimal-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Apurva Patil",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Stochastic Optimal Control (SOC) problems arise in systems influenced by uncertainty, such as autonomous robots or financial models. Traditional methods like dynamic programming are often intractable for high-dimensional, nonlinear systems due to the curse of dimensionality. This dissertation explores the path integral control framework as a scalable, sampling-based alternative. By reformulating SOC problems as expectations over stochastic trajectories, it enables efficient policy synthesis via Monte Carlo sampling and supports real-time implementation through GPU parallelization.\nWe apply this framework to six classes of SOC problems: Chance-Constrained SOC, Stochastic Differential Games, Deceptive Control, Task Hierarchical Control, Risk Mitigation of Stealthy Attacks, and Discrete-Time LQR. A sample complexity analysis for the discrete-time case is also provided. These contributions establish a foundation for simulator-driven autonomy in complex, uncertain environments.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17154",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.364305Z"
  },
  {
    "id": "b49fecec128505b364553e18f0db2088",
    "title": "On the equivalence of a Hessian-free inequality and Lipschitz continuous Hessian",
    "slug": "on-the-equivalence-of-a-hessian-free-inequality-and-lipschitz-continuous-hessian",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Radu I. Bo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "It is known that if a twice differentiable function has a Lipschitz continuous Hessian, then its gradients satisfy a Jensen-type inequality. In particular, this inequality is Hessian-free in the sense that the Hessian does not actually appear in the inequality. In this paper, we show that the converse holds in a generalized setting: if a continuos function from a Hilbert space to a reflexive Banach space satisfies such an inequality, then it is Frchet differentiable and its derivative is Lipschitz continuous. Our proof relies on the Baillon-Haddad theorem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17193",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.364516Z"
  },
  {
    "id": "8f2db31b7a6d75e56dc29c6a3922c5df",
    "title": "Perturbed Gradient Descent via Convex Quadratic Approximation for Nonconvex Bilevel Optimization",
    "slug": "perturbed-gradient-descent-via-convex-quadratic-approximation-for-nonconvex-bilevel-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Nazanin Abolfazli",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Bilevel optimization is a fundamental tool in hierarchical decision-making and has been widely applied to machine learning tasks such as hyperparameter tuning, meta-learning, and continual learning. While significant progress has been made in bilevel optimization, existing methods predominantly focus on the {nonconvex-strongly convex, or the} nonconvex-PL settings, leaving the more general nonconvex-nonconvex framework underexplored. In this paper, we address this gap by developing an efficient gradient-based method inspired by the recently proposed Relaxed Gradient Flow (RXGF) framework with a continuous-time dynamic. In particular, we introduce a discretized variant of RXGF and formulate convex quadratic program subproblems with closed-form solutions. We provide a rigorous convergence analysis, demonstrating that under the existence of a KKT point and a regularity assumption {(lower-level gradient PL assumption)}, our method achieves an iteration complexity of $\\mathcal{O}(1/\\epsilon^{1.5})$ in terms of the squared norm of the KKT residual for the reformulated problem. Moreover, even in the absence of the regularity assumption, we establish an iteration complexity of $\\mathcal{O}(1/\\epsilon^{3})$ for the same metric. Through extensive numerical experiments on convex and nonconvex synthetic benchmarks and a hyper-data cleaning task, we illustrate the efficiency and scalability of our approach.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17215",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.364720Z"
  },
  {
    "id": "72f1d3ff8693d91fb47a1810ad5ff471",
    "title": "Enhancing the controllability of quantum systems via a static field",
    "slug": "enhancing-the-controllability-of-quantum-systems-via-a-static-field",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Ruikang Liang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper we discuss how a general bilinear finite-dimensional closed quantum system with dispersed parameters can be steered between eigenstates. We show that, under suitable conditions on the separation of spectral gaps and the boundedness of parameter dispersion, rotating wave and adiabatic approximations can be employed in cascade to achieve population inversion between arbitrary eigenstates. We propose an explicit control law and test numerically the sharpness of the conditions on several examples.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17303",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.364940Z"
  },
  {
    "id": "b7cd8715594926036730714ef42af67b",
    "title": "Conjugate continuous-discrete projection filter via sparse-Grid quadrature",
    "slug": "conjugate-continuous-discrete-projection-filter-via-sparse-grid-quadrature",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Muhammad F. Emzir",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this article, we study the continuous-discrete projection filter for the exponential-family manifolds with conjugate likehoods. We first derive the local projection error of the prediction step of the continuous-discrete projection filter. We then derive the exact Bayesian update algorithm for a class of discrete measurement processes with additive Gaussian noise. Lastly, we present a numerical simulation of the stochastic van der Pol filtering problem with a nonlinear measurement process. The proposed projection filter shows superior performance compared to several state-of-the-art parametric continuous-discrete filtering methods.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17324",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.365136Z"
  },
  {
    "id": "e585aea1218cd17d62eaf80989eda024",
    "title": "Optimal scheduling of energy and mass flows based on networked multi-carrier hubs formulation: a general framework",
    "slug": "optimal-scheduling-of-energy-and-mass-flows-based-on-networked-multi-carrier-hubs-formulation:-a-general-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Mohamed Tahar Mabrouk",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Due to increased energy demand and environmental concerns such as greenhouse gas emissions and natural resources depletion, optimizing energy and raw materials usage has recently drawn much attention. Achieving more synergy between different energy sectors and manufacturing processes could lead to substantial improvements. Energy hubs are already well-known solutions for studying multi-carrier energy systems. In the present study, a multi-carrier hub is defined as a geographic area where different processes take place to convert energy and material flows possibly consumed locally, stored, or exported. Hub boundaries correspond to an area small enough to neglect losses when energy and materials flows are exchanged between the processes. A general formulation is introduced to model such a hub. This formalism encompasses all the possible configurations without limitations or preconceptions regarding used carriers or processes' architecture. For this purpose, a new hub representation is proposed that allows optimization while considering all possible arrangements (parallel, serial, or a combination of them). It is implemented in a framework that allows the creation of several multi-carrier hubs and connecting some of them to exchange flows through dedicated networks. The formalism is based on linear programming (LP). The features of the developed framework are illustrated by a case study consisting of a network made of three hubs and considering heat, electricity, water, and hydrogen this http URL study aims to optimally schedule processes usage and materials and energy storage to minimize the cost of imported resources. The study is done in a short-term period. It shows the benefits of synergy between the different processes in the hub.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17341",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.365359Z"
  },
  {
    "id": "9f52750e06bb9fc21bebf3324bdb7807",
    "title": "Obtaining Structural Network Controllability with Higher-Order Local Dynamics",
    "slug": "obtaining-structural-network-controllability-with-higher-order-local-dynamics",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Marco Peruzzo",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider a network of identical, first-order linear systems, and investigate how replacing a subset of the systems composing the network with higher-order ones, either taken to be generic or specifically designed, may affect its controllability. After establishing a correspondence between state controllability in networks of first-order systems with output controllability in networks of higher-order systems, we show that adding higher-order dynamics may require significantly fewer subsystem modifications to achieve structural controllability, when compared to first-order heterogeneous subsystems. Furthermore, we characterize the topology of networks (which we call X-networks) in which the introduction of heterogeneous local dynamics is not necessary for structural output controllability, as the latter can be attained by suitable higher-order subsystems with homogeneous internal dynamics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17417",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.365565Z"
  },
  {
    "id": "5e9dfe026f1bab0d85626a53fd15feea",
    "title": "A decision support system for optimised industrial water management",
    "slug": "a-decision-support-system-for-optimised-industrial-water-management",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Stavros Vatikiotis",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Water scarcity and the low quality of wastewater produced in industrial applications present significant challenges, particularly in managing fresh water intake and reusing residual quantities. These issues affect various industries, compelling plant owners and managers to optimise water resources within their process networks. To address this cross-sector business requirement, we propose a Decision Support System (DSS) designed to capture key network components, such as inlet streams, processes, and outlet streams. Data provided to the DSS are exploited by an optimisation module, which supports both network design and operational decisions. This module is coupled with a generic mixed-integer nonlinear programming (MINLP) model, which is linearised into a compact mixed-integer linear programming (MILP) formulation capable of delivering fast optimal solutions across various network designs and input parameterisations. Additionally, a Constraint Programming (CP) approach is incorporated to handle nonlinear expressions through straightforward modeling. This state-of-the-art generalised framework enables broad applicability across a wide range of real-world scenarios, setting it apart from the conventional reliance on customised solutions designed for specific use cases. The proposed framework was tested on 500 synthetic data instances inspired by historical data from three case studies. The obtained results confirm the validity, computational competence and practical impact of our approach both among their operational and network design phases, demonstrating significant improvements over current practices. Notably, the proposed approach achieved a 17.6% reduction in freshwater intake in a chemical industry case and facilitated the reuse of nearly 90% of wastewater in an oil refinery case.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17469",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.365761Z"
  },
  {
    "id": "4af42f045d4dbf71017305595105ad27",
    "title": "Knapsack with compactness: a semidefinite approach",
    "slug": "knapsack-with-compactness:-a-semidefinite-approach",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Hubert Villuendas",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The min-knapsack problem with compactness constraints extends the classical knapsack problem, in the case of ordered items, by introducing a restriction ensuring that they cannot be too far apart. This problem has applications in statistics, particularly in the detection of change-points in time series. In this paper, we propose a semidefinite programming approach for this problem, incorporating compactness in constraints or in objective. We study and compare the different relaxations, and argue that our method provides high-quality heuristics and tight bounds. In particular, the single hyperparameter of our penalized semidefinite models naturally balances the trade-off between compactness and accuracy of the computed solutions. Numerical experiments illustrate, on the hardest instances, the effectiveness and versatility of our approach compared to the existing mixed-integer programming formulation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17543",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.365957Z"
  },
  {
    "id": "4e167b01002b4d9d3edeb75ed6111cd8",
    "title": "Controllability problem of an evolution equation with singular memory",
    "slug": "controllability-problem-of-an-evolution-equation-with-singular-memory",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Sumit Arora",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This work addresses control problems governed by a semilinear evolution equation with singular memory kernel $\\kappa(t)=\\alpha e^{-\\beta t}\\frac{t^{\\nu-1}}{\\Gamma(\\nu)}$, where $\\alpha>0, \\beta\\ge 0$, and $0<\\nu<1$. We examine the existence of a mild solution and the approximate controllability of both linear and semilinear control systems. To this end, we introduce the concept of a resolvent family associated with the linear evolution equation with memory and develop some of its essential properties. Subsequently, we consider a linear-quadratic regulator problem to determine the optimal control that yields approximate controllability for the linear control system. Furthermore, we derive sufficient conditions for the existence of a mild solution and the approximate controllability of a semilinear system in a super-reflexive Banach space. Additionally, we present an approximate controllability result within the framework of a general Banach space. Finally, we apply our theoretical findings to investigate the approximate controllability of the heat equation with singular memory.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17566",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.366145Z"
  },
  {
    "id": "f7b9f15dca4273c7dd9001b9856525b8",
    "title": "Rescaling and unconstrained minimisation of convex quadratic maps",
    "slug": "rescaling-and-unconstrained-minimisation-of-convex-quadratic-maps",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Alexandra Zverovich",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate the properties of a class of piecewise-fractional maps arising from the introduction of an invariance under rescaling into convex quadratic maps. The subsequent maps are quasiconvex, and pseudoconvex on specific convex cones; they can be optimised via exact line search along admissible directions, and the iterates then inherit a bidimensional optimality property. We study the minimisation of such relaxed maps via coordinate descents with gradient-based rules, placing a special emphasis on coordinate directions verifying a maximum-alignment property in the reproducing kernel Hilbert spaces related to the underlying positive-semidefinite matrices. In this setting, we illustrate that accounting for the optimal rescaling of the iterates can in certain situations substantially accelerate the unconstrained minimisation of convex quadratic maps.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17596",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.366347Z"
  },
  {
    "id": "b02a5d1ab6a26ce8301e010cd42c1173",
    "title": "A Robust Fault Detection Filter for Linear Time-Varying System with Non-Gaussian Noise",
    "slug": "a-robust-fault-detection-filter-for-linear-time-varying-system-with-non-gaussian-noise",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Zhemeng Zhang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper addresses the problem of robust fault detection filtering for linear time-varying (LTV) systems with non-Gaussian noise and additive faults. The conventional generalized likelihood ratio (GLR) method utilizes the Kalman filter, which may exhibit inadequate performance under non-Gaussian noise conditions. To mitigate this issue, a fault detection method employing the $H_{\\infty}$ filter is proposed. The $H_{\\infty}$ filter is first derived as the solution to a regularized least-squares (RLS) optimization problem, and the effect of faults on the output prediction error is then analyzed. The proposed approach using the $H_{\\infty}$ filter demonstrates robustness in non-Gaussian noise environments and significantly improves fault detection performance compared to the original GLR method that employs the Kalman filter. The effectiveness of the proposed approach is illustrated using numerical examples.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17648",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.366555Z"
  },
  {
    "id": "680bc2f7b54f4dfae8b8a003c6faf99b",
    "title": "Nonlinear Derivative-free Constrained Optimization with a Penalty-Interior Point Method and Direct Search",
    "slug": "nonlinear-derivative-free-constrained-optimization-with-a-penalty-interior-point-method-and-direct-search",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Andrea Brilli",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this work, we propose the joint use of a mixed penalty-interior point method and direct search, for addressing nonlinearly constrained derivative-free optimization problems. A merit function is considered, wherein the set of nonlinear inequality constraints is divided into two groups: one treated with a logarithmic barrier approach, and another, along with the equality constraints, addressed using a penalization term. This strategy, is adapted and incorporated into a direct search method, enabling the effective handling of general nonlinear constraints. Convergence to KKT-stationary points is established under continuous differentiability assumptions, without requiring any kind of convexity. Using CUTEst test problems, numerical experiments demonstrate the robustness, efficiency, and overall effectiveness of the proposed method, when compared with state-of-the-art solvers",
    "pdfUrl": "https://arxiv.org/pdf/2504.17682",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.366762Z"
  },
  {
    "id": "2260e7e066ceaaaf7fb5c0459dd2df25",
    "title": "Applied Sheaf Theory For Multi-agent Artificial Intelligence (Reinforcement Learning) Systems: A Prospectus",
    "slug": "applied-sheaf-theory-for-multi-agent-artificial-intelligence-(reinforcement-learning)-systems:-a-prospectus",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Eric Schmid",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper provides a pedagogical introduction to classical sheaf theory and sheaf cohomology, followed by a research prospectus exploring potential applications to multi-agent artificial intelligence systems. The first section offers a comprehensive overview of fundamental sheaf-theoretic concepts-presheaves, sheaves, stalks, and cohomology-aimed at researchers in computer science and AI who may not have extensive background in algebraic topology. The second section presents a detailed research prospectus that outlines a roadmap for developing sheaf-theoretic approaches to model and analyze complex systems of interacting agents. We propose that sheaf theory's inherent local-to-global perspective may provide valuable mathematical tools for reasoning about how local agent behaviors collectively determine emergent system properties. The third section contains a literature review connecting sheaf theory with existing research in multi-agent systems, reinforcement learning, and economic modeling. This paper does not present a completed model but rather lays theoretical groundwork and identifies promising research directions that could bridge abstract mathematics with practical AI applications, potentially revealing new approaches to coordination and emergence in multi-agent systems.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17700",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.366954Z"
  },
  {
    "id": "add199977f6076aac066a0275c05fa64",
    "title": "Recursive feasibility for stochastic MPC and the rationale behind fixing flat tires",
    "slug": "recursive-feasibility-for-stochastic-mpc-and-the-rationale-behind-fixing-flat-tires",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Mirko Fiacchini",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we address the problem of designing stochastic model predictive control (SMPC) schemes for linear systems affected by unbounded disturbances. The contribution of the paper is rooted in a measured-state initialization strategy. First, due to the nonzero probability of violating chance-constraints in the case of unbounded noise, we introduce ellipsoidal-based probabilistic reachable sets and we include constraint relaxations to recover recursive feasibility conditioned to the measured state. Second, we prove that the solution of this novel SMPC scheme guarantees closed-loop chance constraints satisfaction under minimum relaxation. Last, we demonstrate that, in expectation, the need of relaxing the constraints vanishes over time, which leads the closed-loop trajectories steered towards the unconstrained LQR invariant region. This novel SMPC scheme is proven to satisfy the recursive feasibility conditioned to the state realization, and its superiority with respect to open-loop initialization schemes is shown through numerical examples.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17718",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.367143Z"
  },
  {
    "id": "fc9e400cdee0c748cb4736c73519e8a5",
    "title": "What makes a good public EV charging station? A revealed preference study",
    "slug": "what-makes-a-good-public-ev-charging-station?-a-revealed-preference-study",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Steven Lamontagne",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "To determine the optimal locations for electric vehicle charging stations, optimisation models need to predict which charging stations users will select. We estimate discrete choice models to predict the usage of charging stations using only readily available information for charging network operators. Our parameter values are estimated from a unique, revealed preferences dataset of charging sessions in Montreal, Quebec. We find that user distance to stations, proximity to home areas, and the number of outlets at each station are significant factors for predicting station usage. Additionally, amenities near charging stations have a neutral effect overall, with some users demonstrating strong preference or aversion for these locations. High variability among the preferences of users highlight the importance of models which incorporate panel effects. Moreover, integrating mixed logit models within the optimization of charging station network design yields high-quality solutions, even when evaluated under other model specifications.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17722",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.367340Z"
  },
  {
    "id": "c40f4694f2e8c3073b03ae13ad440b8e",
    "title": "An Inverse Source Problem for Semilinear Stochastic Hyperbolic Equations",
    "slug": "an-inverse-source-problem-for-semilinear-stochastic-hyperbolic-equations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Qi L",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper investigates an inverse source problem for general semilinear stochastic hyperbolic equations. Motivated by the challenges arising from both randomness and nonlinearity, we develop a globally convergent iterative regularization method that combines Carleman estimate with fixed-point iteration. Our approach enables the reconstruction of the unknown source function from partial lateral Cauchy data, without requiring a good initial guess. We establish a new Carleman estimate for stochastic hyperbolic equations and prove the convergence of the proposed method in weighted spaces. Furthermore, we design an efficient numerical algorithm that avoids solving backward stochastic partial differential equations and is robust to randomness in both the model and the data. Numerical experiments are provided to demonstrate the effectiveness of the method.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17398",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:36.367525Z"
  },
  {
    "id": "a9c25f590b3f233436d3ecf98e9aab0c",
    "title": "Linear Test Approach to Global Controllability of Higher-Order Nonlinear Dispersive Equations with Finite-Dimensional Control",
    "slug": "linear-test-approach-to-global-controllability-of-higher-order-nonlinear-dispersive-equations-with-finite-dimensional-control",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Debanjit Mondal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate a class of higher-order nonlinear dispersive equations posed on the circle, subject to additive forcing by a finite-dimensional control. Our main objective is to establish approximate controllability by using the controllability of the inviscid Burgers system, linearized around a suitably constructed trajectory. In contrast to earlier approaches based on Lie algebraic techniques, our method offers a more concise proof and sheds new light on the structure of the control. Although the approach necessitates a higher-dimensional control space, both the structure and dimension of the control remain uniform with respect to the order of the dispersive equation and the control time.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17580",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:36.367720Z"
  },
  {
    "id": "0f99a0ef3a8fecec27e97a45b7d18a88",
    "title": "On Josephy-Halley method for generalized equations",
    "slug": "on-josephy-halley-method-for-generalized-equations",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Tom Roubal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We extend the classical third-order Halley iteration to the setting of generalized equations of the form \\[ 0 \\in f(x) + F(x), \\] where \\(f\\colon X\\longrightarrow Y\\) is twice continuously Frchet-differentiable on Banach spaces and \\(F\\colon X\\tto Y\\) is a set-valued mapping with closed graph. Building on predictor-corrector framework, our scheme first solves a partially linearized inclusion to produce a predictor \\(u_{k+1}\\), then incorporates second-order information in a Halley-type corrector step to obtain \\(x_{k+1}\\). Under metric regularity of the linearization at a reference solution and Hlder continuity of \\(f''\\), we prove that the iterates converge locally with order \\(2+p\\) (cubically when \\(p=1\\)). Moreover, by constructing a suitable scalar majorant function we derive semilocal Kantorovich-type conditions guaranteeing well-definedness and R-cubic convergence from an explicit neighbourhood of the initial guess. Numerical experiments-including one- and two-dimensional test problems confirm the theoretical convergence rates and illustrate the efficiency of the Josephy-Halley method compared to its Josephy-Newton counterpart.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17649",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:36.367915Z"
  },
  {
    "id": "c637564e4b24b5610273264bc61c7bca",
    "title": "On the Degree Automatability of Sum-of-Squares Proofs",
    "slug": "on-the-degree-automatability-of-sum-of-squares-proofs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computational Complexity (cs.CC)",
    "author": {
      "name": "Alex Bortolotti",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The Sum-of-Squares (SoS) hierarchy, also known as Lasserre hierarchy, has emerged as a promising tool in optimization. However, it remains unclear whether fixed-degree SoS proofs can be automated [O'Donnell (2017)]. Indeed, there are examples of polynomial systems with bounded coefficients that admit low-degree SoS proofs, but these proofs necessarily involve numbers with an exponential number of bits, implying that low-degree SoS proofs cannot always be found efficiently.\nA sufficient condition derived from the Nullstellensatz proof system [Raghavendra and Weitz (2017)] identifies cases where bit complexity issues can be circumvented. One of the main problems left open by Raghavendra and Weitz is proving any result for refutations, as their condition applies only to polynomial systems with a large set of solutions.\nIn this work, we broaden the class of polynomial systems for which degree-$d$ SoS proofs can be automated. To achieve this, we develop a new criterion and we demonstrate how our criterion applies to polynomial systems beyond the scope of Raghavendra and Weitz's result. In particular, we establish a separation for instances arising from Constraint Satisfaction Problems (CSPs). Moreover, our result extends to refutations, establishing that polynomial-time refutation is possible for broad classes of polynomial time solvable constraint problems, highlighting a first advancement in this area.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17756",
    "tags": [
      "Computational Complexity (cs.CC)"
    ],
    "createdAt": "2025-04-25T15:49:36.368119Z"
  },
  {
    "id": "7981270f636086352878f5630e223780",
    "title": "Scheduling and dimensioning of heterogeneous energy stores, with applications to future GB storage needs",
    "slug": "scheduling-and-dimensioning-of-heterogeneous-energy-stores,-with-applications-to-future-gb-storage-needs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Stan Zachary",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Future ``net-zero'' electricity systems in which all or most generation is renewable may require very high volumes of storage, provided jointly by a number of heterogeneous technologies, in order to manage the associated variability in the generation-demand balance. We consider the problems of scheduling and dimensioning such storage. We develop a value-function based approach to optimal scheduling, and show that, to a good approximation, the problem to be solved at each successive point in time reduces to a linear programme with a particularly simple solution. We show that approximately optimal scheduling may be achieved without the need for a running forecast of the future generation-demand balance. We examine the applicability of the above theory to future GB storage needs, and discuss how it may be used to enable the most economic dimensioning of such storage, with possible savings of tens of billions of pounds, relative to the use of a single technology.",
    "pdfUrl": "https://arxiv.org/pdf/2112.00102",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.368307Z"
  },
  {
    "id": "0b08fe3fc08d41e977809cc24d7c4b72",
    "title": "An Operator Learning Approach to Nonsmooth Optimal Control of Nonlinear PDEs",
    "slug": "an-operator-learning-approach-to-nonsmooth-optimal-control-of-nonlinear-pdes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Yongcun Song",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Optimal control problems with nonsmooth objectives and nonlinear partial differential equation (PDE) constraints are challenging, mainly because of the underlying nonsmooth and nonconvex structures and the demanding computational cost for solving multiple high-dimensional and ill-conditioned systems after mesh-based discretization. To mitigate these challenges numerically, we propose an operator learning approach in combination with an effective primal-dual optimization idea which can decouple the treatment of the control and state variables so that each of the resulting iterations only requires solving two PDEs. Our main purpose is to construct neural surrogate models for the involved PDEs by operator learning, allowing the solution of a PDE to be obtained with only a forward pass of the neural network. The resulting algorithmic framework offers a hybrid approach that combines the efficiency and generalization of operator learning with the model-based nature and structure-friendly efficiency of primal-dual-based algorithms. The primal-dual-based operator learning approach offers numerical methods that are mesh-free, easy to implement, and adaptable to various optimal control problems with nonlinear PDEs. It is notable that the neural surrogate models can be reused across iterations and parameter settings, hence retraining of neural networks can be avoided and computational cost can be substantially alleviated. We affirmatively validate the efficiency of the primal-dual-based operator learning approach across a range of typical optimal control problems with nonlinear PDEs.",
    "pdfUrl": "https://arxiv.org/pdf/2409.14417",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.368505Z"
  },
  {
    "id": "49e6524059802276bda0483a3d6bc610",
    "title": "A globalized inexact semismooth Newton method for strongly convex optimal control problems",
    "slug": "a-globalized-inexact-semismooth-newton-method-for-strongly-convex-optimal-control-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Daniel Wachsmuth",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate a globalized inexact semismooth Newton method applied to strongly convex optimization problems in Hilbert spaces. Here, the semismooth Newton method is appplied to the dual problem, which has a continuously differentiable objective. We prove global strong convergence of iterates as well as transition to local superlinear convergence. The latter needs a second-order Taylor expansion involving semismooth derivative concepts. The convergence of the globalized method is demonstrated in numerical examples, for which the local unglobalized method diverges.",
    "pdfUrl": "https://arxiv.org/pdf/2503.21612",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.368687Z"
  },
  {
    "id": "8d69188fe2bdeb36933b26483d5493d4",
    "title": "Scheduling problem of aircrafts on a same runway and dual runways",
    "slug": "scheduling-problem-of-aircrafts-on-a-same-runway-and-dual-runways",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Peng Lin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, the scheduling problems of landing and takeoff aircraft on a same runway and on dual runways are addressed. In contrast to the approaches based on mixed-integer optimization models in existing works, our approach focuses on the minimum separation times between aircraft by introducing some necessary assumptions and new concepts including relevance, breakpoint aircraft, path and class-monotonically-decreasing sequence. Four scheduling problems are discussed including landing scheduling problem, takeoff scheduling problem, and mixed landing and takeoff scheduling problems on a same runway and on dual runways with the consideration of conversions between different aircraft sequences in typical scenarios. Two real-time optimal algorithms are proposed for the four scheduling problems by fully exploiting the combinations of different classes of aircraft, and necessary definitions, lemmas and theorems are presented for the optimal convergence of the algorithms. Numerical examples are presented to show the effectiveness of the proposed algorithms. In particular, when $100$ aircraft are considered, by using the algorithm in this paper, the optimal solution can be obtained in less than $5$ seconds, while by using the CPLEX software to solve the mix-integer optimization model, the optimal solution cannot be obtained within $1$ hour.",
    "pdfUrl": "https://arxiv.org/pdf/2503.22124",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.368891Z"
  },
  {
    "id": "43581fbdb874ea54e4114677954abd74",
    "title": "An Operator Splitting Method for Large-Scale CVaR-Constrained Quadratic Programs",
    "slug": "an-operator-splitting-method-for-large-scale-cvar-constrained-quadratic-programs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Optimization and Control (math.OC)",
    "author": {
      "name": "Eric Luxenberg",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a fast and scalable method for solving quadratic programs with conditional value-at-risk (CVaR) constraints. While these problems can be formulated as standard quadratic programs, the number of variables and constraints grows linearly with the number of scenarios, making general-purpose solvers impractical for large-scale problems. Our method combines operator splitting with a specialized $O(m\\log m)$ algorithm for projecting onto CVaR constraints, where $m$ is the number of scenarios. The method alternates between solving a linear system and performing parallel projections: onto CVaR constraints using our specialized algorithm and onto box constraints with a closed-form solution. Numerical examples from several application domains demonstrate that our method outperforms general-purpose solvers by several orders of magnitude on problems with up to millions of scenarios. Our method is implemented in an open-source package called CVQP.",
    "pdfUrl": "https://arxiv.org/pdf/2504.10814",
    "tags": [
      "Optimization and Control (math.OC)"
    ],
    "createdAt": "2025-04-25T15:49:36.369087Z"
  },
  {
    "id": "ca4cf1b11fc9dfd9c4556565d16b3ab0",
    "title": "QoS-based Beamforming and Compression Design for Cooperative Cellular Networks via Lagrangian Duality",
    "slug": "qos-based-beamforming-and-compression-design-for-cooperative-cellular-networks-via-lagrangian-duality",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Xilai Fan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper considers the quality-of-service (QoS)-based joint beamforming and compression design problem in the downlink cooperative cellular network, where multiple relay-like base stations (BSs), connected to the central processor via rate-limited fronthaul links, cooperatively transmit messages to the users. The problem of interest is formulated as the minimization of the total transmit power of the BSs, subject to all users' signal-to-interference-plus-noise ratio (SINR) constraints and all BSs' fronthaul rate constraints. In this paper, we first show that there is no duality gap between the considered joint optimization problem and its Lagrangian dual by showing the tightness of its semidefinite relaxation (SDR). Then, we propose an efficient algorithm based on the above duality result for solving the considered problem. The proposed algorithm judiciously exploits the special structure of an enhanced Karush-Kuhn-Tucker (KKT) conditions of the considered problem and finds the solution that satisfies the enhanced KKT conditions via two fixed point iterations. Two key features of the proposed algorithm are: (1) it is able to detect whether the considered problem is feasible or not and find its globally optimal solution when it is feasible; (2) it is highly efficient because both of the fixed point iterations in the proposed algorithm are linearly convergent and evaluating the functions in the fixed point iterations are computationally cheap. Numerical results show the global optimality and efficiency of the proposed algorithm.",
    "pdfUrl": "https://arxiv.org/pdf/2306.13962",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:36.369289Z"
  },
  {
    "id": "1bb5390bfc998b435aeac67dab537d89",
    "title": "Minimax Sequential Testing for Poisson Processes",
    "slug": "minimax-sequential-testing-for-poisson-processes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Hongwei Mei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Suppose we observe a Poisson process in real time for which the intensity may take on two possible values $\\lambda_0$ and $\\lambda_1$. Suppose further that the priori probability of the true intensity is not given. We solve a minimax version of Bayesian problem of sequential testing of two simple hypotheses to minimize a linear combination of the probability of wrong detection and the expected waiting time in the worst scenario of all possible priori distributions. An equivalent characterization for the least favorable distributions is derived and a sufficient condition for the existence is concluded.",
    "pdfUrl": "https://arxiv.org/pdf/2311.04084",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:36.369471Z"
  },
  {
    "id": "0db85ee03dfdfee9fa648f0a59be8c10",
    "title": "Predictive and prescriptive analytics for multi-site modelling of frail and elderly patient services",
    "slug": "predictive-and-prescriptive-analytics-for-multi-site-modelling-of-frail-and-elderly-patient-services",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Elizabeth Williams",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Many economies are challenged by the effects of an ageing population, particularly in sectors where resource capacity planning is critical, such as healthcare. This research addresses the operational challenges of bed and staffing capacity planning in hospital wards by using predictive and prescriptive analytical methods, both individually and in tandem. We applied these methodologies to a study of 165,000 patients across a network of 11 hospitals in the UK. Predictive modelling, specifically Classification and Regression Trees, forecasts patient length of stay based on clinical and demographic data. On the prescriptive side, deterministic and two-stage stochastic optimisation models determine optimal bed and staff planning strategies to minimise costs. Linking the predictive models with the prescriptive optimisation models, generates demand forecasts that inform the optimisation process, providing accurate and practical solutions. The results demonstrate that this integrated approach captures real-world variations in patient LOS and offers a 7% cost saving compared to average-based planning. This approach helps healthcare managers make robust decisions by incorporating patient-specific characteristics, improving capacity allocation, and mitigating risks associated with demand variability. Consequently, this combined methodology can be broadly extended across various sectors facing similar challenges, showcasing the versatility and effectiveness of integrating predictive and prescriptive analytics.",
    "pdfUrl": "https://arxiv.org/pdf/2311.07283",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:36.369656Z"
  },
  {
    "id": "780b851eb1377243a9830ee11252c3d3",
    "title": "Fast OMP for Exact Recovery and Sparse Approximation",
    "slug": "fast-omp-for-exact-recovery-and-sparse-approximation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Computer Vision and Pattern Recognition (cs.CV)",
    "author": {
      "name": "Huiyuan Yu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Orthogonal Matching Pursuit (OMP) has been a powerful method in sparse signal recovery and approximation. However OMP suffers computational issue when the signal has large number of non-zeros. This paper advances OMP in two fronts: it offers a fast algorithm for the orthogonal projection of the input signal at each iteration, and a new selection criterion for making the greedy choice, which reduces the number of iterations it takes to recover the signal. The proposed modifications to OMP directly reduce the computational complexity. Experiment results show significant improvement over the classical OMP in computation time. The paper also provided a sufficient condition for exact recovery under the new greedy choice criterion. For general signals that may not have sparse representations, the paper provides a bound for the approximation error. The approximation error is at the same order as OMP but is obtained within fewer iterations and less time.",
    "pdfUrl": "https://arxiv.org/pdf/2404.00146",
    "tags": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "createdAt": "2025-04-25T15:49:36.369852Z"
  },
  {
    "id": "c2f6ad91ec06895c08bb00d213d71472",
    "title": "Robust Model Predictive Control Exploiting Monotonicity Properties",
    "slug": "robust-model-predictive-control-exploiting-monotonicity-properties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Systems and Control (eess.SY)",
    "author": {
      "name": "Moritz Heinlein",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Robust model predictive control algorithms are essential for addressing unavoidable errors due to the uncertainty in predicting real-world systems. However, the formulation of such algorithms typically results in a trade-off between conservatism and computational complexity. Monotone systems facilitate the efficient computation of reachable sets and thus the straightforward formulation of a robust model predictive control approach optimizing over open-loop predictions. We present an approach based on the division of reachable sets to incorporate feedback in the predictions, resulting in less conservative strategies. The concept of mixed-monotonicity enables an extension of our methodology to non-monotone systems. The potential of the proposed approaches is demonstrated through a nonlinear high-dimensional chemical tank reactor cascade case study.",
    "pdfUrl": "https://arxiv.org/pdf/2408.17348",
    "tags": [
      "Systems and Control (eess.SY)"
    ],
    "createdAt": "2025-04-25T15:49:36.370052Z"
  },
  {
    "id": "106281aecaed377e8e4e1a9fa78fe3ed",
    "title": "Optimal Rates for Robust Stochastic Convex Optimization",
    "slug": "optimal-rates-for-robust-stochastic-convex-optimization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Changyu Gao",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Machine learning algorithms in high-dimensional settings are highly susceptible to the influence of even a small fraction of structured outliers, making robust optimization techniques essential. In particular, within the $\\epsilon$-contamination model, where an adversary can inspect and replace up to an $\\epsilon$-fraction of the samples, a fundamental open problem is determining the optimal rates for robust stochastic convex optimization (SCO) under such contamination. We develop novel algorithms that achieve minimax-optimal excess risk (up to logarithmic factors) under the $\\epsilon$-contamination model. Our approach improves over existing algorithms, which are not only suboptimal but also require stringent assumptions, including Lipschitz continuity and smoothness of individual sample functions. By contrast, our optimal algorithms do not require these stringent assumptions, assuming only population-level smoothness of the loss. Moreover, our algorithms can be adapted to handle the case in which the covariance parameter is unknown, and can be extended to nonsmooth population risks via convolutional smoothing. We complement our algorithmic developments with a tight information-theoretic lower bound for robust SCO.",
    "pdfUrl": "https://arxiv.org/pdf/2412.11003",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:36.370249Z"
  },
  {
    "id": "869a871b4cd8b0a97892e15bffb9d343",
    "title": "The monopolist's free boundary problem in the plane",
    "slug": "the-monopolist's-free-boundary-problem-in-the-plane",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Robert J. McCann",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the Monopolist's problem with a focus on the free boundary separating bunched from unbunched consumers, especially in the plane, and give a full description of its solution for the family of square domains $\\{(a,a+1)^2\\}_{a \\ge 0}$. The Monopolist's problem is fundamental in economics, yet widely considered analytically intractable when both consumers and products have more than one degree of heterogeneity. Mathematically, the problem is to minimize a smooth, uniformly convex Lagrangian over the space of nonnegative convex functions. What results is a free boundary problem between the regions of strict and nonstrict convexity. Our work is divided into three parts: a study of the structure of the free boundary problem on convex domains in $\\mathbf{R}^n$ showing that the product allocation map remains Lipschitz up to most of the fixed boundary and that each bunch extends to this boundary; a proof in $\\mathbf{R}^2$ that the interior free boundary can only fail to be smooth in one of four specific ways (cusp, high frequency oscillations, stray bunch, nontranversal bunch); and, finally, the first complete solution to Rochet and Chon's example on the family of squares $\\Omega = (a,a+1)^2$, where we discover bifurcations first to targeted and then to blunt bunching as the distance $a \\ge 0$ to the origin is increased. We use techniques from the study of the Monge--Ampre equation, the obstacle problem, and localization for measures in convex-order.",
    "pdfUrl": "https://arxiv.org/pdf/2412.15505",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:36.370446Z"
  },
  {
    "id": "ca0c18942eb08b805aab9afec0e26e7b",
    "title": "Loop clusters on complete graphs",
    "slug": "loop-clusters-on-complete-graphs",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Yves Le Jan",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We investigate random partitions of complete graphs defined by Poissonian emsembles of Markov loops",
    "pdfUrl": "https://arxiv.org/pdf/2504.16976",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.870756Z"
  },
  {
    "id": "2640a03c48f5b22dc46d593e8ec78d96",
    "title": "Small noise fluctuations and large deviations of conservative SPDEs with Dirichlet boundary conditions",
    "slug": "small-noise-fluctuations-and-large-deviations-of-conservative-spdes-with-dirichlet-boundary-conditions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Shyam Popat",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish a central limit theorem and large deviations principle that characterises small noise fluctuations of the generalised Dean--Kawasaki stochastic PDE. The fluctuations agree to first order with fluctuations of certain interacting particle systems, such as the zero range process, about their hydrodynamic limits. Our main contribution is that we are able to consider stochastic PDEs on general $C^2$ bounded domains with Dirichlet boundary conditions. On the level of particles, the boundary condition corresponds to absorption or injection of particles at the boundary.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17094",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.870968Z"
  },
  {
    "id": "676ff020341c324a617f7755f1eddb17",
    "title": "Large Deviation Principle for Last Passage Percolation Models",
    "slug": "large-deviation-principle-for-last-passage-percolation-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Pranay Agarwal",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Study of the KPZ universality class has seen the emergence of universal objects over the past decade which arrive as the scaling limit of the member models. One such object is the directed landscape, and it is known that exactly solvable last passage percolation (LPP) models converge to the directed landscape under the KPZ scaling. Large deviations of the directed landscape on the metric level were recently studied in arXiv:2405.14924, which also provides a general framework for establishing such large deviation principle (LDP). The main goal of the article is to employ and tweak that framework to establish a LDP for LPP models at the metric level without assuming exact solvability. We then use the LDP on the metric level to establish a LDP for geodesics in these models, providing a streamlined way to study large transversal fluctuations of geodesics in these models.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17172",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.871168Z"
  },
  {
    "id": "0c095f3be60524a3c6d8e8fd7426e60b",
    "title": "Asymptotics of Yule's nonsense correlation for Ornstein-Uhlenbeck paths: The correlated case",
    "slug": "asymptotics-of-yule's-nonsense-correlation-for-ornstein-uhlenbeck-paths:-the-correlated-case",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Soukaina Douissi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the continuous-time version of the empirical correlation coefficient between the paths of two possibly correlated Ornstein-Uhlenbeck processes, known as Yule's nonsense correlation for these paths. Using sharp tools from the analysis on Wiener chaos, we establish the asymptotic normality of the fluctuations of this correlation coefficient around its long-time limit, which is the mathematical correlation coefficient between the two processes. This asymptotic normality is quantified in Kolmogorov distance, which allows us to establish speeds of convergence in the Type-II error for two simple tests of independence of the paths, based on the empirical correlation, and based on its numerator. An application to independence of two observations of solutions to the stochastic heat equation is given, with excellent asymptotic power properties using merely a small number of the solutions' Fourier modes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17175",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.871369Z"
  },
  {
    "id": "0b6931d5d320a9bb89483e0fc99f819e",
    "title": "Approximating fluid queues with quasi birth-and-death processes with rational arrival process components",
    "slug": "approximating-fluid-queues-with-quasi-birth-and-death-processes-with-rational-arrival-process-components",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Nigel Bean",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "A fluid queue is a stochastic process which moves linearly with a rate that is determined by the state of a continuous-time Markov chain (CTMC). In this paper we construct an approximation to a fluid queue using a quasi birth-and-death process with rational arrival process components (QBD-RAP) and prove weak convergence via convergence of generators. The primary motivation for constructing the new approximation is to achieve a better approximation accuracy than existing methods while also ensuring that all approximations to probabilities have all probabilistic properties, such as non-negativity and bounded above by 1.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17176",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.871570Z"
  },
  {
    "id": "6719377adc67381c8075d42ed624b128",
    "title": "Sample-Path Large Deviations for Functionals of Poisson Cluster Processes",
    "slug": "sample-path-large-deviations-for-functionals-of-poisson-cluster-processes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Fabien Baeriswyl",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish sample-path large deviation principles for the centered cumulative functional of marked Poisson cluster processes in the Skorokhod space equipped with the M1 topology, under joint regular variation assumptions on the marks and the offspring distributions governing the propagation mechanism. These findings can also be interpreted as hidden regular variation of the cluster processes' functionals, extending the results in Dombry et al. (2022) to cluster processes with heavy-tailed characteristics, including mixed Binomial Poisson cluster processes and Hawkes processes. Notably, by restricting to the adequate subspace of measures on D([0, 1], R+), and applying the correct normalization and scaling to the paths of the centered cumulative functional, the limit measure concentrates on paths with multiple large jumps.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17363",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.871762Z"
  },
  {
    "id": "1409b0a3973803b3738196d6c7cc0f1a",
    "title": "Mean convergence rates for Gaussian-smoothed Wasserstein distances and classical Wasserstein distances",
    "slug": "mean-convergence-rates-for-gaussian-smoothed-wasserstein-distances-and-classical-wasserstein-distances",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Andrea Cosso",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish upper bounds for the expected Gaussian-smoothed $p$-Wasserstein distance between a probability measure $\\mu$ and the corresponding empirical measure $\\mu_N$, whenever $\\mu$ has finite $q$-th moments for any $q>p$. This generalizes recent results that were valid only for $q>2p+2d$. We provide two distinct proofs of such a result. We also use a third upper bound for the Gaussian-smoothed $p$-Wasserstein distance to derive an upper bound for the classical $p$-Wasserstein distance. Although the latter upper bound is not optimal when $\\mu$ has finite $q$-th moment with $q>p$, this bound does not require imposing such a moment condition on $\\mu$, as it is usually done in the literature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17477",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.871962Z"
  },
  {
    "id": "651e853d7de446469fd2a320d8d0c754",
    "title": "Spectral properties of the Laplacian of Scale-Free Percolation models",
    "slug": "spectral-properties-of-the-laplacian-of-scale-free-percolation-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Rajat Subhra Hazra",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider scale-free percolation on a discrete torus $\\mathbf{V}_N$ of size $N$. Conditionally on an i.i.d. sequence of Pareto weights $(W_i)_{i\\in \\mathbf{V}_N}$ with tail exponent $\\tau-1>0$, we connect any two points $i$ and $j$ on the torus with probability\n$$p_{ij}= \\frac{W_iW_j}{\\|i-j\\|^{\\alpha}} \\wedge 1$$ for some parameter $\\alpha>0$.\nWe focus on the (centred) Laplacian operator of this random graph and study its empirical spectral distribution. We explicitly identify the limiting distribution when $\\alpha<1$ and $\\tau>3$, in terms of the spectral distribution of some non-commutative unbounded operators.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17552",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.872162Z"
  },
  {
    "id": "a268a0a8ea124a0ac02cbc60155c41ad",
    "title": "Convex order and increasing convex order for McKean-Vlasov processes with common noise",
    "slug": "convex-order-and-increasing-convex-order-for-mckean-vlasov-processes-with-common-noise",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Armand Bernou",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish results on the conditional and standard convex order, as well as the increasing convex order, for two processes $ X = (X_t)_{t \\in [0, T]} $ and $ Y = (Y_t)_{t \\in [0, T]}$, defined by the following McKean-Vlasov equations with common Brownian noise $B^0 = (B_t^0)_{t \\in [0, T]}$: \\begin{align} dX_t &= b(t, X_t, \\mathcal{L}^1(X_t))dt + \\sigma(t, X_t, \\mathcal{L}^1(X_t))dB_t + \\sigma^0(t, \\mathcal{L}^1(X_t))dB^0_t, \\\\ dY_t &= \\beta(t, Y_t, \\mathcal{L}^1(Y_t))dt + \\theta(t, Y_t, \\mathcal{L}^1(Y_t))dB_t + \\theta^0(t, \\mathcal{L}^1(Y_t))dB^0_t, \\end{align} where $\\mathcal{L}^1(X_t)$ (respectively $\\mathcal{L}^1(Y_t)$) denotes a version of the conditional distribution of $X_t$ (resp. $Y_t$) given $B^0$. These results extend those established for standard McKean-Vlasov equations in [Liu and Pags, Ann. App. Prob. 2023] and [Liu and Pags, Bernoulli 2022]. Under suitable conditions, for a (non-decreasing) convex functional $F$ on the path space with polynomial growth, we show $\\mathbb{E}[F(X) \\mid B^0] \\leq \\mathbb{E}[F(Y) \\mid B^0]$ almost surely. Moreover, for a (non-decreasing) convex functional $G$ defined on the product space of paths and their marginal distributions, we establish \\[ \\mathbb{E} \\Big[\\,G\\big(X, (\\mathcal{L}^1(X_t))_{t\\in[0, T]}\\big)\\,\\Big| \\, B^0\\,\\Big]\\leq \\mathbb{E} \\Big[\\,G\\big(Y, (\\mathcal{L}^1(Y_t))_{t\\in[0, T]}\\big)\\,\\Big| \\, B^0\\,\\Big] \\quad \\text{almost surely}. \\] Similar convex order results are also established for the corresponding particle system. We explore applications of these results to stochastic control problem - deducing in particular an associated comparison principle for Hamilton-Jacobi-Bellman equations with different coefficients - and to the interbank systemic risk model introduced by in [Carmona, Fouque and Sun, Comm. in Math. Sci. 2015].",
    "pdfUrl": "https://arxiv.org/pdf/2504.17576",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.872364Z"
  },
  {
    "id": "65829e646d437df37fa3044b82a6df23",
    "title": "Extremal negative dependence and the strongly Rayleigh property",
    "slug": "extremal-negative-dependence-and-the-strongly-rayleigh-property",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Hlne Cossette",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We provide a geometrical characterization of extremal negative dependence as a convex polytope in the simplex of multidimensional Bernoulli distributions, and we prove that it is an antichain that satisfies some minimality conditions with respect to the strongest negative dependence orders. We study the strongly Rayleigh property within this class and explicitly find a distribution that satisfies this property by maximizing the entropy. Furthermore, we construct a chain for the supermodular order starting from extremal negative dependence to independence by mixing the maximum entropy strongly Rayleigh distribution with independence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17679",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.872564Z"
  },
  {
    "id": "609aedfdf2b1ca7ddba9bcebcad8cfce",
    "title": "The $q^{\\mathrm{Volume}}$ lozenge tiling model via non-Hermitian orthogonal polynomials",
    "slug": "the-$q^{\\mathrm{volume}}$-lozenge-tiling-model-via-non-hermitian-orthogonal-polynomials",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Ahmad Barhoumi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider the $q^\\text{Volume}$ lozenge tiling model on a large, finite hexagon. It is well-known that random lozenge tilings of the hexagon correspond to a two-dimensional determinantal point process via a bijection with ensembles of non-intersecting paths. The starting point of our analysis is a formula for the correlation kernel due to Duits and Kuijlaars which involves the Christoffel-Darboux kernel of a particular family of non-Hermitian orthogonal polynomials. Our main results are split into two parts: the first part concerns the family of orthogonal polynomials, and the second concerns the behavior of the boundary of the so-called arctic curve. In the first half, we identify the orthogonal polynomials as a non-standard instance of little $q$-Jacobi polynomials and compute their large degree asymptotics in the $q \\to 1$ regime. A consequence of this analysis is a proof that the zeros of the orthogonal polynomials accumulate on an arc of a circle and an asymptotic formula for the Christoffel-Darboux kernel. In the second half, we use these asymptotics to show that the boundary of the liquid region converges to the Airy process, in the sense of finite dimensional distributions, away from the boundary of the hexagon. At inflection points of the arctic curve, we show that we do not need to subtract/add a parabola to the Airy line ensemble, and this effect persists at distances which are $o(N^{-2/9})$ in the tangent direction.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17042",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:36.872753Z"
  },
  {
    "id": "c5b818d514795cc8215a861563f4dee6",
    "title": "Graph Quasirandomness for Hypothesis Testing of Stochastic Block Models",
    "slug": "graph-quasirandomness-for-hypothesis-testing-of-stochastic-block-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Kiril Bangachev",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The celebrated theorem of Chung, Graham, and Wilson on quasirandom graphs implies that if the 4-cycle and edge counts in a graph $G$ are both close to their typical number in $\\mathbb{G}(n,1/2),$ then this also holds for the counts of subgraphs isomorphic to $H$ for any $H$ of constant size. We aim to prove a similar statement where the notion of close is whether the given (signed) subgraph count can be used as a test between $\\mathbb{G}(n,1/2)$ and a stochastic block model $\\mathbb{SBM}.$\nQuantitatively, this is related to approximately maximizing $H \\longrightarrow |\\Phi(H)|^{\\frac{1}{|\\mathsf{V}(H)|}},$ where $\\Phi(H)$ is the Fourier coefficient of $\\mathbb{SBM}$, indexed by subgraph $H.$ This formulation turns out to be equivalent to approximately maximizing the partition function of a spin model over alphabet equal to the community labels in $\\mathbb{SBM}.$\nWe resolve the approximate maximization when $\\mathbb{SBM}$ satisfies one of four conditions: 1) the probability of an edge between any two vertices in different communities is exactly $1/2$; 2) the probability of an edge between two vertices from any two communities is at least $1/2$ (this case is also covered in a recent work of Yu, Zadik, and Zhang); 3) the probability of belonging to any given community is at least $c$ for some universal constant $c>0$; 4) $\\mathbb{SBM}$ has two communities. In each of these cases, we show that there is an approximate maximizer of $|\\Phi(H)|^{\\frac{1}{|\\mathsf{V}(H)|}}$ in the set $\\mathsf{A} = \\{\\text{stars, 4-cycle}\\}.$ This implies that if there exists a constant-degree polynomial test distinguishing $\\mathbb{G}(n,1/2)$ and $\\mathbb{SBM},$ then the two distributions can also be distinguished via the signed count of some graph in $\\mathsf{A}.$ We conjecture that the same holds true for distinguishing $\\mathbb{G}(n,1/2)$ and any graphon if we also add triangles to $\\mathsf{A}.$",
    "pdfUrl": "https://arxiv.org/pdf/2504.17202",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:36.872942Z"
  },
  {
    "id": "8f2fae1520cd7c03f4776d4d02d1227f",
    "title": "Stability of Stochastically Forced Solitons in the Korteweg-de Vries Equation",
    "slug": "stability-of-stochastically-forced-solitons-in-the-korteweg-de-vries-equation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Rik W.S. Westdorp",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the stability and dynamics of solitons in the Korteweg-de Vries (KdV) equation in the presence of noise and deterministic forcing. The noise is space-dependent and statistically translation-invariant. We show that, for small forcing, solitons remain close to the family of traveling waves in a weighted Sobolev norm, with high probability. We study the effective dynamics of the soliton amplitude and position via their variational phase, for which we derive explicit modulation equations. The stability result holds on a time scale where the deterministic forcing induces significant amplitude modulation.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17407",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:36.873140Z"
  },
  {
    "id": "dbce657944ef900e3dbf5b1b0e46629d",
    "title": "Tail asymptotics and precise large deviations for some Poisson cluster processes",
    "slug": "tail-asymptotics-and-precise-large-deviations-for-some-poisson-cluster-processes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Fabien Baeriswyl",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the tail asymptotics of two functionals (the maximum and the sum of the marks) of a generic cluster in two sub-models of the marked Poisson cluster process, namely the renewal Poisson cluster process and the Hawkes process. Under the hypothesis that the governing components of the processes are regularly varying, we extend results due to [18] and [5] notably, relying on Karamata's Tauberian Theorem to do so. We use these asymptotics to derive precise large deviation results in the fashion of [30] for the above-mentioned processes.",
    "pdfUrl": "https://arxiv.org/pdf/2304.09705",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.873333Z"
  },
  {
    "id": "afa3e7c4e2db4e77e05c78be70f89f9b",
    "title": "Pseudorandomness of the Sticky Random Walk",
    "slug": "pseudorandomness-of-the-sticky-random-walk",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Emile Anand",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We extend the pseudorandomness of random walks on expander graphs using the sticky random walk. Building on prior works, it was recently shown that expander random walks can fool all symmetric functions in total variation distance (TVD) upto an $O(\\lambda(\\frac{p}{\\min f})^{O(p)})$ error, where $\\lambda$ is the second largest eigenvalue of the expander, $p$ is the size of the arbitrary alphabet used to label the vertices, and $\\min f = \\min_{b\\in[p]} f_b$, where $f_b$ is the fraction of vertices labeled $b$ in the graph. Golowich and Vadhan conjecture that the dependency on the $(\\frac{p}{\\min f})^{O(p)}$ term is not tight. In this paper, we resolve the conjecture in the affirmative for a family of expanders. We present a generalization of the sticky random walk for which Golowich and Vadhan predict a TVD upper bound of $O(\\lambda p^{O(p)})$ using a Fourier-analytic approach. For this family of graphs, we use a combinatorial approach involving the Krawtchouk functions to derive a strengthened TVD of $O(\\lambda)$. Furthermore, we present equivalencies between the generalized sticky random walk, and, using linear-algebraic techniques, show that the generalized sticky random walk parameterizes an infinite family of expander graphs.",
    "pdfUrl": "https://arxiv.org/pdf/2307.11104",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.873643Z"
  },
  {
    "id": "846a0c2be65504cc214da11a5e33ee33",
    "title": "Long range voter models and dynamical fractional Brownian motion",
    "slug": "long-range-voter-models-and-dynamical-fractional-brownian-motion",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Reuben Drogin",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the voter model on Z with long-range interactions, as proposed by Hammond and Sheffield. We show a spacetime rescaling converges to a fractional Gaussian free field, which can be viewed as a one-parameter family of fractional Brownian motions. As a consequence, we obtain that long-range voter models rescale to fractional Gaussian noise. The argument uses the Lindeberg swapping technique and heat kernel estimates for random walks with jump distributions in the domain of attraction of a stable law.",
    "pdfUrl": "https://arxiv.org/pdf/2311.03662",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.873845Z"
  },
  {
    "id": "b3ef80e117c8a72fab4243655c24f214",
    "title": "Catalan percolation",
    "slug": "catalan-percolation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Eleanor Archer",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In Catalan percolation, all nearest-neighbor edges $\\{i,i+1\\}$ along $\\mathbb Z$ are initially occupied, and all other edges are open independently with probability $p$. Open edges $\\{i,j\\}$ are occupied if some pair of edges $\\{i,k\\}$ and $\\{k,j\\}$, with $i<k<j$, become occupied. This model was introduced by Gravner and the third author, in the context of polluted graph bootstrap percolation.\nWe prove that the critical $p_{\\mathrm c}$ is strictly between that of oriented site percolation on $\\mathbb Z^2$ and the Catalan growth rate $1/4$. Our main result shows that an enhanced oriented percolation model, with non-decaying infinite-range dependency, has a strictly smaller critical parameter than the classical model. This is reminiscent of the work of Duminil-Copin, Hilrio, Kozma and Sidoravicius on brochette percolation. Our proof differs, however, in that we do not use Aizenman--Grimmett enhancements or differential inequalities. Two key ingredients are the work of Hilrio, S, Sanchis and Teixeira on stretched lattices, and the Russo--Seymour--Welsh result for oriented percolation by Duminil-Copin, Tassion and Teixeira.",
    "pdfUrl": "https://arxiv.org/pdf/2404.19583",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.874073Z"
  },
  {
    "id": "814e03a1ea72542f4d205a684b0efdfd",
    "title": "Classification of the limit shape for 1+1-dimensional FPP",
    "slug": "classification-of-the-limit-shape-for-1+1-dimensional-fpp",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Malte Hassler",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a simplified model of planar first passage percolation where weights along vertical edges are deterministic. We show that the limit shape has a flat edge in the vertical direction if and only if the random distribution of the horizontal edges has an atom at the infimum of its support. Furthermore, we present bounds on the upper and lower derivative of the time constant.",
    "pdfUrl": "https://arxiv.org/pdf/2411.13030",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.874266Z"
  },
  {
    "id": "0c9bd9e191a6b795c894f36b02a5125f",
    "title": "Stability of travelling wave solutions to reaction-diffusion equations driven by additive noise with Hlder continuous paths",
    "slug": "stability-of-travelling-wave-solutions-to-reaction-diffusion-equations-driven-by-additive-noise-with-hlder-continuous-paths",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Amjad Saef",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper we investigate stability of travelling wave solutions to a class of reaction-diffusion equations perturbed by infinite-dimensional additive noise with Hlder continuous paths, covering in particular fractional Brownian motion with general Hurst index. We obtain long- and short time asymptotic error bounds on the maximal distance from the solution of the stochastic reaction-diffusion equation to the orbit of travelling wave fronts. These bounds, in terms of Hurst index and Hlder exponent, apply to a large class of infinite-dimensional self-similar drivers with Hlder continuous paths, such as linear fractional stable motion. We find that for short times, higher Hurst indices imply higher stability, while for large times, the difference of Hurst index to Hlder exponent influences the size of scaling exponents of the noise amplitude that are sufficient to ensure stability.",
    "pdfUrl": "https://arxiv.org/pdf/2501.12944",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.874466Z"
  },
  {
    "id": "dbfa9070d02b4fe5f39a52b12ab839d5",
    "title": "Uniqueness of Parisi measures for enriched convex vector spin glass",
    "slug": "uniqueness-of-parisi-measures-for-enriched-convex-vector-spin-glass",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Hong-Bin Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the PDE approach to mean-field spin glasses, it has been observed that the free energy of convex spin glass models could be enriched by adding an extra parameter in its definition, and that the thermodynamic limit of the enriched free energy satisfies a partial differential equation. This parameter can be thought of as a matrix-valued path, and the usual free energy is recovered by setting this parameter to be the constant path taking only the value $0$. Furthermore, the enriched free energy can be expressed using a variational formula, which is a natural extension of the Parisi formula for the usual free energy. For models with scalar spins the Parisi formula can be expressed as an optimization problem over a convex set, and it was shown in [arXiv:1402.5132] that this problem has a unique optimizer thanks to a strict convexity property. For models with vector spins, the Parisi formula cannot easily be written as a convex optimization problem. In this paper, we generalize the uniqueness of Parisi measures proven in [arXiv:1402.5132] to the enriched free energy of models with vector spins when the extra parameter is a strictly increasing path. Our approach relies on a Gateaux differentiability property of the free energy and the envelope theorem.",
    "pdfUrl": "https://arxiv.org/pdf/2504.15818",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.874662Z"
  },
  {
    "id": "d9ea968b1539ef8f12b74e4a72aaddac",
    "title": "Scaling limit for supercritical nearly unstable Hawkes processes with heavy tail",
    "slug": "scaling-limit-for-supercritical-nearly-unstable-hawkes-processes-with-heavy-tail",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Liping Xu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we establish the asymptotic behavior of {\\it supercritical} nearly unstable Hawkes processes with a power law kernel. We find that, the Hawkes process in our context admits a similar equation to that in \\cite{MR3563196} for {\\it subcritical} case. In particular, the rescaled Hawkes process $(Z^n_{nt}/n^{2\\alpha})_{t\\in[0,1]}$ converges in law to a kind of integrated fractional Cox Ingersoll Ross process with different coefficients from that in \\cite{MR3563196}, as $n$ tends to infinity.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16737",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:36.874859Z"
  },
  {
    "id": "4efc1e5e0bd83759c16db58593e42128",
    "title": "Bayesian Mixtures Models with Repulsive and Attractive Atoms",
    "slug": "bayesian-mixtures-models-with-repulsive-and-attractive-atoms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Mario Beraha",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The study of almost surely discrete random probability measures is an active line of research in Bayesian nonparametrics. The idea of assuming interaction across the atoms of the random probability measure has recently spurred significant interest in the context of Bayesian mixture models. This allows the definition of priors that encourage well-separated and interpretable clusters. In this work, we provide a unified framework for the construction and the Bayesian analysis of random probability measures with interacting atoms, encompassing both repulsive and attractive behaviours. Specifically, we derive closed-form expressions for the posterior distribution, the marginal and predictive distributions, which were not previously available except for the case of measures with i.i.d. atoms. We show how these quantities are fundamental both for prior elicitation and to develop new posterior simulation algorithms for hierarchical mixture models. Our results are obtained without any assumption on the finite point process that governs the atoms of the random measure. Their proofs rely on analytical tools borrowed from the Palm calculus theory, which might be of independent interest. We specialise our treatment to the classes of Poisson, Gibbs, and determinantal point processes, as well as in the case of shot-noise Cox processes. Finally, we illustrate the performance of different modelling strategies on simulated and real datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2302.09034",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:36.875055Z"
  },
  {
    "id": "43750a7b29afcb5dbb04610f54d6d747",
    "title": "Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents",
    "slug": "throughput-optimal-scheduling-algorithms-for-llm-inference-and-ai-agents",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Yueying Li",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "As demand for Large Language Models (LLMs) and AI agents rapidly grows, optimizing systems for efficient LLM inference becomes critical. While significant efforts have focused on system-level engineering, little is explored from a mathematical modeling and queuing perspective.\nIn this paper, we aim to develop the queuing fundamentals for large language model (LLM) inference, bridging the gap between the queueing theory and LLM system communities. In particular, we study the throughput aspect in LLM inference systems. We prove that a large class of 'work-conserving' scheduling algorithms can achieve maximum throughput for individual inference LLM engine, highlighting 'work-conserving' as a key design principle in practice. In a network of LLM agents, work-conserving scheduling alone is insufficient, particularly when facing specific workload structures and multi-class workflows that require more sophisticated scheduling strategies. Evaluations of real-world systems show that Orca and Sarathi-serve are throughput-optimal, reassuring practitioners, while FasterTransformer and vanilla vLLM are not maximally stable and should be used with caution. Our results highlight the substantial benefits that the queueing community can offer in improving LLM inference systems and call for more interdisciplinary development.",
    "pdfUrl": "https://arxiv.org/pdf/2504.07347",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:36.875253Z"
  },
  {
    "id": "f5941b15a632184834374432848a5a9d",
    "title": "Orbifolds, higher dagger structures, and idempotents",
    "slug": "orbifolds,-higher-dagger-structures,-and-idempotents",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Quantum Algebra (math.QA)",
    "author": {
      "name": "Nils Carqueville",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The orbifold/condensation completion procedure of defect topological quantum field theories can be seen as carrying out a lattice or state sum model construction internal to an ambient theory. In this paper, we propose a conceptual algebraic description of orbifolds/condensations for arbitrary tangential structures in terms of higher dagger structures and higher idempotents. In particular, we obtain (oriented) orbifold completion from (framed) condensation completion by using a general strictification procedure for higher dagger structures which we describe explicitly in low dimensions; we also discuss the spin and unoriented case. We provide several examples of higher dagger categories, such as those associated to state sum models, (orbifolds of) Landau--Ginzburg models, and truncated affine Rozansky--Witten models. We also explain how their higher dagger structures are naturally induced from rigid symmetric monoidal structures, recontextualizing and extending results from the literature.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17764",
    "tags": [
      "Quantum Algebra (math.QA)"
    ],
    "createdAt": "2025-04-25T15:49:37.205338Z"
  },
  {
    "id": "d548a994ee7cf333488027317d127a46",
    "title": "$C^*$- Colored graph algebras",
    "slug": "$c^*$--colored-graph-algebras",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Farrokh Razavinia",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Following our previous works on $C^*$-graph algebras and the associated Cuntz-Krieger graph families, in this paper we will try to have a look at the colored version of these structures and to see what a $C^*$-colored graph algebra might mean by employing some constructive examples very close to the toy example used in our previous works, and we also will try to study their graph theoretical properties as possible.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16963",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:37.205538Z"
  },
  {
    "id": "459afca5ca8a432ac31945b587c0c128",
    "title": "Quantum Corner VOA and the Super Macdonald Polynomials",
    "slug": "quantum-corner-voa-and-the-super-macdonald-polynomials",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "Panupong Cheewaphutthisakun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we establish a relation between the quantum corner VOA $q\\widetilde{Y}_{L,0,N}[\\Psi]$, which can be regarded as a generalization of quantum $W_N$ algebra, and Sergeev-Veselov super Macdonald polynomials. We demonstrate precisely that, under a specific map, the correlation functions of the currents of $q\\widetilde{Y}_{L,0,N}[\\Psi]$, coincide with the Sergeev-Veselov super Macdonald polynomials.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17326",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:37.205742Z"
  },
  {
    "id": "2bef3343311db9fb7e80142e6e23d79e",
    "title": "Stratifying quiver Schur algebras via ersatz parity sheaves",
    "slug": "stratifying-quiver-schur-algebras-via-ersatz-parity-sheaves",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Ruslan Maksimau",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose an extension of the theory of parity sheaves, which allows for non-locally constant sheaves along strata. Our definition is tailored for proving the existence of (proper, quasihereditary, etc) stratifications of $\\mathrm{Ext}$-algebras. We use this to study quiver Schur algebras $A(\\alpha)$ for the cyclic quiver of length $2$. We find a polynomial quasihereditary structure on $A(\\alpha)$ compatible with the categorified PBW basis of McNamara and Kleshchev-Muth, and sharpen their results to arbitrary characteristic. We also prove that semicuspidal algebras of $A(n\\delta)$ are polynomial quasihereditary covers of semicuspidal algebras of the corresponding KLR algebra $R(n\\delta)$, and compute them diagrammatically.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17430",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:37.205940Z"
  },
  {
    "id": "56e41438f621dda40edb75368eb04ccb",
    "title": "Free field realization of the quantum toroidal algebra of $\\mathfrak{gl}_1$ with general levels",
    "slug": "free-field-realization-of-the-quantum-toroidal-algebra-of-$\\mathfrak{gl}_1$-with-general-levels",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "Zitao Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present a unified free field realization of representations for the quantum toroidal algebra of $\\mathfrak{gl}_1$ with arbitrary levels, constructed using six free boson fields. This realization arises from a specialized factorization of the structure function within the defining relations of the quantum toroidal algebra of $\\mathfrak{gl}_1$. Utilizing this free field realization, we further develop intertwining operators for the algebra of $\\mathfrak{gl}_1$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17508",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:37.206135Z"
  },
  {
    "id": "1c6e6c388642c2129ca843b31a477159",
    "title": "Two-row Delta Springer varieties",
    "slug": "two-row-delta-springer-varieties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Abel Lacabanne",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the geometry and topology of $\\Delta$-Springer varieties associated with two-row partitions. These varieties were introduced in recent work by Griffin-Levinson-Woo to give a geometric realization of a symmetric function appearing in the Delta conjecture by Haglund-Remmel-Wilson. We provide an explicit and combinatorial description of the irreducible components of the two-row $\\Delta$-Springer variety and compare it to the ordinary two-row Springer fiber as well as Kato's exotic Springer fiber corresponding to a one-row bipartition. In addition to that, we extend the action of the symmetric group on the homology of the two-row $\\Delta$-Springer variety to an action of a degenerate affine Hecke algebra and relate this action to a $\\mathfrak{gl}_{2}$-tensor space.",
    "pdfUrl": "https://arxiv.org/pdf/2407.10792",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:37.206336Z"
  },
  {
    "id": "1251a42f75a9d0f9464a3119e524cf83",
    "title": "Cyclic Representations of $U_q(\\hat{\\mathfrak{sl}}_2)$ and its Borel Subalgebras at Roots of Unity and Q-operators",
    "slug": "cyclic-representations-of-$u_q(\\hat{\\mathfrak{sl}}_2)$-and-its-borel-subalgebras-at-roots-of-unity-and-q-operators",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Mathematical Physics (math-ph)",
    "author": {
      "name": "Robert Weston",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider the cyclic representations $\\Omega_{rs}$ of $ U_q(\\widehat{\\mathfrak{sl}}_2)$ at $q^N=1$ that depend upon two points $r,s$ in the chiral Potts algebraic curve. We show how $\\Omega_{rs}$ is related to the tensor product $\\rho_r\\otimes \\bar{\\rho}_s$ of two representations of the upper Borel subalgebra of $U_q(\\widehat{\\mathfrak{sl}}_2)$. This result is analogous to the factorization property of the Verma module of $U_q(\\widehat{\\mathfrak{sl}}_2)$ at generic-$q$ in terms of two q-oscillator representation of the Borel subalgebra - a key step in the construction of the Q-operator. We construct short exact sequences of the different representations and use the results to construct Q operators that satisfy TQ relations for $q^N=1$ for both the 6-vertex and $\\tau_2$ models.",
    "pdfUrl": "https://arxiv.org/pdf/2412.14811",
    "tags": [
      "Mathematical Physics (math-ph)"
    ],
    "createdAt": "2025-04-25T15:49:37.206539Z"
  },
  {
    "id": "ece5b26e4f20b97470857bac34146e6c",
    "title": "Schurification of polynomial quantum wreath products",
    "slug": "schurification-of-polynomial-quantum-wreath-products",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Chun-Ju Lai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the Schur algebra counterpart of a vast class of quantum wreath products. This is achieved by developing a theory of twisted convolution algebras, inspired by geometric intuition. In parallel, we provide an algebraic Schurification via a Kashiwara-Miwa-Stern-type action on a tensor space. We give a uniform proof of Schur duality, and construct explicit bases of the new Schur algebras. This provides new results for, among other examples, Vignras' pro-$p$ Iwahori Hecke algebras of type $A$, degenerate affine Hecke algebras, Kleshchev-Muth's affine zigzag algebras, and Rosso-Savage's affine Frobenius Hecke algebras.",
    "pdfUrl": "https://arxiv.org/pdf/2502.02108",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:37.206733Z"
  },
  {
    "id": "ddb168138bf2a59c718ff4f639d95cc7",
    "title": "The Motzkin subproduct system",
    "slug": "the-motzkin-subproduct-system",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Operator Algebras (math.OA)",
    "author": {
      "name": "Valeriano Aiello",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a subproduct system of finite-dimensional Hilbert spaces using the Motzkin planar algebra and its Jones-Wenzl idempotents, which generalizes the Temperley-Lieb subproduct system of Habbestad and Neshveyev. We provide a description of the corresponding Toeplitz and Cuntz-Pimsner C$^*$-algebras as universal C$^*$-algebras, defined in terms of generators and relations, and we highlight properties of their representation theory.",
    "pdfUrl": "https://arxiv.org/pdf/2502.14057",
    "tags": [
      "Operator Algebras (math.OA)"
    ],
    "createdAt": "2025-04-25T15:49:37.206929Z"
  },
  {
    "id": "0fb069fb4ec901a17a92604297ad497c",
    "title": "The Nilpotency of the Nil Metric $\\mathbb{F}$-Algebras",
    "slug": "the-nilpotency-of-the-nil-metric-$\\mathbb{f}$-algebras",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Rings and Algebras (math.RA)",
    "author": {
      "name": "Antonio de Frana",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $\\mathbb{F}$ be a normed field. In this work, we prove that every nil complete metric $\\mathbb{F}$-algebra is nilpotent when $\\mathbb{F}$ has characteristic zero. This result generalizes Grabiner's Theorem for Banach algebras, first proved in 1969. Furthermore, we show that a metric $\\mathbb{F}$-algebra $\\mathfrak{A}$ and its completion $C(\\mathfrak{A})$ satisfy the same polynomial identities, and consequently, if $\\mathsf{char}(\\mathbb{F})=0$ and $C(\\mathfrak{A})$ is nil, then $\\mathfrak{A}$ is nilpotent. Our results allow us to resolve Kthe's Problem affirmatively for complete metric algebras over normed fields of characteristic zero.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17168",
    "tags": [
      "Rings and Algebras (math.RA)"
    ],
    "createdAt": "2025-04-25T15:49:37.664058Z"
  },
  {
    "id": "16f8ce36a3380ccd0c2bdfd5c7c9f1d3",
    "title": "Commuting degree for BCK-algebras",
    "slug": "commuting-degree-for-bck-algebras",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Rings and Algebras (math.RA)",
    "author": {
      "name": "C. Matthew Evans",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We discuss the following question: given a finite BCK-algebra, what is the probability that two randomly selected elements commute? We call this probability the \\textit{commuting degree} of a BCK-algebra. In a previous paper, the author gave sharp upper and lower bounds for the commuting degree of a BCK-algebra with order $n$. We expand on those results in this paper: we show that, for each $n\\geq 3$, there is a BCK-algebra of order $n$ realizing each possible commuting degree and that the minimum commuting degree is achieved by a unique BCK-algebra of order $n$ Additionally, we show that every rational number in $(0,1]$ is the commuting degree of some finite BCK-algebra.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17283",
    "tags": [
      "Rings and Algebras (math.RA)"
    ],
    "createdAt": "2025-04-25T15:49:37.664277Z"
  },
  {
    "id": "34274f5f3d97d15ebaa8f532057e9111",
    "title": "On the length of generating sets with conditions on minimal polynomial",
    "slug": "on-the-length-of-generating-sets-with-conditions-on-minimal-polynomial",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Rings and Algebras (math.RA)",
    "author": {
      "name": "Chengjie Wang",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Linear upper bounds may be derived by imposing specific structural conditions on a generating set, such as additional constraints on ranks, eigenvalues, or the degree of the minimal polynomial of the generating matrices. This paper establishes a linear upper bound of \\(3n-5\\) for generating sets that contain a matrix whose minimal polynomial has a degree exceeding \\(\\frac{n}{2}\\), where \\(n\\) denotes the order of the matrix. Compared to the bound provided in \\cite[Theorem 3.1]{r2}, this result reduces the constraints on the Jordan canonical forms. Additionally, it is demonstrated that the bound \\(\\frac{7n}{2}-4\\) holds when the generating set contains a matrix with a minimal polynomial of degree \\(t\\) satisfying \\(2t\\le n\\le 3t-1\\). The primary enhancements consist of quantitative bounds and reduced reliance on Jordan form structural constraints.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17348",
    "tags": [
      "Rings and Algebras (math.RA)"
    ],
    "createdAt": "2025-04-25T15:49:37.664475Z"
  },
  {
    "id": "483abbde6cc7f8fa1d751b3908acaa9b",
    "title": "A relation between Turaev coaction, Goncharov--Brown coaction and the reduced coaction Lie algebra",
    "slug": "a-relation-between-turaev-coaction,-goncharov--brown-coaction-and-the-reduced-coaction-lie-algebra",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Rings and Algebras (math.RA)",
    "author": {
      "name": "Muze Ren",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present a formula that relates the Turaev coaction and the Goncharov-Brown coaction. Motivated by this relation, we introduce the reduced coaction equation. The skew-symmetric solutions to this equation form a Lie algebra under Ihara bracket.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17416",
    "tags": [
      "Rings and Algebras (math.RA)"
    ],
    "createdAt": "2025-04-25T15:49:37.664667Z"
  },
  {
    "id": "3a4cc3b1f9b3d81b01d29ce58eb4a9f2",
    "title": "Symmetric semi-invariants for some Inonu-Wigner contractions-II-Case B even",
    "slug": "symmetric-semi-invariants-for-some-inonu-wigner-contractions-ii-case-b-even",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Florence Fauquant-Millet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider a proper parabolic subalgebra p of a simple Lie algebra g and the Inonu-Wigner contraction of p with respect to its decomposition into its standard Levi factor and its nilpotent radical : this is the Lie algebra which is isomorphic to p as a vector space, but where the nilpotent radical becomes an abelian ideal of this contraction. The study of the algebra of symmetric semi-invariants under the adjoint action associated with such a contraction was initiated in my paper entitled : Symmetric Semi-Invariants for some Inonu-Wigner Contractions-I, published in Transformation Groups, January 2025, wherein a lower bound for the formal character of this algebra was built, when the latter is well defined. Here in this paper we build an upper bound for this formal character, when p is a maximal parabolic subalgebra in a classical simple Lie algebra g in type B, when the Levi subalgebra of p is associated with the set of all simple roots without a simple root of even index with Bourbaki notation (we call this case the even case). We show that both bounds coincide. This provides a Weierstrass section for the algebra of symmetric semi-invariants associated with such a contraction and the polynomiality of such an algebra follows.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17036",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:37.664855Z"
  },
  {
    "id": "70363ac8437ac72064a4367d431fe6e6",
    "title": "The autotopism group of a family of commutative semifields",
    "slug": "the-autotopism-group-of-a-family-of-commutative-semifields",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Lukas Klsch",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We completely determine the autotopism group of the (as of now) largest family of commutative semifields found by Glolu and Klsch. Since this family of semifields generally does not have large nuclei, this process is considerably harder than for families considered in preceding work. Our results show that all autotopisms are semilinear over the degree 2 subfield and that the autotopism group is always solvable. Using known connections, our results also completely determine the automorphism groups of the associated rank-metric codes and the collineation groups of the associated translation planes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17057",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:37.665052Z"
  },
  {
    "id": "a23107e80d01199e56a792eb78373fed",
    "title": "Hochschild (Co)homology of D-modules on rigid analytic spaces II",
    "slug": "hochschild-(co)homology-of-d-modules-on-rigid-analytic-spaces-ii",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Fernando Pea Vzquez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $X$ be a smooth $p$-adic Stein space with free tangent sheaf. We use the notion of Hochschild cohomology for sheaves of Ind-Banach algebras developed in our previous work to study the Hochschild cohomology of the algebra of infinite order differential operators $\\mathcal{D}_X$-cap. In particular, we show that the Hochschild cohomology complex of $\\mathcal{D}_X$-cap is a strict complex of nuclear Frchet spaces which is quasi-isomorphic to the de Rham complex of $X$. We then use this to compare the first Hochschild cohomology group of $\\mathcal{D}_X$-cap with a wide array of Ext functors. Finally, we investigate the relation of the Hochschild cohomology of $\\mathcal{D}_X$-cap with the deformation theory of $\\mathcal{D}_X(X)$-cap. Assuming some finiteness conditions on the de Rham cohomology of $X$, we define explicit isomorphisms between the first Hochschild cohomology group of $\\mathcal{D}_X$-cap and the space of bounded outer derivations of $\\mathcal{D}_X(X)$-cap, and between the second Hochschild cohomology group of $\\mathcal{D}_X$-cap and the space of infinitesimal deformations of $\\mathcal{D}_X(X)$-cap.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17167",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:37.665242Z"
  },
  {
    "id": "764fd0bbe9bdf66fec7ad02af94dad8d",
    "title": "Sombor index and eigenvalues of weakly zero-divisor graph of commutative rings",
    "slug": "sombor-index-and-eigenvalues-of-weakly-zero-divisor-graph-of-commutative-rings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Mohd Shariq",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The weakly zero-divisor graph $W\\Gamma(R)$ of a commutative ring $R$ is the simple undirected graph whose vertices are nonzero zero-divisors of $R$ and two distinct vertices $x$, $y$ are adjacent if and only if there exist $w\\in {\\rm ann}(x)$ and $ z\\in {\\rm ann}(y)$ such that $wz =0$. In this paper, we determine the Sombor index for the weakly zero-divisor graph of the integers modulo ring $\\mathbb{Z}_n$. Furthermore, we investigate the Sombor spectrum and establish bounds for the Sombor energy of the weakly zero-divisor graph of $\\mathbb{Z}_n$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17265",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:37.665439Z"
  },
  {
    "id": "97bd0f6d6d641332f1b552ce897a84d6",
    "title": "Minimal Surfaces via Complex Quaternions",
    "slug": "minimal-surfaces-via-complex-quaternions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Complex Variables (math.CV)",
    "author": {
      "name": "Amedeo Altavilla",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Minimal surfaces play a fundamental role in differential geometry, with applications spanning physics, material science, and geometric design. In this paper, we explore a novel quaternionic representation of minimal surfaces, drawing an analogy with the well-established theory of Pythagorean Hodograph (PH) curves. By exploiting the algebraic structure of complex quaternions, we introduce a new approach to generating minimal surfaces via quaternionic transformations. This method extends classical Weierstra-Enneper representations and provides insights into the interplay between quaternionic analysis, PH curves, and minimal surface geometry. Additionally, we discuss the role of the Sylvester equation in this framework and demonstrate practical examples, including the construction of Enneper surface patches. The findings open new avenues in computational geometry and geometric modeling, bridging abstract algebraic structures with practical applications in CAD and computer graphics.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17377",
    "tags": [
      "Complex Variables (math.CV)"
    ],
    "createdAt": "2025-04-25T15:49:37.665635Z"
  },
  {
    "id": "c69618e8cf5e3f9fd1ec8d3b1c80ac27",
    "title": "$(2B, 3A, 5A)$-subalgebras of the Griess algebra with alternating Miyamoto group",
    "slug": "$(2b,-3a,-5a)$-subalgebras-of-the-griess-algebra-with-alternating-miyamoto-group",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Clara Franchi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We use Majorana representations to study the subalgebras of the Griess algebra that have shape $(2B,3A,5A)$ and whose associated Miyamoto groups are isomorphic to $A_n$. We prove that these subalgebras exist only if $n\\in \\{5,6,8\\}$. The case $n=5$ was already treated by Ivanov, Seress, McInroy, and Shpectorov. In case $n=6$ we prove that these algebras are all isomorphic and provide their precise description. In case $n=8$ we prove that these algebras do not arise from standard Majorana representations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17446",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:37.665826Z"
  },
  {
    "id": "53b10b30b3213c5542adcb1a32cbb8bc",
    "title": "Bialgebra theory and $\\mathcal O$-operators of admissible Hom-Poisson algebras",
    "slug": "bialgebra-theory-and-$\\mathcal-o$-operators-of-admissible-hom-poisson-algebras",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Rings and Algebras (math.RA)",
    "author": {
      "name": "Karima Benali",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we present and explore several key concepts within the framework of Hom-Poisson algebras. Specifically, we introduce the notions of admissible Hom-Poisson algebras, along with the related ideas of matched pairs and Manin triples for such algebras. We then define the concept of a purely admissible Hom-Poisson bialgebra, placing particular emphasis on its compatibility with the Manin triple structure associated with a nondegenerate symmetric bilinear form. This compatibility is crucial for understanding the structural interplay between these algebraic objects. Additionally, we investigate the notion of Hom-$ \\mathcal O$-operators acting on admissible Hom-Poisson algebras. We analyze their properties and establish a connection with admissible Hom-pre-Poisson algebras, shedding light on the relationship between these two structures.",
    "pdfUrl": "https://arxiv.org/pdf/2504.03645",
    "tags": [
      "Rings and Algebras (math.RA)"
    ],
    "createdAt": "2025-04-25T15:49:37.666008Z"
  },
  {
    "id": "3a4cc3b1f9b3d81b01d29ce58eb4a9f2",
    "title": "Symmetric semi-invariants for some Inonu-Wigner contractions-II-Case B even",
    "slug": "symmetric-semi-invariants-for-some-inonu-wigner-contractions-ii-case-b-even",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Florence Fauquant-Millet",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider a proper parabolic subalgebra p of a simple Lie algebra g and the Inonu-Wigner contraction of p with respect to its decomposition into its standard Levi factor and its nilpotent radical : this is the Lie algebra which is isomorphic to p as a vector space, but where the nilpotent radical becomes an abelian ideal of this contraction. The study of the algebra of symmetric semi-invariants under the adjoint action associated with such a contraction was initiated in my paper entitled : Symmetric Semi-Invariants for some Inonu-Wigner Contractions-I, published in Transformation Groups, January 2025, wherein a lower bound for the formal character of this algebra was built, when the latter is well defined. Here in this paper we build an upper bound for this formal character, when p is a maximal parabolic subalgebra in a classical simple Lie algebra g in type B, when the Levi subalgebra of p is associated with the set of all simple roots without a simple root of even index with Bourbaki notation (we call this case the even case). We show that both bounds coincide. This provides a Weierstrass section for the algebra of symmetric semi-invariants associated with such a contraction and the polynomiality of such an algebra follows.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17036",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:38.111059Z"
  },
  {
    "id": "363e20f32fd90836acef64b7725d4413",
    "title": "Modular Invariance of Characters for Affine Lie Algebras at Subprincipal Admissible Levels",
    "slug": "modular-invariance-of-characters-for-affine-lie-algebras-at-subprincipal-admissible-levels",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Victor G. Kac",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove that the span of normalized characters of subprincipal admissible modules over an affine Lie algebra of subprincipal admissible level $k$ is $SL_2(\\mathbf{Z})$-invariant and find the explicit modular transformation formula.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17159",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:38.111260Z"
  },
  {
    "id": "9d088ef953d51fa964ac6ab0d5d47ba0",
    "title": "Parametrization of supercuspidal representations of depth zero for some simple adjoint groups",
    "slug": "parametrization-of-supercuspidal-representations-of-depth-zero-for-some-simple-adjoint-groups",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Amoru Fujii",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We construct a surjective map from the set of conjugacy classes of depth-zero cuspidal enhanced L-parameters to that of isomorphism classes of depth-zero supercuspidal representations for simple adjoint groups, and check the bijectivity in various cases. We also prove that the Hiraga--Ichino--Ikeda conjecture on the formal degree of essentially square-integrable irreducible representations holds for this parametrization if it is bijective.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17225",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:38.111451Z"
  },
  {
    "id": "2bef3343311db9fb7e80142e6e23d79e",
    "title": "Stratifying quiver Schur algebras via ersatz parity sheaves",
    "slug": "stratifying-quiver-schur-algebras-via-ersatz-parity-sheaves",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Ruslan Maksimau",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose an extension of the theory of parity sheaves, which allows for non-locally constant sheaves along strata. Our definition is tailored for proving the existence of (proper, quasihereditary, etc) stratifications of $\\mathrm{Ext}$-algebras. We use this to study quiver Schur algebras $A(\\alpha)$ for the cyclic quiver of length $2$. We find a polynomial quasihereditary structure on $A(\\alpha)$ compatible with the categorified PBW basis of McNamara and Kleshchev-Muth, and sharpen their results to arbitrary characteristic. We also prove that semicuspidal algebras of $A(n\\delta)$ are polynomial quasihereditary covers of semicuspidal algebras of the corresponding KLR algebra $R(n\\delta)$, and compute them diagrammatically.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17430",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:38.111645Z"
  },
  {
    "id": "f4b7c071349e5c401ca75670d9f79f26",
    "title": "Lower Bound for Zeros in The Character Table of The Symmetric Group with an n-Core Index",
    "slug": "lower-bound-for-zeros-in-the-character-table-of-the-symmetric-group-with-an-n-core-index",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Jayanta Barman",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "For any two partitions $\\lambda$ and $\\mu$ of a positive integer $N$, let $\\chi_{\\lambda}(\\mu)$ denote the value of the irreducible character of the symmetric group $S_{N}$ associated with $\\lambda$, evaluated at the conjugacy class of elements whose cycle type is determined by $\\mu$. The quantity $Z_{t}(N)$ is defined as $$ Z_{t}(N):= \\#\\{(\\lambda,\\mu): \\chi_{\\lambda}(\\mu) = 0 \\quad \\text{with $\\lambda$ a $t$-core}\\}. $$ We establish the bound $$ \\max\\limits_{1\\leq t \\leq N} Z_{t}(N) \\geq c_{t}(N)p(N-t)\\geq \\frac{2\\pi p(N)^{2}}{1.01e\\sqrt{6N}\\log N} \\biggl(1+O(N^{-\\frac{1}{2}}\\log N)\\biggr), $$ where $p(N)$ denotes the number of partitions of $N$. Also, we give lower bounds for $Z_{t}(N)$ in different ranges of $t$ and obtain a lower bound for the total number of zeros in the character table of $S_N$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17037",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:38.111838Z"
  },
  {
    "id": "a23107e80d01199e56a792eb78373fed",
    "title": "Hochschild (Co)homology of D-modules on rigid analytic spaces II",
    "slug": "hochschild-(co)homology-of-d-modules-on-rigid-analytic-spaces-ii",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Fernando Pea Vzquez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $X$ be a smooth $p$-adic Stein space with free tangent sheaf. We use the notion of Hochschild cohomology for sheaves of Ind-Banach algebras developed in our previous work to study the Hochschild cohomology of the algebra of infinite order differential operators $\\mathcal{D}_X$-cap. In particular, we show that the Hochschild cohomology complex of $\\mathcal{D}_X$-cap is a strict complex of nuclear Frchet spaces which is quasi-isomorphic to the de Rham complex of $X$. We then use this to compare the first Hochschild cohomology group of $\\mathcal{D}_X$-cap with a wide array of Ext functors. Finally, we investigate the relation of the Hochschild cohomology of $\\mathcal{D}_X$-cap with the deformation theory of $\\mathcal{D}_X(X)$-cap. Assuming some finiteness conditions on the de Rham cohomology of $X$, we define explicit isomorphisms between the first Hochschild cohomology group of $\\mathcal{D}_X$-cap and the space of bounded outer derivations of $\\mathcal{D}_X(X)$-cap, and between the second Hochschild cohomology group of $\\mathcal{D}_X$-cap and the space of infinitesimal deformations of $\\mathcal{D}_X(X)$-cap.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17167",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:38.112030Z"
  },
  {
    "id": "da057448299a55c44a433fa825309930",
    "title": "The Fields of Values of the Isaacs' Head Characters",
    "slug": "the-fields-of-values-of-the-isaacs'-head-characters",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Group Theory (math.GR)",
    "author": {
      "name": "Gabriel Navarro",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We determine the fields of values of the Isaacs' head characters of a finite solvable group.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17301",
    "tags": [
      "Group Theory (math.GR)"
    ],
    "createdAt": "2025-04-25T15:49:38.112212Z"
  },
  {
    "id": "459afca5ca8a432ac31945b587c0c128",
    "title": "Quantum Corner VOA and the Super Macdonald Polynomials",
    "slug": "quantum-corner-voa-and-the-super-macdonald-polynomials",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "Panupong Cheewaphutthisakun",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we establish a relation between the quantum corner VOA $q\\widetilde{Y}_{L,0,N}[\\Psi]$, which can be regarded as a generalization of quantum $W_N$ algebra, and Sergeev-Veselov super Macdonald polynomials. We demonstrate precisely that, under a specific map, the correlation functions of the currents of $q\\widetilde{Y}_{L,0,N}[\\Psi]$, coincide with the Sergeev-Veselov super Macdonald polynomials.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17326",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:38.112406Z"
  },
  {
    "id": "56e41438f621dda40edb75368eb04ccb",
    "title": "Free field realization of the quantum toroidal algebra of $\\mathfrak{gl}_1$ with general levels",
    "slug": "free-field-realization-of-the-quantum-toroidal-algebra-of-$\\mathfrak{gl}_1$-with-general-levels",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "High Energy Physics - Theory (hep-th)",
    "author": {
      "name": "Zitao Chen",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We present a unified free field realization of representations for the quantum toroidal algebra of $\\mathfrak{gl}_1$ with arbitrary levels, constructed using six free boson fields. This realization arises from a specialized factorization of the structure function within the defining relations of the quantum toroidal algebra of $\\mathfrak{gl}_1$. Utilizing this free field realization, we further develop intertwining operators for the algebra of $\\mathfrak{gl}_1$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17508",
    "tags": [
      "High Energy Physics - Theory (hep-th)"
    ],
    "createdAt": "2025-04-25T15:49:38.112603Z"
  },
  {
    "id": "1c6e6c388642c2129ca843b31a477159",
    "title": "Two-row Delta Springer varieties",
    "slug": "two-row-delta-springer-varieties",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Abel Lacabanne",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the geometry and topology of $\\Delta$-Springer varieties associated with two-row partitions. These varieties were introduced in recent work by Griffin-Levinson-Woo to give a geometric realization of a symmetric function appearing in the Delta conjecture by Haglund-Remmel-Wilson. We provide an explicit and combinatorial description of the irreducible components of the two-row $\\Delta$-Springer variety and compare it to the ordinary two-row Springer fiber as well as Kato's exotic Springer fiber corresponding to a one-row bipartition. In addition to that, we extend the action of the symmetric group on the homology of the two-row $\\Delta$-Springer variety to an action of a degenerate affine Hecke algebra and relate this action to a $\\mathfrak{gl}_{2}$-tensor space.",
    "pdfUrl": "https://arxiv.org/pdf/2407.10792",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:38.112805Z"
  },
  {
    "id": "c3953d4411aa7423d0f78016365d76e4",
    "title": "Note on Exponents Associated with Y-Systems",
    "slug": "note-on-exponents-associated-with-y-systems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Ryo Takenaka",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $(X_n,\\ell)$ be the pair consisting of the Dynkin diagram of finite type $X_n$ and a positive integer $\\ell\\geq2$, called the level. Then we obtain the Y-system, which is the set of algebraic relations associated with this pair. Related to the Y-system, a sequence of integers called exponents is defined through a quiver derived from the pair $(X_n,\\ell)$. Mizuno provided conjectured formulas for the exponents associated with Y-systems in [Mizuno Y., SIGMA 16 (2020), 028, 42 pages, arXiv:1812.05863]. In this paper, we study the exponents associated with level 2 Y-systems for classical Dynkin types. As a result, we present proofs of Mizuno's conjecture for $(B_n,2)$ and $(D_n,2)$, and give a reformulation for $(C_n,2)$.",
    "pdfUrl": "https://arxiv.org/pdf/2410.02286",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:38.112994Z"
  },
  {
    "id": "ece5b26e4f20b97470857bac34146e6c",
    "title": "Schurification of polynomial quantum wreath products",
    "slug": "schurification-of-polynomial-quantum-wreath-products",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Representation Theory (math.RT)",
    "author": {
      "name": "Chun-Ju Lai",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the Schur algebra counterpart of a vast class of quantum wreath products. This is achieved by developing a theory of twisted convolution algebras, inspired by geometric intuition. In parallel, we provide an algebraic Schurification via a Kashiwara-Miwa-Stern-type action on a tensor space. We give a uniform proof of Schur duality, and construct explicit bases of the new Schur algebras. This provides new results for, among other examples, Vignras' pro-$p$ Iwahori Hecke algebras of type $A$, degenerate affine Hecke algebras, Kleshchev-Muth's affine zigzag algebras, and Rosso-Savage's affine Frobenius Hecke algebras.",
    "pdfUrl": "https://arxiv.org/pdf/2502.02108",
    "tags": [
      "Representation Theory (math.RT)"
    ],
    "createdAt": "2025-04-25T15:49:38.113189Z"
  },
  {
    "id": "e816ab040fb7c957e0c0b14866183f0e",
    "title": "Companion points and locally analytic socle conjecture for Steinberg case",
    "slug": "companion-points-and-locally-analytic-socle-conjecture-for-steinberg-case",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Number Theory (math.NT)",
    "author": {
      "name": "Yiqin He",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we will modify the Breuil-Hellmann-Schraen's (more generally, resp., Breuil-Ding's) local model for the trianguline variety (resp., Bernstein paraboline variety) to certain semistable (resp., potentially semistable) non-crystalline point with regular Hodge-Tate this http URL we deduce several local-global compatibility results, including a classicality result, and the existence of expected companion points on the (definite) eigenvariety and locally analytic socle conjecture for such semistable non-crystalline Galois representations, under certain hypothesis on trianguline variety and the usual Taylor-Wiles assumptions. Moreover, we also discuss slightly the coherent sheaves obtained by patching argument and the coherent sheaves which are constructed from local models and Bezrukavnikov functor, under the route of the recently work of Hellmann-Hernandez-Schraen.",
    "pdfUrl": "https://arxiv.org/pdf/2401.13242",
    "tags": [
      "Number Theory (math.NT)"
    ],
    "createdAt": "2025-04-25T15:49:38.113388Z"
  },
  {
    "id": "98f76051f8cf6d49ea0a4293a6e0078a",
    "title": "Parabolic restrictions and double deformations of weight multiplicities",
    "slug": "parabolic-restrictions-and-double-deformations-of-weight-multiplicities",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Cdric Lecouvey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce some (p,q)-deformations of the weight multiplicities for the representations of any simple Lie algebra g over the complex numbers. This is done by associating the indeterminate q to the positive roots of a parabolic subsystem of g and the indeterminate p to the remaining positive roots. When p=q, we so recover the usual Lusztig analogues of weight multiplicities. We then study the positivity of the coefficients in these double deformations. In particular, the positivity holds when p=1 in which case the polynomials have a natural algebraic interpretation in terms of a parabolic Brylinski filtration. For the parabolic restriction from type C to type A, this positivity result was conjectured by Lee.",
    "pdfUrl": "https://arxiv.org/pdf/2412.10003",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:38.113574Z"
  },
  {
    "id": "60e6b881d7d47f188466ee7d41ad5ac6",
    "title": "Cyclic Sieving of Multisets with Bounded Multiplicity and the Frobenius Coin Problem",
    "slug": "cyclic-sieving-of-multisets-with-bounded-multiplicity-and-the-frobenius-coin-problem",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Drew Armstrong",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The two subjects in the title are related via the specialization of symmetric polynomials at roots of unity. Let $f(z_1,\\ldots,z_n)\\in\\mathbb{Z}[z_1,\\ldots,z_n]$ be a symmetric polynomial with integer coefficients and let $\\omega$ be a primitive $d$th root of unity. If $d|n$ or $d|(n-1)$ then we have $f(1,\\ldots,\\omega^{n-1})\\in\\mathbb{Z}$. If $d|n$ then of course we have $f(\\omega,\\ldots,\\omega^n)=f(1,\\ldots,\\omega^{n-1})\\in\\mathbb{Z}$, but when $d|(n+1)$ we also have $f(\\omega,\\ldots,\\omega^n)\\in\\mathbb{Z}$. We investigate these three families of integers in the case $f=h_k^{(b)}$, where $h_k^{(b)}$ is the coefficient of $t^k$ in the generating function $\\prod_{i=1}^n (1+z_it+\\cdots+(z_it)^{b-1})$. These polynomials were previously considered by several authors. They interpolate between the elementary symmetric polynomials ($b$=2) and the complete homogeneous symmetric polynomials ($b\\to\\infty$). When $\\gcd(b,d)=1$ with $d|n$ or $d|(n-1)$ we find that the integers $h_k^{(b)}=(1,\\omega,\\ldots,\\omega^{n-1})$ are related to cyclic sieving of multisets with multiplicities bounded above by $b$, generalizing the well know cyclic sieving results for sets ($b=2$) and multisets ($b\\to \\infty$). When $\\gcd(b,d)=1$ and $d|(n+1)$ we find that the integers $h_k^{(b)}(\\omega,\\omega^2,\\ldots,\\omega^n)$ are related to the Frobenius coin problem with two coins. The case $\\gcd(b,d)\\neq 1$ is more complicated. At the end of the paper we combine these results with the expansion of $h_k^{(b)}$ in various bases of the ring of symmetric polynomials.",
    "pdfUrl": "https://arxiv.org/pdf/2502.00378",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:38.113764Z"
  },
  {
    "id": "e43be991bf5d519e6767de59207b2ff3",
    "title": "Contact homology of contact manifolds and its applications",
    "slug": "contact-homology-of-contact-manifolds-and-its-applications",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Symplectic Geometry (math.SG)",
    "author": {
      "name": "Frdric Bourgeois",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This is a survey of contact homology and its applications to the study of contact manifolds. It is a small tribute to Yasha Eliashberg's huge generosity with his countless explanations of his deep mathematical insights all along his career. It is also the author's wishful thinking that this text could be useful to students and young mathematicians for learning about some of the holomorphic curves based invariants in contact geometry.",
    "pdfUrl": "https://arxiv.org/pdf/2504.16540",
    "tags": [
      "Symplectic Geometry (math.SG)"
    ],
    "createdAt": "2025-04-25T15:49:38.340339Z"
  },
  {
    "id": "7bcbfdb97c1a726758db25474e4b22cd",
    "title": "Bordism and resolution of singularities",
    "slug": "bordism-and-resolution-of-singularities",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Algebraic Topology (math.AT)",
    "author": {
      "name": "Mohammed Abouzaid",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We adapt algorithms for resolving the singularities of complex algebraic varieties to prove that the natural map of homology theories from complex bordism to the bordism theory of complex derived orbifolds splits. In equivariant stable homotopy theory, our techniques yield a splitting of homology theories for the map from bordism to the equivariant bordism theory of a finite group $\\Gamma$, given by assigning to a manifold its product with $\\Gamma$. In symplectic topology, and using recent work of Abouzaid-McLean-Smith and Hirschi-Swaminathan, we conclude that one can define complex cobordism-valued Gromov-Witten invariant for arbitrary (closed) symplectic manifolds. We apply our results to constrain the topology of the space of Hamiltonian fibrations over $S^2$. The methods we develop apply to normally complex orbifolds, and will hence lead to applications in symplectic topology that rely on moduli spaces of holomorphic curves with Lagrangian boundary conditions.",
    "pdfUrl": "https://arxiv.org/pdf/2412.04451",
    "tags": [
      "Algebraic Topology (math.AT)"
    ],
    "createdAt": "2025-04-25T15:49:38.340544Z"
  },
  {
    "id": "e80463608fa5352a272f234926e51ac8",
    "title": "On estimates for the discrete eigenvalues of two-dimensional quantum waveguides",
    "slug": "on-estimates-for-the-discrete-eigenvalues-of-two-dimensional-quantum-waveguides",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Spectral Theory (math.SP)",
    "author": {
      "name": "Martin Karuhanga",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, we give upper estimates for the number and sum of eigenvalues below the bottom of the essential spectrum counting multiplicities of quantum waveguides in two dimensions. We consider both straight and curved waveguides of constant width, and the estimates are presented in terms of norms of the potential. For curved quantum waveguide, we assume that the waveguide is not self-intersecting and its curvature is a continuous and bounded function on R. The estimates are new, particularly for the case of curved quantum waveguides and this opens a window for their extension to different configurations such as waveguides with local defamations.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17518",
    "tags": [
      "Spectral Theory (math.SP)"
    ],
    "createdAt": "2025-04-25T15:49:38.676270Z"
  },
  {
    "id": "f38a70b695fa49c3618242b08243fbd9",
    "title": "On an infinitesimal Polyakov formula for genus zero polyhedra",
    "slug": "on-an-infinitesimal-polyakov-formula-for-genus-zero-polyhedra",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Spectral Theory (math.SP)",
    "author": {
      "name": "Alexey Kokotov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Let $X$ be a genus zero compact polyhedral surface (the Riemann sphere equipped with a flat conical metric $m$). We derive the variational formulas for the determinant of the Laplacian, ${\\rm det}\\,\\Delta^m$, on $X$ under infinitesimal variations of the positions of the conical points and the conical angles (i. e. infinitesimal variations of $X$ in the class of polyhedra with the same number of vertices). Besides having an independent interest, this derivation may serve as a somewhat belated mathematical counterpart of the well-known heuristic calculation of ${\\rm det}\\,\\Delta^m$ performed by Aurell and Salomonson in the 90-s.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17652",
    "tags": [
      "Spectral Theory (math.SP)"
    ],
    "createdAt": "2025-04-25T15:49:38.676474Z"
  },
  {
    "id": "b1292a6001a27bdb5368c9e845d1f495",
    "title": "Universal Methods for Nonlinear Spectral Problems",
    "slug": "universal-methods-for-nonlinear-spectral-problems",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "Matthew J. Colbrook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Nonlinear spectral problems arise across a range of fields, including mechanical vibrations, fluid-solid interactions, and photonic crystals. Discretizing infinite-dimensional nonlinear spectral problems often introduces significant computational challenges, particularly spectral pollution and invisibility, which can distort or obscure the true underlying spectrum. We present the first general, convergent computational method for computing the spectra and pseudospectra of nonlinear spectral problems. Our approach uses new results on nonlinear injection moduli and requires only minimal continuity assumptions: specifically, continuity with respect to the gap metric on operator graphs, making it applicable to a broad class of problems. We use the Solvability Complexity Index (SCI) hierarchy, which has recently been used to resolve the classical linear problem, to systematically classify the computational complexity of nonlinear spectral problems. Our results establish the optimality of the method and reveal that Hermiticity does not necessarily simplify the computational complexity of these nonlinear problems. Comprehensive examples -- including nonlinear shifts, Klein--Gordon equations, wave equations with acoustic boundary conditions, time-fractional beam equations, and biologically inspired delay differential equations -- demonstrate the robustness, accuracy, and broad applicability of our methodology.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17012",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:38.676671Z"
  },
  {
    "id": "764fd0bbe9bdf66fec7ad02af94dad8d",
    "title": "Sombor index and eigenvalues of weakly zero-divisor graph of commutative rings",
    "slug": "sombor-index-and-eigenvalues-of-weakly-zero-divisor-graph-of-commutative-rings",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Combinatorics (math.CO)",
    "author": {
      "name": "Mohd Shariq",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The weakly zero-divisor graph $W\\Gamma(R)$ of a commutative ring $R$ is the simple undirected graph whose vertices are nonzero zero-divisors of $R$ and two distinct vertices $x$, $y$ are adjacent if and only if there exist $w\\in {\\rm ann}(x)$ and $ z\\in {\\rm ann}(y)$ such that $wz =0$. In this paper, we determine the Sombor index for the weakly zero-divisor graph of the integers modulo ring $\\mathbb{Z}_n$. Furthermore, we investigate the Sombor spectrum and establish bounds for the Sombor energy of the weakly zero-divisor graph of $\\mathbb{Z}_n$.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17265",
    "tags": [
      "Combinatorics (math.CO)"
    ],
    "createdAt": "2025-04-25T15:49:38.676859Z"
  },
  {
    "id": "615ee7d9265dfc0ff580481a92adbae0",
    "title": "A Rellich-type theorem for the Helmholtz equation in a junction of stratified media",
    "slug": "a-rellich-type-theorem-for-the-helmholtz-equation-in-a-junction-of-stratified-media",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Sarah Al Humaikani",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We prove that there are no non-zero square-integrable solutions to a two-dimensional Helmholtz equation in some unbounded inhomogeneous domains which represent junctions of stratified media. More precisely, we consider domains that are unions of three half-planes, where each half-plane is stratified in the direction orthogonal to its boundary. As for the well-known Rellich uniqueness theorem for a homogeneous exterior domain, our result does not require any boundary condition. Our proof is based on half-plane representations of the solution which are derived through a generalization of the Fourier transform adapted to stratified media. A byproduct of our result is the absence of trapped modes at the junction of open waveguides as soon as the angles between branches are greater than $\\pi$/2.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17345",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:38.677060Z"
  },
  {
    "id": "e54ab6402a83ab4e5095e28761eef435",
    "title": "The relativistic rotated harmonic oscillator",
    "slug": "the-relativistic-rotated-harmonic-oscillator",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Spectral Theory (math.SP)",
    "author": {
      "name": "A. Balmaseda",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We introduce a relativistic version of the non-self-adjoint operator obtained by a dilation analytic transformation of the quantum harmonic oscillator. While the spectrum is real and discrete, we show that the eigenfunctions do not form a basis and that the pseudospectra are highly non-trivial.",
    "pdfUrl": "https://arxiv.org/pdf/2411.16494",
    "tags": [
      "Spectral Theory (math.SP)"
    ],
    "createdAt": "2025-04-25T15:49:38.677260Z"
  },
  {
    "id": "fcf5b2cf5743a6699bc9346d4b2a5c01",
    "title": "Analytic Microlocal Bohr-Sommerfeld Expansions",
    "slug": "analytic-microlocal-bohr-sommerfeld-expansions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Spectral Theory (math.SP)",
    "author": {
      "name": "Antide Duraffour",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This article is devoted to Gevrey-analytic estimates in ___, of the Bohr-Sommerfeld expansion of the eigenvalues of self-adjoint pseudo-differential operators acting on L^2(R) in the regular case. We consider an interval of energies in which the spectrum of P is discrete and such that the energy sets are regular connected curves. Under some assumptions on the holomorphy of the symbol p, we will use the isometry between L^2(R) and the Bargmann space to obtain an exponentially sharp description of the spectrum in the energy window . More precisely it is possible to build exponentially sharp WKB quasimodes in the Bargmann space. A precise examination of the principal symbols will provide an interpretation to the Maslov correction $\\pi$___ in the Bargmann space.",
    "pdfUrl": "https://arxiv.org/pdf/2501.06046",
    "tags": [
      "Spectral Theory (math.SP)"
    ],
    "createdAt": "2025-04-25T15:49:38.677442Z"
  },
  {
    "id": "afa3e7c4e2db4e77e05c78be70f89f9b",
    "title": "Pseudorandomness of the Sticky Random Walk",
    "slug": "pseudorandomness-of-the-sticky-random-walk",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Emile Anand",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We extend the pseudorandomness of random walks on expander graphs using the sticky random walk. Building on prior works, it was recently shown that expander random walks can fool all symmetric functions in total variation distance (TVD) upto an $O(\\lambda(\\frac{p}{\\min f})^{O(p)})$ error, where $\\lambda$ is the second largest eigenvalue of the expander, $p$ is the size of the arbitrary alphabet used to label the vertices, and $\\min f = \\min_{b\\in[p]} f_b$, where $f_b$ is the fraction of vertices labeled $b$ in the graph. Golowich and Vadhan conjecture that the dependency on the $(\\frac{p}{\\min f})^{O(p)}$ term is not tight. In this paper, we resolve the conjecture in the affirmative for a family of expanders. We present a generalization of the sticky random walk for which Golowich and Vadhan predict a TVD upper bound of $O(\\lambda p^{O(p)})$ using a Fourier-analytic approach. For this family of graphs, we use a combinatorial approach involving the Krawtchouk functions to derive a strengthened TVD of $O(\\lambda)$. Furthermore, we present equivalencies between the generalized sticky random walk, and, using linear-algebraic techniques, show that the generalized sticky random walk parameterizes an infinite family of expander graphs.",
    "pdfUrl": "https://arxiv.org/pdf/2307.11104",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:38.677634Z"
  },
  {
    "id": "ff607863b83f7bc2d325f54ceaade7c5",
    "title": "Spectral Multipliers II: Elliptic and Parabolic Operators and Bochner-Riesz Means",
    "slug": "spectral-multipliers-ii:-elliptic-and-parabolic-operators-and-bochner-riesz-means",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Analysis of PDEs (math.AP)",
    "author": {
      "name": "Marius Beceanu",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We establish estimates for the Poisson kernel, the heat kernel, and Bochner--Riesz means defined in terms of $H=-\\Delta+V$, where $V$ is a possibly large rough real-valued scalar potential and $H$ can have negative eigenvalues. All results are in three space dimensions.\nWe eliminate several unnecessary conditions on $V$, leaving just $V \\in \\mathcal K_0$, meaning that $V$ is locally integrable and $(-\\Delta)^{-1}|V|$ is bounded.\nFor the spectral multiplier bounds, we assume that $H$ has no zero or positive energy bound states. For $V \\in \\mathcal K_0$, we prove that $H$ has at most a finite number of negative bound states. If in addition $V \\in \\dot W^{-1/4, 4/3}$, then by [GoSc] and [KoTa] there are no positive energy bound states.",
    "pdfUrl": "https://arxiv.org/pdf/2308.09606",
    "tags": [
      "Analysis of PDEs (math.AP)"
    ],
    "createdAt": "2025-04-25T15:49:38.677828Z"
  },
  {
    "id": "722d30dfe9f4c6ce4390e02481b7618c",
    "title": "The Resonance Bias Framework: Resonance, Structure, and Arithmetic in Quadrature Error",
    "slug": "the-resonance-bias-framework:-resonance,-structure,-and-arithmetic-in-quadrature-error",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Numerical Analysis (math.NA)",
    "author": {
      "name": "William Cook",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the trapezoidal rule for periodic functions on uniform grids and show that the quadrature error exhibits a rich deterministic structure, beyond traditional asymptotic or statistical interpretations. Focusing on the prototype function f(x) = sin^2(2 pi k x), we derive an analytical expression for the error governed by a resonance function chi_P(y), closely related to the Dirichlet kernel, roots of unity, and discrete Fourier analysis on the group Z/PZ. This function acts as a spectral filter, connecting the integration error to arithmetic properties such as k/P and geometric phase cancellation, visualized as vector averaging on the unit circle. We introduce the Resonance Bias Framework (RBF), a generalization to arbitrary smooth periodic functions, leading to the error representation B_P[f] = sum_{k != 0} c_k chi_P(k/P). Although this is mathematically equivalent to the classical aliasing sum, it reveals a deeper mechanism: the quadrature error arises from structured resonance rather than random aliasing noise. The RBF thus provides an interpretable framework for understanding integration errors at finite resolution, grounded in number theory and geometry.",
    "pdfUrl": "https://arxiv.org/pdf/2503.12117",
    "tags": [
      "Numerical Analysis (math.NA)"
    ],
    "createdAt": "2025-04-25T15:49:38.678012Z"
  },
  {
    "id": "c5b818d514795cc8215a861563f4dee6",
    "title": "Graph Quasirandomness for Hypothesis Testing of Stochastic Block Models",
    "slug": "graph-quasirandomness-for-hypothesis-testing-of-stochastic-block-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Kiril Bangachev",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The celebrated theorem of Chung, Graham, and Wilson on quasirandom graphs implies that if the 4-cycle and edge counts in a graph $G$ are both close to their typical number in $\\mathbb{G}(n,1/2),$ then this also holds for the counts of subgraphs isomorphic to $H$ for any $H$ of constant size. We aim to prove a similar statement where the notion of close is whether the given (signed) subgraph count can be used as a test between $\\mathbb{G}(n,1/2)$ and a stochastic block model $\\mathbb{SBM}.$\nQuantitatively, this is related to approximately maximizing $H \\longrightarrow |\\Phi(H)|^{\\frac{1}{|\\mathsf{V}(H)|}},$ where $\\Phi(H)$ is the Fourier coefficient of $\\mathbb{SBM}$, indexed by subgraph $H.$ This formulation turns out to be equivalent to approximately maximizing the partition function of a spin model over alphabet equal to the community labels in $\\mathbb{SBM}.$\nWe resolve the approximate maximization when $\\mathbb{SBM}$ satisfies one of four conditions: 1) the probability of an edge between any two vertices in different communities is exactly $1/2$; 2) the probability of an edge between two vertices from any two communities is at least $1/2$ (this case is also covered in a recent work of Yu, Zadik, and Zhang); 3) the probability of belonging to any given community is at least $c$ for some universal constant $c>0$; 4) $\\mathbb{SBM}$ has two communities. In each of these cases, we show that there is an approximate maximizer of $|\\Phi(H)|^{\\frac{1}{|\\mathsf{V}(H)|}}$ in the set $\\mathsf{A} = \\{\\text{stars, 4-cycle}\\}.$ This implies that if there exists a constant-degree polynomial test distinguishing $\\mathbb{G}(n,1/2)$ and $\\mathbb{SBM},$ then the two distributions can also be distinguished via the signed count of some graph in $\\mathsf{A}.$ We conjecture that the same holds true for distinguishing $\\mathbb{G}(n,1/2)$ and any graphon if we also add triangles to $\\mathsf{A}.$",
    "pdfUrl": "https://arxiv.org/pdf/2504.17202",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.091592Z"
  },
  {
    "id": "667bd51b544b129148dd41145cee35b3",
    "title": "Functional $K$ Sample Problem via Multivariate Optimal Measure Transport-Based Permutation Test",
    "slug": "functional-$k$-sample-problem-via-multivariate-optimal-measure-transport-based-permutation-test",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "rka Hudecov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The null hypothesis of equality of distributions of functional data coming from $K$ samples is considered. The proposed test statistic is multivariate and its components are based on pairwise Cramr von Mises comparisons of empirical characteristic functionals. The significance of the test statistic is evaluated via the novel multivariate permutation test, where the final single $p$-value is computed using the discrete optimal measure transport. The methodology is illustrated by real data on cumulative intraday returns of Bitcoin.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17451",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.091813Z"
  },
  {
    "id": "15c26f50dbe477f52bf693ec708dad67",
    "title": "Concentration inequalities and cut-off phenomena for penalized model selection within a basic Rademacher framework",
    "slug": "concentration-inequalities-and-cut-off-phenomena-for-penalized-model-selection-within-a-basic-rademacher-framework",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Pascal Massart",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This article exists first and foremost to contribute to a tribute to Patrick Cattiaux. One of the two authors has known Patrick Cattiaux for a very long time, and owes him a great deal. If we are to illustrate the adage that life is made up of chance, then what could be better than the meeting of two young people in the 80s, both of whom fell in love with the mathematics of randomness, and one of whom changed the other's life by letting him in on a secret: if you really believe in it, you can turn this passion into a profession. By another happy coincidence, this tribute comes at just the right time, as Michel Talagrand has been awarded the Abel prize. The temptation was therefore great to do a double. Following one of the many galleries opened up by mathematics, we shall first draw a link between the mathematics of Patrick Cattiaux and that of Michel Talagrand. Then we shall show how the abstract probabilistic material on the concentration of product measures thus revisited can be used to shed light on cut-off phenomena in our field of expertise, mathematical statistics. Nothing revolutionary here, as everyone knows the impact that Talagrand's work has had on the development of mathematical statistics since the late 90s, but we've chosen a very simple framework in which everything can be explained with minimal technicality, leaving the main ideas to the fore.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17559",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.092013Z"
  },
  {
    "id": "7970fee795cf26403f91d7b8468319ee",
    "title": "Some Results on Generalized Familywise Error Rate Controlling Procedures under Dependence",
    "slug": "some-results-on-generalized-familywise-error-rate-controlling-procedures-under-dependence",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Monitirtha Dey",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The topic of multiple hypotheses testing now has a potpourri of novel theories and ubiquitous applications in diverse scientific fields. However, the universal utility of this field often hinders the possibility of having a generalized theory that accommodates every scenario. This tradeoff is better reflected through the lens of dependence, a central piece behind the theoretical and applied developments of multiple testing. Although omnipresent in many scientific avenues, the nature and extent of dependence vary substantially with the context and complexity of the particular scenario. Positive dependence is the norm in testing many treatments versus a single control or in spatial statistics. On the contrary, negative dependence arises naturally in tests based on split samples and in cyclical, ordered comparisons. In GWAS, the SNP markers are generally considered to be weakly dependent. Generalized familywise error rate (k-FWER) control has been one of the prominent frequentist approaches in simultaneous inference. However, the performances of k-FWER controlling procedures are yet unexplored under different dependencies. This paper revisits the classical testing problem of normal means in different correlated frameworks. We establish upper bounds on the generalized familywise error rates under each dependence, consequently giving rise to improved testing procedures. Towards this, we present improved probability inequalities, which are of independent theoretical interest",
    "pdfUrl": "https://arxiv.org/pdf/2504.17611",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.092208Z"
  },
  {
    "id": "ff63d15f2d54f0c03143bcfe3b4c3557",
    "title": "Relationship between Hlder Divergence and Functional Density Power Divergence: Intersection and Generalization",
    "slug": "relationship-between-hlder-divergence-and-functional-density-power-divergence:-intersection-and-generalization",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Masahiro Kobayashi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this study, we discuss the relationship between two families of density-power-based divergences with functional degrees of freedom -- the Hlder divergence and the functional density power divergence (FDPD) -- based on their intersection and generalization. These divergence families include the density power divergence and the $\\gamma$-divergence as special cases. First, we prove that the intersection of the Hlder divergence and the FDPD is limited to a general divergence family introduced by Jones et al. (Biometrika, 2001). Subsequently, motivated by the fact that Hlder's inequality is used in the proofs of nonnegativity for both the Hlder divergence and the FDPD, we define a generalized divergence family, referred to as the $\\xi$-Hlder divergence. The nonnegativity of the $\\xi$-Hlder divergence is established through a combination of the inequalities used to prove the nonnegativity of the Hlder divergence and the FDPD. Furthermore, we derive an inequality between the composite scoring rules corresponding to different FDPDs based on the $\\xi$-Hlder divergence. Finally, we prove that imposing the mathematical structure of the Hlder score on a composite scoring rule results in the $\\xi$-Hlder divergence.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17008",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:39.092405Z"
  },
  {
    "id": "fc8e83fec66328cdef431d51ec318e9b",
    "title": "Estimation and Inference for the Average Treatment Effect in a Score-Explained Heterogeneous Treatment Effect Model",
    "slug": "estimation-and-inference-for-the-average-treatment-effect-in-a-score-explained-heterogeneous-treatment-effect-model",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Methodology (stat.ME)",
    "author": {
      "name": "Kevin Christian Wibisono",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In many practical situations, randomly assigning treatments to subjects is uncommon due to feasibility constraints. For example, economic aid programs and merit-based scholarships are often restricted to those meeting specific income or exam score thresholds. In these scenarios, traditional approaches to estimating treatment effects typically focus solely on observations near the cutoff point, thereby excluding a significant portion of the sample and potentially leading to information loss. Moreover, these methods generally achieve a non-parametric convergence rate. While some approaches, e.g., Mukherjee et al. (2021), attempt to tackle these issues, they commonly assume that treatment effects are constant across individuals, an assumption that is often unrealistic in practice. In this study, we propose a differencing and matching-based estimator of the average treatment effect on the treated (ATT) in the presence of heterogeneous treatment effects, utilizing all available observations. We establish the asymptotic normality of our estimator and illustrate its effectiveness through various synthetic and real data analyses. Additionally, we demonstrate that our method yields non-parametric estimates of the conditional average treatment effect (CATE) and individual treatment effect (ITE) as a byproduct.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17126",
    "tags": [
      "Methodology (stat.ME)"
    ],
    "createdAt": "2025-04-25T15:49:39.092612Z"
  },
  {
    "id": "0c095f3be60524a3c6d8e8fd7426e60b",
    "title": "Asymptotics of Yule's nonsense correlation for Ornstein-Uhlenbeck paths: The correlated case",
    "slug": "asymptotics-of-yule's-nonsense-correlation-for-ornstein-uhlenbeck-paths:-the-correlated-case",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Probability (math.PR)",
    "author": {
      "name": "Soukaina Douissi",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the continuous-time version of the empirical correlation coefficient between the paths of two possibly correlated Ornstein-Uhlenbeck processes, known as Yule's nonsense correlation for these paths. Using sharp tools from the analysis on Wiener chaos, we establish the asymptotic normality of the fluctuations of this correlation coefficient around its long-time limit, which is the mathematical correlation coefficient between the two processes. This asymptotic normality is quantified in Kolmogorov distance, which allows us to establish speeds of convergence in the Type-II error for two simple tests of independence of the paths, based on the empirical correlation, and based on its numerator. An application to independence of two observations of solutions to the stochastic heat equation is given, with excellent asymptotic power properties using merely a small number of the solutions' Fourier modes.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17175",
    "tags": [
      "Probability (math.PR)"
    ],
    "createdAt": "2025-04-25T15:49:39.092808Z"
  },
  {
    "id": "6ba5e6b1adc5410bf58bf806e4186a15",
    "title": "Signal Recovery from Random Dot-Product Graphs Under Local Differential Privacy",
    "slug": "signal-recovery-from-random-dot-product-graphs-under-local-differential-privacy",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (cs.LG)",
    "author": {
      "name": "Siddharth Vishwanath",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We consider the problem of recovering latent information from graphs under $\\varepsilon$-edge local differential privacy where the presence of relationships/edges between two users/vertices remains confidential, even from the data curator. For the class of generalized random dot-product graphs, we show that a standard local differential privacy mechanism induces a specific geometric distortion in the latent positions. Leveraging this insight, we show that consistent recovery of the latent positions is achievable by appropriately adjusting the statistical inference procedure for the privatized graph. Furthermore, we prove that our procedure is nearly minimax-optimal under local edge differential privacy constraints. Lastly, we show that this framework allows for consistent recovery of geometric and topological information underlying the latent positions, as encoded in their persistence diagrams. Our results extend previous work from the private community detection literature to a substantially richer class of models and inferential tasks.",
    "pdfUrl": "https://arxiv.org/pdf/2504.17274",
    "tags": [
      "Machine Learning (cs.LG)"
    ],
    "createdAt": "2025-04-25T15:49:39.093001Z"
  },
  {
    "id": "e382f8de2e18dea0b25dd4772db1dbc8",
    "title": "Linear Functions to the Extended Reals",
    "slug": "linear-functions-to-the-extended-reals",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Bo Waggoner",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "This paper investigates functions from $\\mathbb{R}^d$ to $\\mathbb{R} \\cup \\{\\pm \\infty\\}$ that satisfy axioms of linearity wherever allowed by extended-value arithmetic. They have a nontrivial structure defined inductively on $d$, and unlike finite linear functions, they require $\\Omega(d^2)$ parameters to uniquely identify. In particular they can capture vertical tangent planes to epigraphs: a function (never $-\\infty$) is convex if and only if it has an extended-valued subgradient at every point in its effective domain, if and only if it is the supremum of a family of \"affine extended\" functions. These results are applied to the well-known characterization of proper scoring rules, for the finite-dimensional case: it is carefully and rigorously extended here to a more constructive form. In particular it is investigated when proper scoring rules can be constructed from a given convex function.",
    "pdfUrl": "https://arxiv.org/pdf/2102.09552",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.093194Z"
  },
  {
    "id": "4e9a98471610940a72f019640774488f",
    "title": "Survival Analysis with Graph-Based Regularization for Predictors",
    "slug": "survival-analysis-with-graph-based-regularization-for-predictors",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Liyan Xie",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We study the variable selection problem in survival analysis to identify the most important factors affecting survival time. Our method incorporates prior knowledge of mutual correlations among variables, represented through a graph. We utilize the Cox proportional hazard model with a graph-based regularizer for variable selection. We present a computationally efficient algorithm developed to solve the graph regularized maximum likelihood problem by establishing connections with the group lasso, and provide theoretical guarantees about the recovery error and asymptotic distribution of the proposed estimators. The improved performance of the proposed approach compared with existing methods are demonstrated in both synthetic and real organ transplantation datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2108.12827",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.093389Z"
  },
  {
    "id": "4efc1e5e0bd83759c16db58593e42128",
    "title": "Bayesian Mixtures Models with Repulsive and Attractive Atoms",
    "slug": "bayesian-mixtures-models-with-repulsive-and-attractive-atoms",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Mario Beraha",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "The study of almost surely discrete random probability measures is an active line of research in Bayesian nonparametrics. The idea of assuming interaction across the atoms of the random probability measure has recently spurred significant interest in the context of Bayesian mixture models. This allows the definition of priors that encourage well-separated and interpretable clusters. In this work, we provide a unified framework for the construction and the Bayesian analysis of random probability measures with interacting atoms, encompassing both repulsive and attractive behaviours. Specifically, we derive closed-form expressions for the posterior distribution, the marginal and predictive distributions, which were not previously available except for the case of measures with i.i.d. atoms. We show how these quantities are fundamental both for prior elicitation and to develop new posterior simulation algorithms for hierarchical mixture models. Our results are obtained without any assumption on the finite point process that governs the atoms of the random measure. Their proofs rely on analytical tools borrowed from the Palm calculus theory, which might be of independent interest. We specialise our treatment to the classes of Poisson, Gibbs, and determinantal point processes, as well as in the case of shot-noise Cox processes. Finally, we illustrate the performance of different modelling strategies on simulated and real datasets.",
    "pdfUrl": "https://arxiv.org/pdf/2302.09034",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.093588Z"
  },
  {
    "id": "b3d0697c08dedef2ff4d3150dff42d26",
    "title": "An Optimal Design Framework for Lasso Sign Recovery",
    "slug": "an-optimal-design-framework-for-lasso-sign-recovery",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Jonathan W. Stallrich",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Supersaturated designs investigate more factors than there are runs, and are often constructed under a criterion measuring a design's proximity to an unattainable orthogonal design. The most popular analysis identifies active factors by inspecting the solution path of a penalized estimator, such as the lasso. Recent criteria encouraging positive correlations between factors have been shown to produce designs with more definitive solution paths so long as the active factors have positive effects. Two open problems affecting the understanding and practicality of supersaturated designs are: (1) do optimal designs under existing criteria maximize support recovery probability across an estimator's solution path, and (2) why do designs with positively correlated columns produce more definitive solution paths when the active factors have positive sign effects? To answer these questions, we develop criteria maximizing the lasso's sign recovery probability. We prove that an orthogonal design is an ideal structure when the signs of the active factors are unknown, and a design constant small, positive correlations is ideal when the signs are assumed known. A computationally-efficient design search algorithm is proposed that first filters through optimal designs under new heuristic criteria to select the one that maximizes the lasso sign recovery probability.",
    "pdfUrl": "https://arxiv.org/pdf/2303.16843",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.093793Z"
  },
  {
    "id": "1e6c9585cc36ab71e15e7e7f69be8492",
    "title": "Precise Error Rates for Computationally Efficient Testing",
    "slug": "precise-error-rates-for-computationally-efficient-testing",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Ankur Moitra",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We revisit the fundamental question of simple-versus-simple hypothesis testing with an eye towards computational complexity, as the statistically optimal likelihood ratio test is often computationally intractable in high-dimensional settings. In the classical spiked Wigner model with a general i.i.d. spike prior we show (conditional on a conjecture) that an existing test based on linear spectral statistics achieves the best possible tradeoff curve between type I and type II error rates among all computationally efficient tests, even though there are exponential-time tests that do better. This result is conditional on an appropriate complexity-theoretic conjecture, namely a natural strengthening of the well-established low-degree conjecture. Our result shows that the spectrum is a sufficient statistic for computationally bounded tests (but not for all tests).\nTo our knowledge, our approach gives the first tool for reasoning about the precise asymptotic testing error achievable with efficient computation. The main ingredients required for our hardness result are a sharp bound on the norm of the low-degree likelihood ratio along with (counterintuitively) a positive result on achievability of testing. This strategy appears to be new even in the setting of unbounded computation, in which case it gives an alternate way to analyze the fundamental statistical limits of testing.",
    "pdfUrl": "https://arxiv.org/pdf/2311.00289",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.093993Z"
  },
  {
    "id": "1bb5390bfc998b435aeac67dab537d89",
    "title": "Minimax Sequential Testing for Poisson Processes",
    "slug": "minimax-sequential-testing-for-poisson-processes",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Hongwei Mei",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Suppose we observe a Poisson process in real time for which the intensity may take on two possible values $\\lambda_0$ and $\\lambda_1$. Suppose further that the priori probability of the true intensity is not given. We solve a minimax version of Bayesian problem of sequential testing of two simple hypotheses to minimize a linear combination of the probability of wrong detection and the expected waiting time in the worst scenario of all possible priori distributions. An equivalent characterization for the least favorable distributions is derived and a sufficient condition for the existence is concluded.",
    "pdfUrl": "https://arxiv.org/pdf/2311.04084",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.094183Z"
  },
  {
    "id": "87b46133df4b70e95e958c11082d5fe7",
    "title": "A sliced Wasserstein and diffusion approach to random coefficient models",
    "slug": "a-sliced-wasserstein-and-diffusion-approach-to-random-coefficient-models",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Keunwoo Lim",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "We propose a new minimum-distance estimator for linear random coefficient models. This estimator integrates the recently advanced sliced Wasserstein distance with the nearest neighbor methods, both of which enhance computational efficiency. We demonstrate that the proposed method is consistent in approximating the true distribution. Moreover, our formulation naturally leads to a diffusion process-based algorithm and is closely connected to treatment effect distribution estimation -- both of which are of independent interest and hold promise for broader applications.",
    "pdfUrl": "https://arxiv.org/pdf/2502.04654",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.094382Z"
  },
  {
    "id": "2afd5d1f0b04c7df2c90fc42bab3bde0",
    "title": "Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation",
    "slug": "attainability-of-two-point-testing-rates-for-finite-sample-location-estimation",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Spencer Compton",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "LeCam's two-point testing method yields perhaps the simplest lower bound for estimating the mean of a distribution: roughly, if it is impossible to well-distinguish a distribution centered at $\\mu$ from the same distribution centered at $\\mu+\\Delta$, then it is impossible to estimate the mean by better than $\\Delta/2$. It is setting-dependent whether or not a nearly matching upper bound is attainable. We study the conditions under which the two-point testing lower bound can be attained for univariate mean estimation; both in the setting of location estimation (where the distribution is known up to translation) and adaptive location estimation (unknown distribution). Roughly, we will say an estimate nearly attains the two-point testing lower bound if it incurs error that is at most polylogarithmically larger than the Hellinger modulus of continuity for $\\tilde{\\Omega}(n)$ samples.\nAdaptive location estimation is particularly interesting as some distributions admit much better guarantees than sub-Gaussian rates (e.g. $\\operatorname{Unif}(\\mu-1,\\mu+1)$ permits error $\\Theta(\\frac{1}{n})$, while the sub-Gaussian rate is $\\Theta(\\frac{1}{\\sqrt{n}})$), yet it is not obvious whether these rates may be adaptively attained by one unified approach. Our main result designs an algorithm that nearly attains the two-point testing rate for mixtures of symmetric, log-concave distributions with a common mean. Moreover, this algorithm runs in near-linear time and is parameter-free. In contrast, we show the two-point testing rate is not nearly attainable even for symmetric, unimodal distributions.\nWe complement this with results for location estimation, showing the two-point testing rate is nearly attainable for unimodal distributions, but unattainable for symmetric distributions.",
    "pdfUrl": "https://arxiv.org/pdf/2502.05730",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.094573Z"
  },
  {
    "id": "4e81ca165413bac888dd84000d1b5fe5",
    "title": "Nonparametric Estimation in Uniform Deconvolution and Interval Censoring",
    "slug": "nonparametric-estimation-in-uniform-deconvolution-and-interval-censoring",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Statistics Theory (math.ST)",
    "author": {
      "name": "Piet Groeneboom",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In the uniform deconvolution problem one is interested in estimating the distribution function $F_0$ of a nonnegative random variable, based on a sample with additive uniform noise. A peculiar and not well understood phenomenon of the nonparametric maximum likelihood estimator in this setting is the dichotomy between the situations where $F_0(1)=1$ and $F_0(1)<1$. If $F_0(1)=1$, the MLE can be computed in a straightforward way and its asymptotic pointwise behavior can be derived using the connection to the so-called current status problem. However, if $F_0(1)<1$, one needs an iterative procedure to compute it and the asymptotic pointwise behavior of the nonparametric maximum likelihood estimator is not known. In this paper we describe the problem, connect it to interval censoring problems and a more general model studied in Groeneboom (2024) to state two competing naturally occurring conjectures for the case $F_0(1)<1$. Asymptotic arguments related to smooth functional theory and extensive simulations lead us to to bet on one of these two conjectures.",
    "pdfUrl": "https://arxiv.org/pdf/2504.14555",
    "tags": [
      "Statistics Theory (math.ST)"
    ],
    "createdAt": "2025-04-25T15:49:39.094768Z"
  },
  {
    "id": "2a92504d7bd7a9c1a6c52fb6c3095ed4",
    "title": "Convergence of Diffusion Models Under the Manifold Hypothesis in High-Dimensions",
    "slug": "convergence-of-diffusion-models-under-the-manifold-hypothesis-in-high-dimensions",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Iskander Azangulov",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Denoising Diffusion Probabilistic Models (DDPM) are powerful state-of-the-art methods used to generate synthetic data from high-dimensional data distributions and are widely used for image, audio, and video generation as well as many more applications in science and beyond. The \\textit{manifold hypothesis} states that high-dimensional data often lie on lower-dimensional manifolds within the ambient space, and is widely believed to hold in provided examples. While recent results have provided invaluable insight into how diffusion models adapt to the manifold hypothesis, they do not capture the great empirical success of these models, making this a very fruitful research direction.\nIn this work, we study DDPMs under the manifold hypothesis and prove that they achieve rates independent of the ambient dimension in terms of score learning. In terms of sampling complexity, we obtain rates independent of the ambient dimension w.r.t. the Kullback-Leibler divergence, and $O(\\sqrt{D})$ w.r.t. the Wasserstein distance. We do this by developing a new framework connecting diffusion models to the well-studied theory of extrema of Gaussian Processes.",
    "pdfUrl": "https://arxiv.org/pdf/2409.18804",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:39.094962Z"
  },
  {
    "id": "c3b6637c4e41139628922c27607bcd28",
    "title": "Linear Convergence of Diffusion Models Under the Manifold Hypothesis",
    "slug": "linear-convergence-of-diffusion-models-under-the-manifold-hypothesis",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Machine Learning (stat.ML)",
    "author": {
      "name": "Peter Potaptchik",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "Score-matching generative models have proven successful at sampling from complex high-dimensional data distributions. In many applications, this distribution is believed to concentrate on a much lower $d$-dimensional manifold embedded into $D$-dimensional space; this is known as the manifold hypothesis. The current best-known convergence guarantees are either linear in $D$ or polynomial (superlinear) in $d$. The latter exploits a novel integration scheme for the backward SDE. We take the best of both worlds and show that the number of steps diffusion models require in order to converge in Kullback-Leibler~(KL) divergence is linear (up to logarithmic terms) in the intrinsic dimension $d$. Moreover, we show that this linear dependency is sharp.",
    "pdfUrl": "https://arxiv.org/pdf/2410.09046",
    "tags": [
      "Machine Learning (stat.ML)"
    ],
    "createdAt": "2025-04-25T15:49:39.095155Z"
  },
  {
    "id": "ab0bc8aacfcd4f0282d95a1723a92046",
    "title": "Proofs for Folklore Theorems on the Radon-Nikodym Derivative",
    "slug": "proofs-for-folklore-theorems-on-the-radon-nikodym-derivative",
    "coverImageUrl": "https://placehold.co/600x300",
    "category": "Information Theory (cs.IT)",
    "author": {
      "name": "Yaiza Bermudez",
      "avatarUrl": "https://placehold.co/64"
    },
    "summary": "In this paper, rigorous statements and formal proofs are presented for both foundational and advanced folklore theorems on the Radon-Nikodym derivative. The cases of conditional and marginal probability measures are carefully considered, which leads to an identity involving the sum of mutual and lautum information suggesting a new interpretation for such a sum.",
    "pdfUrl": "https://arxiv.org/pdf/2501.18374",
    "tags": [
      "Information Theory (cs.IT)"
    ],
    "createdAt": "2025-04-25T15:49:39.095360Z"
  }
]